{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\AJIT\\\\Desktop\\\\Data science\\\\Deep Learning\\\\Code\\\\NSL-KDD\\\\KDDTrain.csv\")\n",
    "df_test = pd.read_csv(\"C:\\\\Users\\\\AJIT\\\\Desktop\\\\Data science\\\\Deep Learning\\\\Code\\\\NSL-KDD\\\\KDDTest.csv\")\n",
    "df_test21 = pd.read_csv(\"C:\\\\Users\\\\AJIT\\\\Desktop\\\\Data science\\\\Deep Learning\\\\Code\\\\NSL-KDD\\\\KDDTest-21.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp  ftp_data   SF        491          0     0   \n",
       "1         0           udp     other   SF        146          0     0   \n",
       "2         0           tcp   private   S0          0          0     0   \n",
       "3         0           tcp      http   SF        232       8153     0   \n",
       "4         0           tcp      http   SF        199        420     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
       "0               0       0    0  ...                  25   \n",
       "1               0       0    0  ...                   1   \n",
       "2               0       0    0  ...                  26   \n",
       "3               0       0    0  ...                 255   \n",
       "4               0       0    0  ...                 255   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                    0.17                    0.03   \n",
       "1                    0.00                    0.60   \n",
       "2                    0.10                    0.05   \n",
       "3                    1.00                    0.00   \n",
       "4                    1.00                    0.00   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.17                         0.00   \n",
       "1                         0.88                         0.00   \n",
       "2                         0.00                         0.00   \n",
       "3                         0.03                         0.04   \n",
       "4                         0.00                         0.00   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                  0.00                      0.00                  0.05   \n",
       "1                  0.00                      0.00                  0.00   \n",
       "2                  1.00                      1.00                  0.00   \n",
       "3                  0.03                      0.01                  0.00   \n",
       "4                  0.00                      0.00                  0.00   \n",
       "\n",
       "   dst_host_srv_rerror_rate    class  \n",
       "0                      0.00   normal  \n",
       "1                      0.00   normal  \n",
       "2                      0.00  anomaly  \n",
       "3                      0.01   normal  \n",
       "4                      0.00   normal  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Type']='Train'\n",
    "df_test['Type']='Test'\n",
    "df_test21['Type']='Test21'\n",
    "data= pd.concat([df,df_test,df_test21],axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>class</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>anomaly</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>normal</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp  ftp_data   SF        491          0     0   \n",
       "1         0           udp     other   SF        146          0     0   \n",
       "2         0           tcp   private   S0          0          0     0   \n",
       "3         0           tcp      http   SF        232       8153     0   \n",
       "4         0           tcp      http   SF        199        420     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_same_srv_rate  \\\n",
       "0               0       0    0  ...                    0.17   \n",
       "1               0       0    0  ...                    0.00   \n",
       "2               0       0    0  ...                    0.10   \n",
       "3               0       0    0  ...                    1.00   \n",
       "4               0       0    0  ...                    1.00   \n",
       "\n",
       "   dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0                    0.03                         0.17   \n",
       "1                    0.60                         0.88   \n",
       "2                    0.05                         0.00   \n",
       "3                    0.00                         0.03   \n",
       "4                    0.00                         0.00   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                         0.00                  0.00   \n",
       "1                         0.00                  0.00   \n",
       "2                         0.00                  1.00   \n",
       "3                         0.04                  0.03   \n",
       "4                         0.00                  0.00   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \\\n",
       "0                      0.00                  0.05                      0.00   \n",
       "1                      0.00                  0.00                      0.00   \n",
       "2                      1.00                  0.00                      0.00   \n",
       "3                      0.01                  0.00                      0.01   \n",
       "4                      0.00                  0.00                      0.00   \n",
       "\n",
       "     class   Type  \n",
       "0   normal  Train  \n",
       "1   normal  Train  \n",
       "2  anomaly  Train  \n",
       "3   normal  Train  \n",
       "4   normal  Train  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = [\"class\"]\n",
    "cat_cols = [\"protocol_type\",\"service\",\"flag\"]\n",
    "other_col=['Type','num_outbound_cmds'] #Test and Train Data set identifier\n",
    "num_cols= list(set(list(df.columns))-set(cat_cols)-set(target_col)-set(other_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "data[\"protocol_type\"] = labelencoder.fit_transform(data[\"protocol_type\"])\n",
    "data[\"service\"] = labelencoder.fit_transform(data[\"service\"])\n",
    "data[\"flag\"] = labelencoder.fit_transform(data[\"flag\"])\n",
    "data[\"class\"] = labelencoder.fit_transform(data[\"class\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Hot-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([data,pd.get_dummies(data[\"protocol_type\"],prefix=\"protocol_type\")],axis=1).drop([\"protocol_type\"],axis=1)\n",
    "data=pd.concat([data,pd.get_dummies(data[\"service\"],prefix=\"service\")],axis=1).drop([\"service\"],axis=1)\n",
    "data=pd.concat([data,pd.get_dummies(data[\"flag\"],prefix=\"flag\")],axis=1).drop([\"flag\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=data[data['Type']=='Train']\n",
    "test=data[data['Type']=='Test']\n",
    "test21=data[data['Type']=='Test21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>flag_1</th>\n",
       "      <th>flag_2</th>\n",
       "      <th>flag_3</th>\n",
       "      <th>flag_4</th>\n",
       "      <th>flag_5</th>\n",
       "      <th>flag_6</th>\n",
       "      <th>flag_7</th>\n",
       "      <th>flag_8</th>\n",
       "      <th>flag_9</th>\n",
       "      <th>flag_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
       "0         0        491          0     0               0       0    0   \n",
       "1         0        146          0     0               0       0    0   \n",
       "2         0          0          0     0               0       0    0   \n",
       "3         0        232       8153     0               0       0    0   \n",
       "4         0        199        420     0               0       0    0   \n",
       "\n",
       "   num_failed_logins  logged_in  num_compromised  ...  flag_1  flag_2  flag_3  \\\n",
       "0                  0          0                0  ...       0       0       0   \n",
       "1                  0          0                0  ...       0       0       0   \n",
       "2                  0          0                0  ...       0       0       0   \n",
       "3                  0          1                0  ...       0       0       0   \n",
       "4                  0          1                0  ...       0       0       0   \n",
       "\n",
       "   flag_4  flag_5  flag_6  flag_7  flag_8  flag_9  flag_10  \n",
       "0       0       0       0       0       0       1        0  \n",
       "1       0       0       0       0       0       1        0  \n",
       "2       0       1       0       0       0       0        0  \n",
       "3       0       0       0       0       0       1        0  \n",
       "4       0       0       0       0       0       1        0  \n",
       "\n",
       "[5 rows x 124 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8e17ffd7ce04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features & Target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cols = set(train.columns)\n",
    "my_cols.remove('class')\n",
    "my_cols.remove('Type')\n",
    "my_cols = list(my_cols)\n",
    "X_train = train[my_cols]\n",
    "y_train=train[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cols = set(test.columns)\n",
    "my_cols.remove('class')\n",
    "my_cols.remove('Type')\n",
    "my_cols = list(my_cols)\n",
    "X_test = test[my_cols]\n",
    "y_test=test[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cols = set(test21.columns)\n",
    "my_cols.remove('class')\n",
    "my_cols.remove('Type')\n",
    "my_cols = list(my_cols)\n",
    "X_test21 = test21[my_cols]\n",
    "y_test21=test21[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 122)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \"\"\"\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_test21 = scaler.transform(X_test21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(.80)  \n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "X_test21 = pca.transform(X_test21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 122)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://chrisalbon.com/machine_learning/feature_selection/recursive_feature_elimination/\n",
    "#https://www.scikit-yb.org/en/latest/api/features/rfecv.html\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "rfecv = RFECV(estimator=model,scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RFECV(cv='warn',\n",
       "   estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False),\n",
       "   min_features_to_select=1, n_jobs=None, scoring='accuracy', step=1,\n",
       "   verbose=0)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=rfecv.transform(X_train)\n",
    "X_test=rfecv.transform(X_test)\n",
    "X_test21=rfecv.transform(X_test21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 56)"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array([False, False,  True, False, False, False,  True, False, False,\n",
    "       False, False, False, False,  True, False,  True, False, False,\n",
    "       False,  True, False,  True, False,  True, False,  True, False,\n",
    "       False, False, False,  True, False, False, False, False, False,\n",
    "       False,  True,  True, False,  True, False, False, False, False,\n",
    "       False, False, False,  True,  True, False, False, False, False,\n",
    "       False,  True, False, False, False,  True, False, False, False,\n",
    "        True,  True,  True, False, False, False, False, False, False,\n",
    "       False, False,  True, False,  True,  True,  True, False, False,\n",
    "        True, False, False, False, False, False, False, False, False,\n",
    "       False, False, False,  True, False, False, False, False, False,\n",
    "       False, False,  True, False, False,  True,  True, False,  True,\n",
    "       False, False,  True,  True, False,  True, False, False, False,\n",
    "       False, False, False, False,  True, False, False, False,  True,\n",
    "        True, False, False, False, False, False, False, False,  True,\n",
    "       False, False, False,  True,  True, False, False, False, False,\n",
    "       False,  True, False, False, False, False,  True, False,  True,\n",
    "       False,  True, False, False, False,  True,  True, False, False,\n",
    "       False,  True, False, False, False,  True, False, False,  True,\n",
    "       False, False, False, False,  True, False, False, False,  True,\n",
    "       False, False, False,  True, False,  True, False, False, False,\n",
    "       False, False, False, False, False,  True, False, False, False,\n",
    "       False, False, False, False,  True, False, False, False, False,\n",
    "        True, False, False, False, False,  True,  True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "cols = [2,9,16,26,69,72,81,84,93,94,101]\n",
    "X_train.drop(X_train.columns[cols],axis=1,inplace=True)\n",
    "X_test.drop(X_test.columns[cols],axis=1,inplace=True)\n",
    "X_test21.drop(X_test21.columns[cols],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.values\n",
    "y_train=y_train.values\n",
    "X_test=X_test.values\n",
    "y_test=y_test.values\n",
    "X_test21=X_test21.values\n",
    "y_test21=y_test21.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 111)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:0.8859120605209053\n",
      "Test Result:0.680846344925479\n",
      "Test21 Result:0.3994092827004219\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lg=LogisticRegression()\n",
    "lg.fit(X_train,y_train)\n",
    "print('Train Result:{}'.format(lg.score(X_train, y_train)))\n",
    "print('Test Result:{}'.format(lg.score(X_test, y_test)))\n",
    "print('Test21 Result:{}'.format(lg.score(X_test21, y_test21)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import GridSearchCV\n",
    "#lg1=LogisticRegression()\n",
    "#param_grid = {\"C\":[0.001,0.01,1,10], \"penalty\":[\"l1\",\"l2\"]}\n",
    "#lg_gscv = GridSearchCV(lg1, param_grid, cv=7)\n",
    "#lg_gscv.fit(X_train, y_train)\n",
    "#print('Train Result:{}'.format(lg_gscv.score(X_train, y_train)))\n",
    "#print('Test Result:{}'.format(lg_gscv.score(X_test, y_test)))\n",
    "#print('Test21 Result:{}'.format(lg_gscv.score(X_test21, y_test21)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#knn = KNeighborsClassifier()\n",
    "#knn.fit(X_train,y_train)\n",
    "#print('Train Result:{}'.format(knn.score(X_train, y_train)))\n",
    "#print('Test Result:{}'.format(knn.score(X_test, y_test)))\n",
    "#print('Test21 Result:{}'.format(knn.score(X_test21, y_test21)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "knn1 = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors': [5,8,12,15,20,25]}\n",
    "knn_gscv = GridSearchCV(knn1, param_grid, cv=7)\n",
    "knn_gscv.fit(X_train, y_train)\n",
    "print('Train Result:{}'.format(knn_gscv.score(X_train, y_train)))\n",
    "print('Test Result:{}'.format(knn_gscv.score(X_test, y_test)))\n",
    "print('Test21 Result:{}'.format(knn_gscv.score(X_test21, y_test21)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:0.999944432537131\n",
      "Test Result:0.8140081618168914\n",
      "Test21 Result:0.6465822784810127\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "tree= tree.DecisionTreeClassifier()\n",
    "clf = tree.fit(X_train,y_train)\n",
    "clf.fit(X_train,y_train)\n",
    "print('Train Result:{}'.format(clf.score(X_train, y_train)))\n",
    "print('Test Result:{}'.format(clf.score(X_test, y_test)))\n",
    "print('Test21 Result:{}'.format(clf.score(X_test21, y_test21)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import tree\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#tree=tree.DecisionTreeClassifier(random_state=1)\n",
    "#param_grid = {}\n",
    "#tree_gscv = GridSearchCV(tree, param_grid, cv=7)\n",
    "#tree_gscv.fit(X_train, y_train)\n",
    "#print('Train Result:{}'.format(tree_gscv.score(X_train, y_train)))\n",
    "#print('Test Result:{}'.format(tree_gscv.score(X_test, y_test)))\n",
    "#print('Test21 Result:{}'.format(tree_gscv.score(X_test21, y_test21)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tree_gscv.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:0.9995951513419542\n",
      "Test Result:0.7967530163236338\n",
      "Test21 Result:0.6137552742616034\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import tree\n",
    "bme= BaggingClassifier(tree.DecisionTreeClassifier(random_state=1))\n",
    "bme.fit(X_train,y_train)\n",
    "print('Train Result:{}'.format(bme.score(X_train, y_train)))\n",
    "print('Test Result:{}'.format(bme.score(X_test, y_test)))\n",
    "print('Test21 Result:{}'.format(bme.score(X_test21, y_test21)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:0.9998809268652806\n",
      "Test Result:0.8139638041163946\n",
      "Test21 Result:0.649873417721519\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree\n",
    "bme1= BaggingClassifier(tree.DecisionTreeClassifier(random_state=1))\n",
    "param_grid = {}\n",
    "bme_gscv = GridSearchCV(bme1, param_grid, cv=3)\n",
    "bme_gscv.fit(X_train, y_train)\n",
    "print('Train Result:{}'.format(bme_gscv.score(X_train, y_train)))\n",
    "print('Test Result:{}'.format(bme_gscv.score(X_test, y_test)))\n",
    "print('Test21 Result:{}'.format(bme_gscv.score(X_test21, y_test21)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AJIT\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:0.9996348423868606\n",
      "Test Result:0.7844215755855216\n",
      "Test Result:0.589957805907173\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(500)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "print('Train Result:{}'.format(rf.score(X_train, y_train)))\n",
    "print('Test Result:{}'.format(rf.score(X_test, y_test)))\n",
    "print('Test Result:{}'.format(rf.score(X_test21, y_test21)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:0.999944432537131\n",
      "Test Result:0.7758605393896381\n",
      "Test Result:0.5735864978902954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "rf1= RandomForestClassifier()\n",
    "param_grid = {'n_estimators':[500]}\n",
    "rf_gscv = GridSearchCV(rf1, param_grid, cv=3)\n",
    "rf_gscv.fit(X_train, y_train)\n",
    "print('Train Result:{}'.format(rf_gscv.score(X_train, y_train)))\n",
    "print('Test Result:{}'.format(rf_gscv.score(X_test, y_test)))\n",
    "print('Test Result:{}'.format(rf_gscv.score(X_test21, y_test21)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:0.9912203408666936\n",
      "Test Result:0.7848651525904897\n",
      "Test Result:0.5918987341772152\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_train, y_train)\n",
    "print('Train Result:{}'.format(ada.score(X_train, y_train)))\n",
    "print('Test Result:{}'.format(ada.score(X_test, y_test)))\n",
    "print('Test Result:{}'.format(ada.score(X_test21, y_test21)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:0.9923951957959245\n",
      "Test Result:0.7746185237757275\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "ada1 = AdaBoostClassifier()\n",
    "param_grid = {\"n_estimators\":[500]}\n",
    "ada_gscv = GridSearchCV(ada1, param_grid, cv=3)\n",
    "ada_gscv.fit(X_train, y_train)\n",
    "print('Train Result:{}'.format(ada_gscv.score(X_train, y_train)))\n",
    "print('Test Result:{}'.format(ada_gscv.score(X_test, y_test)))\n",
    "print('Test Result:{}'.format(ada_gscv.score(X_test21, y_test21)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:0.9957213053590849\n",
      "Test Result:0.8071327182398864\n",
      "Test Result:0.6330801687763713\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbm = GradientBoostingClassifier()\n",
    "gbm.fit(X_train, y_train)\n",
    "print('Train Result:{}'.format(gbm.score(X_train, y_train)))\n",
    "print('Test Result:{}'.format(gbm.score(X_test, y_test)))\n",
    "print('Test Result:{}'.format(gbm.score(X_test21, y_test21)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:0.9986425662641994\n",
      "Test Result:0.8101490418736693\n",
      "Test21 Result:0.6388185654008439\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gbm1 = GradientBoostingClassifier()\n",
    "param_grid = {'learning_rate':[0.02],'n_estimators':[1000,1500]}\n",
    "gbm_gscv = GridSearchCV(gbm1, param_grid, cv=5)\n",
    "gbm_gscv.fit(X_train, y_train)\n",
    "print('Train Result:{}'.format(gbm_gscv.score(X_train, y_train)))\n",
    "print('Test Result:{}'.format(gbm_gscv.score(X_test, y_test)))\n",
    "print('Test21 Result:{}'.format(gbm_gscv.score(X_test21, y_test21)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.02, 'n_estimators': 1500}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_gscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.19686432e-04, 3.98631717e-04, 2.51555392e-03, 6.22917285e-04,\n",
       "       1.80760543e-04, 1.48164431e-04, 3.28083968e-07, 1.13265122e-04,\n",
       "       1.87338650e-04, 1.78328929e-02, 2.55748560e-05, 3.75448312e-04,\n",
       "       1.13520469e-02, 2.77260217e-06, 2.64836166e-05, 4.60692717e-05,\n",
       "       2.28555871e-04, 3.70141753e-05, 7.84767538e-05, 1.35865324e-03,\n",
       "       3.73068282e-06, 1.64548137e-07, 5.51459761e-08, 3.91490325e-04,\n",
       "       4.15058356e-03, 2.67489466e-03, 1.14986582e-05, 1.33135223e-02,\n",
       "       3.19732139e-03, 6.32782155e-04, 7.55359004e-06, 2.49301596e-05,\n",
       "       1.83345989e-04, 3.83774216e-04, 4.09356563e-05, 1.05311667e-04,\n",
       "       3.52271363e-05, 8.39337305e-08, 1.12173174e-05, 2.73644934e-05,\n",
       "       8.57574458e-05, 9.81058514e-06, 4.50458285e-06, 3.72823702e-07,\n",
       "       2.93910234e-03, 3.67212302e-04, 2.06993445e-04, 3.28454532e-03,\n",
       "       6.88022857e-02, 2.07212080e-05, 1.96261864e-03, 2.13011047e-05,\n",
       "       1.32547255e-03, 7.64441053e-05, 2.10771556e-03, 1.43953864e-04,\n",
       "       3.76732357e-03, 5.38253081e-02, 1.24176188e-04, 7.00414615e-01,\n",
       "       2.32106642e-02, 7.46780756e-02, 3.42562631e-04, 7.57516863e-06,\n",
       "       2.87559157e-07, 3.85869088e-05, 9.55923979e-05, 1.01745930e-04,\n",
       "       8.20664564e-06, 4.81066945e-07, 8.09274226e-06, 1.25232207e-05,\n",
       "       3.94808697e-05, 5.29327137e-09, 1.67503641e-04, 2.06441264e-09,\n",
       "       8.33298811e-06, 3.43624155e-04])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=gbm.feature_importances_\n",
    "a=a[a != 0]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=sorted(gbm.feature_importances_, reverse=True)\n",
    "b=b[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'feature_importances_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-39c845a9b461>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpredictors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mfeat_imp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgbm_gscv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mfeat_imp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bar'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Importance of Features'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Feature Importance Score'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'feature_importances_'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "predictors=list(X_train)\n",
    "feat_imp = pd.Series(gbm_gscv.feature_importances_, predictors).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Importance of Features')\n",
    "plt.ylabel('Feature Importance Score')\n",
    "print('Accuracy of the GBM on test set: {:.3f}'.format(gbm_gscv.score(X_test, y_test)))\n",
    "pred=gbm_gscv.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[61, 59]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(range(len(a)), key=lambda i: a[i])[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:0.9998571122383367\n",
      "Test Result:0.8248757984386089\n",
      "Test Result:0.6670886075949367\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "gbm1 = GradientBoostingClassifier()\n",
    "param_grid = {'n_estimators':[1000]}\n",
    "gbm_gscv = GridSearchCV(gbm1, param_grid, cv=3)\n",
    "gbm_gscv.fit(X_train, y_train)\n",
    "print('Train Result:{}'.format(gbm_gscv.score(X_train, y_train)))\n",
    "print('Test Result:{}'.format(gbm_gscv.score(X_test, y_test)))\n",
    "print('Test Result:{}'.format(gbm_gscv.score(X_test21, y_test21)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the GBM on test set: 0.825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.71      0.82     12833\n",
      "           1       0.72      0.97      0.83      9711\n",
      "\n",
      "   micro avg       0.83      0.83      0.83     22544\n",
      "   macro avg       0.85      0.84      0.82     22544\n",
      "weighted avg       0.86      0.83      0.82     22544\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "predictors=list(X_train)\n",
    "feat_imp = pd.Series(gbm.feature_importances_, predictors).sort_values(ascending=False)\n",
    "feat_imp.plot(kind='bar', title='Importance of Features')\n",
    "plt.ylabel('Feature Importance Score')\n",
    "print('Accuracy of the GBM on test set: {:.3f}'.format(gbm.score(X_test, y_test)))\n",
    "pred=gbm.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:0.9998571122383367\n",
      "Test Result:0.7887686302342086\n",
      "Test Result:0.5981434599156118\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb=XGBClassifier(n_estimators=1000)\n",
    "xgb.fit(X_train,y_train)\n",
    "print('Train Result:{}'.format(xgb.score(X_train, y_train)))\n",
    "print('Test Result:{}'.format(xgb.score(X_test, y_test)))\n",
    "print('Test Result:{}'.format(xgb.score(X_test21, y_test21)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:0.9976185373056131\n",
      "Test Result:0.7852200141944642\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "xgb1=XGBClassifier()\n",
    "param_grid = {\"n_estimators\":[1000]}\n",
    "xgb_gscv = GridSearchCV(xgb1, param_grid, cv=3)\n",
    "xgb_gscv.fit(X_train, y_train)\n",
    "print('Train Result:{}'.format(xgb_gscv.score(X_train, y_train)))\n",
    "print('Test Result:{}'.format(xgb_gscv.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:0.999944432537131\n",
      "Test Result:0.7858853797019163\n",
      "Test Result:0.5927426160337552\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgbm=LGBMClassifier()\n",
    "lgbm.fit(X_train,y_train)\n",
    "print('Train Result:{}'.format(lgbm.score(X_train, y_train)))\n",
    "print('Test Result:{}'.format(lgbm.score(X_test, y_test)))\n",
    "print('Test21 Result:{}'.format(lgbm.score(X_test21, y_test21)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:0.9997697919395426\n",
      "Test Result:0.7913413768630234\n",
      "Test21 Result:0.6032067510548523\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "lgbm1=LGBMClassifier()\n",
    "param_grid = {\"n_estimators\":[100]}\n",
    "lgbm_gscv = GridSearchCV(lgbm1, param_grid, cv=5)\n",
    "lgbm_gscv.fit(X_train, y_train)\n",
    "print('Train Result:{}'.format(lgbm_gscv.score(X_train, y_train)))\n",
    "print('Test Result:{}'.format(lgbm_gscv.score(X_test, y_test)))\n",
    "print('Test21 Result:{}'.format(lgbm_gscv.score(X_test21, y_test21)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cat Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.015694\n",
      "0:\tlearn: 0.6499001\ttotal: 138ms\tremaining: 11m 30s\n",
      "1:\tlearn: 0.6164763\ttotal: 269ms\tremaining: 11m 11s\n",
      "2:\tlearn: 0.5784086\ttotal: 423ms\tremaining: 11m 44s\n",
      "3:\tlearn: 0.5410812\ttotal: 568ms\tremaining: 11m 49s\n",
      "4:\tlearn: 0.5142808\ttotal: 748ms\tremaining: 12m 26s\n",
      "5:\tlearn: 0.4769392\ttotal: 878ms\tremaining: 12m 10s\n",
      "6:\tlearn: 0.4514090\ttotal: 1.03s\tremaining: 12m 15s\n",
      "7:\tlearn: 0.4262526\ttotal: 1.18s\tremaining: 12m 14s\n",
      "8:\tlearn: 0.3994338\ttotal: 1.34s\tremaining: 12m 21s\n",
      "9:\tlearn: 0.3716990\ttotal: 1.47s\tremaining: 12m 14s\n",
      "10:\tlearn: 0.3525347\ttotal: 1.64s\tremaining: 12m 25s\n",
      "11:\tlearn: 0.3383662\ttotal: 1.77s\tremaining: 12m 17s\n",
      "12:\tlearn: 0.3200395\ttotal: 1.91s\tremaining: 12m 13s\n",
      "13:\tlearn: 0.3040068\ttotal: 2.06s\tremaining: 12m 15s\n",
      "14:\tlearn: 0.2873660\ttotal: 2.23s\tremaining: 12m 20s\n",
      "15:\tlearn: 0.2722209\ttotal: 2.37s\tremaining: 12m 18s\n",
      "16:\tlearn: 0.2601085\ttotal: 2.54s\tremaining: 12m 25s\n",
      "17:\tlearn: 0.2461161\ttotal: 2.67s\tremaining: 12m 20s\n",
      "18:\tlearn: 0.2349823\ttotal: 2.83s\tremaining: 12m 21s\n",
      "19:\tlearn: 0.2252920\ttotal: 2.97s\tremaining: 12m 20s\n",
      "20:\tlearn: 0.2156464\ttotal: 3.18s\tremaining: 12m 34s\n",
      "21:\tlearn: 0.2051299\ttotal: 3.42s\tremaining: 12m 54s\n",
      "22:\tlearn: 0.1965180\ttotal: 3.74s\tremaining: 13m 29s\n",
      "23:\tlearn: 0.1880269\ttotal: 3.95s\tremaining: 13m 38s\n",
      "24:\tlearn: 0.1802064\ttotal: 4.2s\tremaining: 13m 56s\n",
      "25:\tlearn: 0.1721502\ttotal: 4.35s\tremaining: 13m 51s\n",
      "26:\tlearn: 0.1625496\ttotal: 4.56s\tremaining: 14m\n",
      "27:\tlearn: 0.1568482\ttotal: 4.77s\tremaining: 14m 7s\n",
      "28:\tlearn: 0.1494741\ttotal: 4.96s\tremaining: 14m 10s\n",
      "29:\tlearn: 0.1430516\ttotal: 5.12s\tremaining: 14m 7s\n",
      "30:\tlearn: 0.1395949\ttotal: 5.26s\tremaining: 14m 3s\n",
      "31:\tlearn: 0.1338376\ttotal: 5.41s\tremaining: 13m 59s\n",
      "32:\tlearn: 0.1270709\ttotal: 5.58s\tremaining: 13m 59s\n",
      "33:\tlearn: 0.1230407\ttotal: 5.75s\tremaining: 14m\n",
      "34:\tlearn: 0.1201420\ttotal: 5.91s\tremaining: 13m 57s\n",
      "35:\tlearn: 0.1172999\ttotal: 6.1s\tremaining: 14m 1s\n",
      "36:\tlearn: 0.1133595\ttotal: 6.3s\tremaining: 14m 5s\n",
      "37:\tlearn: 0.1099193\ttotal: 6.49s\tremaining: 14m 7s\n",
      "38:\tlearn: 0.1068195\ttotal: 6.69s\tremaining: 14m 11s\n",
      "39:\tlearn: 0.1045057\ttotal: 6.87s\tremaining: 14m 12s\n",
      "40:\tlearn: 0.1012991\ttotal: 7.09s\tremaining: 14m 18s\n",
      "41:\tlearn: 0.0983044\ttotal: 7.27s\tremaining: 14m 18s\n",
      "42:\tlearn: 0.0950525\ttotal: 7.43s\tremaining: 14m 16s\n",
      "43:\tlearn: 0.0925215\ttotal: 7.57s\tremaining: 14m 12s\n",
      "44:\tlearn: 0.0888338\ttotal: 7.72s\tremaining: 14m 10s\n",
      "45:\tlearn: 0.0865776\ttotal: 7.87s\tremaining: 14m 7s\n",
      "46:\tlearn: 0.0846305\ttotal: 8.01s\tremaining: 14m 3s\n",
      "47:\tlearn: 0.0828578\ttotal: 8.15s\tremaining: 14m 1s\n",
      "48:\tlearn: 0.0800171\ttotal: 8.37s\tremaining: 14m 5s\n",
      "49:\tlearn: 0.0783937\ttotal: 8.55s\tremaining: 14m 6s\n",
      "50:\tlearn: 0.0763823\ttotal: 8.74s\tremaining: 14m 8s\n",
      "51:\tlearn: 0.0747401\ttotal: 8.89s\tremaining: 14m 6s\n",
      "52:\tlearn: 0.0730276\ttotal: 9.02s\tremaining: 14m 2s\n",
      "53:\tlearn: 0.0712560\ttotal: 9.19s\tremaining: 14m 2s\n",
      "54:\tlearn: 0.0699905\ttotal: 9.36s\tremaining: 14m 1s\n",
      "55:\tlearn: 0.0690206\ttotal: 9.54s\tremaining: 14m 2s\n",
      "56:\tlearn: 0.0674300\ttotal: 9.72s\tremaining: 14m 3s\n",
      "57:\tlearn: 0.0660982\ttotal: 9.89s\tremaining: 14m 2s\n",
      "58:\tlearn: 0.0646404\ttotal: 10s\tremaining: 14m 1s\n",
      "59:\tlearn: 0.0629929\ttotal: 10.2s\tremaining: 14m 3s\n",
      "60:\tlearn: 0.0616170\ttotal: 10.4s\tremaining: 14m 1s\n",
      "61:\tlearn: 0.0606996\ttotal: 10.6s\tremaining: 14m 7s\n",
      "62:\tlearn: 0.0594686\ttotal: 10.8s\tremaining: 14m 7s\n",
      "63:\tlearn: 0.0580591\ttotal: 11s\tremaining: 14m 7s\n",
      "64:\tlearn: 0.0569611\ttotal: 11.2s\tremaining: 14m 8s\n",
      "65:\tlearn: 0.0559573\ttotal: 11.3s\tremaining: 14m 8s\n",
      "66:\tlearn: 0.0548395\ttotal: 11.5s\tremaining: 14m 7s\n",
      "67:\tlearn: 0.0536927\ttotal: 11.7s\tremaining: 14m 5s\n",
      "68:\tlearn: 0.0525087\ttotal: 11.8s\tremaining: 14m 3s\n",
      "69:\tlearn: 0.0516630\ttotal: 12s\tremaining: 14m 2s\n",
      "70:\tlearn: 0.0510016\ttotal: 12.1s\tremaining: 14m\n",
      "71:\tlearn: 0.0502847\ttotal: 12.2s\tremaining: 13m 57s\n",
      "72:\tlearn: 0.0496287\ttotal: 12.4s\tremaining: 13m 59s\n",
      "73:\tlearn: 0.0488579\ttotal: 12.6s\tremaining: 13m 58s\n",
      "74:\tlearn: 0.0482384\ttotal: 12.8s\tremaining: 13m 58s\n",
      "75:\tlearn: 0.0477360\ttotal: 13s\tremaining: 13m 59s\n",
      "76:\tlearn: 0.0470020\ttotal: 13.1s\tremaining: 13m 58s\n",
      "77:\tlearn: 0.0465039\ttotal: 13.3s\tremaining: 13m 56s\n",
      "78:\tlearn: 0.0460013\ttotal: 13.4s\tremaining: 13m 54s\n",
      "79:\tlearn: 0.0454133\ttotal: 13.5s\tremaining: 13m 52s\n",
      "80:\tlearn: 0.0447494\ttotal: 13.7s\tremaining: 13m 53s\n",
      "81:\tlearn: 0.0442529\ttotal: 13.9s\tremaining: 13m 52s\n",
      "82:\tlearn: 0.0436737\ttotal: 14s\tremaining: 13m 51s\n",
      "83:\tlearn: 0.0431082\ttotal: 14.1s\tremaining: 13m 47s\n",
      "84:\tlearn: 0.0426260\ttotal: 14.3s\tremaining: 13m 48s\n",
      "85:\tlearn: 0.0418905\ttotal: 14.5s\tremaining: 13m 49s\n",
      "86:\tlearn: 0.0413200\ttotal: 14.7s\tremaining: 13m 48s\n",
      "87:\tlearn: 0.0408814\ttotal: 14.9s\tremaining: 13m 50s\n",
      "88:\tlearn: 0.0404608\ttotal: 15.1s\tremaining: 13m 50s\n",
      "89:\tlearn: 0.0400365\ttotal: 15.2s\tremaining: 13m 50s\n",
      "90:\tlearn: 0.0395235\ttotal: 15.4s\tremaining: 13m 51s\n",
      "91:\tlearn: 0.0391151\ttotal: 15.6s\tremaining: 13m 51s\n",
      "92:\tlearn: 0.0387743\ttotal: 15.8s\tremaining: 13m 51s\n",
      "93:\tlearn: 0.0382033\ttotal: 16s\tremaining: 13m 52s\n",
      "94:\tlearn: 0.0376371\ttotal: 16.1s\tremaining: 13m 52s\n",
      "95:\tlearn: 0.0374269\ttotal: 16.3s\tremaining: 13m 50s\n",
      "96:\tlearn: 0.0369716\ttotal: 16.4s\tremaining: 13m 50s\n",
      "97:\tlearn: 0.0365041\ttotal: 16.6s\tremaining: 13m 49s\n",
      "98:\tlearn: 0.0361443\ttotal: 16.8s\tremaining: 13m 49s\n",
      "99:\tlearn: 0.0358019\ttotal: 16.9s\tremaining: 13m 48s\n",
      "100:\tlearn: 0.0356353\ttotal: 17s\tremaining: 13m 46s\n",
      "101:\tlearn: 0.0353252\ttotal: 17.2s\tremaining: 13m 46s\n",
      "102:\tlearn: 0.0348629\ttotal: 17.4s\tremaining: 13m 46s\n",
      "103:\tlearn: 0.0345744\ttotal: 17.6s\tremaining: 13m 47s\n",
      "104:\tlearn: 0.0343479\ttotal: 17.7s\tremaining: 13m 47s\n",
      "105:\tlearn: 0.0339422\ttotal: 17.9s\tremaining: 13m 47s\n",
      "106:\tlearn: 0.0334284\ttotal: 18.1s\tremaining: 13m 46s\n",
      "107:\tlearn: 0.0331816\ttotal: 18.2s\tremaining: 13m 45s\n",
      "108:\tlearn: 0.0328394\ttotal: 18.4s\tremaining: 13m 45s\n",
      "109:\tlearn: 0.0324925\ttotal: 18.6s\tremaining: 13m 45s\n",
      "110:\tlearn: 0.0323297\ttotal: 18.7s\tremaining: 13m 45s\n",
      "111:\tlearn: 0.0321378\ttotal: 18.9s\tremaining: 13m 46s\n",
      "112:\tlearn: 0.0319742\ttotal: 19.1s\tremaining: 13m 45s\n",
      "113:\tlearn: 0.0316514\ttotal: 19.3s\tremaining: 13m 46s\n",
      "114:\tlearn: 0.0312903\ttotal: 19.5s\tremaining: 13m 49s\n",
      "115:\tlearn: 0.0309502\ttotal: 19.7s\tremaining: 13m 50s\n",
      "116:\tlearn: 0.0306211\ttotal: 19.9s\tremaining: 13m 50s\n",
      "117:\tlearn: 0.0303605\ttotal: 20.1s\tremaining: 13m 49s\n",
      "118:\tlearn: 0.0301282\ttotal: 20.2s\tremaining: 13m 48s\n",
      "119:\tlearn: 0.0297507\ttotal: 20.3s\tremaining: 13m 46s\n",
      "120:\tlearn: 0.0294416\ttotal: 20.5s\tremaining: 13m 46s\n",
      "121:\tlearn: 0.0290208\ttotal: 20.7s\tremaining: 13m 45s\n",
      "122:\tlearn: 0.0289190\ttotal: 20.8s\tremaining: 13m 45s\n",
      "123:\tlearn: 0.0285485\ttotal: 21s\tremaining: 13m 45s\n",
      "124:\tlearn: 0.0283035\ttotal: 21.1s\tremaining: 13m 44s\n",
      "125:\tlearn: 0.0282085\ttotal: 21.3s\tremaining: 13m 45s\n",
      "126:\tlearn: 0.0280609\ttotal: 21.6s\tremaining: 13m 48s\n",
      "127:\tlearn: 0.0277710\ttotal: 21.8s\tremaining: 13m 49s\n",
      "128:\tlearn: 0.0276531\ttotal: 22s\tremaining: 13m 48s\n",
      "129:\tlearn: 0.0274153\ttotal: 22.1s\tremaining: 13m 47s\n",
      "130:\tlearn: 0.0270531\ttotal: 22.2s\tremaining: 13m 46s\n",
      "131:\tlearn: 0.0269151\ttotal: 22.3s\tremaining: 13m 43s\n",
      "132:\tlearn: 0.0266730\ttotal: 22.4s\tremaining: 13m 41s\n",
      "133:\tlearn: 0.0263756\ttotal: 22.6s\tremaining: 13m 40s\n",
      "134:\tlearn: 0.0262817\ttotal: 22.7s\tremaining: 13m 38s\n",
      "135:\tlearn: 0.0260594\ttotal: 22.8s\tremaining: 13m 36s\n",
      "136:\tlearn: 0.0259331\ttotal: 22.9s\tremaining: 13m 34s\n",
      "137:\tlearn: 0.0258343\ttotal: 23.1s\tremaining: 13m 32s\n",
      "138:\tlearn: 0.0255577\ttotal: 23.2s\tremaining: 13m 31s\n",
      "139:\tlearn: 0.0254805\ttotal: 23.3s\tremaining: 13m 28s\n",
      "140:\tlearn: 0.0253841\ttotal: 23.4s\tremaining: 13m 27s\n",
      "141:\tlearn: 0.0252935\ttotal: 23.6s\tremaining: 13m 25s\n",
      "142:\tlearn: 0.0251939\ttotal: 23.7s\tremaining: 13m 25s\n",
      "143:\tlearn: 0.0250692\ttotal: 23.9s\tremaining: 13m 24s\n",
      "144:\tlearn: 0.0249789\ttotal: 24s\tremaining: 13m 24s\n",
      "145:\tlearn: 0.0248483\ttotal: 24.2s\tremaining: 13m 24s\n",
      "146:\tlearn: 0.0246463\ttotal: 24.4s\tremaining: 13m 24s\n",
      "147:\tlearn: 0.0245160\ttotal: 24.5s\tremaining: 13m 24s\n",
      "148:\tlearn: 0.0243783\ttotal: 24.7s\tremaining: 13m 24s\n",
      "149:\tlearn: 0.0241197\ttotal: 24.9s\tremaining: 13m 24s\n",
      "150:\tlearn: 0.0240199\ttotal: 25s\tremaining: 13m 23s\n",
      "151:\tlearn: 0.0239239\ttotal: 25.2s\tremaining: 13m 22s\n",
      "152:\tlearn: 0.0238323\ttotal: 25.3s\tremaining: 13m 22s\n",
      "153:\tlearn: 0.0237683\ttotal: 25.5s\tremaining: 13m 21s\n",
      "154:\tlearn: 0.0237257\ttotal: 25.6s\tremaining: 13m 20s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155:\tlearn: 0.0236656\ttotal: 25.8s\tremaining: 13m 19s\n",
      "156:\tlearn: 0.0235834\ttotal: 25.9s\tremaining: 13m 19s\n",
      "157:\tlearn: 0.0234698\ttotal: 26.1s\tremaining: 13m 19s\n",
      "158:\tlearn: 0.0232290\ttotal: 26.3s\tremaining: 13m 20s\n",
      "159:\tlearn: 0.0230543\ttotal: 26.5s\tremaining: 13m 21s\n",
      "160:\tlearn: 0.0228752\ttotal: 26.7s\tremaining: 13m 21s\n",
      "161:\tlearn: 0.0227961\ttotal: 26.9s\tremaining: 13m 22s\n",
      "162:\tlearn: 0.0227046\ttotal: 27s\tremaining: 13m 22s\n",
      "163:\tlearn: 0.0226096\ttotal: 27.2s\tremaining: 13m 21s\n",
      "164:\tlearn: 0.0225306\ttotal: 27.5s\tremaining: 13m 24s\n",
      "165:\tlearn: 0.0224935\ttotal: 27.6s\tremaining: 13m 25s\n",
      "166:\tlearn: 0.0224758\ttotal: 27.8s\tremaining: 13m 24s\n",
      "167:\tlearn: 0.0223917\ttotal: 28s\tremaining: 13m 24s\n",
      "168:\tlearn: 0.0223444\ttotal: 28.1s\tremaining: 13m 23s\n",
      "169:\tlearn: 0.0222945\ttotal: 28.2s\tremaining: 13m 22s\n",
      "170:\tlearn: 0.0222100\ttotal: 28.4s\tremaining: 13m 21s\n",
      "171:\tlearn: 0.0221675\ttotal: 28.5s\tremaining: 13m 20s\n",
      "172:\tlearn: 0.0221468\ttotal: 28.7s\tremaining: 13m 20s\n",
      "173:\tlearn: 0.0220917\ttotal: 28.8s\tremaining: 13m 19s\n",
      "174:\tlearn: 0.0219896\ttotal: 29s\tremaining: 13m 20s\n",
      "175:\tlearn: 0.0219336\ttotal: 29.2s\tremaining: 13m 20s\n",
      "176:\tlearn: 0.0218585\ttotal: 29.4s\tremaining: 13m 21s\n",
      "177:\tlearn: 0.0218023\ttotal: 29.6s\tremaining: 13m 21s\n",
      "178:\tlearn: 0.0217545\ttotal: 29.7s\tremaining: 13m 20s\n",
      "179:\tlearn: 0.0216536\ttotal: 29.9s\tremaining: 13m 20s\n",
      "180:\tlearn: 0.0216089\ttotal: 30s\tremaining: 13m 18s\n",
      "181:\tlearn: 0.0215559\ttotal: 30.1s\tremaining: 13m 17s\n",
      "182:\tlearn: 0.0215245\ttotal: 30.2s\tremaining: 13m 15s\n",
      "183:\tlearn: 0.0213515\ttotal: 30.3s\tremaining: 13m 13s\n",
      "184:\tlearn: 0.0212499\ttotal: 30.4s\tremaining: 13m 11s\n",
      "185:\tlearn: 0.0211954\ttotal: 30.5s\tremaining: 13m 10s\n",
      "186:\tlearn: 0.0211430\ttotal: 30.7s\tremaining: 13m 9s\n",
      "187:\tlearn: 0.0210820\ttotal: 30.8s\tremaining: 13m 9s\n",
      "188:\tlearn: 0.0210012\ttotal: 31s\tremaining: 13m 9s\n",
      "189:\tlearn: 0.0209639\ttotal: 31.2s\tremaining: 13m 11s\n",
      "190:\tlearn: 0.0208688\ttotal: 31.4s\tremaining: 13m 11s\n",
      "191:\tlearn: 0.0208130\ttotal: 31.6s\tremaining: 13m 10s\n",
      "192:\tlearn: 0.0207452\ttotal: 31.8s\tremaining: 13m 10s\n",
      "193:\tlearn: 0.0206757\ttotal: 31.9s\tremaining: 13m 10s\n",
      "194:\tlearn: 0.0205974\ttotal: 32.1s\tremaining: 13m 10s\n",
      "195:\tlearn: 0.0205400\ttotal: 32.3s\tremaining: 13m 11s\n",
      "196:\tlearn: 0.0205017\ttotal: 32.5s\tremaining: 13m 12s\n",
      "197:\tlearn: 0.0204793\ttotal: 32.6s\tremaining: 13m 11s\n",
      "198:\tlearn: 0.0204313\ttotal: 32.8s\tremaining: 13m 10s\n",
      "199:\tlearn: 0.0203787\ttotal: 32.9s\tremaining: 13m 9s\n",
      "200:\tlearn: 0.0203216\ttotal: 33s\tremaining: 13m 9s\n",
      "201:\tlearn: 0.0202800\ttotal: 33.2s\tremaining: 13m 8s\n",
      "202:\tlearn: 0.0202382\ttotal: 33.3s\tremaining: 13m 7s\n",
      "203:\tlearn: 0.0201992\ttotal: 33.5s\tremaining: 13m 6s\n",
      "204:\tlearn: 0.0201575\ttotal: 33.6s\tremaining: 13m 5s\n",
      "205:\tlearn: 0.0201420\ttotal: 33.7s\tremaining: 13m 4s\n",
      "206:\tlearn: 0.0201029\ttotal: 33.8s\tremaining: 13m 2s\n",
      "207:\tlearn: 0.0200393\ttotal: 33.9s\tremaining: 13m 1s\n",
      "208:\tlearn: 0.0199990\ttotal: 34s\tremaining: 12m 59s\n",
      "209:\tlearn: 0.0198862\ttotal: 34.1s\tremaining: 12m 58s\n",
      "210:\tlearn: 0.0198351\ttotal: 34.3s\tremaining: 12m 58s\n",
      "211:\tlearn: 0.0197852\ttotal: 34.4s\tremaining: 12m 57s\n",
      "212:\tlearn: 0.0197610\ttotal: 34.6s\tremaining: 12m 57s\n",
      "213:\tlearn: 0.0195716\ttotal: 34.9s\tremaining: 13m\n",
      "214:\tlearn: 0.0195424\ttotal: 35s\tremaining: 12m 58s\n",
      "215:\tlearn: 0.0195071\ttotal: 35.1s\tremaining: 12m 57s\n",
      "216:\tlearn: 0.0194038\ttotal: 35.3s\tremaining: 12m 58s\n",
      "217:\tlearn: 0.0193541\ttotal: 35.5s\tremaining: 12m 57s\n",
      "218:\tlearn: 0.0192925\ttotal: 35.7s\tremaining: 12m 58s\n",
      "219:\tlearn: 0.0192565\ttotal: 35.8s\tremaining: 12m 57s\n",
      "220:\tlearn: 0.0192113\ttotal: 35.9s\tremaining: 12m 56s\n",
      "221:\tlearn: 0.0191622\ttotal: 36s\tremaining: 12m 55s\n",
      "222:\tlearn: 0.0190018\ttotal: 36.2s\tremaining: 12m 54s\n",
      "223:\tlearn: 0.0189248\ttotal: 36.3s\tremaining: 12m 53s\n",
      "224:\tlearn: 0.0189022\ttotal: 36.4s\tremaining: 12m 52s\n",
      "225:\tlearn: 0.0188402\ttotal: 36.5s\tremaining: 12m 51s\n",
      "226:\tlearn: 0.0187898\ttotal: 36.7s\tremaining: 12m 51s\n",
      "227:\tlearn: 0.0187715\ttotal: 36.8s\tremaining: 12m 50s\n",
      "228:\tlearn: 0.0187557\ttotal: 36.9s\tremaining: 12m 49s\n",
      "229:\tlearn: 0.0186797\ttotal: 37.1s\tremaining: 12m 49s\n",
      "230:\tlearn: 0.0186566\ttotal: 37.2s\tremaining: 12m 48s\n",
      "231:\tlearn: 0.0186230\ttotal: 37.4s\tremaining: 12m 48s\n",
      "232:\tlearn: 0.0185742\ttotal: 37.5s\tremaining: 12m 48s\n",
      "233:\tlearn: 0.0185278\ttotal: 37.7s\tremaining: 12m 47s\n",
      "234:\tlearn: 0.0184491\ttotal: 37.9s\tremaining: 12m 47s\n",
      "235:\tlearn: 0.0184029\ttotal: 38s\tremaining: 12m 47s\n",
      "236:\tlearn: 0.0183413\ttotal: 38.1s\tremaining: 12m 46s\n",
      "237:\tlearn: 0.0182976\ttotal: 38.3s\tremaining: 12m 45s\n",
      "238:\tlearn: 0.0182696\ttotal: 38.4s\tremaining: 12m 45s\n",
      "239:\tlearn: 0.0182425\ttotal: 38.5s\tremaining: 12m 44s\n",
      "240:\tlearn: 0.0181976\ttotal: 38.7s\tremaining: 12m 44s\n",
      "241:\tlearn: 0.0181452\ttotal: 38.9s\tremaining: 12m 44s\n",
      "242:\tlearn: 0.0181240\ttotal: 39.1s\tremaining: 12m 44s\n",
      "243:\tlearn: 0.0180985\ttotal: 39.2s\tremaining: 12m 44s\n",
      "244:\tlearn: 0.0180304\ttotal: 39.4s\tremaining: 12m 43s\n",
      "245:\tlearn: 0.0179483\ttotal: 39.5s\tremaining: 12m 42s\n",
      "246:\tlearn: 0.0179007\ttotal: 39.6s\tremaining: 12m 42s\n",
      "247:\tlearn: 0.0178443\ttotal: 39.7s\tremaining: 12m 41s\n",
      "248:\tlearn: 0.0178195\ttotal: 39.9s\tremaining: 12m 40s\n",
      "249:\tlearn: 0.0177972\ttotal: 40s\tremaining: 12m 39s\n",
      "250:\tlearn: 0.0177761\ttotal: 40.1s\tremaining: 12m 39s\n",
      "251:\tlearn: 0.0177260\ttotal: 40.3s\tremaining: 12m 39s\n",
      "252:\tlearn: 0.0176887\ttotal: 40.5s\tremaining: 12m 39s\n",
      "253:\tlearn: 0.0176663\ttotal: 40.7s\tremaining: 12m 39s\n",
      "254:\tlearn: 0.0176323\ttotal: 40.8s\tremaining: 12m 39s\n",
      "255:\tlearn: 0.0175724\ttotal: 41s\tremaining: 12m 39s\n",
      "256:\tlearn: 0.0175553\ttotal: 41.2s\tremaining: 12m 39s\n",
      "257:\tlearn: 0.0175263\ttotal: 41.3s\tremaining: 12m 39s\n",
      "258:\tlearn: 0.0175112\ttotal: 41.4s\tremaining: 12m 38s\n",
      "259:\tlearn: 0.0174063\ttotal: 41.6s\tremaining: 12m 38s\n",
      "260:\tlearn: 0.0173661\ttotal: 41.7s\tremaining: 12m 37s\n",
      "261:\tlearn: 0.0173056\ttotal: 41.8s\tremaining: 12m 36s\n",
      "262:\tlearn: 0.0172803\ttotal: 41.9s\tremaining: 12m 34s\n",
      "263:\tlearn: 0.0172277\ttotal: 42s\tremaining: 12m 34s\n",
      "264:\tlearn: 0.0171944\ttotal: 42.1s\tremaining: 12m 32s\n",
      "265:\tlearn: 0.0171791\ttotal: 42.2s\tremaining: 12m 31s\n",
      "266:\tlearn: 0.0171082\ttotal: 42.4s\tremaining: 12m 30s\n",
      "267:\tlearn: 0.0170667\ttotal: 42.5s\tremaining: 12m 29s\n",
      "268:\tlearn: 0.0170297\ttotal: 42.6s\tremaining: 12m 28s\n",
      "269:\tlearn: 0.0169985\ttotal: 42.7s\tremaining: 12m 27s\n",
      "270:\tlearn: 0.0169651\ttotal: 42.8s\tremaining: 12m 26s\n",
      "271:\tlearn: 0.0169385\ttotal: 42.9s\tremaining: 12m 25s\n",
      "272:\tlearn: 0.0169232\ttotal: 43s\tremaining: 12m 24s\n",
      "273:\tlearn: 0.0168600\ttotal: 43.1s\tremaining: 12m 23s\n",
      "274:\tlearn: 0.0168150\ttotal: 43.2s\tremaining: 12m 22s\n",
      "275:\tlearn: 0.0167007\ttotal: 43.4s\tremaining: 12m 22s\n",
      "276:\tlearn: 0.0166835\ttotal: 43.5s\tremaining: 12m 20s\n",
      "277:\tlearn: 0.0166197\ttotal: 43.6s\tremaining: 12m 20s\n",
      "278:\tlearn: 0.0165062\ttotal: 43.7s\tremaining: 12m 19s\n",
      "279:\tlearn: 0.0164432\ttotal: 43.8s\tremaining: 12m 18s\n",
      "280:\tlearn: 0.0163829\ttotal: 44s\tremaining: 12m 18s\n",
      "281:\tlearn: 0.0163534\ttotal: 44.1s\tremaining: 12m 17s\n",
      "282:\tlearn: 0.0163480\ttotal: 44.2s\tremaining: 12m 15s\n",
      "283:\tlearn: 0.0162693\ttotal: 44.3s\tremaining: 12m 15s\n",
      "284:\tlearn: 0.0162200\ttotal: 44.4s\tremaining: 12m 14s\n",
      "285:\tlearn: 0.0161692\ttotal: 44.5s\tremaining: 12m 14s\n",
      "286:\tlearn: 0.0161551\ttotal: 44.7s\tremaining: 12m 13s\n",
      "287:\tlearn: 0.0161110\ttotal: 44.8s\tremaining: 12m 13s\n",
      "288:\tlearn: 0.0161010\ttotal: 44.9s\tremaining: 12m 12s\n",
      "289:\tlearn: 0.0160447\ttotal: 45.1s\tremaining: 12m 11s\n",
      "290:\tlearn: 0.0159921\ttotal: 45.2s\tremaining: 12m 11s\n",
      "291:\tlearn: 0.0158712\ttotal: 45.4s\tremaining: 12m 11s\n",
      "292:\tlearn: 0.0158550\ttotal: 45.5s\tremaining: 12m 10s\n",
      "293:\tlearn: 0.0158058\ttotal: 45.6s\tremaining: 12m 10s\n",
      "294:\tlearn: 0.0157869\ttotal: 45.7s\tremaining: 12m 9s\n",
      "295:\tlearn: 0.0157583\ttotal: 45.8s\tremaining: 12m 8s\n",
      "296:\tlearn: 0.0157262\ttotal: 45.9s\tremaining: 12m 7s\n",
      "297:\tlearn: 0.0157099\ttotal: 46s\tremaining: 12m 6s\n",
      "298:\tlearn: 0.0156480\ttotal: 46.1s\tremaining: 12m 5s\n",
      "299:\tlearn: 0.0155547\ttotal: 46.3s\tremaining: 12m 4s\n",
      "300:\tlearn: 0.0155032\ttotal: 46.4s\tremaining: 12m 3s\n",
      "301:\tlearn: 0.0154780\ttotal: 46.5s\tremaining: 12m 2s\n",
      "302:\tlearn: 0.0154332\ttotal: 46.6s\tremaining: 12m 1s\n",
      "303:\tlearn: 0.0153885\ttotal: 46.7s\tremaining: 12m 1s\n",
      "304:\tlearn: 0.0153261\ttotal: 46.8s\tremaining: 12m\n",
      "305:\tlearn: 0.0152846\ttotal: 46.9s\tremaining: 11m 59s\n",
      "306:\tlearn: 0.0152626\ttotal: 47s\tremaining: 11m 59s\n",
      "307:\tlearn: 0.0152480\ttotal: 47.1s\tremaining: 11m 58s\n",
      "308:\tlearn: 0.0151981\ttotal: 47.2s\tremaining: 11m 57s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309:\tlearn: 0.0151436\ttotal: 47.4s\tremaining: 11m 56s\n",
      "310:\tlearn: 0.0150765\ttotal: 47.5s\tremaining: 11m 55s\n",
      "311:\tlearn: 0.0150448\ttotal: 47.6s\tremaining: 11m 54s\n",
      "312:\tlearn: 0.0149918\ttotal: 47.7s\tremaining: 11m 54s\n",
      "313:\tlearn: 0.0149606\ttotal: 47.8s\tremaining: 11m 53s\n",
      "314:\tlearn: 0.0149467\ttotal: 47.9s\tremaining: 11m 52s\n",
      "315:\tlearn: 0.0148868\ttotal: 48.1s\tremaining: 11m 52s\n",
      "316:\tlearn: 0.0148692\ttotal: 48.1s\tremaining: 11m 51s\n",
      "317:\tlearn: 0.0148055\ttotal: 48.3s\tremaining: 11m 50s\n",
      "318:\tlearn: 0.0147800\ttotal: 48.4s\tremaining: 11m 49s\n",
      "319:\tlearn: 0.0147325\ttotal: 48.5s\tremaining: 11m 48s\n",
      "320:\tlearn: 0.0147034\ttotal: 48.6s\tremaining: 11m 48s\n",
      "321:\tlearn: 0.0146842\ttotal: 48.7s\tremaining: 11m 47s\n",
      "322:\tlearn: 0.0146611\ttotal: 48.8s\tremaining: 11m 46s\n",
      "323:\tlearn: 0.0146320\ttotal: 48.9s\tremaining: 11m 45s\n",
      "324:\tlearn: 0.0146123\ttotal: 49s\tremaining: 11m 44s\n",
      "325:\tlearn: 0.0145833\ttotal: 49.1s\tremaining: 11m 43s\n",
      "326:\tlearn: 0.0145632\ttotal: 49.2s\tremaining: 11m 43s\n",
      "327:\tlearn: 0.0145186\ttotal: 49.3s\tremaining: 11m 42s\n",
      "328:\tlearn: 0.0144793\ttotal: 49.4s\tremaining: 11m 41s\n",
      "329:\tlearn: 0.0144437\ttotal: 49.5s\tremaining: 11m 41s\n",
      "330:\tlearn: 0.0144386\ttotal: 49.6s\tremaining: 11m 40s\n",
      "331:\tlearn: 0.0143886\ttotal: 49.8s\tremaining: 11m 39s\n",
      "332:\tlearn: 0.0143609\ttotal: 49.9s\tremaining: 11m 38s\n",
      "333:\tlearn: 0.0143188\ttotal: 50s\tremaining: 11m 37s\n",
      "334:\tlearn: 0.0142914\ttotal: 50.1s\tremaining: 11m 37s\n",
      "335:\tlearn: 0.0142155\ttotal: 50.2s\tremaining: 11m 36s\n",
      "336:\tlearn: 0.0141669\ttotal: 50.3s\tremaining: 11m 36s\n",
      "337:\tlearn: 0.0141600\ttotal: 50.4s\tremaining: 11m 35s\n",
      "338:\tlearn: 0.0141176\ttotal: 50.5s\tremaining: 11m 34s\n",
      "339:\tlearn: 0.0140893\ttotal: 50.6s\tremaining: 11m 33s\n",
      "340:\tlearn: 0.0140640\ttotal: 50.7s\tremaining: 11m 33s\n",
      "341:\tlearn: 0.0140484\ttotal: 50.9s\tremaining: 11m 32s\n",
      "342:\tlearn: 0.0140110\ttotal: 51s\tremaining: 11m 31s\n",
      "343:\tlearn: 0.0139640\ttotal: 51.1s\tremaining: 11m 31s\n",
      "344:\tlearn: 0.0139268\ttotal: 51.2s\tremaining: 11m 30s\n",
      "345:\tlearn: 0.0139235\ttotal: 51.3s\tremaining: 11m 30s\n",
      "346:\tlearn: 0.0139112\ttotal: 51.4s\tremaining: 11m 29s\n",
      "347:\tlearn: 0.0138863\ttotal: 51.5s\tremaining: 11m 28s\n",
      "348:\tlearn: 0.0138564\ttotal: 51.6s\tremaining: 11m 27s\n",
      "349:\tlearn: 0.0138391\ttotal: 51.7s\tremaining: 11m 27s\n",
      "350:\tlearn: 0.0138219\ttotal: 51.8s\tremaining: 11m 26s\n",
      "351:\tlearn: 0.0137883\ttotal: 51.9s\tremaining: 11m 25s\n",
      "352:\tlearn: 0.0137789\ttotal: 52s\tremaining: 11m 25s\n",
      "353:\tlearn: 0.0137666\ttotal: 52.2s\tremaining: 11m 24s\n",
      "354:\tlearn: 0.0137363\ttotal: 52.3s\tremaining: 11m 23s\n",
      "355:\tlearn: 0.0137309\ttotal: 52.4s\tremaining: 11m 23s\n",
      "356:\tlearn: 0.0137112\ttotal: 52.5s\tremaining: 11m 22s\n",
      "357:\tlearn: 0.0137062\ttotal: 52.6s\tremaining: 11m 21s\n",
      "358:\tlearn: 0.0136398\ttotal: 52.7s\tremaining: 11m 21s\n",
      "359:\tlearn: 0.0136272\ttotal: 52.8s\tremaining: 11m 20s\n",
      "360:\tlearn: 0.0136191\ttotal: 52.9s\tremaining: 11m 19s\n",
      "361:\tlearn: 0.0135678\ttotal: 53s\tremaining: 11m 18s\n",
      "362:\tlearn: 0.0135640\ttotal: 53.1s\tremaining: 11m 18s\n",
      "363:\tlearn: 0.0135304\ttotal: 53.2s\tremaining: 11m 17s\n",
      "364:\tlearn: 0.0134647\ttotal: 53.3s\tremaining: 11m 17s\n",
      "365:\tlearn: 0.0134442\ttotal: 53.4s\tremaining: 11m 16s\n",
      "366:\tlearn: 0.0134347\ttotal: 53.5s\tremaining: 11m 15s\n",
      "367:\tlearn: 0.0133843\ttotal: 53.6s\tremaining: 11m 15s\n",
      "368:\tlearn: 0.0133712\ttotal: 53.8s\tremaining: 11m 14s\n",
      "369:\tlearn: 0.0133435\ttotal: 53.9s\tremaining: 11m 13s\n",
      "370:\tlearn: 0.0133219\ttotal: 54s\tremaining: 11m 13s\n",
      "371:\tlearn: 0.0132953\ttotal: 54.1s\tremaining: 11m 12s\n",
      "372:\tlearn: 0.0132853\ttotal: 54.2s\tremaining: 11m 12s\n",
      "373:\tlearn: 0.0132076\ttotal: 54.3s\tremaining: 11m 11s\n",
      "374:\tlearn: 0.0131770\ttotal: 54.4s\tremaining: 11m 11s\n",
      "375:\tlearn: 0.0131736\ttotal: 54.5s\tremaining: 11m 10s\n",
      "376:\tlearn: 0.0131204\ttotal: 54.6s\tremaining: 11m 9s\n",
      "377:\tlearn: 0.0131030\ttotal: 54.7s\tremaining: 11m 8s\n",
      "378:\tlearn: 0.0130855\ttotal: 54.8s\tremaining: 11m 8s\n",
      "379:\tlearn: 0.0130576\ttotal: 54.9s\tremaining: 11m 7s\n",
      "380:\tlearn: 0.0130345\ttotal: 55s\tremaining: 11m 7s\n",
      "381:\tlearn: 0.0130284\ttotal: 55.1s\tremaining: 11m 6s\n",
      "382:\tlearn: 0.0130109\ttotal: 55.2s\tremaining: 11m 5s\n",
      "383:\tlearn: 0.0129994\ttotal: 55.3s\tremaining: 11m 5s\n",
      "384:\tlearn: 0.0129913\ttotal: 55.4s\tremaining: 11m 4s\n",
      "385:\tlearn: 0.0129524\ttotal: 55.6s\tremaining: 11m 4s\n",
      "386:\tlearn: 0.0129302\ttotal: 55.7s\tremaining: 11m 3s\n",
      "387:\tlearn: 0.0129065\ttotal: 55.8s\tremaining: 11m 3s\n",
      "388:\tlearn: 0.0128995\ttotal: 55.9s\tremaining: 11m 2s\n",
      "389:\tlearn: 0.0128507\ttotal: 56s\tremaining: 11m 2s\n",
      "390:\tlearn: 0.0128326\ttotal: 56.1s\tremaining: 11m 1s\n",
      "391:\tlearn: 0.0128171\ttotal: 56.2s\tremaining: 11m\n",
      "392:\tlearn: 0.0128011\ttotal: 56.3s\tremaining: 11m\n",
      "393:\tlearn: 0.0127911\ttotal: 56.4s\tremaining: 10m 59s\n",
      "394:\tlearn: 0.0127683\ttotal: 56.5s\tremaining: 10m 59s\n",
      "395:\tlearn: 0.0127415\ttotal: 56.7s\tremaining: 10m 58s\n",
      "396:\tlearn: 0.0127248\ttotal: 56.7s\tremaining: 10m 57s\n",
      "397:\tlearn: 0.0126880\ttotal: 56.8s\tremaining: 10m 57s\n",
      "398:\tlearn: 0.0126244\ttotal: 57s\tremaining: 10m 56s\n",
      "399:\tlearn: 0.0126097\ttotal: 57.1s\tremaining: 10m 56s\n",
      "400:\tlearn: 0.0125779\ttotal: 57.2s\tremaining: 10m 55s\n",
      "401:\tlearn: 0.0125677\ttotal: 57.3s\tremaining: 10m 55s\n",
      "402:\tlearn: 0.0125598\ttotal: 57.4s\tremaining: 10m 54s\n",
      "403:\tlearn: 0.0125444\ttotal: 57.5s\tremaining: 10m 53s\n",
      "404:\tlearn: 0.0124919\ttotal: 57.6s\tremaining: 10m 53s\n",
      "405:\tlearn: 0.0124759\ttotal: 57.7s\tremaining: 10m 52s\n",
      "406:\tlearn: 0.0124516\ttotal: 57.8s\tremaining: 10m 52s\n",
      "407:\tlearn: 0.0124314\ttotal: 57.9s\tremaining: 10m 51s\n",
      "408:\tlearn: 0.0124177\ttotal: 58s\tremaining: 10m 50s\n",
      "409:\tlearn: 0.0123880\ttotal: 58.1s\tremaining: 10m 50s\n",
      "410:\tlearn: 0.0123661\ttotal: 58.2s\tremaining: 10m 49s\n",
      "411:\tlearn: 0.0123398\ttotal: 58.3s\tremaining: 10m 49s\n",
      "412:\tlearn: 0.0123254\ttotal: 58.4s\tremaining: 10m 48s\n",
      "413:\tlearn: 0.0122969\ttotal: 58.5s\tremaining: 10m 48s\n",
      "414:\tlearn: 0.0122764\ttotal: 58.6s\tremaining: 10m 47s\n",
      "415:\tlearn: 0.0122682\ttotal: 58.7s\tremaining: 10m 47s\n",
      "416:\tlearn: 0.0122508\ttotal: 58.8s\tremaining: 10m 46s\n",
      "417:\tlearn: 0.0122299\ttotal: 58.9s\tremaining: 10m 46s\n",
      "418:\tlearn: 0.0121905\ttotal: 59.1s\tremaining: 10m 45s\n",
      "419:\tlearn: 0.0121694\ttotal: 59.2s\tremaining: 10m 45s\n",
      "420:\tlearn: 0.0120752\ttotal: 59.3s\tremaining: 10m 45s\n",
      "421:\tlearn: 0.0120456\ttotal: 59.4s\tremaining: 10m 44s\n",
      "422:\tlearn: 0.0119957\ttotal: 59.5s\tremaining: 10m 44s\n",
      "423:\tlearn: 0.0119404\ttotal: 59.7s\tremaining: 10m 43s\n",
      "424:\tlearn: 0.0119107\ttotal: 59.8s\tremaining: 10m 43s\n",
      "425:\tlearn: 0.0118895\ttotal: 59.9s\tremaining: 10m 43s\n",
      "426:\tlearn: 0.0118785\ttotal: 60s\tremaining: 10m 42s\n",
      "427:\tlearn: 0.0118672\ttotal: 1m\tremaining: 10m 41s\n",
      "428:\tlearn: 0.0118520\ttotal: 1m\tremaining: 10m 41s\n",
      "429:\tlearn: 0.0118391\ttotal: 1m\tremaining: 10m 40s\n",
      "430:\tlearn: 0.0118001\ttotal: 1m\tremaining: 10m 40s\n",
      "431:\tlearn: 0.0117656\ttotal: 1m\tremaining: 10m 40s\n",
      "432:\tlearn: 0.0117458\ttotal: 1m\tremaining: 10m 39s\n",
      "433:\tlearn: 0.0117352\ttotal: 1m\tremaining: 10m 39s\n",
      "434:\tlearn: 0.0117150\ttotal: 1m\tremaining: 10m 38s\n",
      "435:\tlearn: 0.0117086\ttotal: 1m\tremaining: 10m 37s\n",
      "436:\tlearn: 0.0116868\ttotal: 1m 1s\tremaining: 10m 37s\n",
      "437:\tlearn: 0.0116683\ttotal: 1m 1s\tremaining: 10m 37s\n",
      "438:\tlearn: 0.0116429\ttotal: 1m 1s\tremaining: 10m 36s\n",
      "439:\tlearn: 0.0116169\ttotal: 1m 1s\tremaining: 10m 36s\n",
      "440:\tlearn: 0.0115752\ttotal: 1m 1s\tremaining: 10m 36s\n",
      "441:\tlearn: 0.0115604\ttotal: 1m 1s\tremaining: 10m 35s\n",
      "442:\tlearn: 0.0115502\ttotal: 1m 1s\tremaining: 10m 35s\n",
      "443:\tlearn: 0.0115297\ttotal: 1m 1s\tremaining: 10m 34s\n",
      "444:\tlearn: 0.0114630\ttotal: 1m 1s\tremaining: 10m 34s\n",
      "445:\tlearn: 0.0114479\ttotal: 1m 2s\tremaining: 10m 33s\n",
      "446:\tlearn: 0.0114404\ttotal: 1m 2s\tremaining: 10m 33s\n",
      "447:\tlearn: 0.0114260\ttotal: 1m 2s\tremaining: 10m 32s\n",
      "448:\tlearn: 0.0113560\ttotal: 1m 2s\tremaining: 10m 32s\n",
      "449:\tlearn: 0.0113200\ttotal: 1m 2s\tremaining: 10m 32s\n",
      "450:\tlearn: 0.0112938\ttotal: 1m 2s\tremaining: 10m 31s\n",
      "451:\tlearn: 0.0112585\ttotal: 1m 2s\tremaining: 10m 31s\n",
      "452:\tlearn: 0.0112496\ttotal: 1m 2s\tremaining: 10m 31s\n",
      "453:\tlearn: 0.0112338\ttotal: 1m 2s\tremaining: 10m 30s\n",
      "454:\tlearn: 0.0112071\ttotal: 1m 3s\tremaining: 10m 30s\n",
      "455:\tlearn: 0.0111771\ttotal: 1m 3s\tremaining: 10m 29s\n",
      "456:\tlearn: 0.0111398\ttotal: 1m 3s\tremaining: 10m 29s\n",
      "457:\tlearn: 0.0111064\ttotal: 1m 3s\tremaining: 10m 29s\n",
      "458:\tlearn: 0.0110716\ttotal: 1m 3s\tremaining: 10m 28s\n",
      "459:\tlearn: 0.0110431\ttotal: 1m 3s\tremaining: 10m 28s\n",
      "460:\tlearn: 0.0110291\ttotal: 1m 3s\tremaining: 10m 27s\n",
      "461:\tlearn: 0.0110104\ttotal: 1m 3s\tremaining: 10m 27s\n",
      "462:\tlearn: 0.0109640\ttotal: 1m 4s\tremaining: 10m 27s\n",
      "463:\tlearn: 0.0109393\ttotal: 1m 4s\tremaining: 10m 26s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464:\tlearn: 0.0109183\ttotal: 1m 4s\tremaining: 10m 26s\n",
      "465:\tlearn: 0.0108531\ttotal: 1m 4s\tremaining: 10m 26s\n",
      "466:\tlearn: 0.0107948\ttotal: 1m 4s\tremaining: 10m 26s\n",
      "467:\tlearn: 0.0107823\ttotal: 1m 4s\tremaining: 10m 25s\n",
      "468:\tlearn: 0.0107634\ttotal: 1m 4s\tremaining: 10m 25s\n",
      "469:\tlearn: 0.0107507\ttotal: 1m 4s\tremaining: 10m 24s\n",
      "470:\tlearn: 0.0107415\ttotal: 1m 4s\tremaining: 10m 24s\n",
      "471:\tlearn: 0.0107134\ttotal: 1m 5s\tremaining: 10m 24s\n",
      "472:\tlearn: 0.0106987\ttotal: 1m 5s\tremaining: 10m 23s\n",
      "473:\tlearn: 0.0106858\ttotal: 1m 5s\tremaining: 10m 23s\n",
      "474:\tlearn: 0.0106686\ttotal: 1m 5s\tremaining: 10m 22s\n",
      "475:\tlearn: 0.0106462\ttotal: 1m 5s\tremaining: 10m 22s\n",
      "476:\tlearn: 0.0106325\ttotal: 1m 5s\tremaining: 10m 22s\n",
      "477:\tlearn: 0.0106135\ttotal: 1m 5s\tremaining: 10m 21s\n",
      "478:\tlearn: 0.0106077\ttotal: 1m 5s\tremaining: 10m 21s\n",
      "479:\tlearn: 0.0105935\ttotal: 1m 5s\tremaining: 10m 20s\n",
      "480:\tlearn: 0.0105801\ttotal: 1m 6s\tremaining: 10m 20s\n",
      "481:\tlearn: 0.0105546\ttotal: 1m 6s\tremaining: 10m 20s\n",
      "482:\tlearn: 0.0105411\ttotal: 1m 6s\tremaining: 10m 19s\n",
      "483:\tlearn: 0.0105287\ttotal: 1m 6s\tremaining: 10m 19s\n",
      "484:\tlearn: 0.0105218\ttotal: 1m 6s\tremaining: 10m 18s\n",
      "485:\tlearn: 0.0105078\ttotal: 1m 6s\tremaining: 10m 18s\n",
      "486:\tlearn: 0.0105011\ttotal: 1m 6s\tremaining: 10m 18s\n",
      "487:\tlearn: 0.0104935\ttotal: 1m 6s\tremaining: 10m 17s\n",
      "488:\tlearn: 0.0104808\ttotal: 1m 6s\tremaining: 10m 17s\n",
      "489:\tlearn: 0.0104701\ttotal: 1m 7s\tremaining: 10m 16s\n",
      "490:\tlearn: 0.0104588\ttotal: 1m 7s\tremaining: 10m 16s\n",
      "491:\tlearn: 0.0104398\ttotal: 1m 7s\tremaining: 10m 16s\n",
      "492:\tlearn: 0.0104085\ttotal: 1m 7s\tremaining: 10m 15s\n",
      "493:\tlearn: 0.0103971\ttotal: 1m 7s\tremaining: 10m 15s\n",
      "494:\tlearn: 0.0103934\ttotal: 1m 7s\tremaining: 10m 15s\n",
      "495:\tlearn: 0.0103926\ttotal: 1m 7s\tremaining: 10m 14s\n",
      "496:\tlearn: 0.0103834\ttotal: 1m 7s\tremaining: 10m 14s\n",
      "497:\tlearn: 0.0103777\ttotal: 1m 7s\tremaining: 10m 13s\n",
      "498:\tlearn: 0.0103716\ttotal: 1m 7s\tremaining: 10m 13s\n",
      "499:\tlearn: 0.0103664\ttotal: 1m 8s\tremaining: 10m 12s\n",
      "500:\tlearn: 0.0103526\ttotal: 1m 8s\tremaining: 10m 12s\n",
      "501:\tlearn: 0.0103413\ttotal: 1m 8s\tremaining: 10m 11s\n",
      "502:\tlearn: 0.0103206\ttotal: 1m 8s\tremaining: 10m 11s\n",
      "503:\tlearn: 0.0103013\ttotal: 1m 8s\tremaining: 10m 11s\n",
      "504:\tlearn: 0.0102910\ttotal: 1m 8s\tremaining: 10m 10s\n",
      "505:\tlearn: 0.0102836\ttotal: 1m 8s\tremaining: 10m 10s\n",
      "506:\tlearn: 0.0102668\ttotal: 1m 8s\tremaining: 10m 9s\n",
      "507:\tlearn: 0.0102368\ttotal: 1m 8s\tremaining: 10m 9s\n",
      "508:\tlearn: 0.0102214\ttotal: 1m 9s\tremaining: 10m 9s\n",
      "509:\tlearn: 0.0102059\ttotal: 1m 9s\tremaining: 10m 8s\n",
      "510:\tlearn: 0.0101876\ttotal: 1m 9s\tremaining: 10m 8s\n",
      "511:\tlearn: 0.0101771\ttotal: 1m 9s\tremaining: 10m 8s\n",
      "512:\tlearn: 0.0101644\ttotal: 1m 9s\tremaining: 10m 7s\n",
      "513:\tlearn: 0.0101392\ttotal: 1m 9s\tremaining: 10m 7s\n",
      "514:\tlearn: 0.0101262\ttotal: 1m 9s\tremaining: 10m 7s\n",
      "515:\tlearn: 0.0101168\ttotal: 1m 9s\tremaining: 10m 6s\n",
      "516:\tlearn: 0.0101111\ttotal: 1m 9s\tremaining: 10m 6s\n",
      "517:\tlearn: 0.0101010\ttotal: 1m 10s\tremaining: 10m 6s\n",
      "518:\tlearn: 0.0100754\ttotal: 1m 10s\tremaining: 10m 5s\n",
      "519:\tlearn: 0.0100697\ttotal: 1m 10s\tremaining: 10m 5s\n",
      "520:\tlearn: 0.0100559\ttotal: 1m 10s\tremaining: 10m 4s\n",
      "521:\tlearn: 0.0100246\ttotal: 1m 10s\tremaining: 10m 4s\n",
      "522:\tlearn: 0.0100138\ttotal: 1m 10s\tremaining: 10m 4s\n",
      "523:\tlearn: 0.0100085\ttotal: 1m 10s\tremaining: 10m 3s\n",
      "524:\tlearn: 0.0099940\ttotal: 1m 10s\tremaining: 10m 3s\n",
      "525:\tlearn: 0.0099647\ttotal: 1m 10s\tremaining: 10m 3s\n",
      "526:\tlearn: 0.0099527\ttotal: 1m 11s\tremaining: 10m 2s\n",
      "527:\tlearn: 0.0099419\ttotal: 1m 11s\tremaining: 10m 2s\n",
      "528:\tlearn: 0.0099367\ttotal: 1m 11s\tremaining: 10m 2s\n",
      "529:\tlearn: 0.0099267\ttotal: 1m 11s\tremaining: 10m 1s\n",
      "530:\tlearn: 0.0099193\ttotal: 1m 11s\tremaining: 10m 1s\n",
      "531:\tlearn: 0.0099014\ttotal: 1m 11s\tremaining: 10m 1s\n",
      "532:\tlearn: 0.0098702\ttotal: 1m 11s\tremaining: 10m\n",
      "533:\tlearn: 0.0098667\ttotal: 1m 11s\tremaining: 10m\n",
      "534:\tlearn: 0.0098527\ttotal: 1m 11s\tremaining: 10m\n",
      "535:\tlearn: 0.0098230\ttotal: 1m 12s\tremaining: 10m\n",
      "536:\tlearn: 0.0098078\ttotal: 1m 12s\tremaining: 9m 59s\n",
      "537:\tlearn: 0.0098034\ttotal: 1m 12s\tremaining: 9m 59s\n",
      "538:\tlearn: 0.0097715\ttotal: 1m 12s\tremaining: 9m 59s\n",
      "539:\tlearn: 0.0097327\ttotal: 1m 12s\tremaining: 9m 58s\n",
      "540:\tlearn: 0.0097062\ttotal: 1m 12s\tremaining: 9m 58s\n",
      "541:\tlearn: 0.0096928\ttotal: 1m 12s\tremaining: 9m 58s\n",
      "542:\tlearn: 0.0096775\ttotal: 1m 12s\tremaining: 9m 57s\n",
      "543:\tlearn: 0.0096517\ttotal: 1m 12s\tremaining: 9m 57s\n",
      "544:\tlearn: 0.0096386\ttotal: 1m 13s\tremaining: 9m 57s\n",
      "545:\tlearn: 0.0096314\ttotal: 1m 13s\tremaining: 9m 56s\n",
      "546:\tlearn: 0.0095701\ttotal: 1m 13s\tremaining: 9m 56s\n",
      "547:\tlearn: 0.0095561\ttotal: 1m 13s\tremaining: 9m 55s\n",
      "548:\tlearn: 0.0095369\ttotal: 1m 13s\tremaining: 9m 55s\n",
      "549:\tlearn: 0.0095315\ttotal: 1m 13s\tremaining: 9m 55s\n",
      "550:\tlearn: 0.0095120\ttotal: 1m 13s\tremaining: 9m 54s\n",
      "551:\tlearn: 0.0094991\ttotal: 1m 13s\tremaining: 9m 54s\n",
      "552:\tlearn: 0.0094817\ttotal: 1m 13s\tremaining: 9m 54s\n",
      "553:\tlearn: 0.0094809\ttotal: 1m 13s\tremaining: 9m 53s\n",
      "554:\tlearn: 0.0094757\ttotal: 1m 14s\tremaining: 9m 53s\n",
      "555:\tlearn: 0.0094660\ttotal: 1m 14s\tremaining: 9m 53s\n",
      "556:\tlearn: 0.0094630\ttotal: 1m 14s\tremaining: 9m 52s\n",
      "557:\tlearn: 0.0094354\ttotal: 1m 14s\tremaining: 9m 52s\n",
      "558:\tlearn: 0.0094228\ttotal: 1m 14s\tremaining: 9m 52s\n",
      "559:\tlearn: 0.0094094\ttotal: 1m 14s\tremaining: 9m 51s\n",
      "560:\tlearn: 0.0094056\ttotal: 1m 14s\tremaining: 9m 51s\n",
      "561:\tlearn: 0.0093867\ttotal: 1m 14s\tremaining: 9m 51s\n",
      "562:\tlearn: 0.0093782\ttotal: 1m 14s\tremaining: 9m 50s\n",
      "563:\tlearn: 0.0093520\ttotal: 1m 15s\tremaining: 9m 50s\n",
      "564:\tlearn: 0.0093434\ttotal: 1m 15s\tremaining: 9m 50s\n",
      "565:\tlearn: 0.0093410\ttotal: 1m 15s\tremaining: 9m 49s\n",
      "566:\tlearn: 0.0093286\ttotal: 1m 15s\tremaining: 9m 49s\n",
      "567:\tlearn: 0.0092925\ttotal: 1m 15s\tremaining: 9m 49s\n",
      "568:\tlearn: 0.0092881\ttotal: 1m 15s\tremaining: 9m 48s\n",
      "569:\tlearn: 0.0092634\ttotal: 1m 15s\tremaining: 9m 48s\n",
      "570:\tlearn: 0.0092523\ttotal: 1m 15s\tremaining: 9m 48s\n",
      "571:\tlearn: 0.0092481\ttotal: 1m 15s\tremaining: 9m 48s\n",
      "572:\tlearn: 0.0092397\ttotal: 1m 16s\tremaining: 9m 47s\n",
      "573:\tlearn: 0.0092298\ttotal: 1m 16s\tremaining: 9m 47s\n",
      "574:\tlearn: 0.0092265\ttotal: 1m 16s\tremaining: 9m 47s\n",
      "575:\tlearn: 0.0092211\ttotal: 1m 16s\tremaining: 9m 47s\n",
      "576:\tlearn: 0.0091678\ttotal: 1m 16s\tremaining: 9m 47s\n",
      "577:\tlearn: 0.0091469\ttotal: 1m 16s\tremaining: 9m 47s\n",
      "578:\tlearn: 0.0091153\ttotal: 1m 16s\tremaining: 9m 46s\n",
      "579:\tlearn: 0.0091106\ttotal: 1m 16s\tremaining: 9m 46s\n",
      "580:\tlearn: 0.0091034\ttotal: 1m 17s\tremaining: 9m 46s\n",
      "581:\tlearn: 0.0090988\ttotal: 1m 17s\tremaining: 9m 46s\n",
      "582:\tlearn: 0.0090856\ttotal: 1m 17s\tremaining: 9m 45s\n",
      "583:\tlearn: 0.0090783\ttotal: 1m 17s\tremaining: 9m 45s\n",
      "584:\tlearn: 0.0090698\ttotal: 1m 17s\tremaining: 9m 45s\n",
      "585:\tlearn: 0.0090565\ttotal: 1m 17s\tremaining: 9m 45s\n",
      "586:\tlearn: 0.0090435\ttotal: 1m 17s\tremaining: 9m 44s\n",
      "587:\tlearn: 0.0090025\ttotal: 1m 17s\tremaining: 9m 44s\n",
      "588:\tlearn: 0.0089943\ttotal: 1m 18s\tremaining: 9m 44s\n",
      "589:\tlearn: 0.0089870\ttotal: 1m 18s\tremaining: 9m 44s\n",
      "590:\tlearn: 0.0089816\ttotal: 1m 18s\tremaining: 9m 43s\n",
      "591:\tlearn: 0.0089717\ttotal: 1m 18s\tremaining: 9m 43s\n",
      "592:\tlearn: 0.0089646\ttotal: 1m 18s\tremaining: 9m 43s\n",
      "593:\tlearn: 0.0089609\ttotal: 1m 18s\tremaining: 9m 42s\n",
      "594:\tlearn: 0.0089526\ttotal: 1m 18s\tremaining: 9m 42s\n",
      "595:\tlearn: 0.0089518\ttotal: 1m 18s\tremaining: 9m 42s\n",
      "596:\tlearn: 0.0089310\ttotal: 1m 18s\tremaining: 9m 41s\n",
      "597:\tlearn: 0.0089136\ttotal: 1m 19s\tremaining: 9m 41s\n",
      "598:\tlearn: 0.0088995\ttotal: 1m 19s\tremaining: 9m 41s\n",
      "599:\tlearn: 0.0088937\ttotal: 1m 19s\tremaining: 9m 41s\n",
      "600:\tlearn: 0.0088818\ttotal: 1m 19s\tremaining: 9m 40s\n",
      "601:\tlearn: 0.0088799\ttotal: 1m 19s\tremaining: 9m 40s\n",
      "602:\tlearn: 0.0088684\ttotal: 1m 19s\tremaining: 9m 40s\n",
      "603:\tlearn: 0.0088220\ttotal: 1m 19s\tremaining: 9m 39s\n",
      "604:\tlearn: 0.0088184\ttotal: 1m 19s\tremaining: 9m 39s\n",
      "605:\tlearn: 0.0088036\ttotal: 1m 19s\tremaining: 9m 39s\n",
      "606:\tlearn: 0.0087990\ttotal: 1m 19s\tremaining: 9m 38s\n",
      "607:\tlearn: 0.0087912\ttotal: 1m 20s\tremaining: 9m 38s\n",
      "608:\tlearn: 0.0087856\ttotal: 1m 20s\tremaining: 9m 38s\n",
      "609:\tlearn: 0.0087467\ttotal: 1m 20s\tremaining: 9m 38s\n",
      "610:\tlearn: 0.0087405\ttotal: 1m 20s\tremaining: 9m 37s\n",
      "611:\tlearn: 0.0087326\ttotal: 1m 20s\tremaining: 9m 37s\n",
      "612:\tlearn: 0.0087236\ttotal: 1m 20s\tremaining: 9m 37s\n",
      "613:\tlearn: 0.0087150\ttotal: 1m 20s\tremaining: 9m 37s\n",
      "614:\tlearn: 0.0087059\ttotal: 1m 20s\tremaining: 9m 36s\n",
      "615:\tlearn: 0.0086994\ttotal: 1m 20s\tremaining: 9m 36s\n",
      "616:\tlearn: 0.0086622\ttotal: 1m 21s\tremaining: 9m 36s\n",
      "617:\tlearn: 0.0085920\ttotal: 1m 21s\tremaining: 9m 36s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "618:\tlearn: 0.0085851\ttotal: 1m 21s\tremaining: 9m 35s\n",
      "619:\tlearn: 0.0085626\ttotal: 1m 21s\tremaining: 9m 35s\n",
      "620:\tlearn: 0.0085492\ttotal: 1m 21s\tremaining: 9m 35s\n",
      "621:\tlearn: 0.0085269\ttotal: 1m 21s\tremaining: 9m 35s\n",
      "622:\tlearn: 0.0085180\ttotal: 1m 21s\tremaining: 9m 35s\n",
      "623:\tlearn: 0.0085105\ttotal: 1m 21s\tremaining: 9m 34s\n",
      "624:\tlearn: 0.0084959\ttotal: 1m 22s\tremaining: 9m 34s\n",
      "625:\tlearn: 0.0084793\ttotal: 1m 22s\tremaining: 9m 34s\n",
      "626:\tlearn: 0.0084706\ttotal: 1m 22s\tremaining: 9m 33s\n",
      "627:\tlearn: 0.0084657\ttotal: 1m 22s\tremaining: 9m 33s\n",
      "628:\tlearn: 0.0084631\ttotal: 1m 22s\tremaining: 9m 33s\n",
      "629:\tlearn: 0.0084578\ttotal: 1m 22s\tremaining: 9m 32s\n",
      "630:\tlearn: 0.0084479\ttotal: 1m 22s\tremaining: 9m 32s\n",
      "631:\tlearn: 0.0084391\ttotal: 1m 22s\tremaining: 9m 32s\n",
      "632:\tlearn: 0.0084336\ttotal: 1m 22s\tremaining: 9m 31s\n",
      "633:\tlearn: 0.0084302\ttotal: 1m 22s\tremaining: 9m 31s\n",
      "634:\tlearn: 0.0084260\ttotal: 1m 23s\tremaining: 9m 31s\n",
      "635:\tlearn: 0.0084128\ttotal: 1m 23s\tremaining: 9m 31s\n",
      "636:\tlearn: 0.0084000\ttotal: 1m 23s\tremaining: 9m 30s\n",
      "637:\tlearn: 0.0083938\ttotal: 1m 23s\tremaining: 9m 30s\n",
      "638:\tlearn: 0.0083839\ttotal: 1m 23s\tremaining: 9m 30s\n",
      "639:\tlearn: 0.0083785\ttotal: 1m 23s\tremaining: 9m 29s\n",
      "640:\tlearn: 0.0083776\ttotal: 1m 23s\tremaining: 9m 29s\n",
      "641:\tlearn: 0.0083701\ttotal: 1m 23s\tremaining: 9m 29s\n",
      "642:\tlearn: 0.0083629\ttotal: 1m 24s\tremaining: 9m 29s\n",
      "643:\tlearn: 0.0083499\ttotal: 1m 24s\tremaining: 9m 28s\n",
      "644:\tlearn: 0.0083446\ttotal: 1m 24s\tremaining: 9m 28s\n",
      "645:\tlearn: 0.0083352\ttotal: 1m 24s\tremaining: 9m 28s\n",
      "646:\tlearn: 0.0083315\ttotal: 1m 24s\tremaining: 9m 28s\n",
      "647:\tlearn: 0.0083255\ttotal: 1m 24s\tremaining: 9m 27s\n",
      "648:\tlearn: 0.0083208\ttotal: 1m 24s\tremaining: 9m 27s\n",
      "649:\tlearn: 0.0083161\ttotal: 1m 24s\tremaining: 9m 26s\n",
      "650:\tlearn: 0.0083072\ttotal: 1m 24s\tremaining: 9m 26s\n",
      "651:\tlearn: 0.0082745\ttotal: 1m 24s\tremaining: 9m 26s\n",
      "652:\tlearn: 0.0082599\ttotal: 1m 25s\tremaining: 9m 26s\n",
      "653:\tlearn: 0.0082539\ttotal: 1m 25s\tremaining: 9m 25s\n",
      "654:\tlearn: 0.0082401\ttotal: 1m 25s\tremaining: 9m 25s\n",
      "655:\tlearn: 0.0082367\ttotal: 1m 25s\tremaining: 9m 25s\n",
      "656:\tlearn: 0.0082046\ttotal: 1m 25s\tremaining: 9m 25s\n",
      "657:\tlearn: 0.0081968\ttotal: 1m 25s\tremaining: 9m 24s\n",
      "658:\tlearn: 0.0081945\ttotal: 1m 25s\tremaining: 9m 24s\n",
      "659:\tlearn: 0.0081769\ttotal: 1m 25s\tremaining: 9m 24s\n",
      "660:\tlearn: 0.0081679\ttotal: 1m 25s\tremaining: 9m 24s\n",
      "661:\tlearn: 0.0081632\ttotal: 1m 26s\tremaining: 9m 23s\n",
      "662:\tlearn: 0.0081481\ttotal: 1m 26s\tremaining: 9m 23s\n",
      "663:\tlearn: 0.0081198\ttotal: 1m 26s\tremaining: 9m 23s\n",
      "664:\tlearn: 0.0081028\ttotal: 1m 26s\tremaining: 9m 23s\n",
      "665:\tlearn: 0.0080964\ttotal: 1m 26s\tremaining: 9m 22s\n",
      "666:\tlearn: 0.0080847\ttotal: 1m 26s\tremaining: 9m 22s\n",
      "667:\tlearn: 0.0080715\ttotal: 1m 26s\tremaining: 9m 22s\n",
      "668:\tlearn: 0.0080621\ttotal: 1m 26s\tremaining: 9m 22s\n",
      "669:\tlearn: 0.0080064\ttotal: 1m 26s\tremaining: 9m 21s\n",
      "670:\tlearn: 0.0080051\ttotal: 1m 27s\tremaining: 9m 21s\n",
      "671:\tlearn: 0.0079964\ttotal: 1m 27s\tremaining: 9m 21s\n",
      "672:\tlearn: 0.0079843\ttotal: 1m 27s\tremaining: 9m 21s\n",
      "673:\tlearn: 0.0079592\ttotal: 1m 27s\tremaining: 9m 20s\n",
      "674:\tlearn: 0.0079474\ttotal: 1m 27s\tremaining: 9m 20s\n",
      "675:\tlearn: 0.0079434\ttotal: 1m 27s\tremaining: 9m 20s\n",
      "676:\tlearn: 0.0079345\ttotal: 1m 27s\tremaining: 9m 20s\n",
      "677:\tlearn: 0.0079205\ttotal: 1m 27s\tremaining: 9m 20s\n",
      "678:\tlearn: 0.0078903\ttotal: 1m 28s\tremaining: 9m 20s\n",
      "679:\tlearn: 0.0078828\ttotal: 1m 28s\tremaining: 9m 19s\n",
      "680:\tlearn: 0.0078775\ttotal: 1m 28s\tremaining: 9m 19s\n",
      "681:\tlearn: 0.0078752\ttotal: 1m 28s\tremaining: 9m 19s\n",
      "682:\tlearn: 0.0078661\ttotal: 1m 28s\tremaining: 9m 18s\n",
      "683:\tlearn: 0.0078643\ttotal: 1m 28s\tremaining: 9m 18s\n",
      "684:\tlearn: 0.0078576\ttotal: 1m 28s\tremaining: 9m 18s\n",
      "685:\tlearn: 0.0078544\ttotal: 1m 28s\tremaining: 9m 17s\n",
      "686:\tlearn: 0.0078486\ttotal: 1m 28s\tremaining: 9m 17s\n",
      "687:\tlearn: 0.0078410\ttotal: 1m 28s\tremaining: 9m 17s\n",
      "688:\tlearn: 0.0078329\ttotal: 1m 29s\tremaining: 9m 17s\n",
      "689:\tlearn: 0.0078280\ttotal: 1m 29s\tremaining: 9m 17s\n",
      "690:\tlearn: 0.0078213\ttotal: 1m 29s\tremaining: 9m 16s\n",
      "691:\tlearn: 0.0078126\ttotal: 1m 29s\tremaining: 9m 16s\n",
      "692:\tlearn: 0.0078055\ttotal: 1m 29s\tremaining: 9m 16s\n",
      "693:\tlearn: 0.0077775\ttotal: 1m 29s\tremaining: 9m 16s\n",
      "694:\tlearn: 0.0077674\ttotal: 1m 29s\tremaining: 9m 15s\n",
      "695:\tlearn: 0.0077464\ttotal: 1m 29s\tremaining: 9m 15s\n",
      "696:\tlearn: 0.0077231\ttotal: 1m 29s\tremaining: 9m 15s\n",
      "697:\tlearn: 0.0077058\ttotal: 1m 30s\tremaining: 9m 15s\n",
      "698:\tlearn: 0.0076971\ttotal: 1m 30s\tremaining: 9m 14s\n",
      "699:\tlearn: 0.0076914\ttotal: 1m 30s\tremaining: 9m 14s\n",
      "700:\tlearn: 0.0076835\ttotal: 1m 30s\tremaining: 9m 14s\n",
      "701:\tlearn: 0.0076811\ttotal: 1m 30s\tremaining: 9m 14s\n",
      "702:\tlearn: 0.0076785\ttotal: 1m 30s\tremaining: 9m 13s\n",
      "703:\tlearn: 0.0076743\ttotal: 1m 30s\tremaining: 9m 13s\n",
      "704:\tlearn: 0.0076532\ttotal: 1m 30s\tremaining: 9m 13s\n",
      "705:\tlearn: 0.0076490\ttotal: 1m 30s\tremaining: 9m 12s\n",
      "706:\tlearn: 0.0076432\ttotal: 1m 31s\tremaining: 9m 12s\n",
      "707:\tlearn: 0.0076236\ttotal: 1m 31s\tremaining: 9m 12s\n",
      "708:\tlearn: 0.0076088\ttotal: 1m 31s\tremaining: 9m 12s\n",
      "709:\tlearn: 0.0075671\ttotal: 1m 31s\tremaining: 9m 11s\n",
      "710:\tlearn: 0.0075539\ttotal: 1m 31s\tremaining: 9m 11s\n",
      "711:\tlearn: 0.0075466\ttotal: 1m 31s\tremaining: 9m 11s\n",
      "712:\tlearn: 0.0075231\ttotal: 1m 31s\tremaining: 9m 11s\n",
      "713:\tlearn: 0.0075120\ttotal: 1m 31s\tremaining: 9m 11s\n",
      "714:\tlearn: 0.0075100\ttotal: 1m 31s\tremaining: 9m 10s\n",
      "715:\tlearn: 0.0075054\ttotal: 1m 32s\tremaining: 9m 10s\n",
      "716:\tlearn: 0.0075028\ttotal: 1m 32s\tremaining: 9m 10s\n",
      "717:\tlearn: 0.0075020\ttotal: 1m 32s\tremaining: 9m 10s\n",
      "718:\tlearn: 0.0074661\ttotal: 1m 32s\tremaining: 9m 10s\n",
      "719:\tlearn: 0.0074631\ttotal: 1m 32s\tremaining: 9m 9s\n",
      "720:\tlearn: 0.0074557\ttotal: 1m 32s\tremaining: 9m 9s\n",
      "721:\tlearn: 0.0074466\ttotal: 1m 32s\tremaining: 9m 9s\n",
      "722:\tlearn: 0.0074448\ttotal: 1m 32s\tremaining: 9m 8s\n",
      "723:\tlearn: 0.0074393\ttotal: 1m 32s\tremaining: 9m 8s\n",
      "724:\tlearn: 0.0074368\ttotal: 1m 33s\tremaining: 9m 8s\n",
      "725:\tlearn: 0.0074335\ttotal: 1m 33s\tremaining: 9m 8s\n",
      "726:\tlearn: 0.0074242\ttotal: 1m 33s\tremaining: 9m 7s\n",
      "727:\tlearn: 0.0074218\ttotal: 1m 33s\tremaining: 9m 7s\n",
      "728:\tlearn: 0.0074108\ttotal: 1m 33s\tremaining: 9m 7s\n",
      "729:\tlearn: 0.0074073\ttotal: 1m 33s\tremaining: 9m 7s\n",
      "730:\tlearn: 0.0074041\ttotal: 1m 33s\tremaining: 9m 6s\n",
      "731:\tlearn: 0.0073881\ttotal: 1m 33s\tremaining: 9m 6s\n",
      "732:\tlearn: 0.0073852\ttotal: 1m 33s\tremaining: 9m 6s\n",
      "733:\tlearn: 0.0073847\ttotal: 1m 33s\tremaining: 9m 5s\n",
      "734:\tlearn: 0.0073814\ttotal: 1m 34s\tremaining: 9m 5s\n",
      "735:\tlearn: 0.0073724\ttotal: 1m 34s\tremaining: 9m 5s\n",
      "736:\tlearn: 0.0073661\ttotal: 1m 34s\tremaining: 9m 5s\n",
      "737:\tlearn: 0.0073576\ttotal: 1m 34s\tremaining: 9m 5s\n",
      "738:\tlearn: 0.0073565\ttotal: 1m 34s\tremaining: 9m 4s\n",
      "739:\tlearn: 0.0073453\ttotal: 1m 34s\tremaining: 9m 4s\n",
      "740:\tlearn: 0.0073254\ttotal: 1m 34s\tremaining: 9m 4s\n",
      "741:\tlearn: 0.0073059\ttotal: 1m 34s\tremaining: 9m 4s\n",
      "742:\tlearn: 0.0072811\ttotal: 1m 34s\tremaining: 9m 4s\n",
      "743:\tlearn: 0.0072753\ttotal: 1m 35s\tremaining: 9m 4s\n",
      "744:\tlearn: 0.0072677\ttotal: 1m 35s\tremaining: 9m 3s\n",
      "745:\tlearn: 0.0072652\ttotal: 1m 35s\tremaining: 9m 3s\n",
      "746:\tlearn: 0.0072564\ttotal: 1m 35s\tremaining: 9m 3s\n",
      "747:\tlearn: 0.0072520\ttotal: 1m 35s\tremaining: 9m 3s\n",
      "748:\tlearn: 0.0072498\ttotal: 1m 35s\tremaining: 9m 2s\n",
      "749:\tlearn: 0.0072435\ttotal: 1m 35s\tremaining: 9m 2s\n",
      "750:\tlearn: 0.0072399\ttotal: 1m 35s\tremaining: 9m 2s\n",
      "751:\tlearn: 0.0072340\ttotal: 1m 35s\tremaining: 9m 2s\n",
      "752:\tlearn: 0.0072229\ttotal: 1m 36s\tremaining: 9m 1s\n",
      "753:\tlearn: 0.0072099\ttotal: 1m 36s\tremaining: 9m 1s\n",
      "754:\tlearn: 0.0071752\ttotal: 1m 36s\tremaining: 9m 1s\n",
      "755:\tlearn: 0.0071719\ttotal: 1m 36s\tremaining: 9m 1s\n",
      "756:\tlearn: 0.0071659\ttotal: 1m 36s\tremaining: 9m 1s\n",
      "757:\tlearn: 0.0071531\ttotal: 1m 36s\tremaining: 9m\n",
      "758:\tlearn: 0.0071494\ttotal: 1m 36s\tremaining: 9m\n",
      "759:\tlearn: 0.0071468\ttotal: 1m 36s\tremaining: 9m\n",
      "760:\tlearn: 0.0071350\ttotal: 1m 37s\tremaining: 9m\n",
      "761:\tlearn: 0.0071255\ttotal: 1m 37s\tremaining: 9m\n",
      "762:\tlearn: 0.0071232\ttotal: 1m 37s\tremaining: 9m\n",
      "763:\tlearn: 0.0071078\ttotal: 1m 37s\tremaining: 9m\n",
      "764:\tlearn: 0.0071012\ttotal: 1m 37s\tremaining: 8m 59s\n",
      "765:\tlearn: 0.0070866\ttotal: 1m 37s\tremaining: 8m 59s\n",
      "766:\tlearn: 0.0070796\ttotal: 1m 37s\tremaining: 8m 59s\n",
      "767:\tlearn: 0.0070747\ttotal: 1m 37s\tremaining: 8m 59s\n",
      "768:\tlearn: 0.0070690\ttotal: 1m 37s\tremaining: 8m 59s\n",
      "769:\tlearn: 0.0070589\ttotal: 1m 38s\tremaining: 8m 58s\n",
      "770:\tlearn: 0.0070490\ttotal: 1m 38s\tremaining: 8m 58s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "771:\tlearn: 0.0070443\ttotal: 1m 38s\tremaining: 8m 58s\n",
      "772:\tlearn: 0.0070430\ttotal: 1m 38s\tremaining: 8m 58s\n",
      "773:\tlearn: 0.0070358\ttotal: 1m 38s\tremaining: 8m 58s\n",
      "774:\tlearn: 0.0070229\ttotal: 1m 38s\tremaining: 8m 58s\n",
      "775:\tlearn: 0.0070174\ttotal: 1m 38s\tremaining: 8m 57s\n",
      "776:\tlearn: 0.0070136\ttotal: 1m 38s\tremaining: 8m 57s\n",
      "777:\tlearn: 0.0070085\ttotal: 1m 39s\tremaining: 8m 57s\n",
      "778:\tlearn: 0.0070030\ttotal: 1m 39s\tremaining: 8m 57s\n",
      "779:\tlearn: 0.0069979\ttotal: 1m 39s\tremaining: 8m 57s\n",
      "780:\tlearn: 0.0069961\ttotal: 1m 39s\tremaining: 8m 56s\n",
      "781:\tlearn: 0.0069927\ttotal: 1m 39s\tremaining: 8m 56s\n",
      "782:\tlearn: 0.0069871\ttotal: 1m 39s\tremaining: 8m 56s\n",
      "783:\tlearn: 0.0069859\ttotal: 1m 39s\tremaining: 8m 56s\n",
      "784:\tlearn: 0.0069843\ttotal: 1m 39s\tremaining: 8m 56s\n",
      "785:\tlearn: 0.0069702\ttotal: 1m 40s\tremaining: 8m 56s\n",
      "786:\tlearn: 0.0069671\ttotal: 1m 40s\tremaining: 8m 56s\n",
      "787:\tlearn: 0.0069603\ttotal: 1m 40s\tremaining: 8m 56s\n",
      "788:\tlearn: 0.0069490\ttotal: 1m 40s\tremaining: 8m 56s\n",
      "789:\tlearn: 0.0069413\ttotal: 1m 40s\tremaining: 8m 56s\n",
      "790:\tlearn: 0.0069371\ttotal: 1m 40s\tremaining: 8m 56s\n",
      "791:\tlearn: 0.0069279\ttotal: 1m 40s\tremaining: 8m 55s\n",
      "792:\tlearn: 0.0069190\ttotal: 1m 40s\tremaining: 8m 55s\n",
      "793:\tlearn: 0.0069067\ttotal: 1m 41s\tremaining: 8m 55s\n",
      "794:\tlearn: 0.0068962\ttotal: 1m 41s\tremaining: 8m 55s\n",
      "795:\tlearn: 0.0068909\ttotal: 1m 41s\tremaining: 8m 55s\n",
      "796:\tlearn: 0.0068811\ttotal: 1m 41s\tremaining: 8m 54s\n",
      "797:\tlearn: 0.0068722\ttotal: 1m 41s\tremaining: 8m 54s\n",
      "798:\tlearn: 0.0068632\ttotal: 1m 41s\tremaining: 8m 54s\n",
      "799:\tlearn: 0.0068437\ttotal: 1m 41s\tremaining: 8m 54s\n",
      "800:\tlearn: 0.0068422\ttotal: 1m 41s\tremaining: 8m 54s\n",
      "801:\tlearn: 0.0068380\ttotal: 1m 41s\tremaining: 8m 53s\n",
      "802:\tlearn: 0.0068181\ttotal: 1m 42s\tremaining: 8m 53s\n",
      "803:\tlearn: 0.0068050\ttotal: 1m 42s\tremaining: 8m 53s\n",
      "804:\tlearn: 0.0068009\ttotal: 1m 42s\tremaining: 8m 53s\n",
      "805:\tlearn: 0.0067989\ttotal: 1m 42s\tremaining: 8m 53s\n",
      "806:\tlearn: 0.0067903\ttotal: 1m 42s\tremaining: 8m 52s\n",
      "807:\tlearn: 0.0067793\ttotal: 1m 42s\tremaining: 8m 52s\n",
      "808:\tlearn: 0.0067704\ttotal: 1m 42s\tremaining: 8m 52s\n",
      "809:\tlearn: 0.0067662\ttotal: 1m 42s\tremaining: 8m 52s\n",
      "810:\tlearn: 0.0067625\ttotal: 1m 43s\tremaining: 8m 52s\n",
      "811:\tlearn: 0.0067600\ttotal: 1m 43s\tremaining: 8m 51s\n",
      "812:\tlearn: 0.0067543\ttotal: 1m 43s\tremaining: 8m 51s\n",
      "813:\tlearn: 0.0067429\ttotal: 1m 43s\tremaining: 8m 51s\n",
      "814:\tlearn: 0.0067425\ttotal: 1m 43s\tremaining: 8m 51s\n",
      "815:\tlearn: 0.0067400\ttotal: 1m 43s\tremaining: 8m 51s\n",
      "816:\tlearn: 0.0067302\ttotal: 1m 43s\tremaining: 8m 50s\n",
      "817:\tlearn: 0.0067262\ttotal: 1m 43s\tremaining: 8m 50s\n",
      "818:\tlearn: 0.0067155\ttotal: 1m 43s\tremaining: 8m 50s\n",
      "819:\tlearn: 0.0067142\ttotal: 1m 43s\tremaining: 8m 50s\n",
      "820:\tlearn: 0.0067063\ttotal: 1m 44s\tremaining: 8m 49s\n",
      "821:\tlearn: 0.0066931\ttotal: 1m 44s\tremaining: 8m 49s\n",
      "822:\tlearn: 0.0066846\ttotal: 1m 44s\tremaining: 8m 49s\n",
      "823:\tlearn: 0.0066636\ttotal: 1m 44s\tremaining: 8m 49s\n",
      "824:\tlearn: 0.0066547\ttotal: 1m 44s\tremaining: 8m 49s\n",
      "825:\tlearn: 0.0066526\ttotal: 1m 44s\tremaining: 8m 48s\n",
      "826:\tlearn: 0.0066333\ttotal: 1m 44s\tremaining: 8m 48s\n",
      "827:\tlearn: 0.0066254\ttotal: 1m 44s\tremaining: 8m 48s\n",
      "828:\tlearn: 0.0066220\ttotal: 1m 45s\tremaining: 8m 48s\n",
      "829:\tlearn: 0.0066165\ttotal: 1m 45s\tremaining: 8m 48s\n",
      "830:\tlearn: 0.0066121\ttotal: 1m 45s\tremaining: 8m 48s\n",
      "831:\tlearn: 0.0066078\ttotal: 1m 45s\tremaining: 8m 47s\n",
      "832:\tlearn: 0.0066017\ttotal: 1m 45s\tremaining: 8m 47s\n",
      "833:\tlearn: 0.0065941\ttotal: 1m 45s\tremaining: 8m 47s\n",
      "834:\tlearn: 0.0065894\ttotal: 1m 45s\tremaining: 8m 47s\n",
      "835:\tlearn: 0.0065819\ttotal: 1m 45s\tremaining: 8m 47s\n",
      "836:\tlearn: 0.0065783\ttotal: 1m 45s\tremaining: 8m 46s\n",
      "837:\tlearn: 0.0065742\ttotal: 1m 46s\tremaining: 8m 46s\n",
      "838:\tlearn: 0.0065673\ttotal: 1m 46s\tremaining: 8m 46s\n",
      "839:\tlearn: 0.0065577\ttotal: 1m 46s\tremaining: 8m 46s\n",
      "840:\tlearn: 0.0065510\ttotal: 1m 46s\tremaining: 8m 46s\n",
      "841:\tlearn: 0.0065455\ttotal: 1m 46s\tremaining: 8m 45s\n",
      "842:\tlearn: 0.0065407\ttotal: 1m 46s\tremaining: 8m 45s\n",
      "843:\tlearn: 0.0065313\ttotal: 1m 46s\tremaining: 8m 45s\n",
      "844:\tlearn: 0.0065298\ttotal: 1m 46s\tremaining: 8m 45s\n",
      "845:\tlearn: 0.0065227\ttotal: 1m 46s\tremaining: 8m 45s\n",
      "846:\tlearn: 0.0065075\ttotal: 1m 47s\tremaining: 8m 44s\n",
      "847:\tlearn: 0.0065032\ttotal: 1m 47s\tremaining: 8m 44s\n",
      "848:\tlearn: 0.0064962\ttotal: 1m 47s\tremaining: 8m 44s\n",
      "849:\tlearn: 0.0064912\ttotal: 1m 47s\tremaining: 8m 44s\n",
      "850:\tlearn: 0.0064880\ttotal: 1m 47s\tremaining: 8m 44s\n",
      "851:\tlearn: 0.0064853\ttotal: 1m 47s\tremaining: 8m 43s\n",
      "852:\tlearn: 0.0064840\ttotal: 1m 47s\tremaining: 8m 43s\n",
      "853:\tlearn: 0.0064762\ttotal: 1m 47s\tremaining: 8m 43s\n",
      "854:\tlearn: 0.0064747\ttotal: 1m 47s\tremaining: 8m 43s\n",
      "855:\tlearn: 0.0064660\ttotal: 1m 48s\tremaining: 8m 42s\n",
      "856:\tlearn: 0.0064547\ttotal: 1m 48s\tremaining: 8m 42s\n",
      "857:\tlearn: 0.0064432\ttotal: 1m 48s\tremaining: 8m 42s\n",
      "858:\tlearn: 0.0064329\ttotal: 1m 48s\tremaining: 8m 42s\n",
      "859:\tlearn: 0.0064284\ttotal: 1m 48s\tremaining: 8m 42s\n",
      "860:\tlearn: 0.0064225\ttotal: 1m 48s\tremaining: 8m 41s\n",
      "861:\tlearn: 0.0064147\ttotal: 1m 48s\tremaining: 8m 41s\n",
      "862:\tlearn: 0.0064105\ttotal: 1m 48s\tremaining: 8m 41s\n",
      "863:\tlearn: 0.0064091\ttotal: 1m 48s\tremaining: 8m 41s\n",
      "864:\tlearn: 0.0064035\ttotal: 1m 48s\tremaining: 8m 40s\n",
      "865:\tlearn: 0.0063978\ttotal: 1m 49s\tremaining: 8m 40s\n",
      "866:\tlearn: 0.0063888\ttotal: 1m 49s\tremaining: 8m 40s\n",
      "867:\tlearn: 0.0063874\ttotal: 1m 49s\tremaining: 8m 40s\n",
      "868:\tlearn: 0.0063843\ttotal: 1m 49s\tremaining: 8m 40s\n",
      "869:\tlearn: 0.0063796\ttotal: 1m 49s\tremaining: 8m 40s\n",
      "870:\tlearn: 0.0063725\ttotal: 1m 49s\tremaining: 8m 39s\n",
      "871:\tlearn: 0.0063638\ttotal: 1m 49s\tremaining: 8m 39s\n",
      "872:\tlearn: 0.0063616\ttotal: 1m 49s\tremaining: 8m 39s\n",
      "873:\tlearn: 0.0063601\ttotal: 1m 50s\tremaining: 8m 39s\n",
      "874:\tlearn: 0.0063572\ttotal: 1m 50s\tremaining: 8m 39s\n",
      "875:\tlearn: 0.0063452\ttotal: 1m 50s\tremaining: 8m 38s\n",
      "876:\tlearn: 0.0063448\ttotal: 1m 50s\tremaining: 8m 38s\n",
      "877:\tlearn: 0.0063367\ttotal: 1m 50s\tremaining: 8m 38s\n",
      "878:\tlearn: 0.0063314\ttotal: 1m 50s\tremaining: 8m 38s\n",
      "879:\tlearn: 0.0063221\ttotal: 1m 50s\tremaining: 8m 38s\n",
      "880:\tlearn: 0.0063205\ttotal: 1m 50s\tremaining: 8m 37s\n",
      "881:\tlearn: 0.0063106\ttotal: 1m 50s\tremaining: 8m 37s\n",
      "882:\tlearn: 0.0063042\ttotal: 1m 50s\tremaining: 8m 37s\n",
      "883:\tlearn: 0.0062990\ttotal: 1m 51s\tremaining: 8m 37s\n",
      "884:\tlearn: 0.0062751\ttotal: 1m 51s\tremaining: 8m 37s\n",
      "885:\tlearn: 0.0062683\ttotal: 1m 51s\tremaining: 8m 36s\n",
      "886:\tlearn: 0.0062609\ttotal: 1m 51s\tremaining: 8m 36s\n",
      "887:\tlearn: 0.0062545\ttotal: 1m 51s\tremaining: 8m 36s\n",
      "888:\tlearn: 0.0062476\ttotal: 1m 51s\tremaining: 8m 36s\n",
      "889:\tlearn: 0.0062208\ttotal: 1m 51s\tremaining: 8m 36s\n",
      "890:\tlearn: 0.0062111\ttotal: 1m 51s\tremaining: 8m 36s\n",
      "891:\tlearn: 0.0062068\ttotal: 1m 52s\tremaining: 8m 35s\n",
      "892:\tlearn: 0.0062051\ttotal: 1m 52s\tremaining: 8m 35s\n",
      "893:\tlearn: 0.0062013\ttotal: 1m 52s\tremaining: 8m 35s\n",
      "894:\tlearn: 0.0061897\ttotal: 1m 52s\tremaining: 8m 35s\n",
      "895:\tlearn: 0.0061881\ttotal: 1m 52s\tremaining: 8m 35s\n",
      "896:\tlearn: 0.0061845\ttotal: 1m 52s\tremaining: 8m 34s\n",
      "897:\tlearn: 0.0061687\ttotal: 1m 52s\tremaining: 8m 34s\n",
      "898:\tlearn: 0.0061631\ttotal: 1m 52s\tremaining: 8m 34s\n",
      "899:\tlearn: 0.0061521\ttotal: 1m 52s\tremaining: 8m 34s\n",
      "900:\tlearn: 0.0061437\ttotal: 1m 52s\tremaining: 8m 34s\n",
      "901:\tlearn: 0.0061411\ttotal: 1m 53s\tremaining: 8m 33s\n",
      "902:\tlearn: 0.0061366\ttotal: 1m 53s\tremaining: 8m 33s\n",
      "903:\tlearn: 0.0061352\ttotal: 1m 53s\tremaining: 8m 33s\n",
      "904:\tlearn: 0.0061223\ttotal: 1m 53s\tremaining: 8m 33s\n",
      "905:\tlearn: 0.0061108\ttotal: 1m 53s\tremaining: 8m 33s\n",
      "906:\tlearn: 0.0061062\ttotal: 1m 53s\tremaining: 8m 32s\n",
      "907:\tlearn: 0.0060993\ttotal: 1m 53s\tremaining: 8m 32s\n",
      "908:\tlearn: 0.0060975\ttotal: 1m 53s\tremaining: 8m 32s\n",
      "909:\tlearn: 0.0060968\ttotal: 1m 53s\tremaining: 8m 32s\n",
      "910:\tlearn: 0.0060845\ttotal: 1m 54s\tremaining: 8m 32s\n",
      "911:\tlearn: 0.0060769\ttotal: 1m 54s\tremaining: 8m 31s\n",
      "912:\tlearn: 0.0060721\ttotal: 1m 54s\tremaining: 8m 31s\n",
      "913:\tlearn: 0.0060653\ttotal: 1m 54s\tremaining: 8m 31s\n",
      "914:\tlearn: 0.0060609\ttotal: 1m 54s\tremaining: 8m 31s\n",
      "915:\tlearn: 0.0060512\ttotal: 1m 54s\tremaining: 8m 31s\n",
      "916:\tlearn: 0.0060449\ttotal: 1m 54s\tremaining: 8m 31s\n",
      "917:\tlearn: 0.0060382\ttotal: 1m 54s\tremaining: 8m 30s\n",
      "918:\tlearn: 0.0060332\ttotal: 1m 54s\tremaining: 8m 30s\n",
      "919:\tlearn: 0.0060327\ttotal: 1m 55s\tremaining: 8m 30s\n",
      "920:\tlearn: 0.0060302\ttotal: 1m 55s\tremaining: 8m 30s\n",
      "921:\tlearn: 0.0060266\ttotal: 1m 55s\tremaining: 8m 29s\n",
      "922:\tlearn: 0.0060210\ttotal: 1m 55s\tremaining: 8m 29s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "923:\tlearn: 0.0060079\ttotal: 1m 55s\tremaining: 8m 29s\n",
      "924:\tlearn: 0.0060007\ttotal: 1m 55s\tremaining: 8m 29s\n",
      "925:\tlearn: 0.0059960\ttotal: 1m 55s\tremaining: 8m 29s\n",
      "926:\tlearn: 0.0059829\ttotal: 1m 55s\tremaining: 8m 29s\n",
      "927:\tlearn: 0.0059754\ttotal: 1m 55s\tremaining: 8m 28s\n",
      "928:\tlearn: 0.0059702\ttotal: 1m 56s\tremaining: 8m 28s\n",
      "929:\tlearn: 0.0059635\ttotal: 1m 56s\tremaining: 8m 28s\n",
      "930:\tlearn: 0.0059615\ttotal: 1m 56s\tremaining: 8m 28s\n",
      "931:\tlearn: 0.0059563\ttotal: 1m 56s\tremaining: 8m 28s\n",
      "932:\tlearn: 0.0059512\ttotal: 1m 56s\tremaining: 8m 27s\n",
      "933:\tlearn: 0.0059422\ttotal: 1m 56s\tremaining: 8m 27s\n",
      "934:\tlearn: 0.0059387\ttotal: 1m 56s\tremaining: 8m 27s\n",
      "935:\tlearn: 0.0059340\ttotal: 1m 56s\tremaining: 8m 27s\n",
      "936:\tlearn: 0.0059277\ttotal: 1m 56s\tremaining: 8m 27s\n",
      "937:\tlearn: 0.0059268\ttotal: 1m 57s\tremaining: 8m 27s\n",
      "938:\tlearn: 0.0059230\ttotal: 1m 57s\tremaining: 8m 26s\n",
      "939:\tlearn: 0.0059190\ttotal: 1m 57s\tremaining: 8m 26s\n",
      "940:\tlearn: 0.0059037\ttotal: 1m 57s\tremaining: 8m 26s\n",
      "941:\tlearn: 0.0058991\ttotal: 1m 57s\tremaining: 8m 26s\n",
      "942:\tlearn: 0.0058980\ttotal: 1m 57s\tremaining: 8m 26s\n",
      "943:\tlearn: 0.0058959\ttotal: 1m 57s\tremaining: 8m 25s\n",
      "944:\tlearn: 0.0058934\ttotal: 1m 57s\tremaining: 8m 25s\n",
      "945:\tlearn: 0.0058915\ttotal: 1m 57s\tremaining: 8m 25s\n",
      "946:\tlearn: 0.0058871\ttotal: 1m 58s\tremaining: 8m 25s\n",
      "947:\tlearn: 0.0058812\ttotal: 1m 58s\tremaining: 8m 24s\n",
      "948:\tlearn: 0.0058759\ttotal: 1m 58s\tremaining: 8m 24s\n",
      "949:\tlearn: 0.0058705\ttotal: 1m 58s\tremaining: 8m 24s\n",
      "950:\tlearn: 0.0058669\ttotal: 1m 58s\tremaining: 8m 24s\n",
      "951:\tlearn: 0.0058643\ttotal: 1m 58s\tremaining: 8m 24s\n",
      "952:\tlearn: 0.0058564\ttotal: 1m 58s\tremaining: 8m 24s\n",
      "953:\tlearn: 0.0058555\ttotal: 1m 58s\tremaining: 8m 23s\n",
      "954:\tlearn: 0.0058530\ttotal: 1m 58s\tremaining: 8m 23s\n",
      "955:\tlearn: 0.0058471\ttotal: 1m 58s\tremaining: 8m 23s\n",
      "956:\tlearn: 0.0058417\ttotal: 1m 59s\tremaining: 8m 23s\n",
      "957:\tlearn: 0.0058350\ttotal: 1m 59s\tremaining: 8m 23s\n",
      "958:\tlearn: 0.0058276\ttotal: 1m 59s\tremaining: 8m 22s\n",
      "959:\tlearn: 0.0058221\ttotal: 1m 59s\tremaining: 8m 22s\n",
      "960:\tlearn: 0.0058195\ttotal: 1m 59s\tremaining: 8m 22s\n",
      "961:\tlearn: 0.0058166\ttotal: 1m 59s\tremaining: 8m 22s\n",
      "962:\tlearn: 0.0058129\ttotal: 1m 59s\tremaining: 8m 22s\n",
      "963:\tlearn: 0.0058114\ttotal: 1m 59s\tremaining: 8m 21s\n",
      "964:\tlearn: 0.0058072\ttotal: 1m 59s\tremaining: 8m 21s\n",
      "965:\tlearn: 0.0058016\ttotal: 2m\tremaining: 8m 21s\n",
      "966:\tlearn: 0.0057879\ttotal: 2m\tremaining: 8m 21s\n",
      "967:\tlearn: 0.0057791\ttotal: 2m\tremaining: 8m 21s\n",
      "968:\tlearn: 0.0057769\ttotal: 2m\tremaining: 8m 20s\n",
      "969:\tlearn: 0.0057732\ttotal: 2m\tremaining: 8m 20s\n",
      "970:\tlearn: 0.0057467\ttotal: 2m\tremaining: 8m 20s\n",
      "971:\tlearn: 0.0057452\ttotal: 2m\tremaining: 8m 20s\n",
      "972:\tlearn: 0.0057398\ttotal: 2m\tremaining: 8m 20s\n",
      "973:\tlearn: 0.0057365\ttotal: 2m\tremaining: 8m 19s\n",
      "974:\tlearn: 0.0057335\ttotal: 2m 1s\tremaining: 8m 19s\n",
      "975:\tlearn: 0.0057256\ttotal: 2m 1s\tremaining: 8m 19s\n",
      "976:\tlearn: 0.0057175\ttotal: 2m 1s\tremaining: 8m 19s\n",
      "977:\tlearn: 0.0057132\ttotal: 2m 1s\tremaining: 8m 19s\n",
      "978:\tlearn: 0.0057102\ttotal: 2m 1s\tremaining: 8m 19s\n",
      "979:\tlearn: 0.0057082\ttotal: 2m 1s\tremaining: 8m 18s\n",
      "980:\tlearn: 0.0057057\ttotal: 2m 1s\tremaining: 8m 18s\n",
      "981:\tlearn: 0.0056967\ttotal: 2m 1s\tremaining: 8m 18s\n",
      "982:\tlearn: 0.0056921\ttotal: 2m 1s\tremaining: 8m 18s\n",
      "983:\tlearn: 0.0056885\ttotal: 2m 2s\tremaining: 8m 18s\n",
      "984:\tlearn: 0.0056868\ttotal: 2m 2s\tremaining: 8m 18s\n",
      "985:\tlearn: 0.0056777\ttotal: 2m 2s\tremaining: 8m 17s\n",
      "986:\tlearn: 0.0056728\ttotal: 2m 2s\tremaining: 8m 17s\n",
      "987:\tlearn: 0.0056635\ttotal: 2m 2s\tremaining: 8m 17s\n",
      "988:\tlearn: 0.0056595\ttotal: 2m 2s\tremaining: 8m 17s\n",
      "989:\tlearn: 0.0056487\ttotal: 2m 2s\tremaining: 8m 17s\n",
      "990:\tlearn: 0.0056449\ttotal: 2m 2s\tremaining: 8m 17s\n",
      "991:\tlearn: 0.0056429\ttotal: 2m 3s\tremaining: 8m 17s\n",
      "992:\tlearn: 0.0056187\ttotal: 2m 3s\tremaining: 8m 17s\n",
      "993:\tlearn: 0.0056144\ttotal: 2m 3s\tremaining: 8m 16s\n",
      "994:\tlearn: 0.0056013\ttotal: 2m 3s\tremaining: 8m 16s\n",
      "995:\tlearn: 0.0055808\ttotal: 2m 3s\tremaining: 8m 16s\n",
      "996:\tlearn: 0.0055795\ttotal: 2m 3s\tremaining: 8m 16s\n",
      "997:\tlearn: 0.0055742\ttotal: 2m 3s\tremaining: 8m 16s\n",
      "998:\tlearn: 0.0055703\ttotal: 2m 3s\tremaining: 8m 15s\n",
      "999:\tlearn: 0.0055645\ttotal: 2m 3s\tremaining: 8m 15s\n",
      "1000:\tlearn: 0.0055621\ttotal: 2m 4s\tremaining: 8m 15s\n",
      "1001:\tlearn: 0.0055593\ttotal: 2m 4s\tremaining: 8m 15s\n",
      "1002:\tlearn: 0.0055486\ttotal: 2m 4s\tremaining: 8m 15s\n",
      "1003:\tlearn: 0.0055467\ttotal: 2m 4s\tremaining: 8m 15s\n",
      "1004:\tlearn: 0.0055427\ttotal: 2m 4s\tremaining: 8m 14s\n",
      "1005:\tlearn: 0.0055347\ttotal: 2m 4s\tremaining: 8m 14s\n",
      "1006:\tlearn: 0.0055266\ttotal: 2m 4s\tremaining: 8m 14s\n",
      "1007:\tlearn: 0.0055247\ttotal: 2m 4s\tremaining: 8m 14s\n",
      "1008:\tlearn: 0.0055166\ttotal: 2m 4s\tremaining: 8m 14s\n",
      "1009:\tlearn: 0.0055121\ttotal: 2m 5s\tremaining: 8m 13s\n",
      "1010:\tlearn: 0.0055110\ttotal: 2m 5s\tremaining: 8m 13s\n",
      "1011:\tlearn: 0.0055080\ttotal: 2m 5s\tremaining: 8m 13s\n",
      "1012:\tlearn: 0.0055044\ttotal: 2m 5s\tremaining: 8m 13s\n",
      "1013:\tlearn: 0.0054995\ttotal: 2m 5s\tremaining: 8m 13s\n",
      "1014:\tlearn: 0.0054956\ttotal: 2m 5s\tremaining: 8m 13s\n",
      "1015:\tlearn: 0.0054905\ttotal: 2m 5s\tremaining: 8m 12s\n",
      "1016:\tlearn: 0.0054855\ttotal: 2m 5s\tremaining: 8m 12s\n",
      "1017:\tlearn: 0.0054832\ttotal: 2m 5s\tremaining: 8m 12s\n",
      "1018:\tlearn: 0.0054794\ttotal: 2m 6s\tremaining: 8m 12s\n",
      "1019:\tlearn: 0.0054779\ttotal: 2m 6s\tremaining: 8m 12s\n",
      "1020:\tlearn: 0.0054735\ttotal: 2m 6s\tremaining: 8m 11s\n",
      "1021:\tlearn: 0.0054712\ttotal: 2m 6s\tremaining: 8m 11s\n",
      "1022:\tlearn: 0.0054685\ttotal: 2m 6s\tremaining: 8m 11s\n",
      "1023:\tlearn: 0.0054653\ttotal: 2m 6s\tremaining: 8m 11s\n",
      "1024:\tlearn: 0.0054620\ttotal: 2m 6s\tremaining: 8m 11s\n",
      "1025:\tlearn: 0.0054400\ttotal: 2m 6s\tremaining: 8m 11s\n",
      "1026:\tlearn: 0.0054346\ttotal: 2m 6s\tremaining: 8m 11s\n",
      "1027:\tlearn: 0.0054313\ttotal: 2m 7s\tremaining: 8m 10s\n",
      "1028:\tlearn: 0.0054250\ttotal: 2m 7s\tremaining: 8m 10s\n",
      "1029:\tlearn: 0.0054191\ttotal: 2m 7s\tremaining: 8m 10s\n",
      "1030:\tlearn: 0.0054152\ttotal: 2m 7s\tremaining: 8m 10s\n",
      "1031:\tlearn: 0.0054116\ttotal: 2m 7s\tremaining: 8m 10s\n",
      "1032:\tlearn: 0.0054027\ttotal: 2m 7s\tremaining: 8m 9s\n",
      "1033:\tlearn: 0.0053933\ttotal: 2m 7s\tremaining: 8m 9s\n",
      "1034:\tlearn: 0.0053838\ttotal: 2m 7s\tremaining: 8m 9s\n",
      "1035:\tlearn: 0.0053823\ttotal: 2m 7s\tremaining: 8m 9s\n",
      "1036:\tlearn: 0.0053802\ttotal: 2m 8s\tremaining: 8m 9s\n",
      "1037:\tlearn: 0.0053725\ttotal: 2m 8s\tremaining: 8m 9s\n",
      "1038:\tlearn: 0.0053590\ttotal: 2m 8s\tremaining: 8m 8s\n",
      "1039:\tlearn: 0.0053563\ttotal: 2m 8s\tremaining: 8m 8s\n",
      "1040:\tlearn: 0.0053514\ttotal: 2m 8s\tremaining: 8m 8s\n",
      "1041:\tlearn: 0.0053492\ttotal: 2m 8s\tremaining: 8m 8s\n",
      "1042:\tlearn: 0.0053478\ttotal: 2m 8s\tremaining: 8m 8s\n",
      "1043:\tlearn: 0.0053378\ttotal: 2m 8s\tremaining: 8m 8s\n",
      "1044:\tlearn: 0.0053361\ttotal: 2m 8s\tremaining: 8m 7s\n",
      "1045:\tlearn: 0.0053348\ttotal: 2m 9s\tremaining: 8m 7s\n",
      "1046:\tlearn: 0.0053331\ttotal: 2m 9s\tremaining: 8m 7s\n",
      "1047:\tlearn: 0.0053303\ttotal: 2m 9s\tremaining: 8m 7s\n",
      "1048:\tlearn: 0.0053213\ttotal: 2m 9s\tremaining: 8m 7s\n",
      "1049:\tlearn: 0.0053135\ttotal: 2m 9s\tremaining: 8m 7s\n",
      "1050:\tlearn: 0.0053086\ttotal: 2m 9s\tremaining: 8m 6s\n",
      "1051:\tlearn: 0.0053060\ttotal: 2m 9s\tremaining: 8m 6s\n",
      "1052:\tlearn: 0.0053031\ttotal: 2m 9s\tremaining: 8m 6s\n",
      "1053:\tlearn: 0.0053001\ttotal: 2m 9s\tremaining: 8m 6s\n",
      "1054:\tlearn: 0.0052979\ttotal: 2m 10s\tremaining: 8m 6s\n",
      "1055:\tlearn: 0.0052939\ttotal: 2m 10s\tremaining: 8m 5s\n",
      "1056:\tlearn: 0.0052846\ttotal: 2m 10s\tremaining: 8m 5s\n",
      "1057:\tlearn: 0.0052818\ttotal: 2m 10s\tremaining: 8m 5s\n",
      "1058:\tlearn: 0.0052814\ttotal: 2m 10s\tremaining: 8m 5s\n",
      "1059:\tlearn: 0.0052752\ttotal: 2m 10s\tremaining: 8m 5s\n",
      "1060:\tlearn: 0.0052623\ttotal: 2m 10s\tremaining: 8m 5s\n",
      "1061:\tlearn: 0.0052537\ttotal: 2m 11s\tremaining: 8m 6s\n",
      "1062:\tlearn: 0.0052509\ttotal: 2m 11s\tremaining: 8m 6s\n",
      "1063:\tlearn: 0.0052430\ttotal: 2m 11s\tremaining: 8m 6s\n",
      "1064:\tlearn: 0.0052382\ttotal: 2m 11s\tremaining: 8m 6s\n",
      "1065:\tlearn: 0.0052358\ttotal: 2m 11s\tremaining: 8m 6s\n",
      "1066:\tlearn: 0.0052293\ttotal: 2m 12s\tremaining: 8m 6s\n",
      "1067:\tlearn: 0.0052264\ttotal: 2m 12s\tremaining: 8m 6s\n",
      "1068:\tlearn: 0.0052235\ttotal: 2m 12s\tremaining: 8m 6s\n",
      "1069:\tlearn: 0.0052198\ttotal: 2m 12s\tremaining: 8m 6s\n",
      "1070:\tlearn: 0.0052109\ttotal: 2m 12s\tremaining: 8m 6s\n",
      "1071:\tlearn: 0.0052031\ttotal: 2m 12s\tremaining: 8m 6s\n",
      "1072:\tlearn: 0.0052020\ttotal: 2m 12s\tremaining: 8m 6s\n",
      "1073:\tlearn: 0.0051963\ttotal: 2m 13s\tremaining: 8m 6s\n",
      "1074:\tlearn: 0.0051939\ttotal: 2m 13s\tremaining: 8m 6s\n",
      "1075:\tlearn: 0.0051932\ttotal: 2m 13s\tremaining: 8m 6s\n",
      "1076:\tlearn: 0.0051894\ttotal: 2m 13s\tremaining: 8m 6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1077:\tlearn: 0.0051867\ttotal: 2m 13s\tremaining: 8m 6s\n",
      "1078:\tlearn: 0.0051826\ttotal: 2m 13s\tremaining: 8m 6s\n",
      "1079:\tlearn: 0.0051798\ttotal: 2m 14s\tremaining: 8m 6s\n",
      "1080:\tlearn: 0.0051722\ttotal: 2m 14s\tremaining: 8m 6s\n",
      "1081:\tlearn: 0.0051573\ttotal: 2m 14s\tremaining: 8m 6s\n",
      "1082:\tlearn: 0.0051552\ttotal: 2m 14s\tremaining: 8m 6s\n",
      "1083:\tlearn: 0.0051538\ttotal: 2m 14s\tremaining: 8m 6s\n",
      "1084:\tlearn: 0.0051522\ttotal: 2m 14s\tremaining: 8m 6s\n",
      "1085:\tlearn: 0.0051461\ttotal: 2m 15s\tremaining: 8m 6s\n",
      "1086:\tlearn: 0.0051426\ttotal: 2m 15s\tremaining: 8m 6s\n",
      "1087:\tlearn: 0.0051420\ttotal: 2m 15s\tremaining: 8m 6s\n",
      "1088:\tlearn: 0.0051292\ttotal: 2m 15s\tremaining: 8m 6s\n",
      "1089:\tlearn: 0.0051259\ttotal: 2m 15s\tremaining: 8m 6s\n",
      "1090:\tlearn: 0.0051246\ttotal: 2m 15s\tremaining: 8m 6s\n",
      "1091:\tlearn: 0.0051156\ttotal: 2m 16s\tremaining: 8m 6s\n",
      "1092:\tlearn: 0.0051134\ttotal: 2m 16s\tremaining: 8m 6s\n",
      "1093:\tlearn: 0.0051093\ttotal: 2m 16s\tremaining: 8m 6s\n",
      "1094:\tlearn: 0.0051062\ttotal: 2m 16s\tremaining: 8m 6s\n",
      "1095:\tlearn: 0.0050994\ttotal: 2m 16s\tremaining: 8m 7s\n",
      "1096:\tlearn: 0.0050953\ttotal: 2m 16s\tremaining: 8m 6s\n",
      "1097:\tlearn: 0.0050907\ttotal: 2m 16s\tremaining: 8m 6s\n",
      "1098:\tlearn: 0.0050885\ttotal: 2m 17s\tremaining: 8m 6s\n",
      "1099:\tlearn: 0.0050879\ttotal: 2m 17s\tremaining: 8m 6s\n",
      "1100:\tlearn: 0.0050853\ttotal: 2m 17s\tremaining: 8m 6s\n",
      "1101:\tlearn: 0.0050824\ttotal: 2m 17s\tremaining: 8m 6s\n",
      "1102:\tlearn: 0.0050799\ttotal: 2m 17s\tremaining: 8m 6s\n",
      "1103:\tlearn: 0.0050758\ttotal: 2m 17s\tremaining: 8m 6s\n",
      "1104:\tlearn: 0.0050721\ttotal: 2m 18s\tremaining: 8m 6s\n",
      "1105:\tlearn: 0.0050697\ttotal: 2m 18s\tremaining: 8m 6s\n",
      "1106:\tlearn: 0.0050689\ttotal: 2m 18s\tremaining: 8m 6s\n",
      "1107:\tlearn: 0.0050631\ttotal: 2m 18s\tremaining: 8m 6s\n",
      "1108:\tlearn: 0.0050605\ttotal: 2m 18s\tremaining: 8m 7s\n",
      "1109:\tlearn: 0.0050578\ttotal: 2m 19s\tremaining: 8m 7s\n",
      "1110:\tlearn: 0.0050542\ttotal: 2m 19s\tremaining: 8m 7s\n",
      "1111:\tlearn: 0.0050453\ttotal: 2m 19s\tremaining: 8m 7s\n",
      "1112:\tlearn: 0.0050421\ttotal: 2m 19s\tremaining: 8m 7s\n",
      "1113:\tlearn: 0.0050347\ttotal: 2m 19s\tremaining: 8m 7s\n",
      "1114:\tlearn: 0.0050313\ttotal: 2m 19s\tremaining: 8m 7s\n",
      "1115:\tlearn: 0.0050296\ttotal: 2m 20s\tremaining: 8m 7s\n",
      "1116:\tlearn: 0.0050281\ttotal: 2m 20s\tremaining: 8m 7s\n",
      "1117:\tlearn: 0.0050207\ttotal: 2m 20s\tremaining: 8m 7s\n",
      "1118:\tlearn: 0.0050137\ttotal: 2m 20s\tremaining: 8m 7s\n",
      "1119:\tlearn: 0.0050092\ttotal: 2m 20s\tremaining: 8m 6s\n",
      "1120:\tlearn: 0.0050071\ttotal: 2m 20s\tremaining: 8m 6s\n",
      "1121:\tlearn: 0.0050042\ttotal: 2m 20s\tremaining: 8m 6s\n",
      "1122:\tlearn: 0.0050014\ttotal: 2m 20s\tremaining: 8m 6s\n",
      "1123:\tlearn: 0.0049977\ttotal: 2m 20s\tremaining: 8m 6s\n",
      "1124:\tlearn: 0.0049942\ttotal: 2m 21s\tremaining: 8m 6s\n",
      "1125:\tlearn: 0.0049819\ttotal: 2m 21s\tremaining: 8m 5s\n",
      "1126:\tlearn: 0.0049761\ttotal: 2m 21s\tremaining: 8m 5s\n",
      "1127:\tlearn: 0.0049749\ttotal: 2m 21s\tremaining: 8m 5s\n",
      "1128:\tlearn: 0.0049737\ttotal: 2m 21s\tremaining: 8m 5s\n",
      "1129:\tlearn: 0.0049716\ttotal: 2m 21s\tremaining: 8m 5s\n",
      "1130:\tlearn: 0.0049683\ttotal: 2m 21s\tremaining: 8m 4s\n",
      "1131:\tlearn: 0.0049647\ttotal: 2m 21s\tremaining: 8m 4s\n",
      "1132:\tlearn: 0.0049621\ttotal: 2m 21s\tremaining: 8m 4s\n",
      "1133:\tlearn: 0.0049599\ttotal: 2m 22s\tremaining: 8m 4s\n",
      "1134:\tlearn: 0.0049579\ttotal: 2m 22s\tremaining: 8m 4s\n",
      "1135:\tlearn: 0.0049548\ttotal: 2m 22s\tremaining: 8m 4s\n",
      "1136:\tlearn: 0.0049537\ttotal: 2m 22s\tremaining: 8m 3s\n",
      "1137:\tlearn: 0.0049515\ttotal: 2m 22s\tremaining: 8m 3s\n",
      "1138:\tlearn: 0.0049415\ttotal: 2m 22s\tremaining: 8m 3s\n",
      "1139:\tlearn: 0.0049384\ttotal: 2m 22s\tremaining: 8m 3s\n",
      "1140:\tlearn: 0.0049217\ttotal: 2m 22s\tremaining: 8m 3s\n",
      "1141:\tlearn: 0.0049196\ttotal: 2m 22s\tremaining: 8m 3s\n",
      "1142:\tlearn: 0.0049143\ttotal: 2m 23s\tremaining: 8m 2s\n",
      "1143:\tlearn: 0.0049134\ttotal: 2m 23s\tremaining: 8m 2s\n",
      "1144:\tlearn: 0.0049120\ttotal: 2m 23s\tremaining: 8m 2s\n",
      "1145:\tlearn: 0.0049096\ttotal: 2m 23s\tremaining: 8m 2s\n",
      "1146:\tlearn: 0.0049082\ttotal: 2m 23s\tremaining: 8m 2s\n",
      "1147:\tlearn: 0.0049056\ttotal: 2m 23s\tremaining: 8m 2s\n",
      "1148:\tlearn: 0.0049003\ttotal: 2m 23s\tremaining: 8m 1s\n",
      "1149:\tlearn: 0.0048953\ttotal: 2m 23s\tremaining: 8m 1s\n",
      "1150:\tlearn: 0.0048909\ttotal: 2m 24s\tremaining: 8m 1s\n",
      "1151:\tlearn: 0.0048854\ttotal: 2m 24s\tremaining: 8m 1s\n",
      "1152:\tlearn: 0.0048841\ttotal: 2m 24s\tremaining: 8m 1s\n",
      "1153:\tlearn: 0.0048774\ttotal: 2m 24s\tremaining: 8m 1s\n",
      "1154:\tlearn: 0.0048742\ttotal: 2m 24s\tremaining: 8m 1s\n",
      "1155:\tlearn: 0.0048717\ttotal: 2m 24s\tremaining: 8m 1s\n",
      "1156:\tlearn: 0.0048642\ttotal: 2m 24s\tremaining: 8m\n",
      "1157:\tlearn: 0.0048612\ttotal: 2m 24s\tremaining: 8m\n",
      "1158:\tlearn: 0.0048591\ttotal: 2m 25s\tremaining: 8m\n",
      "1159:\tlearn: 0.0048580\ttotal: 2m 25s\tremaining: 8m\n",
      "1160:\tlearn: 0.0048557\ttotal: 2m 25s\tremaining: 8m\n",
      "1161:\tlearn: 0.0048536\ttotal: 2m 25s\tremaining: 8m\n",
      "1162:\tlearn: 0.0048487\ttotal: 2m 25s\tremaining: 7m 59s\n",
      "1163:\tlearn: 0.0048461\ttotal: 2m 25s\tremaining: 7m 59s\n",
      "1164:\tlearn: 0.0048437\ttotal: 2m 25s\tremaining: 7m 59s\n",
      "1165:\tlearn: 0.0048402\ttotal: 2m 25s\tremaining: 7m 59s\n",
      "1166:\tlearn: 0.0048321\ttotal: 2m 25s\tremaining: 7m 59s\n",
      "1167:\tlearn: 0.0048284\ttotal: 2m 26s\tremaining: 7m 59s\n",
      "1168:\tlearn: 0.0048265\ttotal: 2m 26s\tremaining: 7m 58s\n",
      "1169:\tlearn: 0.0048222\ttotal: 2m 26s\tremaining: 7m 58s\n",
      "1170:\tlearn: 0.0048204\ttotal: 2m 26s\tremaining: 7m 58s\n",
      "1171:\tlearn: 0.0048154\ttotal: 2m 26s\tremaining: 7m 58s\n",
      "1172:\tlearn: 0.0048137\ttotal: 2m 26s\tremaining: 7m 58s\n",
      "1173:\tlearn: 0.0048082\ttotal: 2m 26s\tremaining: 7m 57s\n",
      "1174:\tlearn: 0.0048008\ttotal: 2m 26s\tremaining: 7m 57s\n",
      "1175:\tlearn: 0.0047954\ttotal: 2m 26s\tremaining: 7m 57s\n",
      "1176:\tlearn: 0.0047895\ttotal: 2m 27s\tremaining: 7m 57s\n",
      "1177:\tlearn: 0.0047793\ttotal: 2m 27s\tremaining: 7m 57s\n",
      "1178:\tlearn: 0.0047761\ttotal: 2m 27s\tremaining: 7m 57s\n",
      "1179:\tlearn: 0.0047704\ttotal: 2m 27s\tremaining: 7m 57s\n",
      "1180:\tlearn: 0.0047616\ttotal: 2m 27s\tremaining: 7m 56s\n",
      "1181:\tlearn: 0.0047569\ttotal: 2m 27s\tremaining: 7m 56s\n",
      "1182:\tlearn: 0.0047552\ttotal: 2m 27s\tremaining: 7m 56s\n",
      "1183:\tlearn: 0.0047547\ttotal: 2m 27s\tremaining: 7m 56s\n",
      "1184:\tlearn: 0.0047524\ttotal: 2m 27s\tremaining: 7m 56s\n",
      "1185:\tlearn: 0.0047471\ttotal: 2m 28s\tremaining: 7m 56s\n",
      "1186:\tlearn: 0.0047440\ttotal: 2m 28s\tremaining: 7m 56s\n",
      "1187:\tlearn: 0.0047428\ttotal: 2m 28s\tremaining: 7m 56s\n",
      "1188:\tlearn: 0.0047409\ttotal: 2m 28s\tremaining: 7m 56s\n",
      "1189:\tlearn: 0.0047357\ttotal: 2m 28s\tremaining: 7m 56s\n",
      "1190:\tlearn: 0.0047350\ttotal: 2m 29s\tremaining: 7m 57s\n",
      "1191:\tlearn: 0.0047287\ttotal: 2m 29s\tremaining: 7m 57s\n",
      "1192:\tlearn: 0.0047273\ttotal: 2m 29s\tremaining: 7m 57s\n",
      "1193:\tlearn: 0.0047248\ttotal: 2m 29s\tremaining: 7m 56s\n",
      "1194:\tlearn: 0.0047229\ttotal: 2m 29s\tremaining: 7m 56s\n",
      "1195:\tlearn: 0.0047201\ttotal: 2m 29s\tremaining: 7m 56s\n",
      "1196:\tlearn: 0.0047153\ttotal: 2m 30s\tremaining: 7m 56s\n",
      "1197:\tlearn: 0.0047145\ttotal: 2m 30s\tremaining: 7m 56s\n",
      "1198:\tlearn: 0.0047128\ttotal: 2m 30s\tremaining: 7m 56s\n",
      "1199:\tlearn: 0.0047117\ttotal: 2m 30s\tremaining: 7m 56s\n",
      "1200:\tlearn: 0.0047091\ttotal: 2m 30s\tremaining: 7m 56s\n",
      "1201:\tlearn: 0.0046897\ttotal: 2m 30s\tremaining: 7m 55s\n",
      "1202:\tlearn: 0.0046849\ttotal: 2m 30s\tremaining: 7m 55s\n",
      "1203:\tlearn: 0.0046839\ttotal: 2m 30s\tremaining: 7m 55s\n",
      "1204:\tlearn: 0.0046832\ttotal: 2m 30s\tremaining: 7m 55s\n",
      "1205:\tlearn: 0.0046823\ttotal: 2m 31s\tremaining: 7m 55s\n",
      "1206:\tlearn: 0.0046802\ttotal: 2m 31s\tremaining: 7m 55s\n",
      "1207:\tlearn: 0.0046781\ttotal: 2m 31s\tremaining: 7m 54s\n",
      "1208:\tlearn: 0.0046768\ttotal: 2m 31s\tremaining: 7m 54s\n",
      "1209:\tlearn: 0.0046654\ttotal: 2m 31s\tremaining: 7m 54s\n",
      "1210:\tlearn: 0.0046647\ttotal: 2m 31s\tremaining: 7m 54s\n",
      "1211:\tlearn: 0.0046614\ttotal: 2m 31s\tremaining: 7m 54s\n",
      "1212:\tlearn: 0.0046592\ttotal: 2m 31s\tremaining: 7m 54s\n",
      "1213:\tlearn: 0.0046552\ttotal: 2m 32s\tremaining: 7m 54s\n",
      "1214:\tlearn: 0.0046539\ttotal: 2m 32s\tremaining: 7m 53s\n",
      "1215:\tlearn: 0.0046521\ttotal: 2m 32s\tremaining: 7m 53s\n",
      "1216:\tlearn: 0.0046477\ttotal: 2m 32s\tremaining: 7m 53s\n",
      "1217:\tlearn: 0.0046446\ttotal: 2m 32s\tremaining: 7m 53s\n",
      "1218:\tlearn: 0.0046435\ttotal: 2m 32s\tremaining: 7m 53s\n",
      "1219:\tlearn: 0.0046400\ttotal: 2m 32s\tremaining: 7m 53s\n",
      "1220:\tlearn: 0.0046393\ttotal: 2m 33s\tremaining: 7m 53s\n",
      "1221:\tlearn: 0.0046382\ttotal: 2m 33s\tremaining: 7m 53s\n",
      "1222:\tlearn: 0.0046369\ttotal: 2m 33s\tremaining: 7m 53s\n",
      "1223:\tlearn: 0.0046200\ttotal: 2m 33s\tremaining: 7m 53s\n",
      "1224:\tlearn: 0.0046161\ttotal: 2m 33s\tremaining: 7m 53s\n",
      "1225:\tlearn: 0.0046108\ttotal: 2m 33s\tremaining: 7m 53s\n",
      "1226:\tlearn: 0.0046101\ttotal: 2m 34s\tremaining: 7m 53s\n",
      "1227:\tlearn: 0.0046084\ttotal: 2m 34s\tremaining: 7m 53s\n",
      "1228:\tlearn: 0.0045983\ttotal: 2m 34s\tremaining: 7m 53s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1229:\tlearn: 0.0045973\ttotal: 2m 34s\tremaining: 7m 53s\n",
      "1230:\tlearn: 0.0045959\ttotal: 2m 34s\tremaining: 7m 53s\n",
      "1231:\tlearn: 0.0045919\ttotal: 2m 34s\tremaining: 7m 53s\n",
      "1232:\tlearn: 0.0045910\ttotal: 2m 35s\tremaining: 7m 54s\n",
      "1233:\tlearn: 0.0045896\ttotal: 2m 35s\tremaining: 7m 54s\n",
      "1234:\tlearn: 0.0045858\ttotal: 2m 35s\tremaining: 7m 53s\n",
      "1235:\tlearn: 0.0045852\ttotal: 2m 35s\tremaining: 7m 53s\n",
      "1236:\tlearn: 0.0045845\ttotal: 2m 35s\tremaining: 7m 54s\n",
      "1237:\tlearn: 0.0045828\ttotal: 2m 35s\tremaining: 7m 54s\n",
      "1238:\tlearn: 0.0045781\ttotal: 2m 36s\tremaining: 7m 54s\n",
      "1239:\tlearn: 0.0045759\ttotal: 2m 36s\tremaining: 7m 54s\n",
      "1240:\tlearn: 0.0045694\ttotal: 2m 36s\tremaining: 7m 54s\n",
      "1241:\tlearn: 0.0045658\ttotal: 2m 36s\tremaining: 7m 54s\n",
      "1242:\tlearn: 0.0045636\ttotal: 2m 36s\tremaining: 7m 54s\n",
      "1243:\tlearn: 0.0045631\ttotal: 2m 37s\tremaining: 7m 54s\n",
      "1244:\tlearn: 0.0045596\ttotal: 2m 37s\tremaining: 7m 54s\n",
      "1245:\tlearn: 0.0045581\ttotal: 2m 37s\tremaining: 7m 54s\n",
      "1246:\tlearn: 0.0045531\ttotal: 2m 37s\tremaining: 7m 54s\n",
      "1247:\tlearn: 0.0045518\ttotal: 2m 37s\tremaining: 7m 54s\n",
      "1248:\tlearn: 0.0045462\ttotal: 2m 37s\tremaining: 7m 54s\n",
      "1249:\tlearn: 0.0045401\ttotal: 2m 38s\tremaining: 7m 54s\n",
      "1250:\tlearn: 0.0045160\ttotal: 2m 38s\tremaining: 7m 54s\n",
      "1251:\tlearn: 0.0045105\ttotal: 2m 38s\tremaining: 7m 54s\n",
      "1252:\tlearn: 0.0045009\ttotal: 2m 38s\tremaining: 7m 54s\n",
      "1253:\tlearn: 0.0044992\ttotal: 2m 38s\tremaining: 7m 54s\n",
      "1254:\tlearn: 0.0044970\ttotal: 2m 38s\tremaining: 7m 54s\n",
      "1255:\tlearn: 0.0044929\ttotal: 2m 39s\tremaining: 7m 54s\n",
      "1256:\tlearn: 0.0044896\ttotal: 2m 39s\tremaining: 7m 54s\n",
      "1257:\tlearn: 0.0044875\ttotal: 2m 39s\tremaining: 7m 53s\n",
      "1258:\tlearn: 0.0044817\ttotal: 2m 39s\tremaining: 7m 53s\n",
      "1259:\tlearn: 0.0044800\ttotal: 2m 39s\tremaining: 7m 53s\n",
      "1260:\tlearn: 0.0044782\ttotal: 2m 39s\tremaining: 7m 53s\n",
      "1261:\tlearn: 0.0044726\ttotal: 2m 39s\tremaining: 7m 53s\n",
      "1262:\tlearn: 0.0044644\ttotal: 2m 39s\tremaining: 7m 53s\n",
      "1263:\tlearn: 0.0044616\ttotal: 2m 40s\tremaining: 7m 53s\n",
      "1264:\tlearn: 0.0044567\ttotal: 2m 40s\tremaining: 7m 53s\n",
      "1265:\tlearn: 0.0044562\ttotal: 2m 40s\tremaining: 7m 52s\n",
      "1266:\tlearn: 0.0044545\ttotal: 2m 40s\tremaining: 7m 52s\n",
      "1267:\tlearn: 0.0044525\ttotal: 2m 40s\tremaining: 7m 52s\n",
      "1268:\tlearn: 0.0044474\ttotal: 2m 40s\tremaining: 7m 52s\n",
      "1269:\tlearn: 0.0044422\ttotal: 2m 40s\tremaining: 7m 52s\n",
      "1270:\tlearn: 0.0044402\ttotal: 2m 40s\tremaining: 7m 52s\n",
      "1271:\tlearn: 0.0044386\ttotal: 2m 41s\tremaining: 7m 52s\n",
      "1272:\tlearn: 0.0044348\ttotal: 2m 41s\tremaining: 7m 51s\n",
      "1273:\tlearn: 0.0044331\ttotal: 2m 41s\tremaining: 7m 51s\n",
      "1274:\tlearn: 0.0044319\ttotal: 2m 41s\tremaining: 7m 51s\n",
      "1275:\tlearn: 0.0044306\ttotal: 2m 41s\tremaining: 7m 51s\n",
      "1276:\tlearn: 0.0044298\ttotal: 2m 41s\tremaining: 7m 51s\n",
      "1277:\tlearn: 0.0044281\ttotal: 2m 41s\tremaining: 7m 51s\n",
      "1278:\tlearn: 0.0044240\ttotal: 2m 41s\tremaining: 7m 50s\n",
      "1279:\tlearn: 0.0044219\ttotal: 2m 41s\tremaining: 7m 50s\n",
      "1280:\tlearn: 0.0044209\ttotal: 2m 42s\tremaining: 7m 50s\n",
      "1281:\tlearn: 0.0044179\ttotal: 2m 42s\tremaining: 7m 50s\n",
      "1282:\tlearn: 0.0044170\ttotal: 2m 42s\tremaining: 7m 50s\n",
      "1283:\tlearn: 0.0044156\ttotal: 2m 42s\tremaining: 7m 50s\n",
      "1284:\tlearn: 0.0044052\ttotal: 2m 42s\tremaining: 7m 50s\n",
      "1285:\tlearn: 0.0044023\ttotal: 2m 42s\tremaining: 7m 49s\n",
      "1286:\tlearn: 0.0044013\ttotal: 2m 42s\tremaining: 7m 49s\n",
      "1287:\tlearn: 0.0044001\ttotal: 2m 42s\tremaining: 7m 49s\n",
      "1288:\tlearn: 0.0043986\ttotal: 2m 43s\tremaining: 7m 49s\n",
      "1289:\tlearn: 0.0043979\ttotal: 2m 43s\tremaining: 7m 49s\n",
      "1290:\tlearn: 0.0043973\ttotal: 2m 43s\tremaining: 7m 49s\n",
      "1291:\tlearn: 0.0043953\ttotal: 2m 43s\tremaining: 7m 49s\n",
      "1292:\tlearn: 0.0043934\ttotal: 2m 43s\tremaining: 7m 49s\n",
      "1293:\tlearn: 0.0043909\ttotal: 2m 43s\tremaining: 7m 49s\n",
      "1294:\tlearn: 0.0043766\ttotal: 2m 44s\tremaining: 7m 49s\n",
      "1295:\tlearn: 0.0043749\ttotal: 2m 44s\tremaining: 7m 50s\n",
      "1296:\tlearn: 0.0043738\ttotal: 2m 44s\tremaining: 7m 50s\n",
      "1297:\tlearn: 0.0043725\ttotal: 2m 44s\tremaining: 7m 50s\n",
      "1298:\tlearn: 0.0043710\ttotal: 2m 45s\tremaining: 7m 50s\n",
      "1299:\tlearn: 0.0043684\ttotal: 2m 45s\tremaining: 7m 50s\n",
      "1300:\tlearn: 0.0043661\ttotal: 2m 45s\tremaining: 7m 50s\n",
      "1301:\tlearn: 0.0043636\ttotal: 2m 45s\tremaining: 7m 50s\n",
      "1302:\tlearn: 0.0043586\ttotal: 2m 45s\tremaining: 7m 50s\n",
      "1303:\tlearn: 0.0043560\ttotal: 2m 45s\tremaining: 7m 49s\n",
      "1304:\tlearn: 0.0043552\ttotal: 2m 46s\tremaining: 7m 50s\n",
      "1305:\tlearn: 0.0043541\ttotal: 2m 46s\tremaining: 7m 49s\n",
      "1306:\tlearn: 0.0043531\ttotal: 2m 46s\tremaining: 7m 50s\n",
      "1307:\tlearn: 0.0043516\ttotal: 2m 46s\tremaining: 7m 50s\n",
      "1308:\tlearn: 0.0043459\ttotal: 2m 46s\tremaining: 7m 50s\n",
      "1309:\tlearn: 0.0043431\ttotal: 2m 47s\tremaining: 7m 50s\n",
      "1310:\tlearn: 0.0043391\ttotal: 2m 47s\tremaining: 7m 50s\n",
      "1311:\tlearn: 0.0043322\ttotal: 2m 47s\tremaining: 7m 50s\n",
      "1312:\tlearn: 0.0043312\ttotal: 2m 47s\tremaining: 7m 50s\n",
      "1313:\tlearn: 0.0043274\ttotal: 2m 47s\tremaining: 7m 49s\n",
      "1314:\tlearn: 0.0043219\ttotal: 2m 47s\tremaining: 7m 49s\n",
      "1315:\tlearn: 0.0043199\ttotal: 2m 47s\tremaining: 7m 49s\n",
      "1316:\tlearn: 0.0043149\ttotal: 2m 48s\tremaining: 7m 50s\n",
      "1317:\tlearn: 0.0043123\ttotal: 2m 48s\tremaining: 7m 49s\n",
      "1318:\tlearn: 0.0043120\ttotal: 2m 48s\tremaining: 7m 49s\n",
      "1319:\tlearn: 0.0043075\ttotal: 2m 48s\tremaining: 7m 49s\n",
      "1320:\tlearn: 0.0043035\ttotal: 2m 48s\tremaining: 7m 49s\n",
      "1321:\tlearn: 0.0043027\ttotal: 2m 48s\tremaining: 7m 49s\n",
      "1322:\tlearn: 0.0043000\ttotal: 2m 48s\tremaining: 7m 49s\n",
      "1323:\tlearn: 0.0042984\ttotal: 2m 49s\tremaining: 7m 49s\n",
      "1324:\tlearn: 0.0042973\ttotal: 2m 49s\tremaining: 7m 49s\n",
      "1325:\tlearn: 0.0042956\ttotal: 2m 49s\tremaining: 7m 49s\n",
      "1326:\tlearn: 0.0042930\ttotal: 2m 49s\tremaining: 7m 49s\n",
      "1327:\tlearn: 0.0042916\ttotal: 2m 49s\tremaining: 7m 48s\n",
      "1328:\tlearn: 0.0042874\ttotal: 2m 49s\tremaining: 7m 48s\n",
      "1329:\tlearn: 0.0042814\ttotal: 2m 49s\tremaining: 7m 48s\n",
      "1330:\tlearn: 0.0042758\ttotal: 2m 49s\tremaining: 7m 48s\n",
      "1331:\tlearn: 0.0042750\ttotal: 2m 50s\tremaining: 7m 48s\n",
      "1332:\tlearn: 0.0042704\ttotal: 2m 50s\tremaining: 7m 48s\n",
      "1333:\tlearn: 0.0042678\ttotal: 2m 50s\tremaining: 7m 48s\n",
      "1334:\tlearn: 0.0042609\ttotal: 2m 50s\tremaining: 7m 48s\n",
      "1335:\tlearn: 0.0042599\ttotal: 2m 50s\tremaining: 7m 47s\n",
      "1336:\tlearn: 0.0042573\ttotal: 2m 50s\tremaining: 7m 47s\n",
      "1337:\tlearn: 0.0042559\ttotal: 2m 50s\tremaining: 7m 47s\n",
      "1338:\tlearn: 0.0042536\ttotal: 2m 50s\tremaining: 7m 47s\n",
      "1339:\tlearn: 0.0042525\ttotal: 2m 51s\tremaining: 7m 47s\n",
      "1340:\tlearn: 0.0042502\ttotal: 2m 51s\tremaining: 7m 47s\n",
      "1341:\tlearn: 0.0042492\ttotal: 2m 51s\tremaining: 7m 46s\n",
      "1342:\tlearn: 0.0042467\ttotal: 2m 51s\tremaining: 7m 46s\n",
      "1343:\tlearn: 0.0042449\ttotal: 2m 51s\tremaining: 7m 46s\n",
      "1344:\tlearn: 0.0042444\ttotal: 2m 51s\tremaining: 7m 46s\n",
      "1345:\tlearn: 0.0042403\ttotal: 2m 51s\tremaining: 7m 46s\n",
      "1346:\tlearn: 0.0042382\ttotal: 2m 51s\tremaining: 7m 46s\n",
      "1347:\tlearn: 0.0042377\ttotal: 2m 51s\tremaining: 7m 45s\n",
      "1348:\tlearn: 0.0042363\ttotal: 2m 52s\tremaining: 7m 45s\n",
      "1349:\tlearn: 0.0042356\ttotal: 2m 52s\tremaining: 7m 45s\n",
      "1350:\tlearn: 0.0042343\ttotal: 2m 52s\tremaining: 7m 45s\n",
      "1351:\tlearn: 0.0042329\ttotal: 2m 52s\tremaining: 7m 45s\n",
      "1352:\tlearn: 0.0042304\ttotal: 2m 52s\tremaining: 7m 45s\n",
      "1353:\tlearn: 0.0042297\ttotal: 2m 52s\tremaining: 7m 44s\n",
      "1354:\tlearn: 0.0042255\ttotal: 2m 52s\tremaining: 7m 44s\n",
      "1355:\tlearn: 0.0042250\ttotal: 2m 52s\tremaining: 7m 44s\n",
      "1356:\tlearn: 0.0042225\ttotal: 2m 53s\tremaining: 7m 44s\n",
      "1357:\tlearn: 0.0042195\ttotal: 2m 53s\tremaining: 7m 44s\n",
      "1358:\tlearn: 0.0042166\ttotal: 2m 53s\tremaining: 7m 44s\n",
      "1359:\tlearn: 0.0042140\ttotal: 2m 53s\tremaining: 7m 44s\n",
      "1360:\tlearn: 0.0042023\ttotal: 2m 53s\tremaining: 7m 44s\n",
      "1361:\tlearn: 0.0042009\ttotal: 2m 53s\tremaining: 7m 43s\n",
      "1362:\tlearn: 0.0041980\ttotal: 2m 53s\tremaining: 7m 43s\n",
      "1363:\tlearn: 0.0041936\ttotal: 2m 53s\tremaining: 7m 43s\n",
      "1364:\tlearn: 0.0041892\ttotal: 2m 54s\tremaining: 7m 43s\n",
      "1365:\tlearn: 0.0041878\ttotal: 2m 54s\tremaining: 7m 43s\n",
      "1366:\tlearn: 0.0041705\ttotal: 2m 54s\tremaining: 7m 43s\n",
      "1367:\tlearn: 0.0041665\ttotal: 2m 54s\tremaining: 7m 43s\n",
      "1368:\tlearn: 0.0041641\ttotal: 2m 54s\tremaining: 7m 42s\n",
      "1369:\tlearn: 0.0041623\ttotal: 2m 54s\tremaining: 7m 42s\n",
      "1370:\tlearn: 0.0041614\ttotal: 2m 54s\tremaining: 7m 42s\n",
      "1371:\tlearn: 0.0041603\ttotal: 2m 54s\tremaining: 7m 42s\n",
      "1372:\tlearn: 0.0041592\ttotal: 2m 55s\tremaining: 7m 42s\n",
      "1373:\tlearn: 0.0041534\ttotal: 2m 55s\tremaining: 7m 42s\n",
      "1374:\tlearn: 0.0041486\ttotal: 2m 55s\tremaining: 7m 42s\n",
      "1375:\tlearn: 0.0041482\ttotal: 2m 55s\tremaining: 7m 41s\n",
      "1376:\tlearn: 0.0041470\ttotal: 2m 55s\tremaining: 7m 41s\n",
      "1377:\tlearn: 0.0041408\ttotal: 2m 55s\tremaining: 7m 41s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1378:\tlearn: 0.0041387\ttotal: 2m 55s\tremaining: 7m 41s\n",
      "1379:\tlearn: 0.0041364\ttotal: 2m 55s\tremaining: 7m 41s\n",
      "1380:\tlearn: 0.0041338\ttotal: 2m 55s\tremaining: 7m 41s\n",
      "1381:\tlearn: 0.0041172\ttotal: 2m 56s\tremaining: 7m 41s\n",
      "1382:\tlearn: 0.0041167\ttotal: 2m 56s\tremaining: 7m 40s\n",
      "1383:\tlearn: 0.0041136\ttotal: 2m 56s\tremaining: 7m 40s\n",
      "1384:\tlearn: 0.0041083\ttotal: 2m 56s\tremaining: 7m 40s\n",
      "1385:\tlearn: 0.0041068\ttotal: 2m 56s\tremaining: 7m 40s\n",
      "1386:\tlearn: 0.0041039\ttotal: 2m 56s\tremaining: 7m 40s\n",
      "1387:\tlearn: 0.0041000\ttotal: 2m 56s\tremaining: 7m 40s\n",
      "1388:\tlearn: 0.0040985\ttotal: 2m 56s\tremaining: 7m 40s\n",
      "1389:\tlearn: 0.0040967\ttotal: 2m 57s\tremaining: 7m 39s\n",
      "1390:\tlearn: 0.0040958\ttotal: 2m 57s\tremaining: 7m 39s\n",
      "1391:\tlearn: 0.0040931\ttotal: 2m 57s\tremaining: 7m 39s\n",
      "1392:\tlearn: 0.0040895\ttotal: 2m 57s\tremaining: 7m 39s\n",
      "1393:\tlearn: 0.0040862\ttotal: 2m 57s\tremaining: 7m 39s\n",
      "1394:\tlearn: 0.0040834\ttotal: 2m 57s\tremaining: 7m 39s\n",
      "1395:\tlearn: 0.0040732\ttotal: 2m 57s\tremaining: 7m 38s\n",
      "1396:\tlearn: 0.0040668\ttotal: 2m 57s\tremaining: 7m 38s\n",
      "1397:\tlearn: 0.0040628\ttotal: 2m 58s\tremaining: 7m 38s\n",
      "1398:\tlearn: 0.0040609\ttotal: 2m 58s\tremaining: 7m 38s\n",
      "1399:\tlearn: 0.0040547\ttotal: 2m 58s\tremaining: 7m 38s\n",
      "1400:\tlearn: 0.0040523\ttotal: 2m 58s\tremaining: 7m 38s\n",
      "1401:\tlearn: 0.0040492\ttotal: 2m 58s\tremaining: 7m 38s\n",
      "1402:\tlearn: 0.0040456\ttotal: 2m 58s\tremaining: 7m 38s\n",
      "1403:\tlearn: 0.0040440\ttotal: 2m 58s\tremaining: 7m 37s\n",
      "1404:\tlearn: 0.0040424\ttotal: 2m 58s\tremaining: 7m 37s\n",
      "1405:\tlearn: 0.0040405\ttotal: 2m 58s\tremaining: 7m 37s\n",
      "1406:\tlearn: 0.0040397\ttotal: 2m 59s\tremaining: 7m 37s\n",
      "1407:\tlearn: 0.0040386\ttotal: 2m 59s\tremaining: 7m 37s\n",
      "1408:\tlearn: 0.0040363\ttotal: 2m 59s\tremaining: 7m 37s\n",
      "1409:\tlearn: 0.0040324\ttotal: 2m 59s\tremaining: 7m 36s\n",
      "1410:\tlearn: 0.0040175\ttotal: 2m 59s\tremaining: 7m 36s\n",
      "1411:\tlearn: 0.0040159\ttotal: 2m 59s\tremaining: 7m 36s\n",
      "1412:\tlearn: 0.0040150\ttotal: 2m 59s\tremaining: 7m 36s\n",
      "1413:\tlearn: 0.0040137\ttotal: 2m 59s\tremaining: 7m 36s\n",
      "1414:\tlearn: 0.0040098\ttotal: 3m\tremaining: 7m 36s\n",
      "1415:\tlearn: 0.0040095\ttotal: 3m\tremaining: 7m 35s\n",
      "1416:\tlearn: 0.0040090\ttotal: 3m\tremaining: 7m 35s\n",
      "1417:\tlearn: 0.0040082\ttotal: 3m\tremaining: 7m 35s\n",
      "1418:\tlearn: 0.0040053\ttotal: 3m\tremaining: 7m 35s\n",
      "1419:\tlearn: 0.0040040\ttotal: 3m\tremaining: 7m 35s\n",
      "1420:\tlearn: 0.0039987\ttotal: 3m\tremaining: 7m 35s\n",
      "1421:\tlearn: 0.0039910\ttotal: 3m\tremaining: 7m 35s\n",
      "1422:\tlearn: 0.0039903\ttotal: 3m\tremaining: 7m 34s\n",
      "1423:\tlearn: 0.0039861\ttotal: 3m 1s\tremaining: 7m 34s\n",
      "1424:\tlearn: 0.0039788\ttotal: 3m 1s\tremaining: 7m 34s\n",
      "1425:\tlearn: 0.0039763\ttotal: 3m 1s\tremaining: 7m 34s\n",
      "1426:\tlearn: 0.0039757\ttotal: 3m 1s\tremaining: 7m 34s\n",
      "1427:\tlearn: 0.0039657\ttotal: 3m 1s\tremaining: 7m 34s\n",
      "1428:\tlearn: 0.0039600\ttotal: 3m 1s\tremaining: 7m 34s\n",
      "1429:\tlearn: 0.0039576\ttotal: 3m 1s\tremaining: 7m 33s\n",
      "1430:\tlearn: 0.0039554\ttotal: 3m 1s\tremaining: 7m 33s\n",
      "1431:\tlearn: 0.0039527\ttotal: 3m 2s\tremaining: 7m 33s\n",
      "1432:\tlearn: 0.0039505\ttotal: 3m 2s\tremaining: 7m 33s\n",
      "1433:\tlearn: 0.0039451\ttotal: 3m 2s\tremaining: 7m 33s\n",
      "1434:\tlearn: 0.0039431\ttotal: 3m 2s\tremaining: 7m 33s\n",
      "1435:\tlearn: 0.0039408\ttotal: 3m 2s\tremaining: 7m 33s\n",
      "1436:\tlearn: 0.0039378\ttotal: 3m 2s\tremaining: 7m 32s\n",
      "1437:\tlearn: 0.0039337\ttotal: 3m 2s\tremaining: 7m 32s\n",
      "1438:\tlearn: 0.0039289\ttotal: 3m 2s\tremaining: 7m 32s\n",
      "1439:\tlearn: 0.0039229\ttotal: 3m 3s\tremaining: 7m 32s\n",
      "1440:\tlearn: 0.0039214\ttotal: 3m 3s\tremaining: 7m 32s\n",
      "1441:\tlearn: 0.0039206\ttotal: 3m 3s\tremaining: 7m 32s\n",
      "1442:\tlearn: 0.0039182\ttotal: 3m 3s\tremaining: 7m 32s\n",
      "1443:\tlearn: 0.0039172\ttotal: 3m 3s\tremaining: 7m 31s\n",
      "1444:\tlearn: 0.0039122\ttotal: 3m 3s\tremaining: 7m 31s\n",
      "1445:\tlearn: 0.0039099\ttotal: 3m 3s\tremaining: 7m 31s\n",
      "1446:\tlearn: 0.0039062\ttotal: 3m 3s\tremaining: 7m 31s\n",
      "1447:\tlearn: 0.0039050\ttotal: 3m 3s\tremaining: 7m 31s\n",
      "1448:\tlearn: 0.0039010\ttotal: 3m 4s\tremaining: 7m 31s\n",
      "1449:\tlearn: 0.0038992\ttotal: 3m 4s\tremaining: 7m 31s\n",
      "1450:\tlearn: 0.0038947\ttotal: 3m 4s\tremaining: 7m 30s\n",
      "1451:\tlearn: 0.0038942\ttotal: 3m 4s\tremaining: 7m 30s\n",
      "1452:\tlearn: 0.0038929\ttotal: 3m 4s\tremaining: 7m 30s\n",
      "1453:\tlearn: 0.0038915\ttotal: 3m 4s\tremaining: 7m 30s\n",
      "1454:\tlearn: 0.0038900\ttotal: 3m 4s\tremaining: 7m 30s\n",
      "1455:\tlearn: 0.0038837\ttotal: 3m 5s\tremaining: 7m 30s\n",
      "1456:\tlearn: 0.0038812\ttotal: 3m 5s\tremaining: 7m 30s\n",
      "1457:\tlearn: 0.0038792\ttotal: 3m 5s\tremaining: 7m 30s\n",
      "1458:\tlearn: 0.0038785\ttotal: 3m 5s\tremaining: 7m 29s\n",
      "1459:\tlearn: 0.0038779\ttotal: 3m 5s\tremaining: 7m 29s\n",
      "1460:\tlearn: 0.0038770\ttotal: 3m 5s\tremaining: 7m 29s\n",
      "1461:\tlearn: 0.0038712\ttotal: 3m 5s\tremaining: 7m 29s\n",
      "1462:\tlearn: 0.0038698\ttotal: 3m 5s\tremaining: 7m 29s\n",
      "1463:\tlearn: 0.0038693\ttotal: 3m 5s\tremaining: 7m 29s\n",
      "1464:\tlearn: 0.0038609\ttotal: 3m 6s\tremaining: 7m 29s\n",
      "1465:\tlearn: 0.0038578\ttotal: 3m 6s\tremaining: 7m 28s\n",
      "1466:\tlearn: 0.0038564\ttotal: 3m 6s\tremaining: 7m 28s\n",
      "1467:\tlearn: 0.0038547\ttotal: 3m 6s\tremaining: 7m 28s\n",
      "1468:\tlearn: 0.0038510\ttotal: 3m 6s\tremaining: 7m 28s\n",
      "1469:\tlearn: 0.0038507\ttotal: 3m 6s\tremaining: 7m 28s\n",
      "1470:\tlearn: 0.0038491\ttotal: 3m 6s\tremaining: 7m 28s\n",
      "1471:\tlearn: 0.0038476\ttotal: 3m 6s\tremaining: 7m 28s\n",
      "1472:\tlearn: 0.0038415\ttotal: 3m 7s\tremaining: 7m 27s\n",
      "1473:\tlearn: 0.0038404\ttotal: 3m 7s\tremaining: 7m 28s\n",
      "1474:\tlearn: 0.0038353\ttotal: 3m 7s\tremaining: 7m 28s\n",
      "1475:\tlearn: 0.0038342\ttotal: 3m 7s\tremaining: 7m 28s\n",
      "1476:\tlearn: 0.0038315\ttotal: 3m 8s\tremaining: 7m 28s\n",
      "1477:\tlearn: 0.0038301\ttotal: 3m 8s\tremaining: 7m 28s\n",
      "1478:\tlearn: 0.0038287\ttotal: 3m 8s\tremaining: 7m 28s\n",
      "1479:\tlearn: 0.0038271\ttotal: 3m 8s\tremaining: 7m 28s\n",
      "1480:\tlearn: 0.0038202\ttotal: 3m 8s\tremaining: 7m 28s\n",
      "1481:\tlearn: 0.0038190\ttotal: 3m 9s\tremaining: 7m 28s\n",
      "1482:\tlearn: 0.0038178\ttotal: 3m 9s\tremaining: 7m 28s\n",
      "1483:\tlearn: 0.0038108\ttotal: 3m 9s\tremaining: 7m 28s\n",
      "1484:\tlearn: 0.0038032\ttotal: 3m 9s\tremaining: 7m 28s\n",
      "1485:\tlearn: 0.0038025\ttotal: 3m 9s\tremaining: 7m 28s\n",
      "1486:\tlearn: 0.0037986\ttotal: 3m 10s\tremaining: 7m 28s\n",
      "1487:\tlearn: 0.0037980\ttotal: 3m 10s\tremaining: 7m 28s\n",
      "1488:\tlearn: 0.0037946\ttotal: 3m 10s\tremaining: 7m 28s\n",
      "1489:\tlearn: 0.0037914\ttotal: 3m 10s\tremaining: 7m 28s\n",
      "1490:\tlearn: 0.0037909\ttotal: 3m 10s\tremaining: 7m 28s\n",
      "1491:\tlearn: 0.0037878\ttotal: 3m 10s\tremaining: 7m 28s\n",
      "1492:\tlearn: 0.0037850\ttotal: 3m 10s\tremaining: 7m 28s\n",
      "1493:\tlearn: 0.0037771\ttotal: 3m 11s\tremaining: 7m 28s\n",
      "1494:\tlearn: 0.0037745\ttotal: 3m 11s\tremaining: 7m 28s\n",
      "1495:\tlearn: 0.0037703\ttotal: 3m 11s\tremaining: 7m 28s\n",
      "1496:\tlearn: 0.0037678\ttotal: 3m 11s\tremaining: 7m 27s\n",
      "1497:\tlearn: 0.0037658\ttotal: 3m 11s\tremaining: 7m 27s\n",
      "1498:\tlearn: 0.0037621\ttotal: 3m 11s\tremaining: 7m 27s\n",
      "1499:\tlearn: 0.0037571\ttotal: 3m 11s\tremaining: 7m 27s\n",
      "1500:\tlearn: 0.0037552\ttotal: 3m 11s\tremaining: 7m 27s\n",
      "1501:\tlearn: 0.0037542\ttotal: 3m 12s\tremaining: 7m 27s\n",
      "1502:\tlearn: 0.0037496\ttotal: 3m 12s\tremaining: 7m 27s\n",
      "1503:\tlearn: 0.0037473\ttotal: 3m 12s\tremaining: 7m 27s\n",
      "1504:\tlearn: 0.0037447\ttotal: 3m 12s\tremaining: 7m 26s\n",
      "1505:\tlearn: 0.0037431\ttotal: 3m 12s\tremaining: 7m 26s\n",
      "1506:\tlearn: 0.0037381\ttotal: 3m 12s\tremaining: 7m 26s\n",
      "1507:\tlearn: 0.0037373\ttotal: 3m 12s\tremaining: 7m 26s\n",
      "1508:\tlearn: 0.0037337\ttotal: 3m 12s\tremaining: 7m 26s\n",
      "1509:\tlearn: 0.0037324\ttotal: 3m 13s\tremaining: 7m 26s\n",
      "1510:\tlearn: 0.0037304\ttotal: 3m 13s\tremaining: 7m 25s\n",
      "1511:\tlearn: 0.0037267\ttotal: 3m 13s\tremaining: 7m 25s\n",
      "1512:\tlearn: 0.0037259\ttotal: 3m 13s\tremaining: 7m 25s\n",
      "1513:\tlearn: 0.0037227\ttotal: 3m 13s\tremaining: 7m 25s\n",
      "1514:\tlearn: 0.0037202\ttotal: 3m 13s\tremaining: 7m 25s\n",
      "1515:\tlearn: 0.0037196\ttotal: 3m 13s\tremaining: 7m 25s\n",
      "1516:\tlearn: 0.0037178\ttotal: 3m 13s\tremaining: 7m 25s\n",
      "1517:\tlearn: 0.0037172\ttotal: 3m 14s\tremaining: 7m 25s\n",
      "1518:\tlearn: 0.0037134\ttotal: 3m 14s\tremaining: 7m 25s\n",
      "1519:\tlearn: 0.0037126\ttotal: 3m 14s\tremaining: 7m 25s\n",
      "1520:\tlearn: 0.0037122\ttotal: 3m 14s\tremaining: 7m 24s\n",
      "1521:\tlearn: 0.0037100\ttotal: 3m 14s\tremaining: 7m 24s\n",
      "1522:\tlearn: 0.0037066\ttotal: 3m 14s\tremaining: 7m 24s\n",
      "1523:\tlearn: 0.0037015\ttotal: 3m 14s\tremaining: 7m 24s\n",
      "1524:\tlearn: 0.0037007\ttotal: 3m 15s\tremaining: 7m 24s\n",
      "1525:\tlearn: 0.0037002\ttotal: 3m 15s\tremaining: 7m 24s\n",
      "1526:\tlearn: 0.0036999\ttotal: 3m 15s\tremaining: 7m 24s\n",
      "1527:\tlearn: 0.0036981\ttotal: 3m 15s\tremaining: 7m 24s\n",
      "1528:\tlearn: 0.0036931\ttotal: 3m 15s\tremaining: 7m 23s\n",
      "1529:\tlearn: 0.0036917\ttotal: 3m 15s\tremaining: 7m 23s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1530:\tlearn: 0.0036871\ttotal: 3m 15s\tremaining: 7m 23s\n",
      "1531:\tlearn: 0.0036856\ttotal: 3m 15s\tremaining: 7m 23s\n",
      "1532:\tlearn: 0.0036847\ttotal: 3m 16s\tremaining: 7m 23s\n",
      "1533:\tlearn: 0.0036787\ttotal: 3m 16s\tremaining: 7m 23s\n",
      "1534:\tlearn: 0.0036770\ttotal: 3m 16s\tremaining: 7m 23s\n",
      "1535:\tlearn: 0.0036767\ttotal: 3m 16s\tremaining: 7m 22s\n",
      "1536:\tlearn: 0.0036737\ttotal: 3m 16s\tremaining: 7m 22s\n",
      "1537:\tlearn: 0.0036730\ttotal: 3m 16s\tremaining: 7m 22s\n",
      "1538:\tlearn: 0.0036713\ttotal: 3m 16s\tremaining: 7m 22s\n",
      "1539:\tlearn: 0.0036709\ttotal: 3m 17s\tremaining: 7m 22s\n",
      "1540:\tlearn: 0.0036704\ttotal: 3m 17s\tremaining: 7m 22s\n",
      "1541:\tlearn: 0.0036688\ttotal: 3m 17s\tremaining: 7m 22s\n",
      "1542:\tlearn: 0.0036625\ttotal: 3m 17s\tremaining: 7m 22s\n",
      "1543:\tlearn: 0.0036624\ttotal: 3m 17s\tremaining: 7m 22s\n",
      "1544:\tlearn: 0.0036577\ttotal: 3m 17s\tremaining: 7m 22s\n",
      "1545:\tlearn: 0.0036569\ttotal: 3m 18s\tremaining: 7m 22s\n",
      "1546:\tlearn: 0.0036542\ttotal: 3m 18s\tremaining: 7m 22s\n",
      "1547:\tlearn: 0.0036529\ttotal: 3m 18s\tremaining: 7m 22s\n",
      "1548:\tlearn: 0.0036513\ttotal: 3m 18s\tremaining: 7m 22s\n",
      "1549:\tlearn: 0.0036348\ttotal: 3m 18s\tremaining: 7m 22s\n",
      "1550:\tlearn: 0.0036340\ttotal: 3m 18s\tremaining: 7m 22s\n",
      "1551:\tlearn: 0.0036329\ttotal: 3m 19s\tremaining: 7m 22s\n",
      "1552:\tlearn: 0.0036317\ttotal: 3m 19s\tremaining: 7m 22s\n",
      "1553:\tlearn: 0.0036303\ttotal: 3m 19s\tremaining: 7m 22s\n",
      "1554:\tlearn: 0.0036297\ttotal: 3m 19s\tremaining: 7m 22s\n",
      "1555:\tlearn: 0.0036267\ttotal: 3m 19s\tremaining: 7m 22s\n",
      "1556:\tlearn: 0.0036259\ttotal: 3m 20s\tremaining: 7m 22s\n",
      "1557:\tlearn: 0.0036216\ttotal: 3m 20s\tremaining: 7m 22s\n",
      "1558:\tlearn: 0.0036194\ttotal: 3m 20s\tremaining: 7m 22s\n",
      "1559:\tlearn: 0.0036187\ttotal: 3m 20s\tremaining: 7m 22s\n",
      "1560:\tlearn: 0.0036173\ttotal: 3m 20s\tremaining: 7m 22s\n",
      "1561:\tlearn: 0.0036144\ttotal: 3m 21s\tremaining: 7m 22s\n",
      "1562:\tlearn: 0.0036075\ttotal: 3m 21s\tremaining: 7m 22s\n",
      "1563:\tlearn: 0.0036045\ttotal: 3m 21s\tremaining: 7m 22s\n",
      "1564:\tlearn: 0.0036012\ttotal: 3m 21s\tremaining: 7m 22s\n",
      "1565:\tlearn: 0.0036005\ttotal: 3m 21s\tremaining: 7m 22s\n",
      "1566:\tlearn: 0.0036002\ttotal: 3m 21s\tremaining: 7m 22s\n",
      "1567:\tlearn: 0.0035972\ttotal: 3m 22s\tremaining: 7m 22s\n",
      "1568:\tlearn: 0.0035964\ttotal: 3m 22s\tremaining: 7m 22s\n",
      "1569:\tlearn: 0.0035956\ttotal: 3m 22s\tremaining: 7m 22s\n",
      "1570:\tlearn: 0.0035951\ttotal: 3m 22s\tremaining: 7m 22s\n",
      "1571:\tlearn: 0.0035929\ttotal: 3m 22s\tremaining: 7m 22s\n",
      "1572:\tlearn: 0.0035923\ttotal: 3m 23s\tremaining: 7m 22s\n",
      "1573:\tlearn: 0.0035782\ttotal: 3m 23s\tremaining: 7m 22s\n",
      "1574:\tlearn: 0.0035741\ttotal: 3m 23s\tremaining: 7m 22s\n",
      "1575:\tlearn: 0.0035739\ttotal: 3m 23s\tremaining: 7m 22s\n",
      "1576:\tlearn: 0.0035710\ttotal: 3m 23s\tremaining: 7m 22s\n",
      "1577:\tlearn: 0.0035695\ttotal: 3m 23s\tremaining: 7m 22s\n",
      "1578:\tlearn: 0.0035607\ttotal: 3m 24s\tremaining: 7m 22s\n",
      "1579:\tlearn: 0.0035600\ttotal: 3m 24s\tremaining: 7m 22s\n",
      "1580:\tlearn: 0.0035585\ttotal: 3m 24s\tremaining: 7m 22s\n",
      "1581:\tlearn: 0.0035573\ttotal: 3m 24s\tremaining: 7m 22s\n",
      "1582:\tlearn: 0.0035555\ttotal: 3m 24s\tremaining: 7m 22s\n",
      "1583:\tlearn: 0.0035536\ttotal: 3m 24s\tremaining: 7m 21s\n",
      "1584:\tlearn: 0.0035491\ttotal: 3m 25s\tremaining: 7m 22s\n",
      "1585:\tlearn: 0.0035488\ttotal: 3m 25s\tremaining: 7m 22s\n",
      "1586:\tlearn: 0.0035477\ttotal: 3m 25s\tremaining: 7m 22s\n",
      "1587:\tlearn: 0.0035455\ttotal: 3m 25s\tremaining: 7m 21s\n",
      "1588:\tlearn: 0.0035415\ttotal: 3m 25s\tremaining: 7m 21s\n",
      "1589:\tlearn: 0.0035389\ttotal: 3m 25s\tremaining: 7m 21s\n",
      "1590:\tlearn: 0.0035369\ttotal: 3m 26s\tremaining: 7m 21s\n",
      "1591:\tlearn: 0.0035365\ttotal: 3m 26s\tremaining: 7m 21s\n",
      "1592:\tlearn: 0.0035319\ttotal: 3m 26s\tremaining: 7m 21s\n",
      "1593:\tlearn: 0.0035306\ttotal: 3m 26s\tremaining: 7m 21s\n",
      "1594:\tlearn: 0.0035287\ttotal: 3m 26s\tremaining: 7m 21s\n",
      "1595:\tlearn: 0.0035264\ttotal: 3m 27s\tremaining: 7m 21s\n",
      "1596:\tlearn: 0.0035120\ttotal: 3m 27s\tremaining: 7m 21s\n",
      "1597:\tlearn: 0.0035069\ttotal: 3m 27s\tremaining: 7m 21s\n",
      "1598:\tlearn: 0.0035063\ttotal: 3m 27s\tremaining: 7m 21s\n",
      "1599:\tlearn: 0.0035032\ttotal: 3m 27s\tremaining: 7m 21s\n",
      "1600:\tlearn: 0.0035022\ttotal: 3m 27s\tremaining: 7m 21s\n",
      "1601:\tlearn: 0.0035009\ttotal: 3m 28s\tremaining: 7m 21s\n",
      "1602:\tlearn: 0.0034977\ttotal: 3m 28s\tremaining: 7m 21s\n",
      "1603:\tlearn: 0.0034954\ttotal: 3m 28s\tremaining: 7m 21s\n",
      "1604:\tlearn: 0.0034932\ttotal: 3m 28s\tremaining: 7m 21s\n",
      "1605:\tlearn: 0.0034916\ttotal: 3m 28s\tremaining: 7m 21s\n",
      "1606:\tlearn: 0.0034906\ttotal: 3m 29s\tremaining: 7m 21s\n",
      "1607:\tlearn: 0.0034880\ttotal: 3m 29s\tremaining: 7m 21s\n",
      "1608:\tlearn: 0.0034859\ttotal: 3m 29s\tremaining: 7m 21s\n",
      "1609:\tlearn: 0.0034853\ttotal: 3m 29s\tremaining: 7m 21s\n",
      "1610:\tlearn: 0.0034829\ttotal: 3m 29s\tremaining: 7m 21s\n",
      "1611:\tlearn: 0.0034820\ttotal: 3m 29s\tremaining: 7m 21s\n",
      "1612:\tlearn: 0.0034816\ttotal: 3m 30s\tremaining: 7m 21s\n",
      "1613:\tlearn: 0.0034811\ttotal: 3m 30s\tremaining: 7m 21s\n",
      "1614:\tlearn: 0.0034785\ttotal: 3m 30s\tremaining: 7m 21s\n",
      "1615:\tlearn: 0.0034735\ttotal: 3m 30s\tremaining: 7m 21s\n",
      "1616:\tlearn: 0.0034714\ttotal: 3m 30s\tremaining: 7m 21s\n",
      "1617:\tlearn: 0.0034692\ttotal: 3m 31s\tremaining: 7m 21s\n",
      "1618:\tlearn: 0.0034665\ttotal: 3m 31s\tremaining: 7m 21s\n",
      "1619:\tlearn: 0.0034625\ttotal: 3m 31s\tremaining: 7m 21s\n",
      "1620:\tlearn: 0.0034615\ttotal: 3m 31s\tremaining: 7m 21s\n",
      "1621:\tlearn: 0.0034588\ttotal: 3m 31s\tremaining: 7m 21s\n",
      "1622:\tlearn: 0.0034562\ttotal: 3m 31s\tremaining: 7m 21s\n",
      "1623:\tlearn: 0.0034558\ttotal: 3m 32s\tremaining: 7m 21s\n",
      "1624:\tlearn: 0.0034547\ttotal: 3m 32s\tremaining: 7m 21s\n",
      "1625:\tlearn: 0.0034511\ttotal: 3m 32s\tremaining: 7m 21s\n",
      "1626:\tlearn: 0.0034498\ttotal: 3m 32s\tremaining: 7m 21s\n",
      "1627:\tlearn: 0.0034493\ttotal: 3m 32s\tremaining: 7m 20s\n",
      "1628:\tlearn: 0.0034491\ttotal: 3m 33s\tremaining: 7m 20s\n",
      "1629:\tlearn: 0.0034487\ttotal: 3m 33s\tremaining: 7m 20s\n",
      "1630:\tlearn: 0.0034469\ttotal: 3m 33s\tremaining: 7m 20s\n",
      "1631:\tlearn: 0.0034465\ttotal: 3m 33s\tremaining: 7m 20s\n",
      "1632:\tlearn: 0.0034458\ttotal: 3m 33s\tremaining: 7m 20s\n",
      "1633:\tlearn: 0.0034437\ttotal: 3m 33s\tremaining: 7m 20s\n",
      "1634:\tlearn: 0.0034412\ttotal: 3m 34s\tremaining: 7m 20s\n",
      "1635:\tlearn: 0.0034378\ttotal: 3m 34s\tremaining: 7m 20s\n",
      "1636:\tlearn: 0.0034365\ttotal: 3m 34s\tremaining: 7m 20s\n",
      "1637:\tlearn: 0.0034361\ttotal: 3m 34s\tremaining: 7m 20s\n",
      "1638:\tlearn: 0.0034351\ttotal: 3m 34s\tremaining: 7m 20s\n",
      "1639:\tlearn: 0.0034348\ttotal: 3m 34s\tremaining: 7m 20s\n",
      "1640:\tlearn: 0.0034312\ttotal: 3m 35s\tremaining: 7m 20s\n",
      "1641:\tlearn: 0.0034304\ttotal: 3m 35s\tremaining: 7m 20s\n",
      "1642:\tlearn: 0.0034253\ttotal: 3m 35s\tremaining: 7m 20s\n",
      "1643:\tlearn: 0.0034220\ttotal: 3m 35s\tremaining: 7m 20s\n",
      "1644:\tlearn: 0.0034215\ttotal: 3m 35s\tremaining: 7m 20s\n",
      "1645:\tlearn: 0.0034213\ttotal: 3m 36s\tremaining: 7m 20s\n",
      "1646:\tlearn: 0.0034202\ttotal: 3m 36s\tremaining: 7m 20s\n",
      "1647:\tlearn: 0.0034190\ttotal: 3m 36s\tremaining: 7m 20s\n",
      "1648:\tlearn: 0.0034184\ttotal: 3m 36s\tremaining: 7m 19s\n",
      "1649:\tlearn: 0.0034173\ttotal: 3m 36s\tremaining: 7m 19s\n",
      "1650:\tlearn: 0.0034165\ttotal: 3m 36s\tremaining: 7m 19s\n",
      "1651:\tlearn: 0.0034151\ttotal: 3m 37s\tremaining: 7m 19s\n",
      "1652:\tlearn: 0.0034140\ttotal: 3m 37s\tremaining: 7m 19s\n",
      "1653:\tlearn: 0.0034112\ttotal: 3m 37s\tremaining: 7m 20s\n",
      "1654:\tlearn: 0.0034109\ttotal: 3m 37s\tremaining: 7m 20s\n",
      "1655:\tlearn: 0.0034103\ttotal: 3m 38s\tremaining: 7m 20s\n",
      "1656:\tlearn: 0.0034085\ttotal: 3m 38s\tremaining: 7m 20s\n",
      "1657:\tlearn: 0.0034076\ttotal: 3m 38s\tremaining: 7m 20s\n",
      "1658:\tlearn: 0.0034073\ttotal: 3m 38s\tremaining: 7m 20s\n",
      "1659:\tlearn: 0.0034065\ttotal: 3m 38s\tremaining: 7m 20s\n",
      "1660:\tlearn: 0.0033974\ttotal: 3m 38s\tremaining: 7m 20s\n",
      "1661:\tlearn: 0.0033953\ttotal: 3m 39s\tremaining: 7m 20s\n",
      "1662:\tlearn: 0.0033920\ttotal: 3m 39s\tremaining: 7m 20s\n",
      "1663:\tlearn: 0.0033864\ttotal: 3m 39s\tremaining: 7m 20s\n",
      "1664:\tlearn: 0.0033862\ttotal: 3m 39s\tremaining: 7m 20s\n",
      "1665:\tlearn: 0.0033858\ttotal: 3m 39s\tremaining: 7m 20s\n",
      "1666:\tlearn: 0.0033804\ttotal: 3m 40s\tremaining: 7m 20s\n",
      "1667:\tlearn: 0.0033791\ttotal: 3m 40s\tremaining: 7m 20s\n",
      "1668:\tlearn: 0.0033774\ttotal: 3m 40s\tremaining: 7m 20s\n",
      "1669:\tlearn: 0.0033763\ttotal: 3m 40s\tremaining: 7m 20s\n",
      "1670:\tlearn: 0.0033739\ttotal: 3m 41s\tremaining: 7m 20s\n",
      "1671:\tlearn: 0.0033699\ttotal: 3m 41s\tremaining: 7m 20s\n",
      "1672:\tlearn: 0.0033670\ttotal: 3m 41s\tremaining: 7m 20s\n",
      "1673:\tlearn: 0.0033657\ttotal: 3m 41s\tremaining: 7m 20s\n",
      "1674:\tlearn: 0.0033647\ttotal: 3m 41s\tremaining: 7m 20s\n",
      "1675:\tlearn: 0.0033645\ttotal: 3m 42s\tremaining: 7m 20s\n",
      "1676:\tlearn: 0.0033622\ttotal: 3m 42s\tremaining: 7m 20s\n",
      "1677:\tlearn: 0.0033577\ttotal: 3m 42s\tremaining: 7m 20s\n",
      "1678:\tlearn: 0.0033569\ttotal: 3m 42s\tremaining: 7m 20s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1679:\tlearn: 0.0033531\ttotal: 3m 42s\tremaining: 7m 20s\n",
      "1680:\tlearn: 0.0033522\ttotal: 3m 43s\tremaining: 7m 20s\n",
      "1681:\tlearn: 0.0033511\ttotal: 3m 43s\tremaining: 7m 20s\n",
      "1682:\tlearn: 0.0033502\ttotal: 3m 43s\tremaining: 7m 20s\n",
      "1683:\tlearn: 0.0033383\ttotal: 3m 43s\tremaining: 7m 20s\n",
      "1684:\tlearn: 0.0033343\ttotal: 3m 43s\tremaining: 7m 20s\n",
      "1685:\tlearn: 0.0033307\ttotal: 3m 44s\tremaining: 7m 20s\n",
      "1686:\tlearn: 0.0033294\ttotal: 3m 44s\tremaining: 7m 20s\n",
      "1687:\tlearn: 0.0033290\ttotal: 3m 44s\tremaining: 7m 20s\n",
      "1688:\tlearn: 0.0033283\ttotal: 3m 44s\tremaining: 7m 20s\n",
      "1689:\tlearn: 0.0033228\ttotal: 3m 44s\tremaining: 7m 20s\n",
      "1690:\tlearn: 0.0033210\ttotal: 3m 45s\tremaining: 7m 20s\n",
      "1691:\tlearn: 0.0033192\ttotal: 3m 45s\tremaining: 7m 20s\n",
      "1692:\tlearn: 0.0033159\ttotal: 3m 45s\tremaining: 7m 20s\n",
      "1693:\tlearn: 0.0033140\ttotal: 3m 45s\tremaining: 7m 20s\n",
      "1694:\tlearn: 0.0033100\ttotal: 3m 45s\tremaining: 7m 20s\n",
      "1695:\tlearn: 0.0033095\ttotal: 3m 46s\tremaining: 7m 20s\n",
      "1696:\tlearn: 0.0033048\ttotal: 3m 46s\tremaining: 7m 20s\n",
      "1697:\tlearn: 0.0033021\ttotal: 3m 46s\tremaining: 7m 20s\n",
      "1698:\tlearn: 0.0033011\ttotal: 3m 46s\tremaining: 7m 20s\n",
      "1699:\tlearn: 0.0033010\ttotal: 3m 46s\tremaining: 7m 20s\n",
      "1700:\tlearn: 0.0033007\ttotal: 3m 46s\tremaining: 7m 20s\n",
      "1701:\tlearn: 0.0032955\ttotal: 3m 47s\tremaining: 7m 20s\n",
      "1702:\tlearn: 0.0032914\ttotal: 3m 47s\tremaining: 7m 20s\n",
      "1703:\tlearn: 0.0032911\ttotal: 3m 47s\tremaining: 7m 20s\n",
      "1704:\tlearn: 0.0032905\ttotal: 3m 47s\tremaining: 7m 20s\n",
      "1705:\tlearn: 0.0032892\ttotal: 3m 48s\tremaining: 7m 20s\n",
      "1706:\tlearn: 0.0032880\ttotal: 3m 48s\tremaining: 7m 20s\n",
      "1707:\tlearn: 0.0032871\ttotal: 3m 48s\tremaining: 7m 20s\n",
      "1708:\tlearn: 0.0032821\ttotal: 3m 48s\tremaining: 7m 20s\n",
      "1709:\tlearn: 0.0032818\ttotal: 3m 48s\tremaining: 7m 20s\n",
      "1710:\tlearn: 0.0032812\ttotal: 3m 48s\tremaining: 7m 20s\n",
      "1711:\tlearn: 0.0032791\ttotal: 3m 49s\tremaining: 7m 20s\n",
      "1712:\tlearn: 0.0032718\ttotal: 3m 49s\tremaining: 7m 20s\n",
      "1713:\tlearn: 0.0032708\ttotal: 3m 49s\tremaining: 7m 20s\n",
      "1714:\tlearn: 0.0032668\ttotal: 3m 49s\tremaining: 7m 20s\n",
      "1715:\tlearn: 0.0032663\ttotal: 3m 49s\tremaining: 7m 20s\n",
      "1716:\tlearn: 0.0032660\ttotal: 3m 50s\tremaining: 7m 20s\n",
      "1717:\tlearn: 0.0032659\ttotal: 3m 50s\tremaining: 7m 19s\n",
      "1718:\tlearn: 0.0032638\ttotal: 3m 50s\tremaining: 7m 19s\n",
      "1719:\tlearn: 0.0032635\ttotal: 3m 50s\tremaining: 7m 19s\n",
      "1720:\tlearn: 0.0032630\ttotal: 3m 50s\tremaining: 7m 19s\n",
      "1721:\tlearn: 0.0032595\ttotal: 3m 51s\tremaining: 7m 19s\n",
      "1722:\tlearn: 0.0032577\ttotal: 3m 51s\tremaining: 7m 19s\n",
      "1723:\tlearn: 0.0032539\ttotal: 3m 51s\tremaining: 7m 19s\n",
      "1724:\tlearn: 0.0032525\ttotal: 3m 51s\tremaining: 7m 19s\n",
      "1725:\tlearn: 0.0032504\ttotal: 3m 51s\tremaining: 7m 19s\n",
      "1726:\tlearn: 0.0032471\ttotal: 3m 52s\tremaining: 7m 19s\n",
      "1727:\tlearn: 0.0032455\ttotal: 3m 52s\tremaining: 7m 19s\n",
      "1728:\tlearn: 0.0032449\ttotal: 3m 52s\tremaining: 7m 19s\n",
      "1729:\tlearn: 0.0032428\ttotal: 3m 52s\tremaining: 7m 19s\n",
      "1730:\tlearn: 0.0032418\ttotal: 3m 52s\tremaining: 7m 19s\n",
      "1731:\tlearn: 0.0032403\ttotal: 3m 53s\tremaining: 7m 19s\n",
      "1732:\tlearn: 0.0032395\ttotal: 3m 53s\tremaining: 7m 19s\n",
      "1733:\tlearn: 0.0032381\ttotal: 3m 53s\tremaining: 7m 19s\n",
      "1734:\tlearn: 0.0032301\ttotal: 3m 53s\tremaining: 7m 19s\n",
      "1735:\tlearn: 0.0032292\ttotal: 3m 53s\tremaining: 7m 19s\n",
      "1736:\tlearn: 0.0032283\ttotal: 3m 54s\tremaining: 7m 19s\n",
      "1737:\tlearn: 0.0032273\ttotal: 3m 54s\tremaining: 7m 19s\n",
      "1738:\tlearn: 0.0032248\ttotal: 3m 54s\tremaining: 7m 19s\n",
      "1739:\tlearn: 0.0032216\ttotal: 3m 54s\tremaining: 7m 19s\n",
      "1740:\tlearn: 0.0032212\ttotal: 3m 54s\tremaining: 7m 19s\n",
      "1741:\tlearn: 0.0032189\ttotal: 3m 54s\tremaining: 7m 19s\n",
      "1742:\tlearn: 0.0032167\ttotal: 3m 55s\tremaining: 7m 19s\n",
      "1743:\tlearn: 0.0032130\ttotal: 3m 55s\tremaining: 7m 19s\n",
      "1744:\tlearn: 0.0032104\ttotal: 3m 55s\tremaining: 7m 19s\n",
      "1745:\tlearn: 0.0032098\ttotal: 3m 55s\tremaining: 7m 19s\n",
      "1746:\tlearn: 0.0032092\ttotal: 3m 55s\tremaining: 7m 19s\n",
      "1747:\tlearn: 0.0032088\ttotal: 3m 56s\tremaining: 7m 19s\n",
      "1748:\tlearn: 0.0032071\ttotal: 3m 56s\tremaining: 7m 19s\n",
      "1749:\tlearn: 0.0032052\ttotal: 3m 56s\tremaining: 7m 19s\n",
      "1750:\tlearn: 0.0032043\ttotal: 3m 56s\tremaining: 7m 18s\n",
      "1751:\tlearn: 0.0032039\ttotal: 3m 56s\tremaining: 7m 18s\n",
      "1752:\tlearn: 0.0032036\ttotal: 3m 56s\tremaining: 7m 18s\n",
      "1753:\tlearn: 0.0032029\ttotal: 3m 57s\tremaining: 7m 18s\n",
      "1754:\tlearn: 0.0032016\ttotal: 3m 57s\tremaining: 7m 18s\n",
      "1755:\tlearn: 0.0032004\ttotal: 3m 57s\tremaining: 7m 19s\n",
      "1756:\tlearn: 0.0031986\ttotal: 3m 57s\tremaining: 7m 19s\n",
      "1757:\tlearn: 0.0031984\ttotal: 3m 58s\tremaining: 7m 19s\n",
      "1758:\tlearn: 0.0031949\ttotal: 3m 58s\tremaining: 7m 19s\n",
      "1759:\tlearn: 0.0031943\ttotal: 3m 58s\tremaining: 7m 19s\n",
      "1760:\tlearn: 0.0031939\ttotal: 3m 58s\tremaining: 7m 19s\n",
      "1761:\tlearn: 0.0031932\ttotal: 3m 59s\tremaining: 7m 19s\n",
      "1762:\tlearn: 0.0031927\ttotal: 3m 59s\tremaining: 7m 19s\n",
      "1763:\tlearn: 0.0031913\ttotal: 3m 59s\tremaining: 7m 19s\n",
      "1764:\tlearn: 0.0031889\ttotal: 3m 59s\tremaining: 7m 19s\n",
      "1765:\tlearn: 0.0031867\ttotal: 3m 59s\tremaining: 7m 19s\n",
      "1766:\tlearn: 0.0031861\ttotal: 4m\tremaining: 7m 19s\n",
      "1767:\tlearn: 0.0031844\ttotal: 4m\tremaining: 7m 19s\n",
      "1768:\tlearn: 0.0031830\ttotal: 4m\tremaining: 7m 19s\n",
      "1769:\tlearn: 0.0031811\ttotal: 4m\tremaining: 7m 19s\n",
      "1770:\tlearn: 0.0031800\ttotal: 4m 1s\tremaining: 7m 19s\n",
      "1771:\tlearn: 0.0031760\ttotal: 4m 1s\tremaining: 7m 19s\n",
      "1772:\tlearn: 0.0031732\ttotal: 4m 1s\tremaining: 7m 19s\n",
      "1773:\tlearn: 0.0031730\ttotal: 4m 1s\tremaining: 7m 19s\n",
      "1774:\tlearn: 0.0031710\ttotal: 4m 2s\tremaining: 7m 19s\n",
      "1775:\tlearn: 0.0031706\ttotal: 4m 2s\tremaining: 7m 19s\n",
      "1776:\tlearn: 0.0031701\ttotal: 4m 2s\tremaining: 7m 19s\n",
      "1777:\tlearn: 0.0031613\ttotal: 4m 2s\tremaining: 7m 19s\n",
      "1778:\tlearn: 0.0031611\ttotal: 4m 3s\tremaining: 7m 20s\n",
      "1779:\tlearn: 0.0031590\ttotal: 4m 3s\tremaining: 7m 20s\n",
      "1780:\tlearn: 0.0031502\ttotal: 4m 3s\tremaining: 7m 20s\n",
      "1781:\tlearn: 0.0031495\ttotal: 4m 3s\tremaining: 7m 20s\n",
      "1782:\tlearn: 0.0031492\ttotal: 4m 4s\tremaining: 7m 20s\n",
      "1783:\tlearn: 0.0031474\ttotal: 4m 4s\tremaining: 7m 20s\n",
      "1784:\tlearn: 0.0031469\ttotal: 4m 4s\tremaining: 7m 20s\n",
      "1785:\tlearn: 0.0031454\ttotal: 4m 4s\tremaining: 7m 20s\n",
      "1786:\tlearn: 0.0031448\ttotal: 4m 5s\tremaining: 7m 20s\n",
      "1787:\tlearn: 0.0031403\ttotal: 4m 5s\tremaining: 7m 21s\n",
      "1788:\tlearn: 0.0031394\ttotal: 4m 5s\tremaining: 7m 21s\n",
      "1789:\tlearn: 0.0031370\ttotal: 4m 6s\tremaining: 7m 21s\n",
      "1790:\tlearn: 0.0031358\ttotal: 4m 6s\tremaining: 7m 21s\n",
      "1791:\tlearn: 0.0031357\ttotal: 4m 6s\tremaining: 7m 21s\n",
      "1792:\tlearn: 0.0031345\ttotal: 4m 6s\tremaining: 7m 21s\n",
      "1793:\tlearn: 0.0031333\ttotal: 4m 6s\tremaining: 7m 21s\n",
      "1794:\tlearn: 0.0031216\ttotal: 4m 7s\tremaining: 7m 21s\n",
      "1795:\tlearn: 0.0031195\ttotal: 4m 7s\tremaining: 7m 21s\n",
      "1796:\tlearn: 0.0031167\ttotal: 4m 7s\tremaining: 7m 21s\n",
      "1797:\tlearn: 0.0031144\ttotal: 4m 7s\tremaining: 7m 21s\n",
      "1798:\tlearn: 0.0031137\ttotal: 4m 8s\tremaining: 7m 21s\n",
      "1799:\tlearn: 0.0031133\ttotal: 4m 8s\tremaining: 7m 21s\n",
      "1800:\tlearn: 0.0031115\ttotal: 4m 8s\tremaining: 7m 21s\n",
      "1801:\tlearn: 0.0031094\ttotal: 4m 8s\tremaining: 7m 21s\n",
      "1802:\tlearn: 0.0031059\ttotal: 4m 9s\tremaining: 7m 22s\n",
      "1803:\tlearn: 0.0031002\ttotal: 4m 9s\tremaining: 7m 22s\n",
      "1804:\tlearn: 0.0031001\ttotal: 4m 9s\tremaining: 7m 22s\n",
      "1805:\tlearn: 0.0030989\ttotal: 4m 10s\tremaining: 7m 22s\n",
      "1806:\tlearn: 0.0030971\ttotal: 4m 10s\tremaining: 7m 22s\n",
      "1807:\tlearn: 0.0030968\ttotal: 4m 10s\tremaining: 7m 22s\n",
      "1808:\tlearn: 0.0030954\ttotal: 4m 10s\tremaining: 7m 22s\n",
      "1809:\tlearn: 0.0030946\ttotal: 4m 10s\tremaining: 7m 22s\n",
      "1810:\tlearn: 0.0030922\ttotal: 4m 11s\tremaining: 7m 22s\n",
      "1811:\tlearn: 0.0030911\ttotal: 4m 11s\tremaining: 7m 22s\n",
      "1812:\tlearn: 0.0030903\ttotal: 4m 11s\tremaining: 7m 22s\n",
      "1813:\tlearn: 0.0030897\ttotal: 4m 12s\tremaining: 7m 22s\n",
      "1814:\tlearn: 0.0030867\ttotal: 4m 12s\tremaining: 7m 23s\n",
      "1815:\tlearn: 0.0030863\ttotal: 4m 12s\tremaining: 7m 23s\n",
      "1816:\tlearn: 0.0030860\ttotal: 4m 12s\tremaining: 7m 23s\n",
      "1817:\tlearn: 0.0030832\ttotal: 4m 13s\tremaining: 7m 23s\n",
      "1818:\tlearn: 0.0030812\ttotal: 4m 13s\tremaining: 7m 23s\n",
      "1819:\tlearn: 0.0030807\ttotal: 4m 13s\tremaining: 7m 23s\n",
      "1820:\tlearn: 0.0030794\ttotal: 4m 13s\tremaining: 7m 23s\n",
      "1821:\tlearn: 0.0030790\ttotal: 4m 14s\tremaining: 7m 23s\n",
      "1822:\tlearn: 0.0030780\ttotal: 4m 14s\tremaining: 7m 23s\n",
      "1823:\tlearn: 0.0030774\ttotal: 4m 14s\tremaining: 7m 23s\n",
      "1824:\tlearn: 0.0030765\ttotal: 4m 14s\tremaining: 7m 23s\n",
      "1825:\tlearn: 0.0030760\ttotal: 4m 14s\tremaining: 7m 23s\n",
      "1826:\tlearn: 0.0030758\ttotal: 4m 15s\tremaining: 7m 22s\n",
      "1827:\tlearn: 0.0030752\ttotal: 4m 15s\tremaining: 7m 22s\n",
      "1828:\tlearn: 0.0030733\ttotal: 4m 15s\tremaining: 7m 22s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1829:\tlearn: 0.0030698\ttotal: 4m 15s\tremaining: 7m 22s\n",
      "1830:\tlearn: 0.0030696\ttotal: 4m 15s\tremaining: 7m 22s\n",
      "1831:\tlearn: 0.0030666\ttotal: 4m 16s\tremaining: 7m 22s\n",
      "1832:\tlearn: 0.0030653\ttotal: 4m 16s\tremaining: 7m 22s\n",
      "1833:\tlearn: 0.0030647\ttotal: 4m 16s\tremaining: 7m 22s\n",
      "1834:\tlearn: 0.0030638\ttotal: 4m 16s\tremaining: 7m 22s\n",
      "1835:\tlearn: 0.0030588\ttotal: 4m 16s\tremaining: 7m 22s\n",
      "1836:\tlearn: 0.0030566\ttotal: 4m 17s\tremaining: 7m 22s\n",
      "1837:\tlearn: 0.0030554\ttotal: 4m 17s\tremaining: 7m 22s\n",
      "1838:\tlearn: 0.0030532\ttotal: 4m 17s\tremaining: 7m 22s\n",
      "1839:\tlearn: 0.0030509\ttotal: 4m 17s\tremaining: 7m 22s\n",
      "1840:\tlearn: 0.0030509\ttotal: 4m 17s\tremaining: 7m 22s\n",
      "1841:\tlearn: 0.0030503\ttotal: 4m 18s\tremaining: 7m 22s\n",
      "1842:\tlearn: 0.0030497\ttotal: 4m 18s\tremaining: 7m 22s\n",
      "1843:\tlearn: 0.0030497\ttotal: 4m 18s\tremaining: 7m 22s\n",
      "1844:\tlearn: 0.0030494\ttotal: 4m 18s\tremaining: 7m 22s\n",
      "1845:\tlearn: 0.0030490\ttotal: 4m 19s\tremaining: 7m 22s\n",
      "1846:\tlearn: 0.0030488\ttotal: 4m 19s\tremaining: 7m 22s\n",
      "1847:\tlearn: 0.0030477\ttotal: 4m 19s\tremaining: 7m 22s\n",
      "1848:\tlearn: 0.0030468\ttotal: 4m 19s\tremaining: 7m 22s\n",
      "1849:\tlearn: 0.0030439\ttotal: 4m 20s\tremaining: 7m 22s\n",
      "1850:\tlearn: 0.0030434\ttotal: 4m 20s\tremaining: 7m 22s\n",
      "1851:\tlearn: 0.0030422\ttotal: 4m 20s\tremaining: 7m 22s\n",
      "1852:\tlearn: 0.0030419\ttotal: 4m 20s\tremaining: 7m 22s\n",
      "1853:\tlearn: 0.0030400\ttotal: 4m 20s\tremaining: 7m 22s\n",
      "1854:\tlearn: 0.0030380\ttotal: 4m 20s\tremaining: 7m 22s\n",
      "1855:\tlearn: 0.0030351\ttotal: 4m 21s\tremaining: 7m 22s\n",
      "1856:\tlearn: 0.0030332\ttotal: 4m 21s\tremaining: 7m 22s\n",
      "1857:\tlearn: 0.0030326\ttotal: 4m 21s\tremaining: 7m 22s\n",
      "1858:\tlearn: 0.0030298\ttotal: 4m 21s\tremaining: 7m 22s\n",
      "1859:\tlearn: 0.0030163\ttotal: 4m 21s\tremaining: 7m 22s\n",
      "1860:\tlearn: 0.0030153\ttotal: 4m 22s\tremaining: 7m 21s\n",
      "1861:\tlearn: 0.0030146\ttotal: 4m 22s\tremaining: 7m 21s\n",
      "1862:\tlearn: 0.0030144\ttotal: 4m 22s\tremaining: 7m 21s\n",
      "1863:\tlearn: 0.0030141\ttotal: 4m 22s\tremaining: 7m 21s\n",
      "1864:\tlearn: 0.0030138\ttotal: 4m 22s\tremaining: 7m 21s\n",
      "1865:\tlearn: 0.0030108\ttotal: 4m 22s\tremaining: 7m 21s\n",
      "1866:\tlearn: 0.0030104\ttotal: 4m 23s\tremaining: 7m 21s\n",
      "1867:\tlearn: 0.0030100\ttotal: 4m 23s\tremaining: 7m 21s\n",
      "1868:\tlearn: 0.0030056\ttotal: 4m 23s\tremaining: 7m 21s\n",
      "1869:\tlearn: 0.0030052\ttotal: 4m 23s\tremaining: 7m 21s\n",
      "1870:\tlearn: 0.0030031\ttotal: 4m 23s\tremaining: 7m 20s\n",
      "1871:\tlearn: 0.0029997\ttotal: 4m 23s\tremaining: 7m 20s\n",
      "1872:\tlearn: 0.0029966\ttotal: 4m 23s\tremaining: 7m 20s\n",
      "1873:\tlearn: 0.0029934\ttotal: 4m 24s\tremaining: 7m 20s\n",
      "1874:\tlearn: 0.0029924\ttotal: 4m 24s\tremaining: 7m 20s\n",
      "1875:\tlearn: 0.0029917\ttotal: 4m 24s\tremaining: 7m 20s\n",
      "1876:\tlearn: 0.0029891\ttotal: 4m 24s\tremaining: 7m 20s\n",
      "1877:\tlearn: 0.0029885\ttotal: 4m 24s\tremaining: 7m 20s\n",
      "1878:\tlearn: 0.0029875\ttotal: 4m 25s\tremaining: 7m 20s\n",
      "1879:\tlearn: 0.0029865\ttotal: 4m 25s\tremaining: 7m 20s\n",
      "1880:\tlearn: 0.0029852\ttotal: 4m 25s\tremaining: 7m 20s\n",
      "1881:\tlearn: 0.0029847\ttotal: 4m 25s\tremaining: 7m 19s\n",
      "1882:\tlearn: 0.0029845\ttotal: 4m 25s\tremaining: 7m 19s\n",
      "1883:\tlearn: 0.0029843\ttotal: 4m 25s\tremaining: 7m 19s\n",
      "1884:\tlearn: 0.0029840\ttotal: 4m 26s\tremaining: 7m 19s\n",
      "1885:\tlearn: 0.0029838\ttotal: 4m 26s\tremaining: 7m 19s\n",
      "1886:\tlearn: 0.0029826\ttotal: 4m 26s\tremaining: 7m 19s\n",
      "1887:\tlearn: 0.0029813\ttotal: 4m 26s\tremaining: 7m 19s\n",
      "1888:\tlearn: 0.0029812\ttotal: 4m 26s\tremaining: 7m 19s\n",
      "1889:\tlearn: 0.0029791\ttotal: 4m 26s\tremaining: 7m 19s\n",
      "1890:\tlearn: 0.0029755\ttotal: 4m 27s\tremaining: 7m 19s\n",
      "1891:\tlearn: 0.0029751\ttotal: 4m 27s\tremaining: 7m 18s\n",
      "1892:\tlearn: 0.0029732\ttotal: 4m 27s\tremaining: 7m 18s\n",
      "1893:\tlearn: 0.0029725\ttotal: 4m 27s\tremaining: 7m 18s\n",
      "1894:\tlearn: 0.0029723\ttotal: 4m 27s\tremaining: 7m 18s\n",
      "1895:\tlearn: 0.0029685\ttotal: 4m 27s\tremaining: 7m 18s\n",
      "1896:\tlearn: 0.0029677\ttotal: 4m 27s\tremaining: 7m 18s\n",
      "1897:\tlearn: 0.0029663\ttotal: 4m 28s\tremaining: 7m 18s\n",
      "1898:\tlearn: 0.0029638\ttotal: 4m 28s\tremaining: 7m 18s\n",
      "1899:\tlearn: 0.0029633\ttotal: 4m 28s\tremaining: 7m 17s\n",
      "1900:\tlearn: 0.0029619\ttotal: 4m 28s\tremaining: 7m 17s\n",
      "1901:\tlearn: 0.0029615\ttotal: 4m 28s\tremaining: 7m 17s\n",
      "1902:\tlearn: 0.0029608\ttotal: 4m 28s\tremaining: 7m 17s\n",
      "1903:\tlearn: 0.0029604\ttotal: 4m 29s\tremaining: 7m 17s\n",
      "1904:\tlearn: 0.0029600\ttotal: 4m 29s\tremaining: 7m 17s\n",
      "1905:\tlearn: 0.0029598\ttotal: 4m 29s\tremaining: 7m 17s\n",
      "1906:\tlearn: 0.0029574\ttotal: 4m 29s\tremaining: 7m 17s\n",
      "1907:\tlearn: 0.0029568\ttotal: 4m 29s\tremaining: 7m 17s\n",
      "1908:\tlearn: 0.0029567\ttotal: 4m 29s\tremaining: 7m 16s\n",
      "1909:\tlearn: 0.0029564\ttotal: 4m 30s\tremaining: 7m 16s\n",
      "1910:\tlearn: 0.0029552\ttotal: 4m 30s\tremaining: 7m 16s\n",
      "1911:\tlearn: 0.0029527\ttotal: 4m 30s\tremaining: 7m 16s\n",
      "1912:\tlearn: 0.0029522\ttotal: 4m 30s\tremaining: 7m 16s\n",
      "1913:\tlearn: 0.0029514\ttotal: 4m 30s\tremaining: 7m 16s\n",
      "1914:\tlearn: 0.0029508\ttotal: 4m 30s\tremaining: 7m 16s\n",
      "1915:\tlearn: 0.0029489\ttotal: 4m 30s\tremaining: 7m 16s\n",
      "1916:\tlearn: 0.0029465\ttotal: 4m 31s\tremaining: 7m 15s\n",
      "1917:\tlearn: 0.0029459\ttotal: 4m 31s\tremaining: 7m 15s\n",
      "1918:\tlearn: 0.0029440\ttotal: 4m 31s\tremaining: 7m 15s\n",
      "1919:\tlearn: 0.0029436\ttotal: 4m 31s\tremaining: 7m 15s\n",
      "1920:\tlearn: 0.0029433\ttotal: 4m 31s\tremaining: 7m 15s\n",
      "1921:\tlearn: 0.0029429\ttotal: 4m 31s\tremaining: 7m 15s\n",
      "1922:\tlearn: 0.0029417\ttotal: 4m 31s\tremaining: 7m 15s\n",
      "1923:\tlearn: 0.0029404\ttotal: 4m 32s\tremaining: 7m 14s\n",
      "1924:\tlearn: 0.0029399\ttotal: 4m 32s\tremaining: 7m 14s\n",
      "1925:\tlearn: 0.0029382\ttotal: 4m 32s\tremaining: 7m 14s\n",
      "1926:\tlearn: 0.0029381\ttotal: 4m 32s\tremaining: 7m 14s\n",
      "1927:\tlearn: 0.0029379\ttotal: 4m 32s\tremaining: 7m 14s\n",
      "1928:\tlearn: 0.0029378\ttotal: 4m 32s\tremaining: 7m 14s\n",
      "1929:\tlearn: 0.0029373\ttotal: 4m 32s\tremaining: 7m 14s\n",
      "1930:\tlearn: 0.0029351\ttotal: 4m 33s\tremaining: 7m 13s\n",
      "1931:\tlearn: 0.0029326\ttotal: 4m 33s\tremaining: 7m 13s\n",
      "1932:\tlearn: 0.0029324\ttotal: 4m 33s\tremaining: 7m 13s\n",
      "1933:\tlearn: 0.0029309\ttotal: 4m 33s\tremaining: 7m 13s\n",
      "1934:\tlearn: 0.0029305\ttotal: 4m 33s\tremaining: 7m 13s\n",
      "1935:\tlearn: 0.0029301\ttotal: 4m 33s\tremaining: 7m 13s\n",
      "1936:\tlearn: 0.0029250\ttotal: 4m 33s\tremaining: 7m 13s\n",
      "1937:\tlearn: 0.0029235\ttotal: 4m 34s\tremaining: 7m 13s\n",
      "1938:\tlearn: 0.0029221\ttotal: 4m 34s\tremaining: 7m 12s\n",
      "1939:\tlearn: 0.0029211\ttotal: 4m 34s\tremaining: 7m 12s\n",
      "1940:\tlearn: 0.0029203\ttotal: 4m 34s\tremaining: 7m 12s\n",
      "1941:\tlearn: 0.0029158\ttotal: 4m 34s\tremaining: 7m 12s\n",
      "1942:\tlearn: 0.0029151\ttotal: 4m 34s\tremaining: 7m 12s\n",
      "1943:\tlearn: 0.0029131\ttotal: 4m 34s\tremaining: 7m 12s\n",
      "1944:\tlearn: 0.0029124\ttotal: 4m 35s\tremaining: 7m 12s\n",
      "1945:\tlearn: 0.0029119\ttotal: 4m 35s\tremaining: 7m 11s\n",
      "1946:\tlearn: 0.0029106\ttotal: 4m 35s\tremaining: 7m 11s\n",
      "1947:\tlearn: 0.0029101\ttotal: 4m 35s\tremaining: 7m 11s\n",
      "1948:\tlearn: 0.0029081\ttotal: 4m 35s\tremaining: 7m 11s\n",
      "1949:\tlearn: 0.0029079\ttotal: 4m 35s\tremaining: 7m 11s\n",
      "1950:\tlearn: 0.0029072\ttotal: 4m 35s\tremaining: 7m 11s\n",
      "1951:\tlearn: 0.0029043\ttotal: 4m 36s\tremaining: 7m 11s\n",
      "1952:\tlearn: 0.0029008\ttotal: 4m 36s\tremaining: 7m 11s\n",
      "1953:\tlearn: 0.0028973\ttotal: 4m 36s\tremaining: 7m 11s\n",
      "1954:\tlearn: 0.0028966\ttotal: 4m 36s\tremaining: 7m 10s\n",
      "1955:\tlearn: 0.0028963\ttotal: 4m 36s\tremaining: 7m 10s\n",
      "1956:\tlearn: 0.0028958\ttotal: 4m 36s\tremaining: 7m 10s\n",
      "1957:\tlearn: 0.0028943\ttotal: 4m 37s\tremaining: 7m 10s\n",
      "1958:\tlearn: 0.0028918\ttotal: 4m 37s\tremaining: 7m 10s\n",
      "1959:\tlearn: 0.0028912\ttotal: 4m 37s\tremaining: 7m 10s\n",
      "1960:\tlearn: 0.0028875\ttotal: 4m 37s\tremaining: 7m 10s\n",
      "1961:\tlearn: 0.0028863\ttotal: 4m 37s\tremaining: 7m 10s\n",
      "1962:\tlearn: 0.0028850\ttotal: 4m 37s\tremaining: 7m 10s\n",
      "1963:\tlearn: 0.0028842\ttotal: 4m 38s\tremaining: 7m 9s\n",
      "1964:\tlearn: 0.0028787\ttotal: 4m 38s\tremaining: 7m 9s\n",
      "1965:\tlearn: 0.0028786\ttotal: 4m 38s\tremaining: 7m 9s\n",
      "1966:\tlearn: 0.0028769\ttotal: 4m 38s\tremaining: 7m 9s\n",
      "1967:\tlearn: 0.0028724\ttotal: 4m 38s\tremaining: 7m 9s\n",
      "1968:\tlearn: 0.0028721\ttotal: 4m 38s\tremaining: 7m 9s\n",
      "1969:\tlearn: 0.0028693\ttotal: 4m 39s\tremaining: 7m 9s\n",
      "1970:\tlearn: 0.0028689\ttotal: 4m 39s\tremaining: 7m 9s\n",
      "1971:\tlearn: 0.0028686\ttotal: 4m 39s\tremaining: 7m 8s\n",
      "1972:\tlearn: 0.0028683\ttotal: 4m 39s\tremaining: 7m 8s\n",
      "1973:\tlearn: 0.0028666\ttotal: 4m 39s\tremaining: 7m 8s\n",
      "1974:\tlearn: 0.0028631\ttotal: 4m 39s\tremaining: 7m 8s\n",
      "1975:\tlearn: 0.0028616\ttotal: 4m 39s\tremaining: 7m 8s\n",
      "1976:\tlearn: 0.0028610\ttotal: 4m 40s\tremaining: 7m 8s\n",
      "1977:\tlearn: 0.0028601\ttotal: 4m 40s\tremaining: 7m 8s\n",
      "1978:\tlearn: 0.0028599\ttotal: 4m 40s\tremaining: 7m 7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1979:\tlearn: 0.0028596\ttotal: 4m 40s\tremaining: 7m 7s\n",
      "1980:\tlearn: 0.0028593\ttotal: 4m 40s\tremaining: 7m 7s\n",
      "1981:\tlearn: 0.0028578\ttotal: 4m 40s\tremaining: 7m 7s\n",
      "1982:\tlearn: 0.0028575\ttotal: 4m 40s\tremaining: 7m 7s\n",
      "1983:\tlearn: 0.0028560\ttotal: 4m 41s\tremaining: 7m 7s\n",
      "1984:\tlearn: 0.0028528\ttotal: 4m 41s\tremaining: 7m 7s\n",
      "1985:\tlearn: 0.0028517\ttotal: 4m 41s\tremaining: 7m 6s\n",
      "1986:\tlearn: 0.0028510\ttotal: 4m 41s\tremaining: 7m 6s\n",
      "1987:\tlearn: 0.0028500\ttotal: 4m 41s\tremaining: 7m 6s\n",
      "1988:\tlearn: 0.0028486\ttotal: 4m 41s\tremaining: 7m 6s\n",
      "1989:\tlearn: 0.0028464\ttotal: 4m 41s\tremaining: 7m 6s\n",
      "1990:\tlearn: 0.0028461\ttotal: 4m 41s\tremaining: 7m 5s\n",
      "1991:\tlearn: 0.0028456\ttotal: 4m 41s\tremaining: 7m 5s\n",
      "1992:\tlearn: 0.0028426\ttotal: 4m 42s\tremaining: 7m 5s\n",
      "1993:\tlearn: 0.0028419\ttotal: 4m 42s\tremaining: 7m 5s\n",
      "1994:\tlearn: 0.0028418\ttotal: 4m 42s\tremaining: 7m 5s\n",
      "1995:\tlearn: 0.0028401\ttotal: 4m 42s\tremaining: 7m 5s\n",
      "1996:\tlearn: 0.0028400\ttotal: 4m 42s\tremaining: 7m 4s\n",
      "1997:\tlearn: 0.0028384\ttotal: 4m 42s\tremaining: 7m 4s\n",
      "1998:\tlearn: 0.0028378\ttotal: 4m 42s\tremaining: 7m 4s\n",
      "1999:\tlearn: 0.0028373\ttotal: 4m 42s\tremaining: 7m 4s\n",
      "2000:\tlearn: 0.0028355\ttotal: 4m 42s\tremaining: 7m 4s\n",
      "2001:\tlearn: 0.0028353\ttotal: 4m 43s\tremaining: 7m 3s\n",
      "2002:\tlearn: 0.0028343\ttotal: 4m 43s\tremaining: 7m 3s\n",
      "2003:\tlearn: 0.0028335\ttotal: 4m 43s\tremaining: 7m 3s\n",
      "2004:\tlearn: 0.0028324\ttotal: 4m 43s\tremaining: 7m 3s\n",
      "2005:\tlearn: 0.0028221\ttotal: 4m 43s\tremaining: 7m 3s\n",
      "2006:\tlearn: 0.0028217\ttotal: 4m 43s\tremaining: 7m 3s\n",
      "2007:\tlearn: 0.0028209\ttotal: 4m 43s\tremaining: 7m 2s\n",
      "2008:\tlearn: 0.0028166\ttotal: 4m 43s\tremaining: 7m 2s\n",
      "2009:\tlearn: 0.0028157\ttotal: 4m 44s\tremaining: 7m 2s\n",
      "2010:\tlearn: 0.0028146\ttotal: 4m 44s\tremaining: 7m 2s\n",
      "2011:\tlearn: 0.0028140\ttotal: 4m 44s\tremaining: 7m 2s\n",
      "2012:\tlearn: 0.0028124\ttotal: 4m 44s\tremaining: 7m 1s\n",
      "2013:\tlearn: 0.0028113\ttotal: 4m 44s\tremaining: 7m 1s\n",
      "2014:\tlearn: 0.0028085\ttotal: 4m 44s\tremaining: 7m 1s\n",
      "2015:\tlearn: 0.0028083\ttotal: 4m 44s\tremaining: 7m 1s\n",
      "2016:\tlearn: 0.0028062\ttotal: 4m 44s\tremaining: 7m 1s\n",
      "2017:\tlearn: 0.0028038\ttotal: 4m 44s\tremaining: 7m 1s\n",
      "2018:\tlearn: 0.0028028\ttotal: 4m 45s\tremaining: 7m\n",
      "2019:\tlearn: 0.0028024\ttotal: 4m 45s\tremaining: 7m\n",
      "2020:\tlearn: 0.0028014\ttotal: 4m 45s\tremaining: 7m\n",
      "2021:\tlearn: 0.0028002\ttotal: 4m 45s\tremaining: 7m\n",
      "2022:\tlearn: 0.0027998\ttotal: 4m 45s\tremaining: 7m\n",
      "2023:\tlearn: 0.0027992\ttotal: 4m 45s\tremaining: 7m\n",
      "2024:\tlearn: 0.0027988\ttotal: 4m 45s\tremaining: 6m 59s\n",
      "2025:\tlearn: 0.0027975\ttotal: 4m 45s\tremaining: 6m 59s\n",
      "2026:\tlearn: 0.0027972\ttotal: 4m 46s\tremaining: 6m 59s\n",
      "2027:\tlearn: 0.0027961\ttotal: 4m 46s\tremaining: 6m 59s\n",
      "2028:\tlearn: 0.0027932\ttotal: 4m 46s\tremaining: 6m 59s\n",
      "2029:\tlearn: 0.0027929\ttotal: 4m 46s\tremaining: 6m 58s\n",
      "2030:\tlearn: 0.0027926\ttotal: 4m 46s\tremaining: 6m 58s\n",
      "2031:\tlearn: 0.0027925\ttotal: 4m 46s\tremaining: 6m 58s\n",
      "2032:\tlearn: 0.0027924\ttotal: 4m 46s\tremaining: 6m 58s\n",
      "2033:\tlearn: 0.0027912\ttotal: 4m 46s\tremaining: 6m 58s\n",
      "2034:\tlearn: 0.0027909\ttotal: 4m 46s\tremaining: 6m 58s\n",
      "2035:\tlearn: 0.0027903\ttotal: 4m 47s\tremaining: 6m 57s\n",
      "2036:\tlearn: 0.0027900\ttotal: 4m 47s\tremaining: 6m 57s\n",
      "2037:\tlearn: 0.0027898\ttotal: 4m 47s\tremaining: 6m 57s\n",
      "2038:\tlearn: 0.0027884\ttotal: 4m 47s\tremaining: 6m 57s\n",
      "2039:\tlearn: 0.0027874\ttotal: 4m 47s\tremaining: 6m 57s\n",
      "2040:\tlearn: 0.0027865\ttotal: 4m 47s\tremaining: 6m 56s\n",
      "2041:\tlearn: 0.0027853\ttotal: 4m 47s\tremaining: 6m 56s\n",
      "2042:\tlearn: 0.0027846\ttotal: 4m 47s\tremaining: 6m 56s\n",
      "2043:\tlearn: 0.0027845\ttotal: 4m 47s\tremaining: 6m 56s\n",
      "2044:\tlearn: 0.0027842\ttotal: 4m 48s\tremaining: 6m 56s\n",
      "2045:\tlearn: 0.0027833\ttotal: 4m 48s\tremaining: 6m 56s\n",
      "2046:\tlearn: 0.0027828\ttotal: 4m 48s\tremaining: 6m 55s\n",
      "2047:\tlearn: 0.0027800\ttotal: 4m 48s\tremaining: 6m 55s\n",
      "2048:\tlearn: 0.0027792\ttotal: 4m 48s\tremaining: 6m 55s\n",
      "2049:\tlearn: 0.0027790\ttotal: 4m 48s\tremaining: 6m 55s\n",
      "2050:\tlearn: 0.0027749\ttotal: 4m 48s\tremaining: 6m 55s\n",
      "2051:\tlearn: 0.0027675\ttotal: 4m 48s\tremaining: 6m 55s\n",
      "2052:\tlearn: 0.0027660\ttotal: 4m 49s\tremaining: 6m 54s\n",
      "2053:\tlearn: 0.0027630\ttotal: 4m 49s\tremaining: 6m 54s\n",
      "2054:\tlearn: 0.0027620\ttotal: 4m 49s\tremaining: 6m 54s\n",
      "2055:\tlearn: 0.0027609\ttotal: 4m 49s\tremaining: 6m 54s\n",
      "2056:\tlearn: 0.0027606\ttotal: 4m 49s\tremaining: 6m 54s\n",
      "2057:\tlearn: 0.0027586\ttotal: 4m 49s\tremaining: 6m 53s\n",
      "2058:\tlearn: 0.0027563\ttotal: 4m 49s\tremaining: 6m 53s\n",
      "2059:\tlearn: 0.0027519\ttotal: 4m 49s\tremaining: 6m 53s\n",
      "2060:\tlearn: 0.0027508\ttotal: 4m 49s\tremaining: 6m 53s\n",
      "2061:\tlearn: 0.0027505\ttotal: 4m 50s\tremaining: 6m 53s\n",
      "2062:\tlearn: 0.0027492\ttotal: 4m 50s\tremaining: 6m 53s\n",
      "2063:\tlearn: 0.0027490\ttotal: 4m 50s\tremaining: 6m 52s\n",
      "2064:\tlearn: 0.0027461\ttotal: 4m 50s\tremaining: 6m 52s\n",
      "2065:\tlearn: 0.0027458\ttotal: 4m 50s\tremaining: 6m 52s\n",
      "2066:\tlearn: 0.0027411\ttotal: 4m 50s\tremaining: 6m 52s\n",
      "2067:\tlearn: 0.0027398\ttotal: 4m 50s\tremaining: 6m 52s\n",
      "2068:\tlearn: 0.0027379\ttotal: 4m 50s\tremaining: 6m 52s\n",
      "2069:\tlearn: 0.0027377\ttotal: 4m 51s\tremaining: 6m 51s\n",
      "2070:\tlearn: 0.0027374\ttotal: 4m 51s\tremaining: 6m 51s\n",
      "2071:\tlearn: 0.0027364\ttotal: 4m 51s\tremaining: 6m 51s\n",
      "2072:\tlearn: 0.0027353\ttotal: 4m 51s\tremaining: 6m 51s\n",
      "2073:\tlearn: 0.0027308\ttotal: 4m 51s\tremaining: 6m 51s\n",
      "2074:\tlearn: 0.0027296\ttotal: 4m 51s\tremaining: 6m 51s\n",
      "2075:\tlearn: 0.0027254\ttotal: 4m 51s\tremaining: 6m 50s\n",
      "2076:\tlearn: 0.0027244\ttotal: 4m 51s\tremaining: 6m 50s\n",
      "2077:\tlearn: 0.0027238\ttotal: 4m 51s\tremaining: 6m 50s\n",
      "2078:\tlearn: 0.0027185\ttotal: 4m 52s\tremaining: 6m 50s\n",
      "2079:\tlearn: 0.0027169\ttotal: 4m 52s\tremaining: 6m 50s\n",
      "2080:\tlearn: 0.0027157\ttotal: 4m 52s\tremaining: 6m 50s\n",
      "2081:\tlearn: 0.0027144\ttotal: 4m 52s\tremaining: 6m 49s\n",
      "2082:\tlearn: 0.0027131\ttotal: 4m 52s\tremaining: 6m 49s\n",
      "2083:\tlearn: 0.0027109\ttotal: 4m 52s\tremaining: 6m 49s\n",
      "2084:\tlearn: 0.0027106\ttotal: 4m 52s\tremaining: 6m 49s\n",
      "2085:\tlearn: 0.0027035\ttotal: 4m 52s\tremaining: 6m 49s\n",
      "2086:\tlearn: 0.0027011\ttotal: 4m 53s\tremaining: 6m 49s\n",
      "2087:\tlearn: 0.0026998\ttotal: 4m 53s\tremaining: 6m 48s\n",
      "2088:\tlearn: 0.0026997\ttotal: 4m 53s\tremaining: 6m 48s\n",
      "2089:\tlearn: 0.0026995\ttotal: 4m 53s\tremaining: 6m 48s\n",
      "2090:\tlearn: 0.0026989\ttotal: 4m 53s\tremaining: 6m 48s\n",
      "2091:\tlearn: 0.0026980\ttotal: 4m 53s\tremaining: 6m 48s\n",
      "2092:\tlearn: 0.0026979\ttotal: 4m 53s\tremaining: 6m 47s\n",
      "2093:\tlearn: 0.0026967\ttotal: 4m 53s\tremaining: 6m 47s\n",
      "2094:\tlearn: 0.0026950\ttotal: 4m 53s\tremaining: 6m 47s\n",
      "2095:\tlearn: 0.0026947\ttotal: 4m 54s\tremaining: 6m 47s\n",
      "2096:\tlearn: 0.0026903\ttotal: 4m 54s\tremaining: 6m 47s\n",
      "2097:\tlearn: 0.0026897\ttotal: 4m 54s\tremaining: 6m 47s\n",
      "2098:\tlearn: 0.0026882\ttotal: 4m 54s\tremaining: 6m 46s\n",
      "2099:\tlearn: 0.0026861\ttotal: 4m 54s\tremaining: 6m 46s\n",
      "2100:\tlearn: 0.0026859\ttotal: 4m 54s\tremaining: 6m 46s\n",
      "2101:\tlearn: 0.0026822\ttotal: 4m 54s\tremaining: 6m 46s\n",
      "2102:\tlearn: 0.0026805\ttotal: 4m 54s\tremaining: 6m 46s\n",
      "2103:\tlearn: 0.0026790\ttotal: 4m 54s\tremaining: 6m 46s\n",
      "2104:\tlearn: 0.0026789\ttotal: 4m 55s\tremaining: 6m 45s\n",
      "2105:\tlearn: 0.0026783\ttotal: 4m 55s\tremaining: 6m 45s\n",
      "2106:\tlearn: 0.0026767\ttotal: 4m 55s\tremaining: 6m 45s\n",
      "2107:\tlearn: 0.0026704\ttotal: 4m 55s\tremaining: 6m 45s\n",
      "2108:\tlearn: 0.0026695\ttotal: 4m 55s\tremaining: 6m 45s\n",
      "2109:\tlearn: 0.0026665\ttotal: 4m 55s\tremaining: 6m 44s\n",
      "2110:\tlearn: 0.0026663\ttotal: 4m 55s\tremaining: 6m 44s\n",
      "2111:\tlearn: 0.0026659\ttotal: 4m 55s\tremaining: 6m 44s\n",
      "2112:\tlearn: 0.0026643\ttotal: 4m 55s\tremaining: 6m 44s\n",
      "2113:\tlearn: 0.0026641\ttotal: 4m 56s\tremaining: 6m 44s\n",
      "2114:\tlearn: 0.0026617\ttotal: 4m 56s\tremaining: 6m 44s\n",
      "2115:\tlearn: 0.0026555\ttotal: 4m 56s\tremaining: 6m 43s\n",
      "2116:\tlearn: 0.0026552\ttotal: 4m 56s\tremaining: 6m 43s\n",
      "2117:\tlearn: 0.0026546\ttotal: 4m 56s\tremaining: 6m 43s\n",
      "2118:\tlearn: 0.0026544\ttotal: 4m 56s\tremaining: 6m 43s\n",
      "2119:\tlearn: 0.0026526\ttotal: 4m 56s\tremaining: 6m 43s\n",
      "2120:\tlearn: 0.0026522\ttotal: 4m 56s\tremaining: 6m 43s\n",
      "2121:\tlearn: 0.0026513\ttotal: 4m 57s\tremaining: 6m 42s\n",
      "2122:\tlearn: 0.0026505\ttotal: 4m 57s\tremaining: 6m 42s\n",
      "2123:\tlearn: 0.0026479\ttotal: 4m 57s\tremaining: 6m 42s\n",
      "2124:\tlearn: 0.0026478\ttotal: 4m 57s\tremaining: 6m 42s\n",
      "2125:\tlearn: 0.0026471\ttotal: 4m 57s\tremaining: 6m 42s\n",
      "2126:\tlearn: 0.0026460\ttotal: 4m 57s\tremaining: 6m 42s\n",
      "2127:\tlearn: 0.0026433\ttotal: 4m 57s\tremaining: 6m 41s\n",
      "2128:\tlearn: 0.0026426\ttotal: 4m 57s\tremaining: 6m 41s\n",
      "2129:\tlearn: 0.0026422\ttotal: 4m 57s\tremaining: 6m 41s\n",
      "2130:\tlearn: 0.0026420\ttotal: 4m 58s\tremaining: 6m 41s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2131:\tlearn: 0.0026401\ttotal: 4m 58s\tremaining: 6m 41s\n",
      "2132:\tlearn: 0.0026396\ttotal: 4m 58s\tremaining: 6m 40s\n",
      "2133:\tlearn: 0.0026381\ttotal: 4m 58s\tremaining: 6m 40s\n",
      "2134:\tlearn: 0.0026378\ttotal: 4m 58s\tremaining: 6m 40s\n",
      "2135:\tlearn: 0.0026373\ttotal: 4m 58s\tremaining: 6m 40s\n",
      "2136:\tlearn: 0.0026360\ttotal: 4m 58s\tremaining: 6m 40s\n",
      "2137:\tlearn: 0.0026357\ttotal: 4m 58s\tremaining: 6m 40s\n",
      "2138:\tlearn: 0.0026333\ttotal: 4m 58s\tremaining: 6m 39s\n",
      "2139:\tlearn: 0.0026327\ttotal: 4m 59s\tremaining: 6m 39s\n",
      "2140:\tlearn: 0.0026295\ttotal: 4m 59s\tremaining: 6m 39s\n",
      "2141:\tlearn: 0.0026288\ttotal: 4m 59s\tremaining: 6m 39s\n",
      "2142:\tlearn: 0.0026275\ttotal: 4m 59s\tremaining: 6m 39s\n",
      "2143:\tlearn: 0.0026268\ttotal: 4m 59s\tremaining: 6m 39s\n",
      "2144:\tlearn: 0.0026260\ttotal: 4m 59s\tremaining: 6m 38s\n",
      "2145:\tlearn: 0.0026255\ttotal: 4m 59s\tremaining: 6m 38s\n",
      "2146:\tlearn: 0.0026250\ttotal: 4m 59s\tremaining: 6m 38s\n",
      "2147:\tlearn: 0.0026238\ttotal: 5m\tremaining: 6m 38s\n",
      "2148:\tlearn: 0.0026236\ttotal: 5m\tremaining: 6m 38s\n",
      "2149:\tlearn: 0.0026228\ttotal: 5m\tremaining: 6m 38s\n",
      "2150:\tlearn: 0.0026211\ttotal: 5m\tremaining: 6m 37s\n",
      "2151:\tlearn: 0.0026209\ttotal: 5m\tremaining: 6m 37s\n",
      "2152:\tlearn: 0.0026201\ttotal: 5m\tremaining: 6m 37s\n",
      "2153:\tlearn: 0.0026195\ttotal: 5m\tremaining: 6m 37s\n",
      "2154:\tlearn: 0.0026189\ttotal: 5m\tremaining: 6m 37s\n",
      "2155:\tlearn: 0.0026188\ttotal: 5m\tremaining: 6m 36s\n",
      "2156:\tlearn: 0.0026176\ttotal: 5m 1s\tremaining: 6m 36s\n",
      "2157:\tlearn: 0.0026166\ttotal: 5m 1s\tremaining: 6m 36s\n",
      "2158:\tlearn: 0.0026156\ttotal: 5m 1s\tremaining: 6m 36s\n",
      "2159:\tlearn: 0.0026150\ttotal: 5m 1s\tremaining: 6m 36s\n",
      "2160:\tlearn: 0.0026136\ttotal: 5m 1s\tremaining: 6m 36s\n",
      "2161:\tlearn: 0.0026116\ttotal: 5m 1s\tremaining: 6m 35s\n",
      "2162:\tlearn: 0.0026106\ttotal: 5m 1s\tremaining: 6m 35s\n",
      "2163:\tlearn: 0.0026099\ttotal: 5m 1s\tremaining: 6m 35s\n",
      "2164:\tlearn: 0.0026092\ttotal: 5m 2s\tremaining: 6m 35s\n",
      "2165:\tlearn: 0.0026073\ttotal: 5m 2s\tremaining: 6m 35s\n",
      "2166:\tlearn: 0.0026064\ttotal: 5m 2s\tremaining: 6m 35s\n",
      "2167:\tlearn: 0.0026059\ttotal: 5m 2s\tremaining: 6m 34s\n",
      "2168:\tlearn: 0.0026003\ttotal: 5m 2s\tremaining: 6m 34s\n",
      "2169:\tlearn: 0.0025998\ttotal: 5m 2s\tremaining: 6m 34s\n",
      "2170:\tlearn: 0.0025995\ttotal: 5m 2s\tremaining: 6m 34s\n",
      "2171:\tlearn: 0.0025985\ttotal: 5m 2s\tremaining: 6m 34s\n",
      "2172:\tlearn: 0.0025961\ttotal: 5m 2s\tremaining: 6m 34s\n",
      "2173:\tlearn: 0.0025948\ttotal: 5m 3s\tremaining: 6m 33s\n",
      "2174:\tlearn: 0.0025918\ttotal: 5m 3s\tremaining: 6m 33s\n",
      "2175:\tlearn: 0.0025907\ttotal: 5m 3s\tremaining: 6m 33s\n",
      "2176:\tlearn: 0.0025838\ttotal: 5m 3s\tremaining: 6m 33s\n",
      "2177:\tlearn: 0.0025818\ttotal: 5m 3s\tremaining: 6m 33s\n",
      "2178:\tlearn: 0.0025810\ttotal: 5m 3s\tremaining: 6m 33s\n",
      "2179:\tlearn: 0.0025809\ttotal: 5m 3s\tremaining: 6m 32s\n",
      "2180:\tlearn: 0.0025791\ttotal: 5m 3s\tremaining: 6m 32s\n",
      "2181:\tlearn: 0.0025789\ttotal: 5m 4s\tremaining: 6m 32s\n",
      "2182:\tlearn: 0.0025781\ttotal: 5m 4s\tremaining: 6m 32s\n",
      "2183:\tlearn: 0.0025765\ttotal: 5m 4s\tremaining: 6m 32s\n",
      "2184:\tlearn: 0.0025759\ttotal: 5m 4s\tremaining: 6m 32s\n",
      "2185:\tlearn: 0.0025737\ttotal: 5m 4s\tremaining: 6m 31s\n",
      "2186:\tlearn: 0.0025729\ttotal: 5m 4s\tremaining: 6m 31s\n",
      "2187:\tlearn: 0.0025700\ttotal: 5m 4s\tremaining: 6m 31s\n",
      "2188:\tlearn: 0.0025695\ttotal: 5m 4s\tremaining: 6m 31s\n",
      "2189:\tlearn: 0.0025690\ttotal: 5m 4s\tremaining: 6m 31s\n",
      "2190:\tlearn: 0.0025670\ttotal: 5m 5s\tremaining: 6m 31s\n",
      "2191:\tlearn: 0.0025669\ttotal: 5m 5s\tremaining: 6m 30s\n",
      "2192:\tlearn: 0.0025667\ttotal: 5m 5s\tremaining: 6m 30s\n",
      "2193:\tlearn: 0.0025647\ttotal: 5m 5s\tremaining: 6m 30s\n",
      "2194:\tlearn: 0.0025645\ttotal: 5m 5s\tremaining: 6m 30s\n",
      "2195:\tlearn: 0.0025622\ttotal: 5m 5s\tremaining: 6m 30s\n",
      "2196:\tlearn: 0.0025621\ttotal: 5m 5s\tremaining: 6m 30s\n",
      "2197:\tlearn: 0.0025617\ttotal: 5m 5s\tremaining: 6m 29s\n",
      "2198:\tlearn: 0.0025595\ttotal: 5m 5s\tremaining: 6m 29s\n",
      "2199:\tlearn: 0.0025593\ttotal: 5m 6s\tremaining: 6m 29s\n",
      "2200:\tlearn: 0.0025573\ttotal: 5m 6s\tremaining: 6m 29s\n",
      "2201:\tlearn: 0.0025564\ttotal: 5m 6s\tremaining: 6m 29s\n",
      "2202:\tlearn: 0.0025550\ttotal: 5m 6s\tremaining: 6m 28s\n",
      "2203:\tlearn: 0.0025544\ttotal: 5m 6s\tremaining: 6m 28s\n",
      "2204:\tlearn: 0.0025488\ttotal: 5m 6s\tremaining: 6m 28s\n",
      "2205:\tlearn: 0.0025483\ttotal: 5m 6s\tremaining: 6m 28s\n",
      "2206:\tlearn: 0.0025482\ttotal: 5m 6s\tremaining: 6m 28s\n",
      "2207:\tlearn: 0.0025477\ttotal: 5m 6s\tremaining: 6m 28s\n",
      "2208:\tlearn: 0.0025475\ttotal: 5m 7s\tremaining: 6m 27s\n",
      "2209:\tlearn: 0.0025462\ttotal: 5m 7s\tremaining: 6m 27s\n",
      "2210:\tlearn: 0.0025433\ttotal: 5m 7s\tremaining: 6m 27s\n",
      "2211:\tlearn: 0.0025426\ttotal: 5m 7s\tremaining: 6m 27s\n",
      "2212:\tlearn: 0.0025414\ttotal: 5m 7s\tremaining: 6m 27s\n",
      "2213:\tlearn: 0.0025409\ttotal: 5m 7s\tremaining: 6m 27s\n",
      "2214:\tlearn: 0.0025403\ttotal: 5m 7s\tremaining: 6m 26s\n",
      "2215:\tlearn: 0.0025397\ttotal: 5m 7s\tremaining: 6m 26s\n",
      "2216:\tlearn: 0.0025390\ttotal: 5m 7s\tremaining: 6m 26s\n",
      "2217:\tlearn: 0.0025379\ttotal: 5m 8s\tremaining: 6m 26s\n",
      "2218:\tlearn: 0.0025376\ttotal: 5m 8s\tremaining: 6m 26s\n",
      "2219:\tlearn: 0.0025375\ttotal: 5m 8s\tremaining: 6m 26s\n",
      "2220:\tlearn: 0.0025331\ttotal: 5m 8s\tremaining: 6m 25s\n",
      "2221:\tlearn: 0.0025326\ttotal: 5m 8s\tremaining: 6m 25s\n",
      "2222:\tlearn: 0.0025307\ttotal: 5m 8s\tremaining: 6m 25s\n",
      "2223:\tlearn: 0.0025284\ttotal: 5m 8s\tremaining: 6m 25s\n",
      "2224:\tlearn: 0.0025258\ttotal: 5m 8s\tremaining: 6m 25s\n",
      "2225:\tlearn: 0.0025254\ttotal: 5m 8s\tremaining: 6m 25s\n",
      "2226:\tlearn: 0.0025237\ttotal: 5m 9s\tremaining: 6m 24s\n",
      "2227:\tlearn: 0.0025203\ttotal: 5m 9s\tremaining: 6m 24s\n",
      "2228:\tlearn: 0.0025202\ttotal: 5m 9s\tremaining: 6m 24s\n",
      "2229:\tlearn: 0.0025186\ttotal: 5m 9s\tremaining: 6m 24s\n",
      "2230:\tlearn: 0.0025178\ttotal: 5m 9s\tremaining: 6m 24s\n",
      "2231:\tlearn: 0.0025161\ttotal: 5m 9s\tremaining: 6m 24s\n",
      "2232:\tlearn: 0.0025147\ttotal: 5m 9s\tremaining: 6m 23s\n",
      "2233:\tlearn: 0.0025121\ttotal: 5m 9s\tremaining: 6m 23s\n",
      "2234:\tlearn: 0.0025117\ttotal: 5m 10s\tremaining: 6m 23s\n",
      "2235:\tlearn: 0.0025114\ttotal: 5m 10s\tremaining: 6m 23s\n",
      "2236:\tlearn: 0.0025106\ttotal: 5m 10s\tremaining: 6m 23s\n",
      "2237:\tlearn: 0.0025090\ttotal: 5m 10s\tremaining: 6m 23s\n",
      "2238:\tlearn: 0.0025088\ttotal: 5m 10s\tremaining: 6m 22s\n",
      "2239:\tlearn: 0.0025065\ttotal: 5m 10s\tremaining: 6m 22s\n",
      "2240:\tlearn: 0.0025060\ttotal: 5m 10s\tremaining: 6m 22s\n",
      "2241:\tlearn: 0.0025058\ttotal: 5m 10s\tremaining: 6m 22s\n",
      "2242:\tlearn: 0.0025053\ttotal: 5m 10s\tremaining: 6m 22s\n",
      "2243:\tlearn: 0.0025051\ttotal: 5m 11s\tremaining: 6m 22s\n",
      "2244:\tlearn: 0.0025041\ttotal: 5m 11s\tremaining: 6m 21s\n",
      "2245:\tlearn: 0.0025040\ttotal: 5m 11s\tremaining: 6m 21s\n",
      "2246:\tlearn: 0.0025037\ttotal: 5m 11s\tremaining: 6m 21s\n",
      "2247:\tlearn: 0.0025028\ttotal: 5m 11s\tremaining: 6m 21s\n",
      "2248:\tlearn: 0.0025023\ttotal: 5m 11s\tremaining: 6m 21s\n",
      "2249:\tlearn: 0.0025013\ttotal: 5m 11s\tremaining: 6m 21s\n",
      "2250:\tlearn: 0.0025004\ttotal: 5m 11s\tremaining: 6m 20s\n",
      "2251:\tlearn: 0.0024987\ttotal: 5m 11s\tremaining: 6m 20s\n",
      "2252:\tlearn: 0.0024981\ttotal: 5m 12s\tremaining: 6m 20s\n",
      "2253:\tlearn: 0.0024977\ttotal: 5m 12s\tremaining: 6m 20s\n",
      "2254:\tlearn: 0.0024970\ttotal: 5m 12s\tremaining: 6m 20s\n",
      "2255:\tlearn: 0.0024947\ttotal: 5m 12s\tremaining: 6m 20s\n",
      "2256:\tlearn: 0.0024945\ttotal: 5m 12s\tremaining: 6m 19s\n",
      "2257:\tlearn: 0.0024926\ttotal: 5m 12s\tremaining: 6m 19s\n",
      "2258:\tlearn: 0.0024924\ttotal: 5m 12s\tremaining: 6m 19s\n",
      "2259:\tlearn: 0.0024921\ttotal: 5m 12s\tremaining: 6m 19s\n",
      "2260:\tlearn: 0.0024913\ttotal: 5m 13s\tremaining: 6m 19s\n",
      "2261:\tlearn: 0.0024911\ttotal: 5m 13s\tremaining: 6m 19s\n",
      "2262:\tlearn: 0.0024901\ttotal: 5m 13s\tremaining: 6m 19s\n",
      "2263:\tlearn: 0.0024895\ttotal: 5m 13s\tremaining: 6m 18s\n",
      "2264:\tlearn: 0.0024891\ttotal: 5m 13s\tremaining: 6m 18s\n",
      "2265:\tlearn: 0.0024883\ttotal: 5m 13s\tremaining: 6m 18s\n",
      "2266:\tlearn: 0.0024880\ttotal: 5m 13s\tremaining: 6m 18s\n",
      "2267:\tlearn: 0.0024865\ttotal: 5m 14s\tremaining: 6m 18s\n",
      "2268:\tlearn: 0.0024852\ttotal: 5m 14s\tremaining: 6m 18s\n",
      "2269:\tlearn: 0.0024838\ttotal: 5m 14s\tremaining: 6m 18s\n",
      "2270:\tlearn: 0.0024818\ttotal: 5m 14s\tremaining: 6m 17s\n",
      "2271:\tlearn: 0.0024814\ttotal: 5m 14s\tremaining: 6m 17s\n",
      "2272:\tlearn: 0.0024808\ttotal: 5m 14s\tremaining: 6m 17s\n",
      "2273:\tlearn: 0.0024807\ttotal: 5m 14s\tremaining: 6m 17s\n",
      "2274:\tlearn: 0.0024803\ttotal: 5m 14s\tremaining: 6m 17s\n",
      "2275:\tlearn: 0.0024795\ttotal: 5m 15s\tremaining: 6m 17s\n",
      "2276:\tlearn: 0.0024785\ttotal: 5m 15s\tremaining: 6m 16s\n",
      "2277:\tlearn: 0.0024783\ttotal: 5m 15s\tremaining: 6m 16s\n",
      "2278:\tlearn: 0.0024778\ttotal: 5m 15s\tremaining: 6m 16s\n",
      "2279:\tlearn: 0.0024773\ttotal: 5m 15s\tremaining: 6m 16s\n",
      "2280:\tlearn: 0.0024769\ttotal: 5m 15s\tremaining: 6m 16s\n",
      "2281:\tlearn: 0.0024741\ttotal: 5m 15s\tremaining: 6m 16s\n",
      "2282:\tlearn: 0.0024707\ttotal: 5m 16s\tremaining: 6m 16s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2283:\tlearn: 0.0024698\ttotal: 5m 16s\tremaining: 6m 16s\n",
      "2284:\tlearn: 0.0024694\ttotal: 5m 16s\tremaining: 6m 15s\n",
      "2285:\tlearn: 0.0024693\ttotal: 5m 16s\tremaining: 6m 15s\n",
      "2286:\tlearn: 0.0024691\ttotal: 5m 16s\tremaining: 6m 15s\n",
      "2287:\tlearn: 0.0024687\ttotal: 5m 16s\tremaining: 6m 15s\n",
      "2288:\tlearn: 0.0024663\ttotal: 5m 17s\tremaining: 6m 15s\n",
      "2289:\tlearn: 0.0024657\ttotal: 5m 17s\tremaining: 6m 15s\n",
      "2290:\tlearn: 0.0024657\ttotal: 5m 17s\tremaining: 6m 15s\n",
      "2291:\tlearn: 0.0024647\ttotal: 5m 17s\tremaining: 6m 15s\n",
      "2292:\tlearn: 0.0024639\ttotal: 5m 17s\tremaining: 6m 14s\n",
      "2293:\tlearn: 0.0024638\ttotal: 5m 17s\tremaining: 6m 14s\n",
      "2294:\tlearn: 0.0024635\ttotal: 5m 17s\tremaining: 6m 14s\n",
      "2295:\tlearn: 0.0024624\ttotal: 5m 18s\tremaining: 6m 14s\n",
      "2296:\tlearn: 0.0024619\ttotal: 5m 18s\tremaining: 6m 14s\n",
      "2297:\tlearn: 0.0024614\ttotal: 5m 18s\tremaining: 6m 14s\n",
      "2298:\tlearn: 0.0024593\ttotal: 5m 18s\tremaining: 6m 14s\n",
      "2299:\tlearn: 0.0024583\ttotal: 5m 18s\tremaining: 6m 13s\n",
      "2300:\tlearn: 0.0024580\ttotal: 5m 18s\tremaining: 6m 13s\n",
      "2301:\tlearn: 0.0024572\ttotal: 5m 18s\tremaining: 6m 13s\n",
      "2302:\tlearn: 0.0024563\ttotal: 5m 18s\tremaining: 6m 13s\n",
      "2303:\tlearn: 0.0024553\ttotal: 5m 18s\tremaining: 6m 13s\n",
      "2304:\tlearn: 0.0024529\ttotal: 5m 19s\tremaining: 6m 13s\n",
      "2305:\tlearn: 0.0024525\ttotal: 5m 19s\tremaining: 6m 12s\n",
      "2306:\tlearn: 0.0024522\ttotal: 5m 19s\tremaining: 6m 12s\n",
      "2307:\tlearn: 0.0024479\ttotal: 5m 19s\tremaining: 6m 12s\n",
      "2308:\tlearn: 0.0024469\ttotal: 5m 19s\tremaining: 6m 12s\n",
      "2309:\tlearn: 0.0024466\ttotal: 5m 19s\tremaining: 6m 12s\n",
      "2310:\tlearn: 0.0024460\ttotal: 5m 19s\tremaining: 6m 12s\n",
      "2311:\tlearn: 0.0024458\ttotal: 5m 19s\tremaining: 6m 11s\n",
      "2312:\tlearn: 0.0024442\ttotal: 5m 20s\tremaining: 6m 11s\n",
      "2313:\tlearn: 0.0024399\ttotal: 5m 20s\tremaining: 6m 11s\n",
      "2314:\tlearn: 0.0024388\ttotal: 5m 20s\tremaining: 6m 11s\n",
      "2315:\tlearn: 0.0024379\ttotal: 5m 20s\tremaining: 6m 11s\n",
      "2316:\tlearn: 0.0024373\ttotal: 5m 20s\tremaining: 6m 11s\n",
      "2317:\tlearn: 0.0024358\ttotal: 5m 20s\tremaining: 6m 10s\n",
      "2318:\tlearn: 0.0024346\ttotal: 5m 20s\tremaining: 6m 10s\n",
      "2319:\tlearn: 0.0024337\ttotal: 5m 20s\tremaining: 6m 10s\n",
      "2320:\tlearn: 0.0024336\ttotal: 5m 20s\tremaining: 6m 10s\n",
      "2321:\tlearn: 0.0024311\ttotal: 5m 21s\tremaining: 6m 10s\n",
      "2322:\tlearn: 0.0024271\ttotal: 5m 21s\tremaining: 6m 10s\n",
      "2323:\tlearn: 0.0024255\ttotal: 5m 21s\tremaining: 6m 9s\n",
      "2324:\tlearn: 0.0024249\ttotal: 5m 21s\tremaining: 6m 9s\n",
      "2325:\tlearn: 0.0024238\ttotal: 5m 21s\tremaining: 6m 9s\n",
      "2326:\tlearn: 0.0024177\ttotal: 5m 21s\tremaining: 6m 9s\n",
      "2327:\tlearn: 0.0024171\ttotal: 5m 21s\tremaining: 6m 9s\n",
      "2328:\tlearn: 0.0024162\ttotal: 5m 21s\tremaining: 6m 9s\n",
      "2329:\tlearn: 0.0024160\ttotal: 5m 21s\tremaining: 6m 8s\n",
      "2330:\tlearn: 0.0024156\ttotal: 5m 22s\tremaining: 6m 8s\n",
      "2331:\tlearn: 0.0024146\ttotal: 5m 22s\tremaining: 6m 8s\n",
      "2332:\tlearn: 0.0024143\ttotal: 5m 22s\tremaining: 6m 8s\n",
      "2333:\tlearn: 0.0024136\ttotal: 5m 22s\tremaining: 6m 8s\n",
      "2334:\tlearn: 0.0024115\ttotal: 5m 22s\tremaining: 6m 8s\n",
      "2335:\tlearn: 0.0024071\ttotal: 5m 22s\tremaining: 6m 7s\n",
      "2336:\tlearn: 0.0024066\ttotal: 5m 22s\tremaining: 6m 7s\n",
      "2337:\tlearn: 0.0024051\ttotal: 5m 22s\tremaining: 6m 7s\n",
      "2338:\tlearn: 0.0024049\ttotal: 5m 23s\tremaining: 6m 7s\n",
      "2339:\tlearn: 0.0024028\ttotal: 5m 23s\tremaining: 6m 7s\n",
      "2340:\tlearn: 0.0024023\ttotal: 5m 23s\tremaining: 6m 7s\n",
      "2341:\tlearn: 0.0024021\ttotal: 5m 23s\tremaining: 6m 7s\n",
      "2342:\tlearn: 0.0024020\ttotal: 5m 23s\tremaining: 6m 6s\n",
      "2343:\tlearn: 0.0024015\ttotal: 5m 23s\tremaining: 6m 6s\n",
      "2344:\tlearn: 0.0024007\ttotal: 5m 23s\tremaining: 6m 6s\n",
      "2345:\tlearn: 0.0023983\ttotal: 5m 23s\tremaining: 6m 6s\n",
      "2346:\tlearn: 0.0023978\ttotal: 5m 24s\tremaining: 6m 6s\n",
      "2347:\tlearn: 0.0023963\ttotal: 5m 24s\tremaining: 6m 6s\n",
      "2348:\tlearn: 0.0023961\ttotal: 5m 24s\tremaining: 6m 5s\n",
      "2349:\tlearn: 0.0023957\ttotal: 5m 24s\tremaining: 6m 5s\n",
      "2350:\tlearn: 0.0023955\ttotal: 5m 24s\tremaining: 6m 5s\n",
      "2351:\tlearn: 0.0023937\ttotal: 5m 24s\tremaining: 6m 5s\n",
      "2352:\tlearn: 0.0023931\ttotal: 5m 24s\tremaining: 6m 5s\n",
      "2353:\tlearn: 0.0023929\ttotal: 5m 24s\tremaining: 6m 5s\n",
      "2354:\tlearn: 0.0023912\ttotal: 5m 25s\tremaining: 6m 5s\n",
      "2355:\tlearn: 0.0023895\ttotal: 5m 25s\tremaining: 6m 4s\n",
      "2356:\tlearn: 0.0023887\ttotal: 5m 25s\tremaining: 6m 4s\n",
      "2357:\tlearn: 0.0023884\ttotal: 5m 25s\tremaining: 6m 4s\n",
      "2358:\tlearn: 0.0023869\ttotal: 5m 25s\tremaining: 6m 4s\n",
      "2359:\tlearn: 0.0023867\ttotal: 5m 25s\tremaining: 6m 4s\n",
      "2360:\tlearn: 0.0023859\ttotal: 5m 25s\tremaining: 6m 4s\n",
      "2361:\tlearn: 0.0023856\ttotal: 5m 26s\tremaining: 6m 4s\n",
      "2362:\tlearn: 0.0023854\ttotal: 5m 26s\tremaining: 6m 4s\n",
      "2363:\tlearn: 0.0023845\ttotal: 5m 26s\tremaining: 6m 3s\n",
      "2364:\tlearn: 0.0023832\ttotal: 5m 26s\tremaining: 6m 3s\n",
      "2365:\tlearn: 0.0023822\ttotal: 5m 26s\tremaining: 6m 3s\n",
      "2366:\tlearn: 0.0023811\ttotal: 5m 26s\tremaining: 6m 3s\n",
      "2367:\tlearn: 0.0023811\ttotal: 5m 26s\tremaining: 6m 3s\n",
      "2368:\tlearn: 0.0023809\ttotal: 5m 27s\tremaining: 6m 3s\n",
      "2369:\tlearn: 0.0023802\ttotal: 5m 27s\tremaining: 6m 3s\n",
      "2370:\tlearn: 0.0023783\ttotal: 5m 27s\tremaining: 6m 2s\n",
      "2371:\tlearn: 0.0023781\ttotal: 5m 27s\tremaining: 6m 2s\n",
      "2372:\tlearn: 0.0023775\ttotal: 5m 27s\tremaining: 6m 2s\n",
      "2373:\tlearn: 0.0023774\ttotal: 5m 27s\tremaining: 6m 2s\n",
      "2374:\tlearn: 0.0023763\ttotal: 5m 27s\tremaining: 6m 2s\n",
      "2375:\tlearn: 0.0023758\ttotal: 5m 28s\tremaining: 6m 2s\n",
      "2376:\tlearn: 0.0023755\ttotal: 5m 28s\tremaining: 6m 2s\n",
      "2377:\tlearn: 0.0023743\ttotal: 5m 28s\tremaining: 6m 1s\n",
      "2378:\tlearn: 0.0023740\ttotal: 5m 28s\tremaining: 6m 1s\n",
      "2379:\tlearn: 0.0023727\ttotal: 5m 28s\tremaining: 6m 1s\n",
      "2380:\tlearn: 0.0023715\ttotal: 5m 28s\tremaining: 6m 1s\n",
      "2381:\tlearn: 0.0023712\ttotal: 5m 28s\tremaining: 6m 1s\n",
      "2382:\tlearn: 0.0023708\ttotal: 5m 28s\tremaining: 6m 1s\n",
      "2383:\tlearn: 0.0023706\ttotal: 5m 29s\tremaining: 6m 1s\n",
      "2384:\tlearn: 0.0023673\ttotal: 5m 29s\tremaining: 6m 1s\n",
      "2385:\tlearn: 0.0023666\ttotal: 5m 29s\tremaining: 6m\n",
      "2386:\tlearn: 0.0023660\ttotal: 5m 29s\tremaining: 6m\n",
      "2387:\tlearn: 0.0023648\ttotal: 5m 29s\tremaining: 6m\n",
      "2388:\tlearn: 0.0023639\ttotal: 5m 29s\tremaining: 6m\n",
      "2389:\tlearn: 0.0023631\ttotal: 5m 29s\tremaining: 6m\n",
      "2390:\tlearn: 0.0023622\ttotal: 5m 30s\tremaining: 6m\n",
      "2391:\tlearn: 0.0023618\ttotal: 5m 30s\tremaining: 6m\n",
      "2392:\tlearn: 0.0023617\ttotal: 5m 30s\tremaining: 5m 59s\n",
      "2393:\tlearn: 0.0023604\ttotal: 5m 30s\tremaining: 5m 59s\n",
      "2394:\tlearn: 0.0023581\ttotal: 5m 30s\tremaining: 5m 59s\n",
      "2395:\tlearn: 0.0023580\ttotal: 5m 30s\tremaining: 5m 59s\n",
      "2396:\tlearn: 0.0023564\ttotal: 5m 30s\tremaining: 5m 59s\n",
      "2397:\tlearn: 0.0023556\ttotal: 5m 31s\tremaining: 5m 59s\n",
      "2398:\tlearn: 0.0023537\ttotal: 5m 31s\tremaining: 5m 59s\n",
      "2399:\tlearn: 0.0023532\ttotal: 5m 31s\tremaining: 5m 58s\n",
      "2400:\tlearn: 0.0023519\ttotal: 5m 31s\tremaining: 5m 58s\n",
      "2401:\tlearn: 0.0023517\ttotal: 5m 31s\tremaining: 5m 58s\n",
      "2402:\tlearn: 0.0023507\ttotal: 5m 31s\tremaining: 5m 58s\n",
      "2403:\tlearn: 0.0023505\ttotal: 5m 31s\tremaining: 5m 58s\n",
      "2404:\tlearn: 0.0023484\ttotal: 5m 31s\tremaining: 5m 58s\n",
      "2405:\tlearn: 0.0023482\ttotal: 5m 32s\tremaining: 5m 58s\n",
      "2406:\tlearn: 0.0023482\ttotal: 5m 32s\tremaining: 5m 58s\n",
      "2407:\tlearn: 0.0023431\ttotal: 5m 32s\tremaining: 5m 58s\n",
      "2408:\tlearn: 0.0023411\ttotal: 5m 32s\tremaining: 5m 57s\n",
      "2409:\tlearn: 0.0023409\ttotal: 5m 32s\tremaining: 5m 57s\n",
      "2410:\tlearn: 0.0023406\ttotal: 5m 33s\tremaining: 5m 57s\n",
      "2411:\tlearn: 0.0023401\ttotal: 5m 33s\tremaining: 5m 57s\n",
      "2412:\tlearn: 0.0023400\ttotal: 5m 33s\tremaining: 5m 57s\n",
      "2413:\tlearn: 0.0023387\ttotal: 5m 33s\tremaining: 5m 57s\n",
      "2414:\tlearn: 0.0023377\ttotal: 5m 33s\tremaining: 5m 57s\n",
      "2415:\tlearn: 0.0023375\ttotal: 5m 34s\tremaining: 5m 57s\n",
      "2416:\tlearn: 0.0023364\ttotal: 5m 34s\tremaining: 5m 57s\n",
      "2417:\tlearn: 0.0023361\ttotal: 5m 34s\tremaining: 5m 57s\n",
      "2418:\tlearn: 0.0023358\ttotal: 5m 34s\tremaining: 5m 57s\n",
      "2419:\tlearn: 0.0023357\ttotal: 5m 34s\tremaining: 5m 56s\n",
      "2420:\tlearn: 0.0023343\ttotal: 5m 34s\tremaining: 5m 56s\n",
      "2421:\tlearn: 0.0023341\ttotal: 5m 35s\tremaining: 5m 56s\n",
      "2422:\tlearn: 0.0023336\ttotal: 5m 35s\tremaining: 5m 56s\n",
      "2423:\tlearn: 0.0023335\ttotal: 5m 35s\tremaining: 5m 56s\n",
      "2424:\tlearn: 0.0023321\ttotal: 5m 35s\tremaining: 5m 56s\n",
      "2425:\tlearn: 0.0023317\ttotal: 5m 35s\tremaining: 5m 56s\n",
      "2426:\tlearn: 0.0023306\ttotal: 5m 35s\tremaining: 5m 56s\n",
      "2427:\tlearn: 0.0023303\ttotal: 5m 36s\tremaining: 5m 55s\n",
      "2428:\tlearn: 0.0023300\ttotal: 5m 36s\tremaining: 5m 55s\n",
      "2429:\tlearn: 0.0023292\ttotal: 5m 36s\tremaining: 5m 55s\n",
      "2430:\tlearn: 0.0023288\ttotal: 5m 36s\tremaining: 5m 55s\n",
      "2431:\tlearn: 0.0023284\ttotal: 5m 36s\tremaining: 5m 55s\n",
      "2432:\tlearn: 0.0023279\ttotal: 5m 36s\tremaining: 5m 55s\n",
      "2433:\tlearn: 0.0023277\ttotal: 5m 36s\tremaining: 5m 55s\n",
      "2434:\tlearn: 0.0023262\ttotal: 5m 36s\tremaining: 5m 54s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2435:\tlearn: 0.0023255\ttotal: 5m 37s\tremaining: 5m 54s\n",
      "2436:\tlearn: 0.0023254\ttotal: 5m 37s\tremaining: 5m 54s\n",
      "2437:\tlearn: 0.0023253\ttotal: 5m 37s\tremaining: 5m 54s\n",
      "2438:\tlearn: 0.0023251\ttotal: 5m 37s\tremaining: 5m 54s\n",
      "2439:\tlearn: 0.0023242\ttotal: 5m 37s\tremaining: 5m 54s\n",
      "2440:\tlearn: 0.0023221\ttotal: 5m 37s\tremaining: 5m 54s\n",
      "2441:\tlearn: 0.0023192\ttotal: 5m 37s\tremaining: 5m 54s\n",
      "2442:\tlearn: 0.0023187\ttotal: 5m 38s\tremaining: 5m 53s\n",
      "2443:\tlearn: 0.0023169\ttotal: 5m 38s\tremaining: 5m 53s\n",
      "2444:\tlearn: 0.0023167\ttotal: 5m 38s\tremaining: 5m 53s\n",
      "2445:\tlearn: 0.0023162\ttotal: 5m 38s\tremaining: 5m 53s\n",
      "2446:\tlearn: 0.0023161\ttotal: 5m 38s\tremaining: 5m 53s\n",
      "2447:\tlearn: 0.0023156\ttotal: 5m 38s\tremaining: 5m 53s\n",
      "2448:\tlearn: 0.0023144\ttotal: 5m 38s\tremaining: 5m 53s\n",
      "2449:\tlearn: 0.0023143\ttotal: 5m 39s\tremaining: 5m 52s\n",
      "2450:\tlearn: 0.0023130\ttotal: 5m 39s\tremaining: 5m 52s\n",
      "2451:\tlearn: 0.0023117\ttotal: 5m 39s\tremaining: 5m 52s\n",
      "2452:\tlearn: 0.0023116\ttotal: 5m 39s\tremaining: 5m 52s\n",
      "2453:\tlearn: 0.0023106\ttotal: 5m 39s\tremaining: 5m 52s\n",
      "2454:\tlearn: 0.0023106\ttotal: 5m 39s\tremaining: 5m 52s\n",
      "2455:\tlearn: 0.0023098\ttotal: 5m 39s\tremaining: 5m 52s\n",
      "2456:\tlearn: 0.0023089\ttotal: 5m 40s\tremaining: 5m 51s\n",
      "2457:\tlearn: 0.0023088\ttotal: 5m 40s\tremaining: 5m 51s\n",
      "2458:\tlearn: 0.0023085\ttotal: 5m 40s\tremaining: 5m 51s\n",
      "2459:\tlearn: 0.0023068\ttotal: 5m 40s\tremaining: 5m 51s\n",
      "2460:\tlearn: 0.0023065\ttotal: 5m 40s\tremaining: 5m 51s\n",
      "2461:\tlearn: 0.0023063\ttotal: 5m 40s\tremaining: 5m 51s\n",
      "2462:\tlearn: 0.0023060\ttotal: 5m 40s\tremaining: 5m 51s\n",
      "2463:\tlearn: 0.0023056\ttotal: 5m 40s\tremaining: 5m 50s\n",
      "2464:\tlearn: 0.0023052\ttotal: 5m 41s\tremaining: 5m 50s\n",
      "2465:\tlearn: 0.0023036\ttotal: 5m 41s\tremaining: 5m 50s\n",
      "2466:\tlearn: 0.0023029\ttotal: 5m 41s\tremaining: 5m 50s\n",
      "2467:\tlearn: 0.0023019\ttotal: 5m 41s\tremaining: 5m 50s\n",
      "2468:\tlearn: 0.0023010\ttotal: 5m 41s\tremaining: 5m 50s\n",
      "2469:\tlearn: 0.0023006\ttotal: 5m 41s\tremaining: 5m 50s\n",
      "2470:\tlearn: 0.0023000\ttotal: 5m 41s\tremaining: 5m 49s\n",
      "2471:\tlearn: 0.0023000\ttotal: 5m 42s\tremaining: 5m 49s\n",
      "2472:\tlearn: 0.0022993\ttotal: 5m 42s\tremaining: 5m 49s\n",
      "2473:\tlearn: 0.0022979\ttotal: 5m 42s\tremaining: 5m 49s\n",
      "2474:\tlearn: 0.0022977\ttotal: 5m 42s\tremaining: 5m 49s\n",
      "2475:\tlearn: 0.0022971\ttotal: 5m 42s\tremaining: 5m 49s\n",
      "2476:\tlearn: 0.0022961\ttotal: 5m 42s\tremaining: 5m 49s\n",
      "2477:\tlearn: 0.0022950\ttotal: 5m 42s\tremaining: 5m 48s\n",
      "2478:\tlearn: 0.0022944\ttotal: 5m 42s\tremaining: 5m 48s\n",
      "2479:\tlearn: 0.0022942\ttotal: 5m 43s\tremaining: 5m 48s\n",
      "2480:\tlearn: 0.0022939\ttotal: 5m 43s\tremaining: 5m 48s\n",
      "2481:\tlearn: 0.0022922\ttotal: 5m 43s\tremaining: 5m 48s\n",
      "2482:\tlearn: 0.0022904\ttotal: 5m 43s\tremaining: 5m 48s\n",
      "2483:\tlearn: 0.0022903\ttotal: 5m 43s\tremaining: 5m 47s\n",
      "2484:\tlearn: 0.0022879\ttotal: 5m 43s\tremaining: 5m 47s\n",
      "2485:\tlearn: 0.0022878\ttotal: 5m 43s\tremaining: 5m 47s\n",
      "2486:\tlearn: 0.0022876\ttotal: 5m 44s\tremaining: 5m 47s\n",
      "2487:\tlearn: 0.0022844\ttotal: 5m 44s\tremaining: 5m 47s\n",
      "2488:\tlearn: 0.0022829\ttotal: 5m 44s\tremaining: 5m 47s\n",
      "2489:\tlearn: 0.0022818\ttotal: 5m 44s\tremaining: 5m 47s\n",
      "2490:\tlearn: 0.0022816\ttotal: 5m 44s\tremaining: 5m 47s\n",
      "2491:\tlearn: 0.0022812\ttotal: 5m 44s\tremaining: 5m 46s\n",
      "2492:\tlearn: 0.0022800\ttotal: 5m 44s\tremaining: 5m 46s\n",
      "2493:\tlearn: 0.0022785\ttotal: 5m 44s\tremaining: 5m 46s\n",
      "2494:\tlearn: 0.0022774\ttotal: 5m 45s\tremaining: 5m 46s\n",
      "2495:\tlearn: 0.0022772\ttotal: 5m 45s\tremaining: 5m 46s\n",
      "2496:\tlearn: 0.0022750\ttotal: 5m 45s\tremaining: 5m 46s\n",
      "2497:\tlearn: 0.0022749\ttotal: 5m 45s\tremaining: 5m 46s\n",
      "2498:\tlearn: 0.0022743\ttotal: 5m 45s\tremaining: 5m 45s\n",
      "2499:\tlearn: 0.0022735\ttotal: 5m 45s\tremaining: 5m 45s\n",
      "2500:\tlearn: 0.0022734\ttotal: 5m 45s\tremaining: 5m 45s\n",
      "2501:\tlearn: 0.0022732\ttotal: 5m 46s\tremaining: 5m 45s\n",
      "2502:\tlearn: 0.0022727\ttotal: 5m 46s\tremaining: 5m 45s\n",
      "2503:\tlearn: 0.0022726\ttotal: 5m 46s\tremaining: 5m 45s\n",
      "2504:\tlearn: 0.0022722\ttotal: 5m 46s\tremaining: 5m 44s\n",
      "2505:\tlearn: 0.0022717\ttotal: 5m 46s\tremaining: 5m 44s\n",
      "2506:\tlearn: 0.0022713\ttotal: 5m 46s\tremaining: 5m 44s\n",
      "2507:\tlearn: 0.0022708\ttotal: 5m 46s\tremaining: 5m 44s\n",
      "2508:\tlearn: 0.0022707\ttotal: 5m 46s\tremaining: 5m 44s\n",
      "2509:\tlearn: 0.0022706\ttotal: 5m 46s\tremaining: 5m 44s\n",
      "2510:\tlearn: 0.0022701\ttotal: 5m 47s\tremaining: 5m 44s\n",
      "2511:\tlearn: 0.0022700\ttotal: 5m 47s\tremaining: 5m 43s\n",
      "2512:\tlearn: 0.0022688\ttotal: 5m 47s\tremaining: 5m 43s\n",
      "2513:\tlearn: 0.0022680\ttotal: 5m 47s\tremaining: 5m 43s\n",
      "2514:\tlearn: 0.0022674\ttotal: 5m 47s\tremaining: 5m 43s\n",
      "2515:\tlearn: 0.0022670\ttotal: 5m 47s\tremaining: 5m 43s\n",
      "2516:\tlearn: 0.0022667\ttotal: 5m 47s\tremaining: 5m 43s\n",
      "2517:\tlearn: 0.0022656\ttotal: 5m 47s\tremaining: 5m 42s\n",
      "2518:\tlearn: 0.0022653\ttotal: 5m 48s\tremaining: 5m 42s\n",
      "2519:\tlearn: 0.0022652\ttotal: 5m 48s\tremaining: 5m 42s\n",
      "2520:\tlearn: 0.0022649\ttotal: 5m 48s\tremaining: 5m 42s\n",
      "2521:\tlearn: 0.0022639\ttotal: 5m 48s\tremaining: 5m 42s\n",
      "2522:\tlearn: 0.0022638\ttotal: 5m 48s\tremaining: 5m 42s\n",
      "2523:\tlearn: 0.0022629\ttotal: 5m 49s\tremaining: 5m 42s\n",
      "2524:\tlearn: 0.0022621\ttotal: 5m 49s\tremaining: 5m 42s\n",
      "2525:\tlearn: 0.0022618\ttotal: 5m 49s\tremaining: 5m 42s\n",
      "2526:\tlearn: 0.0022612\ttotal: 5m 49s\tremaining: 5m 42s\n",
      "2527:\tlearn: 0.0022588\ttotal: 5m 49s\tremaining: 5m 41s\n",
      "2528:\tlearn: 0.0022582\ttotal: 5m 49s\tremaining: 5m 41s\n",
      "2529:\tlearn: 0.0022576\ttotal: 5m 50s\tremaining: 5m 41s\n",
      "2530:\tlearn: 0.0022538\ttotal: 5m 50s\tremaining: 5m 41s\n",
      "2531:\tlearn: 0.0022493\ttotal: 5m 50s\tremaining: 5m 41s\n",
      "2532:\tlearn: 0.0022476\ttotal: 5m 50s\tremaining: 5m 41s\n",
      "2533:\tlearn: 0.0022475\ttotal: 5m 50s\tremaining: 5m 41s\n",
      "2534:\tlearn: 0.0022474\ttotal: 5m 51s\tremaining: 5m 41s\n",
      "2535:\tlearn: 0.0022473\ttotal: 5m 51s\tremaining: 5m 41s\n",
      "2536:\tlearn: 0.0022464\ttotal: 5m 51s\tremaining: 5m 41s\n",
      "2537:\tlearn: 0.0022457\ttotal: 5m 51s\tremaining: 5m 41s\n",
      "2538:\tlearn: 0.0022450\ttotal: 5m 51s\tremaining: 5m 40s\n",
      "2539:\tlearn: 0.0022448\ttotal: 5m 51s\tremaining: 5m 40s\n",
      "2540:\tlearn: 0.0022446\ttotal: 5m 52s\tremaining: 5m 40s\n",
      "2541:\tlearn: 0.0022442\ttotal: 5m 52s\tremaining: 5m 40s\n",
      "2542:\tlearn: 0.0022433\ttotal: 5m 52s\tremaining: 5m 40s\n",
      "2543:\tlearn: 0.0022431\ttotal: 5m 52s\tremaining: 5m 40s\n",
      "2544:\tlearn: 0.0022423\ttotal: 5m 52s\tremaining: 5m 40s\n",
      "2545:\tlearn: 0.0022418\ttotal: 5m 53s\tremaining: 5m 40s\n",
      "2546:\tlearn: 0.0022412\ttotal: 5m 53s\tremaining: 5m 40s\n",
      "2547:\tlearn: 0.0022410\ttotal: 5m 53s\tremaining: 5m 40s\n",
      "2548:\tlearn: 0.0022409\ttotal: 5m 53s\tremaining: 5m 40s\n",
      "2549:\tlearn: 0.0022408\ttotal: 5m 53s\tremaining: 5m 39s\n",
      "2550:\tlearn: 0.0022372\ttotal: 5m 54s\tremaining: 5m 39s\n",
      "2551:\tlearn: 0.0022367\ttotal: 5m 54s\tremaining: 5m 39s\n",
      "2552:\tlearn: 0.0022367\ttotal: 5m 54s\tremaining: 5m 39s\n",
      "2553:\tlearn: 0.0022366\ttotal: 5m 54s\tremaining: 5m 39s\n",
      "2554:\tlearn: 0.0022350\ttotal: 5m 54s\tremaining: 5m 39s\n",
      "2555:\tlearn: 0.0022343\ttotal: 5m 54s\tremaining: 5m 39s\n",
      "2556:\tlearn: 0.0022331\ttotal: 5m 55s\tremaining: 5m 39s\n",
      "2557:\tlearn: 0.0022331\ttotal: 5m 55s\tremaining: 5m 39s\n",
      "2558:\tlearn: 0.0022328\ttotal: 5m 55s\tremaining: 5m 39s\n",
      "2559:\tlearn: 0.0022327\ttotal: 5m 55s\tremaining: 5m 39s\n",
      "2560:\tlearn: 0.0022324\ttotal: 5m 56s\tremaining: 5m 39s\n",
      "2561:\tlearn: 0.0022322\ttotal: 5m 56s\tremaining: 5m 38s\n",
      "2562:\tlearn: 0.0022291\ttotal: 5m 56s\tremaining: 5m 38s\n",
      "2563:\tlearn: 0.0022281\ttotal: 5m 56s\tremaining: 5m 38s\n",
      "2564:\tlearn: 0.0022272\ttotal: 5m 56s\tremaining: 5m 38s\n",
      "2565:\tlearn: 0.0022268\ttotal: 5m 56s\tremaining: 5m 38s\n",
      "2566:\tlearn: 0.0022266\ttotal: 5m 56s\tremaining: 5m 38s\n",
      "2567:\tlearn: 0.0022249\ttotal: 5m 57s\tremaining: 5m 38s\n",
      "2568:\tlearn: 0.0022245\ttotal: 5m 57s\tremaining: 5m 38s\n",
      "2569:\tlearn: 0.0022243\ttotal: 5m 57s\tremaining: 5m 38s\n",
      "2570:\tlearn: 0.0022243\ttotal: 5m 57s\tremaining: 5m 37s\n",
      "2571:\tlearn: 0.0022236\ttotal: 5m 57s\tremaining: 5m 37s\n",
      "2572:\tlearn: 0.0022234\ttotal: 5m 58s\tremaining: 5m 37s\n",
      "2573:\tlearn: 0.0022233\ttotal: 5m 58s\tremaining: 5m 37s\n",
      "2574:\tlearn: 0.0022232\ttotal: 5m 58s\tremaining: 5m 37s\n",
      "2575:\tlearn: 0.0022227\ttotal: 5m 58s\tremaining: 5m 37s\n",
      "2576:\tlearn: 0.0022223\ttotal: 5m 58s\tremaining: 5m 37s\n",
      "2577:\tlearn: 0.0022222\ttotal: 5m 58s\tremaining: 5m 37s\n",
      "2578:\tlearn: 0.0022215\ttotal: 5m 59s\tremaining: 5m 37s\n",
      "2579:\tlearn: 0.0022212\ttotal: 5m 59s\tremaining: 5m 36s\n",
      "2580:\tlearn: 0.0022207\ttotal: 5m 59s\tremaining: 5m 36s\n",
      "2581:\tlearn: 0.0022204\ttotal: 5m 59s\tremaining: 5m 36s\n",
      "2582:\tlearn: 0.0022198\ttotal: 5m 59s\tremaining: 5m 36s\n",
      "2583:\tlearn: 0.0022187\ttotal: 5m 59s\tremaining: 5m 36s\n",
      "2584:\tlearn: 0.0022166\ttotal: 5m 59s\tremaining: 5m 36s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2585:\tlearn: 0.0022162\ttotal: 6m\tremaining: 5m 36s\n",
      "2586:\tlearn: 0.0022160\ttotal: 6m\tremaining: 5m 35s\n",
      "2587:\tlearn: 0.0022153\ttotal: 6m\tremaining: 5m 35s\n",
      "2588:\tlearn: 0.0022152\ttotal: 6m\tremaining: 5m 35s\n",
      "2589:\tlearn: 0.0022142\ttotal: 6m\tremaining: 5m 35s\n",
      "2590:\tlearn: 0.0022138\ttotal: 6m\tremaining: 5m 35s\n",
      "2591:\tlearn: 0.0022117\ttotal: 6m\tremaining: 5m 35s\n",
      "2592:\tlearn: 0.0022108\ttotal: 6m\tremaining: 5m 35s\n",
      "2593:\tlearn: 0.0022081\ttotal: 6m 1s\tremaining: 5m 34s\n",
      "2594:\tlearn: 0.0022073\ttotal: 6m 1s\tremaining: 5m 34s\n",
      "2595:\tlearn: 0.0022068\ttotal: 6m 1s\tremaining: 5m 34s\n",
      "2596:\tlearn: 0.0022066\ttotal: 6m 1s\tremaining: 5m 34s\n",
      "2597:\tlearn: 0.0022059\ttotal: 6m 1s\tremaining: 5m 34s\n",
      "2598:\tlearn: 0.0022023\ttotal: 6m 1s\tremaining: 5m 34s\n",
      "2599:\tlearn: 0.0022001\ttotal: 6m 1s\tremaining: 5m 34s\n",
      "2600:\tlearn: 0.0021998\ttotal: 6m 2s\tremaining: 5m 33s\n",
      "2601:\tlearn: 0.0021995\ttotal: 6m 2s\tremaining: 5m 33s\n",
      "2602:\tlearn: 0.0021994\ttotal: 6m 2s\tremaining: 5m 33s\n",
      "2603:\tlearn: 0.0021993\ttotal: 6m 2s\tremaining: 5m 33s\n",
      "2604:\tlearn: 0.0021988\ttotal: 6m 2s\tremaining: 5m 33s\n",
      "2605:\tlearn: 0.0021976\ttotal: 6m 2s\tremaining: 5m 33s\n",
      "2606:\tlearn: 0.0021962\ttotal: 6m 2s\tremaining: 5m 32s\n",
      "2607:\tlearn: 0.0021958\ttotal: 6m 2s\tremaining: 5m 32s\n",
      "2608:\tlearn: 0.0021953\ttotal: 6m 3s\tremaining: 5m 32s\n",
      "2609:\tlearn: 0.0021946\ttotal: 6m 3s\tremaining: 5m 32s\n",
      "2610:\tlearn: 0.0021942\ttotal: 6m 3s\tremaining: 5m 32s\n",
      "2611:\tlearn: 0.0021940\ttotal: 6m 3s\tremaining: 5m 32s\n",
      "2612:\tlearn: 0.0021934\ttotal: 6m 3s\tremaining: 5m 32s\n",
      "2613:\tlearn: 0.0021894\ttotal: 6m 3s\tremaining: 5m 32s\n",
      "2614:\tlearn: 0.0021894\ttotal: 6m 4s\tremaining: 5m 32s\n",
      "2615:\tlearn: 0.0021891\ttotal: 6m 4s\tremaining: 5m 31s\n",
      "2616:\tlearn: 0.0021890\ttotal: 6m 4s\tremaining: 5m 31s\n",
      "2617:\tlearn: 0.0021889\ttotal: 6m 4s\tremaining: 5m 31s\n",
      "2618:\tlearn: 0.0021856\ttotal: 6m 4s\tremaining: 5m 31s\n",
      "2619:\tlearn: 0.0021847\ttotal: 6m 4s\tremaining: 5m 31s\n",
      "2620:\tlearn: 0.0021845\ttotal: 6m 4s\tremaining: 5m 31s\n",
      "2621:\tlearn: 0.0021841\ttotal: 6m 4s\tremaining: 5m 30s\n",
      "2622:\tlearn: 0.0021832\ttotal: 6m 5s\tremaining: 5m 30s\n",
      "2623:\tlearn: 0.0021826\ttotal: 6m 5s\tremaining: 5m 30s\n",
      "2624:\tlearn: 0.0021824\ttotal: 6m 5s\tremaining: 5m 30s\n",
      "2625:\tlearn: 0.0021820\ttotal: 6m 5s\tremaining: 5m 30s\n",
      "2626:\tlearn: 0.0021819\ttotal: 6m 5s\tremaining: 5m 30s\n",
      "2627:\tlearn: 0.0021811\ttotal: 6m 5s\tremaining: 5m 30s\n",
      "2628:\tlearn: 0.0021806\ttotal: 6m 5s\tremaining: 5m 29s\n",
      "2629:\tlearn: 0.0021801\ttotal: 6m 6s\tremaining: 5m 29s\n",
      "2630:\tlearn: 0.0021790\ttotal: 6m 6s\tremaining: 5m 29s\n",
      "2631:\tlearn: 0.0021784\ttotal: 6m 6s\tremaining: 5m 29s\n",
      "2632:\tlearn: 0.0021776\ttotal: 6m 6s\tremaining: 5m 29s\n",
      "2633:\tlearn: 0.0021772\ttotal: 6m 6s\tremaining: 5m 29s\n",
      "2634:\tlearn: 0.0021750\ttotal: 6m 6s\tremaining: 5m 29s\n",
      "2635:\tlearn: 0.0021746\ttotal: 6m 7s\tremaining: 5m 29s\n",
      "2636:\tlearn: 0.0021744\ttotal: 6m 7s\tremaining: 5m 29s\n",
      "2637:\tlearn: 0.0021741\ttotal: 6m 7s\tremaining: 5m 28s\n",
      "2638:\tlearn: 0.0021726\ttotal: 6m 7s\tremaining: 5m 28s\n",
      "2639:\tlearn: 0.0021725\ttotal: 6m 7s\tremaining: 5m 28s\n",
      "2640:\tlearn: 0.0021720\ttotal: 6m 7s\tremaining: 5m 28s\n",
      "2641:\tlearn: 0.0021718\ttotal: 6m 8s\tremaining: 5m 28s\n",
      "2642:\tlearn: 0.0021717\ttotal: 6m 8s\tremaining: 5m 28s\n",
      "2643:\tlearn: 0.0021708\ttotal: 6m 8s\tremaining: 5m 28s\n",
      "2644:\tlearn: 0.0021707\ttotal: 6m 8s\tremaining: 5m 28s\n",
      "2645:\tlearn: 0.0021695\ttotal: 6m 8s\tremaining: 5m 28s\n",
      "2646:\tlearn: 0.0021689\ttotal: 6m 8s\tremaining: 5m 27s\n",
      "2647:\tlearn: 0.0021674\ttotal: 6m 9s\tremaining: 5m 27s\n",
      "2648:\tlearn: 0.0021666\ttotal: 6m 9s\tremaining: 5m 27s\n",
      "2649:\tlearn: 0.0021659\ttotal: 6m 9s\tremaining: 5m 27s\n",
      "2650:\tlearn: 0.0021646\ttotal: 6m 9s\tremaining: 5m 27s\n",
      "2651:\tlearn: 0.0021645\ttotal: 6m 9s\tremaining: 5m 27s\n",
      "2652:\tlearn: 0.0021637\ttotal: 6m 9s\tremaining: 5m 27s\n",
      "2653:\tlearn: 0.0021633\ttotal: 6m 10s\tremaining: 5m 27s\n",
      "2654:\tlearn: 0.0021631\ttotal: 6m 10s\tremaining: 5m 27s\n",
      "2655:\tlearn: 0.0021626\ttotal: 6m 10s\tremaining: 5m 26s\n",
      "2656:\tlearn: 0.0021625\ttotal: 6m 10s\tremaining: 5m 26s\n",
      "2657:\tlearn: 0.0021619\ttotal: 6m 10s\tremaining: 5m 26s\n",
      "2658:\tlearn: 0.0021608\ttotal: 6m 10s\tremaining: 5m 26s\n",
      "2659:\tlearn: 0.0021606\ttotal: 6m 10s\tremaining: 5m 26s\n",
      "2660:\tlearn: 0.0021600\ttotal: 6m 11s\tremaining: 5m 26s\n",
      "2661:\tlearn: 0.0021599\ttotal: 6m 11s\tremaining: 5m 25s\n",
      "2662:\tlearn: 0.0021589\ttotal: 6m 11s\tremaining: 5m 25s\n",
      "2663:\tlearn: 0.0021577\ttotal: 6m 11s\tremaining: 5m 25s\n",
      "2664:\tlearn: 0.0021575\ttotal: 6m 11s\tremaining: 5m 25s\n",
      "2665:\tlearn: 0.0021567\ttotal: 6m 11s\tremaining: 5m 25s\n",
      "2666:\tlearn: 0.0021562\ttotal: 6m 11s\tremaining: 5m 25s\n",
      "2667:\tlearn: 0.0021561\ttotal: 6m 11s\tremaining: 5m 25s\n",
      "2668:\tlearn: 0.0021554\ttotal: 6m 11s\tremaining: 5m 24s\n",
      "2669:\tlearn: 0.0021548\ttotal: 6m 12s\tremaining: 5m 24s\n",
      "2670:\tlearn: 0.0021543\ttotal: 6m 12s\tremaining: 5m 24s\n",
      "2671:\tlearn: 0.0021516\ttotal: 6m 12s\tremaining: 5m 24s\n",
      "2672:\tlearn: 0.0021511\ttotal: 6m 12s\tremaining: 5m 24s\n",
      "2673:\tlearn: 0.0021505\ttotal: 6m 12s\tremaining: 5m 24s\n",
      "2674:\tlearn: 0.0021499\ttotal: 6m 12s\tremaining: 5m 23s\n",
      "2675:\tlearn: 0.0021499\ttotal: 6m 12s\tremaining: 5m 23s\n",
      "2676:\tlearn: 0.0021484\ttotal: 6m 12s\tremaining: 5m 23s\n",
      "2677:\tlearn: 0.0021477\ttotal: 6m 13s\tremaining: 5m 23s\n",
      "2678:\tlearn: 0.0021471\ttotal: 6m 13s\tremaining: 5m 23s\n",
      "2679:\tlearn: 0.0021421\ttotal: 6m 13s\tremaining: 5m 23s\n",
      "2680:\tlearn: 0.0021420\ttotal: 6m 13s\tremaining: 5m 22s\n",
      "2681:\tlearn: 0.0021419\ttotal: 6m 13s\tremaining: 5m 22s\n",
      "2682:\tlearn: 0.0021417\ttotal: 6m 13s\tremaining: 5m 22s\n",
      "2683:\tlearn: 0.0021416\ttotal: 6m 13s\tremaining: 5m 22s\n",
      "2684:\tlearn: 0.0021413\ttotal: 6m 13s\tremaining: 5m 22s\n",
      "2685:\tlearn: 0.0021408\ttotal: 6m 14s\tremaining: 5m 22s\n",
      "2686:\tlearn: 0.0021402\ttotal: 6m 14s\tremaining: 5m 22s\n",
      "2687:\tlearn: 0.0021402\ttotal: 6m 14s\tremaining: 5m 22s\n",
      "2688:\tlearn: 0.0021401\ttotal: 6m 14s\tremaining: 5m 21s\n",
      "2689:\tlearn: 0.0021393\ttotal: 6m 14s\tremaining: 5m 21s\n",
      "2690:\tlearn: 0.0021391\ttotal: 6m 14s\tremaining: 5m 21s\n",
      "2691:\tlearn: 0.0021389\ttotal: 6m 14s\tremaining: 5m 21s\n",
      "2692:\tlearn: 0.0021387\ttotal: 6m 15s\tremaining: 5m 21s\n",
      "2693:\tlearn: 0.0021386\ttotal: 6m 15s\tremaining: 5m 21s\n",
      "2694:\tlearn: 0.0021384\ttotal: 6m 15s\tremaining: 5m 21s\n",
      "2695:\tlearn: 0.0021372\ttotal: 6m 15s\tremaining: 5m 20s\n",
      "2696:\tlearn: 0.0021371\ttotal: 6m 15s\tremaining: 5m 20s\n",
      "2697:\tlearn: 0.0021370\ttotal: 6m 15s\tremaining: 5m 20s\n",
      "2698:\tlearn: 0.0021353\ttotal: 6m 15s\tremaining: 5m 20s\n",
      "2699:\tlearn: 0.0021322\ttotal: 6m 15s\tremaining: 5m 20s\n",
      "2700:\tlearn: 0.0021322\ttotal: 6m 16s\tremaining: 5m 20s\n",
      "2701:\tlearn: 0.0021303\ttotal: 6m 16s\tremaining: 5m 19s\n",
      "2702:\tlearn: 0.0021302\ttotal: 6m 16s\tremaining: 5m 19s\n",
      "2703:\tlearn: 0.0021291\ttotal: 6m 16s\tremaining: 5m 19s\n",
      "2704:\tlearn: 0.0021254\ttotal: 6m 16s\tremaining: 5m 19s\n",
      "2705:\tlearn: 0.0021251\ttotal: 6m 16s\tremaining: 5m 19s\n",
      "2706:\tlearn: 0.0021247\ttotal: 6m 16s\tremaining: 5m 19s\n",
      "2707:\tlearn: 0.0021212\ttotal: 6m 16s\tremaining: 5m 19s\n",
      "2708:\tlearn: 0.0021208\ttotal: 6m 17s\tremaining: 5m 18s\n",
      "2709:\tlearn: 0.0021158\ttotal: 6m 17s\tremaining: 5m 18s\n",
      "2710:\tlearn: 0.0021146\ttotal: 6m 17s\tremaining: 5m 18s\n",
      "2711:\tlearn: 0.0021144\ttotal: 6m 17s\tremaining: 5m 18s\n",
      "2712:\tlearn: 0.0021138\ttotal: 6m 17s\tremaining: 5m 18s\n",
      "2713:\tlearn: 0.0021109\ttotal: 6m 17s\tremaining: 5m 18s\n",
      "2714:\tlearn: 0.0021103\ttotal: 6m 17s\tremaining: 5m 17s\n",
      "2715:\tlearn: 0.0021100\ttotal: 6m 17s\tremaining: 5m 17s\n",
      "2716:\tlearn: 0.0021076\ttotal: 6m 18s\tremaining: 5m 17s\n",
      "2717:\tlearn: 0.0021074\ttotal: 6m 18s\tremaining: 5m 17s\n",
      "2718:\tlearn: 0.0021065\ttotal: 6m 18s\tremaining: 5m 17s\n",
      "2719:\tlearn: 0.0021064\ttotal: 6m 18s\tremaining: 5m 17s\n",
      "2720:\tlearn: 0.0021059\ttotal: 6m 18s\tremaining: 5m 17s\n",
      "2721:\tlearn: 0.0021057\ttotal: 6m 18s\tremaining: 5m 16s\n",
      "2722:\tlearn: 0.0021055\ttotal: 6m 18s\tremaining: 5m 16s\n",
      "2723:\tlearn: 0.0021044\ttotal: 6m 18s\tremaining: 5m 16s\n",
      "2724:\tlearn: 0.0021039\ttotal: 6m 18s\tremaining: 5m 16s\n",
      "2725:\tlearn: 0.0021030\ttotal: 6m 19s\tremaining: 5m 16s\n",
      "2726:\tlearn: 0.0021016\ttotal: 6m 19s\tremaining: 5m 16s\n",
      "2727:\tlearn: 0.0021014\ttotal: 6m 19s\tremaining: 5m 15s\n",
      "2728:\tlearn: 0.0021013\ttotal: 6m 19s\tremaining: 5m 15s\n",
      "2729:\tlearn: 0.0021003\ttotal: 6m 19s\tremaining: 5m 15s\n",
      "2730:\tlearn: 0.0020999\ttotal: 6m 19s\tremaining: 5m 15s\n",
      "2731:\tlearn: 0.0020983\ttotal: 6m 19s\tremaining: 5m 15s\n",
      "2732:\tlearn: 0.0020982\ttotal: 6m 19s\tremaining: 5m 15s\n",
      "2733:\tlearn: 0.0020980\ttotal: 6m 20s\tremaining: 5m 15s\n",
      "2734:\tlearn: 0.0020960\ttotal: 6m 20s\tremaining: 5m 14s\n",
      "2735:\tlearn: 0.0020942\ttotal: 6m 20s\tremaining: 5m 14s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2736:\tlearn: 0.0020940\ttotal: 6m 20s\tremaining: 5m 14s\n",
      "2737:\tlearn: 0.0020927\ttotal: 6m 20s\tremaining: 5m 14s\n",
      "2738:\tlearn: 0.0020924\ttotal: 6m 20s\tremaining: 5m 14s\n",
      "2739:\tlearn: 0.0020922\ttotal: 6m 20s\tremaining: 5m 14s\n",
      "2740:\tlearn: 0.0020921\ttotal: 6m 20s\tremaining: 5m 13s\n",
      "2741:\tlearn: 0.0020902\ttotal: 6m 21s\tremaining: 5m 13s\n",
      "2742:\tlearn: 0.0020887\ttotal: 6m 21s\tremaining: 5m 13s\n",
      "2743:\tlearn: 0.0020885\ttotal: 6m 21s\tremaining: 5m 13s\n",
      "2744:\tlearn: 0.0020863\ttotal: 6m 21s\tremaining: 5m 13s\n",
      "2745:\tlearn: 0.0020855\ttotal: 6m 21s\tremaining: 5m 13s\n",
      "2746:\tlearn: 0.0020852\ttotal: 6m 21s\tremaining: 5m 13s\n",
      "2747:\tlearn: 0.0020852\ttotal: 6m 21s\tremaining: 5m 12s\n",
      "2748:\tlearn: 0.0020833\ttotal: 6m 22s\tremaining: 5m 12s\n",
      "2749:\tlearn: 0.0020820\ttotal: 6m 22s\tremaining: 5m 12s\n",
      "2750:\tlearn: 0.0020816\ttotal: 6m 22s\tremaining: 5m 12s\n",
      "2751:\tlearn: 0.0020809\ttotal: 6m 22s\tremaining: 5m 12s\n",
      "2752:\tlearn: 0.0020803\ttotal: 6m 22s\tremaining: 5m 12s\n",
      "2753:\tlearn: 0.0020797\ttotal: 6m 22s\tremaining: 5m 12s\n",
      "2754:\tlearn: 0.0020786\ttotal: 6m 23s\tremaining: 5m 12s\n",
      "2755:\tlearn: 0.0020778\ttotal: 6m 23s\tremaining: 5m 12s\n",
      "2756:\tlearn: 0.0020764\ttotal: 6m 23s\tremaining: 5m 11s\n",
      "2757:\tlearn: 0.0020761\ttotal: 6m 23s\tremaining: 5m 11s\n",
      "2758:\tlearn: 0.0020758\ttotal: 6m 23s\tremaining: 5m 11s\n",
      "2759:\tlearn: 0.0020755\ttotal: 6m 23s\tremaining: 5m 11s\n",
      "2760:\tlearn: 0.0020754\ttotal: 6m 23s\tremaining: 5m 11s\n",
      "2761:\tlearn: 0.0020753\ttotal: 6m 24s\tremaining: 5m 11s\n",
      "2762:\tlearn: 0.0020750\ttotal: 6m 24s\tremaining: 5m 11s\n",
      "2763:\tlearn: 0.0020747\ttotal: 6m 24s\tremaining: 5m 11s\n",
      "2764:\tlearn: 0.0020736\ttotal: 6m 24s\tremaining: 5m 10s\n",
      "2765:\tlearn: 0.0020728\ttotal: 6m 24s\tremaining: 5m 10s\n",
      "2766:\tlearn: 0.0020718\ttotal: 6m 24s\tremaining: 5m 10s\n",
      "2767:\tlearn: 0.0020713\ttotal: 6m 25s\tremaining: 5m 10s\n",
      "2768:\tlearn: 0.0020709\ttotal: 6m 25s\tremaining: 5m 10s\n",
      "2769:\tlearn: 0.0020688\ttotal: 6m 25s\tremaining: 5m 10s\n",
      "2770:\tlearn: 0.0020686\ttotal: 6m 25s\tremaining: 5m 10s\n",
      "2771:\tlearn: 0.0020672\ttotal: 6m 25s\tremaining: 5m 10s\n",
      "2772:\tlearn: 0.0020669\ttotal: 6m 26s\tremaining: 5m 10s\n",
      "2773:\tlearn: 0.0020669\ttotal: 6m 26s\tremaining: 5m 10s\n",
      "2774:\tlearn: 0.0020667\ttotal: 6m 26s\tremaining: 5m 9s\n",
      "2775:\tlearn: 0.0020665\ttotal: 6m 26s\tremaining: 5m 9s\n",
      "2776:\tlearn: 0.0020661\ttotal: 6m 26s\tremaining: 5m 9s\n",
      "2777:\tlearn: 0.0020660\ttotal: 6m 27s\tremaining: 5m 9s\n",
      "2778:\tlearn: 0.0020660\ttotal: 6m 27s\tremaining: 5m 9s\n",
      "2779:\tlearn: 0.0020651\ttotal: 6m 27s\tremaining: 5m 9s\n",
      "2780:\tlearn: 0.0020649\ttotal: 6m 27s\tremaining: 5m 9s\n",
      "2781:\tlearn: 0.0020649\ttotal: 6m 27s\tremaining: 5m 9s\n",
      "2782:\tlearn: 0.0020648\ttotal: 6m 27s\tremaining: 5m 9s\n",
      "2783:\tlearn: 0.0020646\ttotal: 6m 28s\tremaining: 5m 8s\n",
      "2784:\tlearn: 0.0020640\ttotal: 6m 28s\tremaining: 5m 8s\n",
      "2785:\tlearn: 0.0020637\ttotal: 6m 28s\tremaining: 5m 8s\n",
      "2786:\tlearn: 0.0020632\ttotal: 6m 28s\tremaining: 5m 8s\n",
      "2787:\tlearn: 0.0020630\ttotal: 6m 28s\tremaining: 5m 8s\n",
      "2788:\tlearn: 0.0020612\ttotal: 6m 28s\tremaining: 5m 8s\n",
      "2789:\tlearn: 0.0020612\ttotal: 6m 29s\tremaining: 5m 8s\n",
      "2790:\tlearn: 0.0020612\ttotal: 6m 29s\tremaining: 5m 8s\n",
      "2791:\tlearn: 0.0020609\ttotal: 6m 29s\tremaining: 5m 7s\n",
      "2792:\tlearn: 0.0020604\ttotal: 6m 29s\tremaining: 5m 7s\n",
      "2793:\tlearn: 0.0020602\ttotal: 6m 29s\tremaining: 5m 7s\n",
      "2794:\tlearn: 0.0020601\ttotal: 6m 29s\tremaining: 5m 7s\n",
      "2795:\tlearn: 0.0020586\ttotal: 6m 29s\tremaining: 5m 7s\n",
      "2796:\tlearn: 0.0020583\ttotal: 6m 29s\tremaining: 5m 7s\n",
      "2797:\tlearn: 0.0020580\ttotal: 6m 30s\tremaining: 5m 6s\n",
      "2798:\tlearn: 0.0020580\ttotal: 6m 30s\tremaining: 5m 6s\n",
      "2799:\tlearn: 0.0020575\ttotal: 6m 30s\tremaining: 5m 6s\n",
      "2800:\tlearn: 0.0020553\ttotal: 6m 30s\tremaining: 5m 6s\n",
      "2801:\tlearn: 0.0020548\ttotal: 6m 30s\tremaining: 5m 6s\n",
      "2802:\tlearn: 0.0020542\ttotal: 6m 30s\tremaining: 5m 6s\n",
      "2803:\tlearn: 0.0020521\ttotal: 6m 30s\tremaining: 5m 6s\n",
      "2804:\tlearn: 0.0020514\ttotal: 6m 30s\tremaining: 5m 5s\n",
      "2805:\tlearn: 0.0020513\ttotal: 6m 31s\tremaining: 5m 5s\n",
      "2806:\tlearn: 0.0020493\ttotal: 6m 31s\tremaining: 5m 5s\n",
      "2807:\tlearn: 0.0020481\ttotal: 6m 31s\tremaining: 5m 5s\n",
      "2808:\tlearn: 0.0020473\ttotal: 6m 31s\tremaining: 5m 5s\n",
      "2809:\tlearn: 0.0020471\ttotal: 6m 31s\tremaining: 5m 5s\n",
      "2810:\tlearn: 0.0020467\ttotal: 6m 31s\tremaining: 5m 5s\n",
      "2811:\tlearn: 0.0020464\ttotal: 6m 31s\tremaining: 5m 4s\n",
      "2812:\tlearn: 0.0020451\ttotal: 6m 31s\tremaining: 5m 4s\n",
      "2813:\tlearn: 0.0020445\ttotal: 6m 32s\tremaining: 5m 4s\n",
      "2814:\tlearn: 0.0020436\ttotal: 6m 32s\tremaining: 5m 4s\n",
      "2815:\tlearn: 0.0020432\ttotal: 6m 32s\tremaining: 5m 4s\n",
      "2816:\tlearn: 0.0020423\ttotal: 6m 32s\tremaining: 5m 4s\n",
      "2817:\tlearn: 0.0020397\ttotal: 6m 32s\tremaining: 5m 3s\n",
      "2818:\tlearn: 0.0020391\ttotal: 6m 32s\tremaining: 5m 3s\n",
      "2819:\tlearn: 0.0020389\ttotal: 6m 32s\tremaining: 5m 3s\n",
      "2820:\tlearn: 0.0020375\ttotal: 6m 32s\tremaining: 5m 3s\n",
      "2821:\tlearn: 0.0020373\ttotal: 6m 32s\tremaining: 5m 3s\n",
      "2822:\tlearn: 0.0020361\ttotal: 6m 33s\tremaining: 5m 3s\n",
      "2823:\tlearn: 0.0020355\ttotal: 6m 33s\tremaining: 5m 2s\n",
      "2824:\tlearn: 0.0020338\ttotal: 6m 33s\tremaining: 5m 2s\n",
      "2825:\tlearn: 0.0020334\ttotal: 6m 33s\tremaining: 5m 2s\n",
      "2826:\tlearn: 0.0020332\ttotal: 6m 33s\tremaining: 5m 2s\n",
      "2827:\tlearn: 0.0020329\ttotal: 6m 33s\tremaining: 5m 2s\n",
      "2828:\tlearn: 0.0020320\ttotal: 6m 33s\tremaining: 5m 2s\n",
      "2829:\tlearn: 0.0020316\ttotal: 6m 33s\tremaining: 5m 2s\n",
      "2830:\tlearn: 0.0020313\ttotal: 6m 34s\tremaining: 5m 1s\n",
      "2831:\tlearn: 0.0020276\ttotal: 6m 34s\tremaining: 5m 1s\n",
      "2832:\tlearn: 0.0020273\ttotal: 6m 34s\tremaining: 5m 1s\n",
      "2833:\tlearn: 0.0020272\ttotal: 6m 34s\tremaining: 5m 1s\n",
      "2834:\tlearn: 0.0020270\ttotal: 6m 34s\tremaining: 5m 1s\n",
      "2835:\tlearn: 0.0020267\ttotal: 6m 34s\tremaining: 5m 1s\n",
      "2836:\tlearn: 0.0020254\ttotal: 6m 34s\tremaining: 5m 1s\n",
      "2837:\tlearn: 0.0020250\ttotal: 6m 35s\tremaining: 5m\n",
      "2838:\tlearn: 0.0020239\ttotal: 6m 35s\tremaining: 5m\n",
      "2839:\tlearn: 0.0020238\ttotal: 6m 35s\tremaining: 5m\n",
      "2840:\tlearn: 0.0020219\ttotal: 6m 35s\tremaining: 5m\n",
      "2841:\tlearn: 0.0020218\ttotal: 6m 35s\tremaining: 5m\n",
      "2842:\tlearn: 0.0020213\ttotal: 6m 35s\tremaining: 5m\n",
      "2843:\tlearn: 0.0020212\ttotal: 6m 36s\tremaining: 5m\n",
      "2844:\tlearn: 0.0020210\ttotal: 6m 36s\tremaining: 5m\n",
      "2845:\tlearn: 0.0020208\ttotal: 6m 36s\tremaining: 4m 59s\n",
      "2846:\tlearn: 0.0020206\ttotal: 6m 36s\tremaining: 4m 59s\n",
      "2847:\tlearn: 0.0020204\ttotal: 6m 36s\tremaining: 4m 59s\n",
      "2848:\tlearn: 0.0020202\ttotal: 6m 36s\tremaining: 4m 59s\n",
      "2849:\tlearn: 0.0020193\ttotal: 6m 36s\tremaining: 4m 59s\n",
      "2850:\tlearn: 0.0020185\ttotal: 6m 37s\tremaining: 4m 59s\n",
      "2851:\tlearn: 0.0020185\ttotal: 6m 37s\tremaining: 4m 59s\n",
      "2852:\tlearn: 0.0020173\ttotal: 6m 37s\tremaining: 4m 59s\n",
      "2853:\tlearn: 0.0020166\ttotal: 6m 37s\tremaining: 4m 58s\n",
      "2854:\tlearn: 0.0020163\ttotal: 6m 37s\tremaining: 4m 58s\n",
      "2855:\tlearn: 0.0020161\ttotal: 6m 37s\tremaining: 4m 58s\n",
      "2856:\tlearn: 0.0020160\ttotal: 6m 37s\tremaining: 4m 58s\n",
      "2857:\tlearn: 0.0020152\ttotal: 6m 38s\tremaining: 4m 58s\n",
      "2858:\tlearn: 0.0020150\ttotal: 6m 38s\tremaining: 4m 58s\n",
      "2859:\tlearn: 0.0020141\ttotal: 6m 38s\tremaining: 4m 58s\n",
      "2860:\tlearn: 0.0020139\ttotal: 6m 38s\tremaining: 4m 58s\n",
      "2861:\tlearn: 0.0020126\ttotal: 6m 38s\tremaining: 4m 57s\n",
      "2862:\tlearn: 0.0020125\ttotal: 6m 38s\tremaining: 4m 57s\n",
      "2863:\tlearn: 0.0020119\ttotal: 6m 39s\tremaining: 4m 57s\n",
      "2864:\tlearn: 0.0020117\ttotal: 6m 39s\tremaining: 4m 57s\n",
      "2865:\tlearn: 0.0020115\ttotal: 6m 39s\tremaining: 4m 57s\n",
      "2866:\tlearn: 0.0020113\ttotal: 6m 39s\tremaining: 4m 57s\n",
      "2867:\tlearn: 0.0020103\ttotal: 6m 39s\tremaining: 4m 57s\n",
      "2868:\tlearn: 0.0020096\ttotal: 6m 39s\tremaining: 4m 57s\n",
      "2869:\tlearn: 0.0020093\ttotal: 6m 40s\tremaining: 4m 56s\n",
      "2870:\tlearn: 0.0020090\ttotal: 6m 40s\tremaining: 4m 56s\n",
      "2871:\tlearn: 0.0020088\ttotal: 6m 40s\tremaining: 4m 56s\n",
      "2872:\tlearn: 0.0020083\ttotal: 6m 40s\tremaining: 4m 56s\n",
      "2873:\tlearn: 0.0020071\ttotal: 6m 40s\tremaining: 4m 56s\n",
      "2874:\tlearn: 0.0020070\ttotal: 6m 40s\tremaining: 4m 56s\n",
      "2875:\tlearn: 0.0020059\ttotal: 6m 40s\tremaining: 4m 56s\n",
      "2876:\tlearn: 0.0020010\ttotal: 6m 41s\tremaining: 4m 56s\n",
      "2877:\tlearn: 0.0020008\ttotal: 6m 41s\tremaining: 4m 55s\n",
      "2878:\tlearn: 0.0020004\ttotal: 6m 41s\tremaining: 4m 55s\n",
      "2879:\tlearn: 0.0019997\ttotal: 6m 41s\tremaining: 4m 55s\n",
      "2880:\tlearn: 0.0019993\ttotal: 6m 41s\tremaining: 4m 55s\n",
      "2881:\tlearn: 0.0019978\ttotal: 6m 41s\tremaining: 4m 55s\n",
      "2882:\tlearn: 0.0019978\ttotal: 6m 42s\tremaining: 4m 55s\n",
      "2883:\tlearn: 0.0019978\ttotal: 6m 42s\tremaining: 4m 55s\n",
      "2884:\tlearn: 0.0019977\ttotal: 6m 42s\tremaining: 4m 54s\n",
      "2885:\tlearn: 0.0019976\ttotal: 6m 42s\tremaining: 4m 54s\n",
      "2886:\tlearn: 0.0019912\ttotal: 6m 42s\tremaining: 4m 54s\n",
      "2887:\tlearn: 0.0019906\ttotal: 6m 42s\tremaining: 4m 54s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2888:\tlearn: 0.0019899\ttotal: 6m 42s\tremaining: 4m 54s\n",
      "2889:\tlearn: 0.0019894\ttotal: 6m 43s\tremaining: 4m 54s\n",
      "2890:\tlearn: 0.0019887\ttotal: 6m 43s\tremaining: 4m 54s\n",
      "2891:\tlearn: 0.0019884\ttotal: 6m 43s\tremaining: 4m 54s\n",
      "2892:\tlearn: 0.0019884\ttotal: 6m 43s\tremaining: 4m 53s\n",
      "2893:\tlearn: 0.0019878\ttotal: 6m 43s\tremaining: 4m 53s\n",
      "2894:\tlearn: 0.0019870\ttotal: 6m 43s\tremaining: 4m 53s\n",
      "2895:\tlearn: 0.0019867\ttotal: 6m 43s\tremaining: 4m 53s\n",
      "2896:\tlearn: 0.0019864\ttotal: 6m 44s\tremaining: 4m 53s\n",
      "2897:\tlearn: 0.0019842\ttotal: 6m 44s\tremaining: 4m 53s\n",
      "2898:\tlearn: 0.0019838\ttotal: 6m 44s\tremaining: 4m 53s\n",
      "2899:\tlearn: 0.0019825\ttotal: 6m 44s\tremaining: 4m 52s\n",
      "2900:\tlearn: 0.0019823\ttotal: 6m 44s\tremaining: 4m 52s\n",
      "2901:\tlearn: 0.0019822\ttotal: 6m 44s\tremaining: 4m 52s\n",
      "2902:\tlearn: 0.0019817\ttotal: 6m 44s\tremaining: 4m 52s\n",
      "2903:\tlearn: 0.0019816\ttotal: 6m 44s\tremaining: 4m 52s\n",
      "2904:\tlearn: 0.0019808\ttotal: 6m 45s\tremaining: 4m 52s\n",
      "2905:\tlearn: 0.0019800\ttotal: 6m 45s\tremaining: 4m 51s\n",
      "2906:\tlearn: 0.0019796\ttotal: 6m 45s\tremaining: 4m 51s\n",
      "2907:\tlearn: 0.0019794\ttotal: 6m 45s\tremaining: 4m 51s\n",
      "2908:\tlearn: 0.0019793\ttotal: 6m 45s\tremaining: 4m 51s\n",
      "2909:\tlearn: 0.0019791\ttotal: 6m 45s\tremaining: 4m 51s\n",
      "2910:\tlearn: 0.0019786\ttotal: 6m 45s\tremaining: 4m 51s\n",
      "2911:\tlearn: 0.0019784\ttotal: 6m 45s\tremaining: 4m 51s\n",
      "2912:\tlearn: 0.0019780\ttotal: 6m 46s\tremaining: 4m 50s\n",
      "2913:\tlearn: 0.0019779\ttotal: 6m 46s\tremaining: 4m 50s\n",
      "2914:\tlearn: 0.0019751\ttotal: 6m 46s\tremaining: 4m 50s\n",
      "2915:\tlearn: 0.0019749\ttotal: 6m 46s\tremaining: 4m 50s\n",
      "2916:\tlearn: 0.0019736\ttotal: 6m 46s\tremaining: 4m 50s\n",
      "2917:\tlearn: 0.0019721\ttotal: 6m 46s\tremaining: 4m 50s\n",
      "2918:\tlearn: 0.0019719\ttotal: 6m 46s\tremaining: 4m 50s\n",
      "2919:\tlearn: 0.0019699\ttotal: 6m 46s\tremaining: 4m 49s\n",
      "2920:\tlearn: 0.0019698\ttotal: 6m 47s\tremaining: 4m 49s\n",
      "2921:\tlearn: 0.0019697\ttotal: 6m 47s\tremaining: 4m 49s\n",
      "2922:\tlearn: 0.0019688\ttotal: 6m 47s\tremaining: 4m 49s\n",
      "2923:\tlearn: 0.0019687\ttotal: 6m 47s\tremaining: 4m 49s\n",
      "2924:\tlearn: 0.0019686\ttotal: 6m 47s\tremaining: 4m 49s\n",
      "2925:\tlearn: 0.0019684\ttotal: 6m 47s\tremaining: 4m 48s\n",
      "2926:\tlearn: 0.0019680\ttotal: 6m 47s\tremaining: 4m 48s\n",
      "2927:\tlearn: 0.0019677\ttotal: 6m 47s\tremaining: 4m 48s\n",
      "2928:\tlearn: 0.0019661\ttotal: 6m 48s\tremaining: 4m 48s\n",
      "2929:\tlearn: 0.0019646\ttotal: 6m 48s\tremaining: 4m 48s\n",
      "2930:\tlearn: 0.0019646\ttotal: 6m 48s\tremaining: 4m 48s\n",
      "2931:\tlearn: 0.0019645\ttotal: 6m 48s\tremaining: 4m 48s\n",
      "2932:\tlearn: 0.0019639\ttotal: 6m 48s\tremaining: 4m 47s\n",
      "2933:\tlearn: 0.0019633\ttotal: 6m 48s\tremaining: 4m 47s\n",
      "2934:\tlearn: 0.0019624\ttotal: 6m 48s\tremaining: 4m 47s\n",
      "2935:\tlearn: 0.0019620\ttotal: 6m 48s\tremaining: 4m 47s\n",
      "2936:\tlearn: 0.0019618\ttotal: 6m 48s\tremaining: 4m 47s\n",
      "2937:\tlearn: 0.0019616\ttotal: 6m 49s\tremaining: 4m 47s\n",
      "2938:\tlearn: 0.0019615\ttotal: 6m 49s\tremaining: 4m 46s\n",
      "2939:\tlearn: 0.0019589\ttotal: 6m 49s\tremaining: 4m 46s\n",
      "2940:\tlearn: 0.0019584\ttotal: 6m 49s\tremaining: 4m 46s\n",
      "2941:\tlearn: 0.0019566\ttotal: 6m 49s\tremaining: 4m 46s\n",
      "2942:\tlearn: 0.0019560\ttotal: 6m 49s\tremaining: 4m 46s\n",
      "2943:\tlearn: 0.0019557\ttotal: 6m 49s\tremaining: 4m 46s\n",
      "2944:\tlearn: 0.0019549\ttotal: 6m 50s\tremaining: 4m 46s\n",
      "2945:\tlearn: 0.0019548\ttotal: 6m 50s\tremaining: 4m 45s\n",
      "2946:\tlearn: 0.0019546\ttotal: 6m 50s\tremaining: 4m 45s\n",
      "2947:\tlearn: 0.0019533\ttotal: 6m 50s\tremaining: 4m 45s\n",
      "2948:\tlearn: 0.0019529\ttotal: 6m 50s\tremaining: 4m 45s\n",
      "2949:\tlearn: 0.0019528\ttotal: 6m 50s\tremaining: 4m 45s\n",
      "2950:\tlearn: 0.0019521\ttotal: 6m 50s\tremaining: 4m 45s\n",
      "2951:\tlearn: 0.0019504\ttotal: 6m 50s\tremaining: 4m 45s\n",
      "2952:\tlearn: 0.0019503\ttotal: 6m 50s\tremaining: 4m 44s\n",
      "2953:\tlearn: 0.0019502\ttotal: 6m 51s\tremaining: 4m 44s\n",
      "2954:\tlearn: 0.0019501\ttotal: 6m 51s\tremaining: 4m 44s\n",
      "2955:\tlearn: 0.0019471\ttotal: 6m 51s\tremaining: 4m 44s\n",
      "2956:\tlearn: 0.0019469\ttotal: 6m 51s\tremaining: 4m 44s\n",
      "2957:\tlearn: 0.0019465\ttotal: 6m 51s\tremaining: 4m 44s\n",
      "2958:\tlearn: 0.0019464\ttotal: 6m 51s\tremaining: 4m 44s\n",
      "2959:\tlearn: 0.0019449\ttotal: 6m 52s\tremaining: 4m 44s\n",
      "2960:\tlearn: 0.0019447\ttotal: 6m 52s\tremaining: 4m 43s\n",
      "2961:\tlearn: 0.0019444\ttotal: 6m 52s\tremaining: 4m 43s\n",
      "2962:\tlearn: 0.0019443\ttotal: 6m 52s\tremaining: 4m 43s\n",
      "2963:\tlearn: 0.0019430\ttotal: 6m 52s\tremaining: 4m 43s\n",
      "2964:\tlearn: 0.0019429\ttotal: 6m 52s\tremaining: 4m 43s\n",
      "2965:\tlearn: 0.0019416\ttotal: 6m 53s\tremaining: 4m 43s\n",
      "2966:\tlearn: 0.0019414\ttotal: 6m 53s\tremaining: 4m 43s\n",
      "2967:\tlearn: 0.0019402\ttotal: 6m 53s\tremaining: 4m 43s\n",
      "2968:\tlearn: 0.0019397\ttotal: 6m 53s\tremaining: 4m 42s\n",
      "2969:\tlearn: 0.0019395\ttotal: 6m 53s\tremaining: 4m 42s\n",
      "2970:\tlearn: 0.0019381\ttotal: 6m 53s\tremaining: 4m 42s\n",
      "2971:\tlearn: 0.0019369\ttotal: 6m 54s\tremaining: 4m 42s\n",
      "2972:\tlearn: 0.0019366\ttotal: 6m 54s\tremaining: 4m 42s\n",
      "2973:\tlearn: 0.0019356\ttotal: 6m 54s\tremaining: 4m 42s\n",
      "2974:\tlearn: 0.0019353\ttotal: 6m 54s\tremaining: 4m 42s\n",
      "2975:\tlearn: 0.0019350\ttotal: 6m 54s\tremaining: 4m 41s\n",
      "2976:\tlearn: 0.0019347\ttotal: 6m 54s\tremaining: 4m 41s\n",
      "2977:\tlearn: 0.0019342\ttotal: 6m 54s\tremaining: 4m 41s\n",
      "2978:\tlearn: 0.0019328\ttotal: 6m 54s\tremaining: 4m 41s\n",
      "2979:\tlearn: 0.0019323\ttotal: 6m 54s\tremaining: 4m 41s\n",
      "2980:\tlearn: 0.0019296\ttotal: 6m 55s\tremaining: 4m 41s\n",
      "2981:\tlearn: 0.0019295\ttotal: 6m 55s\tremaining: 4m 40s\n",
      "2982:\tlearn: 0.0019294\ttotal: 6m 55s\tremaining: 4m 40s\n",
      "2983:\tlearn: 0.0019290\ttotal: 6m 55s\tremaining: 4m 40s\n",
      "2984:\tlearn: 0.0019289\ttotal: 6m 55s\tremaining: 4m 40s\n",
      "2985:\tlearn: 0.0019285\ttotal: 6m 55s\tremaining: 4m 40s\n",
      "2986:\tlearn: 0.0019284\ttotal: 6m 55s\tremaining: 4m 40s\n",
      "2987:\tlearn: 0.0019283\ttotal: 6m 55s\tremaining: 4m 40s\n",
      "2988:\tlearn: 0.0019282\ttotal: 6m 56s\tremaining: 4m 39s\n",
      "2989:\tlearn: 0.0019270\ttotal: 6m 56s\tremaining: 4m 39s\n",
      "2990:\tlearn: 0.0019256\ttotal: 6m 56s\tremaining: 4m 39s\n",
      "2991:\tlearn: 0.0019229\ttotal: 6m 56s\tremaining: 4m 39s\n",
      "2992:\tlearn: 0.0019220\ttotal: 6m 56s\tremaining: 4m 39s\n",
      "2993:\tlearn: 0.0019219\ttotal: 6m 56s\tremaining: 4m 39s\n",
      "2994:\tlearn: 0.0019210\ttotal: 6m 56s\tremaining: 4m 39s\n",
      "2995:\tlearn: 0.0019210\ttotal: 6m 57s\tremaining: 4m 39s\n",
      "2996:\tlearn: 0.0019210\ttotal: 6m 57s\tremaining: 4m 38s\n",
      "2997:\tlearn: 0.0019208\ttotal: 6m 57s\tremaining: 4m 38s\n",
      "2998:\tlearn: 0.0019191\ttotal: 6m 57s\tremaining: 4m 38s\n",
      "2999:\tlearn: 0.0019181\ttotal: 6m 57s\tremaining: 4m 38s\n",
      "3000:\tlearn: 0.0019174\ttotal: 6m 57s\tremaining: 4m 38s\n",
      "3001:\tlearn: 0.0019174\ttotal: 6m 57s\tremaining: 4m 38s\n",
      "3002:\tlearn: 0.0019173\ttotal: 6m 58s\tremaining: 4m 38s\n",
      "3003:\tlearn: 0.0019172\ttotal: 6m 58s\tremaining: 4m 37s\n",
      "3004:\tlearn: 0.0019164\ttotal: 6m 58s\tremaining: 4m 37s\n",
      "3005:\tlearn: 0.0019161\ttotal: 6m 58s\tremaining: 4m 37s\n",
      "3006:\tlearn: 0.0019159\ttotal: 6m 58s\tremaining: 4m 37s\n",
      "3007:\tlearn: 0.0019151\ttotal: 6m 58s\tremaining: 4m 37s\n",
      "3008:\tlearn: 0.0019145\ttotal: 6m 58s\tremaining: 4m 37s\n",
      "3009:\tlearn: 0.0019142\ttotal: 6m 58s\tremaining: 4m 36s\n",
      "3010:\tlearn: 0.0019141\ttotal: 6m 58s\tremaining: 4m 36s\n",
      "3011:\tlearn: 0.0019140\ttotal: 6m 59s\tremaining: 4m 36s\n",
      "3012:\tlearn: 0.0019139\ttotal: 6m 59s\tremaining: 4m 36s\n",
      "3013:\tlearn: 0.0019132\ttotal: 6m 59s\tremaining: 4m 36s\n",
      "3014:\tlearn: 0.0019130\ttotal: 6m 59s\tremaining: 4m 36s\n",
      "3015:\tlearn: 0.0019130\ttotal: 6m 59s\tremaining: 4m 35s\n",
      "3016:\tlearn: 0.0019114\ttotal: 6m 59s\tremaining: 4m 35s\n",
      "3017:\tlearn: 0.0019113\ttotal: 6m 59s\tremaining: 4m 35s\n",
      "3018:\tlearn: 0.0019092\ttotal: 6m 59s\tremaining: 4m 35s\n",
      "3019:\tlearn: 0.0019087\ttotal: 6m 59s\tremaining: 4m 35s\n",
      "3020:\tlearn: 0.0019074\ttotal: 6m 59s\tremaining: 4m 35s\n",
      "3021:\tlearn: 0.0019073\ttotal: 7m\tremaining: 4m 34s\n",
      "3022:\tlearn: 0.0019072\ttotal: 7m\tremaining: 4m 34s\n",
      "3023:\tlearn: 0.0019064\ttotal: 7m\tremaining: 4m 34s\n",
      "3024:\tlearn: 0.0019063\ttotal: 7m\tremaining: 4m 34s\n",
      "3025:\tlearn: 0.0019058\ttotal: 7m\tremaining: 4m 34s\n",
      "3026:\tlearn: 0.0019050\ttotal: 7m\tremaining: 4m 34s\n",
      "3027:\tlearn: 0.0019043\ttotal: 7m\tremaining: 4m 34s\n",
      "3028:\tlearn: 0.0019042\ttotal: 7m 1s\tremaining: 4m 33s\n",
      "3029:\tlearn: 0.0019041\ttotal: 7m 1s\tremaining: 4m 33s\n",
      "3030:\tlearn: 0.0019040\ttotal: 7m 1s\tremaining: 4m 33s\n",
      "3031:\tlearn: 0.0019035\ttotal: 7m 1s\tremaining: 4m 33s\n",
      "3032:\tlearn: 0.0019033\ttotal: 7m 1s\tremaining: 4m 33s\n",
      "3033:\tlearn: 0.0019030\ttotal: 7m 1s\tremaining: 4m 33s\n",
      "3034:\tlearn: 0.0019029\ttotal: 7m 1s\tremaining: 4m 33s\n",
      "3035:\tlearn: 0.0019029\ttotal: 7m 1s\tremaining: 4m 32s\n",
      "3036:\tlearn: 0.0019024\ttotal: 7m 2s\tremaining: 4m 32s\n",
      "3037:\tlearn: 0.0019022\ttotal: 7m 2s\tremaining: 4m 32s\n",
      "3038:\tlearn: 0.0018992\ttotal: 7m 2s\tremaining: 4m 32s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3039:\tlearn: 0.0018985\ttotal: 7m 2s\tremaining: 4m 32s\n",
      "3040:\tlearn: 0.0018982\ttotal: 7m 2s\tremaining: 4m 32s\n",
      "3041:\tlearn: 0.0018979\ttotal: 7m 2s\tremaining: 4m 32s\n",
      "3042:\tlearn: 0.0018979\ttotal: 7m 3s\tremaining: 4m 32s\n",
      "3043:\tlearn: 0.0018977\ttotal: 7m 3s\tremaining: 4m 32s\n",
      "3044:\tlearn: 0.0018976\ttotal: 7m 3s\tremaining: 4m 31s\n",
      "3045:\tlearn: 0.0018967\ttotal: 7m 3s\tremaining: 4m 31s\n",
      "3046:\tlearn: 0.0018965\ttotal: 7m 3s\tremaining: 4m 31s\n",
      "3047:\tlearn: 0.0018963\ttotal: 7m 3s\tremaining: 4m 31s\n",
      "3048:\tlearn: 0.0018960\ttotal: 7m 4s\tremaining: 4m 31s\n",
      "3049:\tlearn: 0.0018945\ttotal: 7m 4s\tremaining: 4m 31s\n",
      "3050:\tlearn: 0.0018939\ttotal: 7m 4s\tremaining: 4m 31s\n",
      "3051:\tlearn: 0.0018938\ttotal: 7m 4s\tremaining: 4m 31s\n",
      "3052:\tlearn: 0.0018929\ttotal: 7m 4s\tremaining: 4m 30s\n",
      "3053:\tlearn: 0.0018927\ttotal: 7m 5s\tremaining: 4m 30s\n",
      "3054:\tlearn: 0.0018926\ttotal: 7m 5s\tremaining: 4m 30s\n",
      "3055:\tlearn: 0.0018925\ttotal: 7m 5s\tremaining: 4m 30s\n",
      "3056:\tlearn: 0.0018918\ttotal: 7m 5s\tremaining: 4m 30s\n",
      "3057:\tlearn: 0.0018909\ttotal: 7m 5s\tremaining: 4m 30s\n",
      "3058:\tlearn: 0.0018907\ttotal: 7m 5s\tremaining: 4m 30s\n",
      "3059:\tlearn: 0.0018906\ttotal: 7m 6s\tremaining: 4m 30s\n",
      "3060:\tlearn: 0.0018904\ttotal: 7m 6s\tremaining: 4m 30s\n",
      "3061:\tlearn: 0.0018902\ttotal: 7m 6s\tremaining: 4m 29s\n",
      "3062:\tlearn: 0.0018895\ttotal: 7m 6s\tremaining: 4m 29s\n",
      "3063:\tlearn: 0.0018892\ttotal: 7m 6s\tremaining: 4m 29s\n",
      "3064:\tlearn: 0.0018891\ttotal: 7m 6s\tremaining: 4m 29s\n",
      "3065:\tlearn: 0.0018879\ttotal: 7m 7s\tremaining: 4m 29s\n",
      "3066:\tlearn: 0.0018859\ttotal: 7m 7s\tremaining: 4m 29s\n",
      "3067:\tlearn: 0.0018859\ttotal: 7m 7s\tremaining: 4m 29s\n",
      "3068:\tlearn: 0.0018854\ttotal: 7m 7s\tremaining: 4m 28s\n",
      "3069:\tlearn: 0.0018853\ttotal: 7m 7s\tremaining: 4m 28s\n",
      "3070:\tlearn: 0.0018853\ttotal: 7m 7s\tremaining: 4m 28s\n",
      "3071:\tlearn: 0.0018844\ttotal: 7m 7s\tremaining: 4m 28s\n",
      "3072:\tlearn: 0.0018840\ttotal: 7m 7s\tremaining: 4m 28s\n",
      "3073:\tlearn: 0.0018837\ttotal: 7m 8s\tremaining: 4m 28s\n",
      "3074:\tlearn: 0.0018834\ttotal: 7m 8s\tremaining: 4m 28s\n",
      "3075:\tlearn: 0.0018829\ttotal: 7m 8s\tremaining: 4m 27s\n",
      "3076:\tlearn: 0.0018825\ttotal: 7m 8s\tremaining: 4m 27s\n",
      "3077:\tlearn: 0.0018820\ttotal: 7m 8s\tremaining: 4m 27s\n",
      "3078:\tlearn: 0.0018820\ttotal: 7m 8s\tremaining: 4m 27s\n",
      "3079:\tlearn: 0.0018809\ttotal: 7m 8s\tremaining: 4m 27s\n",
      "3080:\tlearn: 0.0018807\ttotal: 7m 8s\tremaining: 4m 27s\n",
      "3081:\tlearn: 0.0018806\ttotal: 7m 9s\tremaining: 4m 26s\n",
      "3082:\tlearn: 0.0018802\ttotal: 7m 9s\tremaining: 4m 26s\n",
      "3083:\tlearn: 0.0018799\ttotal: 7m 9s\tremaining: 4m 26s\n",
      "3084:\tlearn: 0.0018797\ttotal: 7m 9s\tremaining: 4m 26s\n",
      "3085:\tlearn: 0.0018791\ttotal: 7m 9s\tremaining: 4m 26s\n",
      "3086:\tlearn: 0.0018785\ttotal: 7m 9s\tremaining: 4m 26s\n",
      "3087:\tlearn: 0.0018785\ttotal: 7m 9s\tremaining: 4m 26s\n",
      "3088:\tlearn: 0.0018781\ttotal: 7m 9s\tremaining: 4m 25s\n",
      "3089:\tlearn: 0.0018778\ttotal: 7m 9s\tremaining: 4m 25s\n",
      "3090:\tlearn: 0.0018771\ttotal: 7m 10s\tremaining: 4m 25s\n",
      "3091:\tlearn: 0.0018767\ttotal: 7m 10s\tremaining: 4m 25s\n",
      "3092:\tlearn: 0.0018761\ttotal: 7m 10s\tremaining: 4m 25s\n",
      "3093:\tlearn: 0.0018754\ttotal: 7m 10s\tremaining: 4m 25s\n",
      "3094:\tlearn: 0.0018748\ttotal: 7m 10s\tremaining: 4m 25s\n",
      "3095:\tlearn: 0.0018747\ttotal: 7m 10s\tremaining: 4m 24s\n",
      "3096:\tlearn: 0.0018733\ttotal: 7m 11s\tremaining: 4m 24s\n",
      "3097:\tlearn: 0.0018718\ttotal: 7m 11s\tremaining: 4m 24s\n",
      "3098:\tlearn: 0.0018716\ttotal: 7m 11s\tremaining: 4m 24s\n",
      "3099:\tlearn: 0.0018711\ttotal: 7m 11s\tremaining: 4m 24s\n",
      "3100:\tlearn: 0.0018704\ttotal: 7m 11s\tremaining: 4m 24s\n",
      "3101:\tlearn: 0.0018702\ttotal: 7m 11s\tremaining: 4m 24s\n",
      "3102:\tlearn: 0.0018701\ttotal: 7m 12s\tremaining: 4m 24s\n",
      "3103:\tlearn: 0.0018671\ttotal: 7m 12s\tremaining: 4m 24s\n",
      "3104:\tlearn: 0.0018661\ttotal: 7m 12s\tremaining: 4m 23s\n",
      "3105:\tlearn: 0.0018658\ttotal: 7m 12s\tremaining: 4m 23s\n",
      "3106:\tlearn: 0.0018654\ttotal: 7m 12s\tremaining: 4m 23s\n",
      "3107:\tlearn: 0.0018654\ttotal: 7m 12s\tremaining: 4m 23s\n",
      "3108:\tlearn: 0.0018653\ttotal: 7m 12s\tremaining: 4m 23s\n",
      "3109:\tlearn: 0.0018648\ttotal: 7m 13s\tremaining: 4m 23s\n",
      "3110:\tlearn: 0.0018643\ttotal: 7m 13s\tremaining: 4m 23s\n",
      "3111:\tlearn: 0.0018641\ttotal: 7m 13s\tremaining: 4m 22s\n",
      "3112:\tlearn: 0.0018641\ttotal: 7m 13s\tremaining: 4m 22s\n",
      "3113:\tlearn: 0.0018638\ttotal: 7m 13s\tremaining: 4m 22s\n",
      "3114:\tlearn: 0.0018638\ttotal: 7m 13s\tremaining: 4m 22s\n",
      "3115:\tlearn: 0.0018636\ttotal: 7m 14s\tremaining: 4m 22s\n",
      "3116:\tlearn: 0.0018635\ttotal: 7m 14s\tremaining: 4m 22s\n",
      "3117:\tlearn: 0.0018634\ttotal: 7m 14s\tremaining: 4m 22s\n",
      "3118:\tlearn: 0.0018630\ttotal: 7m 14s\tremaining: 4m 22s\n",
      "3119:\tlearn: 0.0018626\ttotal: 7m 14s\tremaining: 4m 21s\n",
      "3120:\tlearn: 0.0018622\ttotal: 7m 14s\tremaining: 4m 21s\n",
      "3121:\tlearn: 0.0018614\ttotal: 7m 15s\tremaining: 4m 21s\n",
      "3122:\tlearn: 0.0018612\ttotal: 7m 15s\tremaining: 4m 21s\n",
      "3123:\tlearn: 0.0018593\ttotal: 7m 15s\tremaining: 4m 21s\n",
      "3124:\tlearn: 0.0018590\ttotal: 7m 15s\tremaining: 4m 21s\n",
      "3125:\tlearn: 0.0018590\ttotal: 7m 15s\tremaining: 4m 21s\n",
      "3126:\tlearn: 0.0018588\ttotal: 7m 15s\tremaining: 4m 20s\n",
      "3127:\tlearn: 0.0018587\ttotal: 7m 15s\tremaining: 4m 20s\n",
      "3128:\tlearn: 0.0018585\ttotal: 7m 16s\tremaining: 4m 20s\n",
      "3129:\tlearn: 0.0018553\ttotal: 7m 16s\tremaining: 4m 20s\n",
      "3130:\tlearn: 0.0018551\ttotal: 7m 16s\tremaining: 4m 20s\n",
      "3131:\tlearn: 0.0018551\ttotal: 7m 16s\tremaining: 4m 20s\n",
      "3132:\tlearn: 0.0018550\ttotal: 7m 16s\tremaining: 4m 20s\n",
      "3133:\tlearn: 0.0018544\ttotal: 7m 16s\tremaining: 4m 20s\n",
      "3134:\tlearn: 0.0018541\ttotal: 7m 16s\tremaining: 4m 19s\n",
      "3135:\tlearn: 0.0018533\ttotal: 7m 17s\tremaining: 4m 19s\n",
      "3136:\tlearn: 0.0018533\ttotal: 7m 17s\tremaining: 4m 19s\n",
      "3137:\tlearn: 0.0018521\ttotal: 7m 17s\tremaining: 4m 19s\n",
      "3138:\tlearn: 0.0018517\ttotal: 7m 17s\tremaining: 4m 19s\n",
      "3139:\tlearn: 0.0018507\ttotal: 7m 17s\tremaining: 4m 19s\n",
      "3140:\tlearn: 0.0018503\ttotal: 7m 17s\tremaining: 4m 19s\n",
      "3141:\tlearn: 0.0018493\ttotal: 7m 17s\tremaining: 4m 18s\n",
      "3142:\tlearn: 0.0018490\ttotal: 7m 18s\tremaining: 4m 18s\n",
      "3143:\tlearn: 0.0018480\ttotal: 7m 18s\tremaining: 4m 18s\n",
      "3144:\tlearn: 0.0018477\ttotal: 7m 18s\tremaining: 4m 18s\n",
      "3145:\tlearn: 0.0018473\ttotal: 7m 18s\tremaining: 4m 18s\n",
      "3146:\tlearn: 0.0018470\ttotal: 7m 18s\tremaining: 4m 18s\n",
      "3147:\tlearn: 0.0018457\ttotal: 7m 18s\tremaining: 4m 18s\n",
      "3148:\tlearn: 0.0018452\ttotal: 7m 19s\tremaining: 4m 18s\n",
      "3149:\tlearn: 0.0018448\ttotal: 7m 19s\tremaining: 4m 17s\n",
      "3150:\tlearn: 0.0018438\ttotal: 7m 19s\tremaining: 4m 17s\n",
      "3151:\tlearn: 0.0018436\ttotal: 7m 19s\tremaining: 4m 17s\n",
      "3152:\tlearn: 0.0018434\ttotal: 7m 19s\tremaining: 4m 17s\n",
      "3153:\tlearn: 0.0018433\ttotal: 7m 19s\tremaining: 4m 17s\n",
      "3154:\tlearn: 0.0018426\ttotal: 7m 19s\tremaining: 4m 17s\n",
      "3155:\tlearn: 0.0018415\ttotal: 7m 20s\tremaining: 4m 17s\n",
      "3156:\tlearn: 0.0018410\ttotal: 7m 20s\tremaining: 4m 17s\n",
      "3157:\tlearn: 0.0018398\ttotal: 7m 20s\tremaining: 4m 16s\n",
      "3158:\tlearn: 0.0018372\ttotal: 7m 20s\tremaining: 4m 16s\n",
      "3159:\tlearn: 0.0018370\ttotal: 7m 20s\tremaining: 4m 16s\n",
      "3160:\tlearn: 0.0018365\ttotal: 7m 20s\tremaining: 4m 16s\n",
      "3161:\tlearn: 0.0018364\ttotal: 7m 21s\tremaining: 4m 16s\n",
      "3162:\tlearn: 0.0018362\ttotal: 7m 21s\tremaining: 4m 16s\n",
      "3163:\tlearn: 0.0018349\ttotal: 7m 21s\tremaining: 4m 16s\n",
      "3164:\tlearn: 0.0018347\ttotal: 7m 21s\tremaining: 4m 16s\n",
      "3165:\tlearn: 0.0018346\ttotal: 7m 21s\tremaining: 4m 15s\n",
      "3166:\tlearn: 0.0018344\ttotal: 7m 21s\tremaining: 4m 15s\n",
      "3167:\tlearn: 0.0018342\ttotal: 7m 22s\tremaining: 4m 15s\n",
      "3168:\tlearn: 0.0018330\ttotal: 7m 22s\tremaining: 4m 15s\n",
      "3169:\tlearn: 0.0018328\ttotal: 7m 22s\tremaining: 4m 15s\n",
      "3170:\tlearn: 0.0018328\ttotal: 7m 22s\tremaining: 4m 15s\n",
      "3171:\tlearn: 0.0018326\ttotal: 7m 22s\tremaining: 4m 14s\n",
      "3172:\tlearn: 0.0018322\ttotal: 7m 22s\tremaining: 4m 14s\n",
      "3173:\tlearn: 0.0018322\ttotal: 7m 22s\tremaining: 4m 14s\n",
      "3174:\tlearn: 0.0018320\ttotal: 7m 22s\tremaining: 4m 14s\n",
      "3175:\tlearn: 0.0018316\ttotal: 7m 22s\tremaining: 4m 14s\n",
      "3176:\tlearn: 0.0018309\ttotal: 7m 23s\tremaining: 4m 14s\n",
      "3177:\tlearn: 0.0018306\ttotal: 7m 23s\tremaining: 4m 14s\n",
      "3178:\tlearn: 0.0018305\ttotal: 7m 23s\tremaining: 4m 13s\n",
      "3179:\tlearn: 0.0018292\ttotal: 7m 23s\tremaining: 4m 13s\n",
      "3180:\tlearn: 0.0018282\ttotal: 7m 23s\tremaining: 4m 13s\n",
      "3181:\tlearn: 0.0018278\ttotal: 7m 23s\tremaining: 4m 13s\n",
      "3182:\tlearn: 0.0018272\ttotal: 7m 23s\tremaining: 4m 13s\n",
      "3183:\tlearn: 0.0018269\ttotal: 7m 23s\tremaining: 4m 13s\n",
      "3184:\tlearn: 0.0018267\ttotal: 7m 24s\tremaining: 4m 13s\n",
      "3185:\tlearn: 0.0018261\ttotal: 7m 24s\tremaining: 4m 12s\n",
      "3186:\tlearn: 0.0018260\ttotal: 7m 24s\tremaining: 4m 12s\n",
      "3187:\tlearn: 0.0018238\ttotal: 7m 24s\tremaining: 4m 12s\n",
      "3188:\tlearn: 0.0018234\ttotal: 7m 24s\tremaining: 4m 12s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3189:\tlearn: 0.0018226\ttotal: 7m 24s\tremaining: 4m 12s\n",
      "3190:\tlearn: 0.0018221\ttotal: 7m 24s\tremaining: 4m 12s\n",
      "3191:\tlearn: 0.0018213\ttotal: 7m 24s\tremaining: 4m 12s\n",
      "3192:\tlearn: 0.0018212\ttotal: 7m 25s\tremaining: 4m 11s\n",
      "3193:\tlearn: 0.0018206\ttotal: 7m 25s\tremaining: 4m 11s\n",
      "3194:\tlearn: 0.0018196\ttotal: 7m 25s\tremaining: 4m 11s\n",
      "3195:\tlearn: 0.0018194\ttotal: 7m 25s\tremaining: 4m 11s\n",
      "3196:\tlearn: 0.0018188\ttotal: 7m 25s\tremaining: 4m 11s\n",
      "3197:\tlearn: 0.0018185\ttotal: 7m 25s\tremaining: 4m 11s\n",
      "3198:\tlearn: 0.0018185\ttotal: 7m 26s\tremaining: 4m 11s\n",
      "3199:\tlearn: 0.0018182\ttotal: 7m 26s\tremaining: 4m 10s\n",
      "3200:\tlearn: 0.0018179\ttotal: 7m 26s\tremaining: 4m 10s\n",
      "3201:\tlearn: 0.0018177\ttotal: 7m 26s\tremaining: 4m 10s\n",
      "3202:\tlearn: 0.0018175\ttotal: 7m 26s\tremaining: 4m 10s\n",
      "3203:\tlearn: 0.0018173\ttotal: 7m 26s\tremaining: 4m 10s\n",
      "3204:\tlearn: 0.0018173\ttotal: 7m 26s\tremaining: 4m 10s\n",
      "3205:\tlearn: 0.0018171\ttotal: 7m 27s\tremaining: 4m 10s\n",
      "3206:\tlearn: 0.0018168\ttotal: 7m 27s\tremaining: 4m 10s\n",
      "3207:\tlearn: 0.0018164\ttotal: 7m 27s\tremaining: 4m 9s\n",
      "3208:\tlearn: 0.0018155\ttotal: 7m 27s\tremaining: 4m 9s\n",
      "3209:\tlearn: 0.0018153\ttotal: 7m 27s\tremaining: 4m 9s\n",
      "3210:\tlearn: 0.0018124\ttotal: 7m 27s\tremaining: 4m 9s\n",
      "3211:\tlearn: 0.0018122\ttotal: 7m 28s\tremaining: 4m 9s\n",
      "3212:\tlearn: 0.0018120\ttotal: 7m 28s\tremaining: 4m 9s\n",
      "3213:\tlearn: 0.0018119\ttotal: 7m 28s\tremaining: 4m 9s\n",
      "3214:\tlearn: 0.0018116\ttotal: 7m 28s\tremaining: 4m 9s\n",
      "3215:\tlearn: 0.0018109\ttotal: 7m 28s\tremaining: 4m 8s\n",
      "3216:\tlearn: 0.0018107\ttotal: 7m 28s\tremaining: 4m 8s\n",
      "3217:\tlearn: 0.0018107\ttotal: 7m 28s\tremaining: 4m 8s\n",
      "3218:\tlearn: 0.0018106\ttotal: 7m 29s\tremaining: 4m 8s\n",
      "3219:\tlearn: 0.0018105\ttotal: 7m 29s\tremaining: 4m 8s\n",
      "3220:\tlearn: 0.0018105\ttotal: 7m 29s\tremaining: 4m 8s\n",
      "3221:\tlearn: 0.0018102\ttotal: 7m 29s\tremaining: 4m 8s\n",
      "3222:\tlearn: 0.0018100\ttotal: 7m 29s\tremaining: 4m 7s\n",
      "3223:\tlearn: 0.0018100\ttotal: 7m 29s\tremaining: 4m 7s\n",
      "3224:\tlearn: 0.0018092\ttotal: 7m 30s\tremaining: 4m 7s\n",
      "3225:\tlearn: 0.0018090\ttotal: 7m 30s\tremaining: 4m 7s\n",
      "3226:\tlearn: 0.0018086\ttotal: 7m 30s\tremaining: 4m 7s\n",
      "3227:\tlearn: 0.0018085\ttotal: 7m 30s\tremaining: 4m 7s\n",
      "3228:\tlearn: 0.0018083\ttotal: 7m 30s\tremaining: 4m 7s\n",
      "3229:\tlearn: 0.0018081\ttotal: 7m 30s\tremaining: 4m 6s\n",
      "3230:\tlearn: 0.0018079\ttotal: 7m 30s\tremaining: 4m 6s\n",
      "3231:\tlearn: 0.0018079\ttotal: 7m 30s\tremaining: 4m 6s\n",
      "3232:\tlearn: 0.0018057\ttotal: 7m 31s\tremaining: 4m 6s\n",
      "3233:\tlearn: 0.0018028\ttotal: 7m 31s\tremaining: 4m 6s\n",
      "3234:\tlearn: 0.0018020\ttotal: 7m 31s\tremaining: 4m 6s\n",
      "3235:\tlearn: 0.0018013\ttotal: 7m 31s\tremaining: 4m 6s\n",
      "3236:\tlearn: 0.0018006\ttotal: 7m 31s\tremaining: 4m 5s\n",
      "3237:\tlearn: 0.0018003\ttotal: 7m 31s\tremaining: 4m 5s\n",
      "3238:\tlearn: 0.0017998\ttotal: 7m 32s\tremaining: 4m 5s\n",
      "3239:\tlearn: 0.0017997\ttotal: 7m 32s\tremaining: 4m 5s\n",
      "3240:\tlearn: 0.0017994\ttotal: 7m 32s\tremaining: 4m 5s\n",
      "3241:\tlearn: 0.0017985\ttotal: 7m 32s\tremaining: 4m 5s\n",
      "3242:\tlearn: 0.0017984\ttotal: 7m 32s\tremaining: 4m 5s\n",
      "3243:\tlearn: 0.0017983\ttotal: 7m 32s\tremaining: 4m 5s\n",
      "3244:\tlearn: 0.0017979\ttotal: 7m 32s\tremaining: 4m 4s\n",
      "3245:\tlearn: 0.0017978\ttotal: 7m 33s\tremaining: 4m 4s\n",
      "3246:\tlearn: 0.0017975\ttotal: 7m 33s\tremaining: 4m 4s\n",
      "3247:\tlearn: 0.0017967\ttotal: 7m 33s\tremaining: 4m 4s\n",
      "3248:\tlearn: 0.0017962\ttotal: 7m 33s\tremaining: 4m 4s\n",
      "3249:\tlearn: 0.0017961\ttotal: 7m 33s\tremaining: 4m 4s\n",
      "3250:\tlearn: 0.0017960\ttotal: 7m 34s\tremaining: 4m 4s\n",
      "3251:\tlearn: 0.0017955\ttotal: 7m 34s\tremaining: 4m 4s\n",
      "3252:\tlearn: 0.0017952\ttotal: 7m 34s\tremaining: 4m 4s\n",
      "3253:\tlearn: 0.0017943\ttotal: 7m 34s\tremaining: 4m 3s\n",
      "3254:\tlearn: 0.0017943\ttotal: 7m 34s\tremaining: 4m 3s\n",
      "3255:\tlearn: 0.0017941\ttotal: 7m 34s\tremaining: 4m 3s\n",
      "3256:\tlearn: 0.0017934\ttotal: 7m 34s\tremaining: 4m 3s\n",
      "3257:\tlearn: 0.0017917\ttotal: 7m 35s\tremaining: 4m 3s\n",
      "3258:\tlearn: 0.0017917\ttotal: 7m 35s\tremaining: 4m 3s\n",
      "3259:\tlearn: 0.0017915\ttotal: 7m 35s\tremaining: 4m 3s\n",
      "3260:\tlearn: 0.0017914\ttotal: 7m 35s\tremaining: 4m 2s\n",
      "3261:\tlearn: 0.0017913\ttotal: 7m 35s\tremaining: 4m 2s\n",
      "3262:\tlearn: 0.0017895\ttotal: 7m 35s\tremaining: 4m 2s\n",
      "3263:\tlearn: 0.0017888\ttotal: 7m 36s\tremaining: 4m 2s\n",
      "3264:\tlearn: 0.0017879\ttotal: 7m 36s\tremaining: 4m 2s\n",
      "3265:\tlearn: 0.0017878\ttotal: 7m 36s\tremaining: 4m 2s\n",
      "3266:\tlearn: 0.0017876\ttotal: 7m 36s\tremaining: 4m 2s\n",
      "3267:\tlearn: 0.0017853\ttotal: 7m 36s\tremaining: 4m 1s\n",
      "3268:\tlearn: 0.0017847\ttotal: 7m 36s\tremaining: 4m 1s\n",
      "3269:\tlearn: 0.0017843\ttotal: 7m 36s\tremaining: 4m 1s\n",
      "3270:\tlearn: 0.0017837\ttotal: 7m 36s\tremaining: 4m 1s\n",
      "3271:\tlearn: 0.0017831\ttotal: 7m 37s\tremaining: 4m 1s\n",
      "3272:\tlearn: 0.0017828\ttotal: 7m 37s\tremaining: 4m 1s\n",
      "3273:\tlearn: 0.0017825\ttotal: 7m 37s\tremaining: 4m 1s\n",
      "3274:\tlearn: 0.0017822\ttotal: 7m 37s\tremaining: 4m 1s\n",
      "3275:\tlearn: 0.0017821\ttotal: 7m 37s\tremaining: 4m\n",
      "3276:\tlearn: 0.0017792\ttotal: 7m 37s\tremaining: 4m\n",
      "3277:\tlearn: 0.0017791\ttotal: 7m 38s\tremaining: 4m\n",
      "3278:\tlearn: 0.0017789\ttotal: 7m 38s\tremaining: 4m\n",
      "3279:\tlearn: 0.0017788\ttotal: 7m 38s\tremaining: 4m\n",
      "3280:\tlearn: 0.0017772\ttotal: 7m 38s\tremaining: 4m\n",
      "3281:\tlearn: 0.0017769\ttotal: 7m 38s\tremaining: 4m\n",
      "3282:\tlearn: 0.0017764\ttotal: 7m 38s\tremaining: 3m 59s\n",
      "3283:\tlearn: 0.0017759\ttotal: 7m 38s\tremaining: 3m 59s\n",
      "3284:\tlearn: 0.0017757\ttotal: 7m 38s\tremaining: 3m 59s\n",
      "3285:\tlearn: 0.0017753\ttotal: 7m 38s\tremaining: 3m 59s\n",
      "3286:\tlearn: 0.0017749\ttotal: 7m 39s\tremaining: 3m 59s\n",
      "3287:\tlearn: 0.0017743\ttotal: 7m 39s\tremaining: 3m 59s\n",
      "3288:\tlearn: 0.0017740\ttotal: 7m 39s\tremaining: 3m 58s\n",
      "3289:\tlearn: 0.0017740\ttotal: 7m 39s\tremaining: 3m 58s\n",
      "3290:\tlearn: 0.0017730\ttotal: 7m 39s\tremaining: 3m 58s\n",
      "3291:\tlearn: 0.0017729\ttotal: 7m 39s\tremaining: 3m 58s\n",
      "3292:\tlearn: 0.0017728\ttotal: 7m 39s\tremaining: 3m 58s\n",
      "3293:\tlearn: 0.0017708\ttotal: 7m 40s\tremaining: 3m 58s\n",
      "3294:\tlearn: 0.0017698\ttotal: 7m 40s\tremaining: 3m 58s\n",
      "3295:\tlearn: 0.0017697\ttotal: 7m 40s\tremaining: 3m 58s\n",
      "3296:\tlearn: 0.0017696\ttotal: 7m 40s\tremaining: 3m 57s\n",
      "3297:\tlearn: 0.0017691\ttotal: 7m 40s\tremaining: 3m 57s\n",
      "3298:\tlearn: 0.0017682\ttotal: 7m 40s\tremaining: 3m 57s\n",
      "3299:\tlearn: 0.0017678\ttotal: 7m 40s\tremaining: 3m 57s\n",
      "3300:\tlearn: 0.0017678\ttotal: 7m 41s\tremaining: 3m 57s\n",
      "3301:\tlearn: 0.0017677\ttotal: 7m 41s\tremaining: 3m 57s\n",
      "3302:\tlearn: 0.0017676\ttotal: 7m 41s\tremaining: 3m 57s\n",
      "3303:\tlearn: 0.0017667\ttotal: 7m 41s\tremaining: 3m 56s\n",
      "3304:\tlearn: 0.0017665\ttotal: 7m 41s\tremaining: 3m 56s\n",
      "3305:\tlearn: 0.0017664\ttotal: 7m 41s\tremaining: 3m 56s\n",
      "3306:\tlearn: 0.0017664\ttotal: 7m 41s\tremaining: 3m 56s\n",
      "3307:\tlearn: 0.0017658\ttotal: 7m 42s\tremaining: 3m 56s\n",
      "3308:\tlearn: 0.0017657\ttotal: 7m 42s\tremaining: 3m 56s\n",
      "3309:\tlearn: 0.0017657\ttotal: 7m 42s\tremaining: 3m 56s\n",
      "3310:\tlearn: 0.0017633\ttotal: 7m 42s\tremaining: 3m 55s\n",
      "3311:\tlearn: 0.0017630\ttotal: 7m 42s\tremaining: 3m 55s\n",
      "3312:\tlearn: 0.0017630\ttotal: 7m 42s\tremaining: 3m 55s\n",
      "3313:\tlearn: 0.0017622\ttotal: 7m 42s\tremaining: 3m 55s\n",
      "3314:\tlearn: 0.0017613\ttotal: 7m 43s\tremaining: 3m 55s\n",
      "3315:\tlearn: 0.0017613\ttotal: 7m 43s\tremaining: 3m 55s\n",
      "3316:\tlearn: 0.0017612\ttotal: 7m 43s\tremaining: 3m 55s\n",
      "3317:\tlearn: 0.0017608\ttotal: 7m 43s\tremaining: 3m 54s\n",
      "3318:\tlearn: 0.0017597\ttotal: 7m 43s\tremaining: 3m 54s\n",
      "3319:\tlearn: 0.0017583\ttotal: 7m 43s\tremaining: 3m 54s\n",
      "3320:\tlearn: 0.0017580\ttotal: 7m 43s\tremaining: 3m 54s\n",
      "3321:\tlearn: 0.0017579\ttotal: 7m 43s\tremaining: 3m 54s\n",
      "3322:\tlearn: 0.0017578\ttotal: 7m 43s\tremaining: 3m 54s\n",
      "3323:\tlearn: 0.0017577\ttotal: 7m 44s\tremaining: 3m 53s\n",
      "3324:\tlearn: 0.0017576\ttotal: 7m 44s\tremaining: 3m 53s\n",
      "3325:\tlearn: 0.0017575\ttotal: 7m 44s\tremaining: 3m 53s\n",
      "3326:\tlearn: 0.0017571\ttotal: 7m 44s\tremaining: 3m 53s\n",
      "3327:\tlearn: 0.0017563\ttotal: 7m 44s\tremaining: 3m 53s\n",
      "3328:\tlearn: 0.0017557\ttotal: 7m 44s\tremaining: 3m 53s\n",
      "3329:\tlearn: 0.0017555\ttotal: 7m 44s\tremaining: 3m 53s\n",
      "3330:\tlearn: 0.0017554\ttotal: 7m 44s\tremaining: 3m 52s\n",
      "3331:\tlearn: 0.0017550\ttotal: 7m 44s\tremaining: 3m 52s\n",
      "3332:\tlearn: 0.0017548\ttotal: 7m 45s\tremaining: 3m 52s\n",
      "3333:\tlearn: 0.0017547\ttotal: 7m 45s\tremaining: 3m 52s\n",
      "3334:\tlearn: 0.0017542\ttotal: 7m 45s\tremaining: 3m 52s\n",
      "3335:\tlearn: 0.0017541\ttotal: 7m 45s\tremaining: 3m 52s\n",
      "3336:\tlearn: 0.0017539\ttotal: 7m 45s\tremaining: 3m 51s\n",
      "3337:\tlearn: 0.0017537\ttotal: 7m 45s\tremaining: 3m 51s\n",
      "3338:\tlearn: 0.0017532\ttotal: 7m 45s\tremaining: 3m 51s\n",
      "3339:\tlearn: 0.0017532\ttotal: 7m 45s\tremaining: 3m 51s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3340:\tlearn: 0.0017530\ttotal: 7m 45s\tremaining: 3m 51s\n",
      "3341:\tlearn: 0.0017528\ttotal: 7m 45s\tremaining: 3m 51s\n",
      "3342:\tlearn: 0.0017524\ttotal: 7m 46s\tremaining: 3m 51s\n",
      "3343:\tlearn: 0.0017522\ttotal: 7m 46s\tremaining: 3m 50s\n",
      "3344:\tlearn: 0.0017521\ttotal: 7m 46s\tremaining: 3m 50s\n",
      "3345:\tlearn: 0.0017511\ttotal: 7m 46s\tremaining: 3m 50s\n",
      "3346:\tlearn: 0.0017498\ttotal: 7m 46s\tremaining: 3m 50s\n",
      "3347:\tlearn: 0.0017495\ttotal: 7m 46s\tremaining: 3m 50s\n",
      "3348:\tlearn: 0.0017493\ttotal: 7m 46s\tremaining: 3m 50s\n",
      "3349:\tlearn: 0.0017482\ttotal: 7m 46s\tremaining: 3m 49s\n",
      "3350:\tlearn: 0.0017481\ttotal: 7m 47s\tremaining: 3m 49s\n",
      "3351:\tlearn: 0.0017478\ttotal: 7m 47s\tremaining: 3m 49s\n",
      "3352:\tlearn: 0.0017474\ttotal: 7m 47s\tremaining: 3m 49s\n",
      "3353:\tlearn: 0.0017473\ttotal: 7m 47s\tremaining: 3m 49s\n",
      "3354:\tlearn: 0.0017469\ttotal: 7m 47s\tremaining: 3m 49s\n",
      "3355:\tlearn: 0.0017462\ttotal: 7m 47s\tremaining: 3m 49s\n",
      "3356:\tlearn: 0.0017459\ttotal: 7m 47s\tremaining: 3m 48s\n",
      "3357:\tlearn: 0.0017455\ttotal: 7m 47s\tremaining: 3m 48s\n",
      "3358:\tlearn: 0.0017450\ttotal: 7m 47s\tremaining: 3m 48s\n",
      "3359:\tlearn: 0.0017448\ttotal: 7m 48s\tremaining: 3m 48s\n",
      "3360:\tlearn: 0.0017441\ttotal: 7m 48s\tremaining: 3m 48s\n",
      "3361:\tlearn: 0.0017438\ttotal: 7m 48s\tremaining: 3m 48s\n",
      "3362:\tlearn: 0.0017438\ttotal: 7m 48s\tremaining: 3m 48s\n",
      "3363:\tlearn: 0.0017435\ttotal: 7m 48s\tremaining: 3m 47s\n",
      "3364:\tlearn: 0.0017419\ttotal: 7m 48s\tremaining: 3m 47s\n",
      "3365:\tlearn: 0.0017418\ttotal: 7m 48s\tremaining: 3m 47s\n",
      "3366:\tlearn: 0.0017417\ttotal: 7m 49s\tremaining: 3m 47s\n",
      "3367:\tlearn: 0.0017413\ttotal: 7m 49s\tremaining: 3m 47s\n",
      "3368:\tlearn: 0.0017412\ttotal: 7m 49s\tremaining: 3m 47s\n",
      "3369:\tlearn: 0.0017411\ttotal: 7m 49s\tremaining: 3m 47s\n",
      "3370:\tlearn: 0.0017404\ttotal: 7m 49s\tremaining: 3m 46s\n",
      "3371:\tlearn: 0.0017403\ttotal: 7m 49s\tremaining: 3m 46s\n",
      "3372:\tlearn: 0.0017402\ttotal: 7m 49s\tremaining: 3m 46s\n",
      "3373:\tlearn: 0.0017400\ttotal: 7m 49s\tremaining: 3m 46s\n",
      "3374:\tlearn: 0.0017395\ttotal: 7m 50s\tremaining: 3m 46s\n",
      "3375:\tlearn: 0.0017392\ttotal: 7m 50s\tremaining: 3m 46s\n",
      "3376:\tlearn: 0.0017387\ttotal: 7m 50s\tremaining: 3m 46s\n",
      "3377:\tlearn: 0.0017380\ttotal: 7m 50s\tremaining: 3m 45s\n",
      "3378:\tlearn: 0.0017379\ttotal: 7m 50s\tremaining: 3m 45s\n",
      "3379:\tlearn: 0.0017353\ttotal: 7m 50s\tremaining: 3m 45s\n",
      "3380:\tlearn: 0.0017348\ttotal: 7m 50s\tremaining: 3m 45s\n",
      "3381:\tlearn: 0.0017346\ttotal: 7m 50s\tremaining: 3m 45s\n",
      "3382:\tlearn: 0.0017343\ttotal: 7m 51s\tremaining: 3m 45s\n",
      "3383:\tlearn: 0.0017337\ttotal: 7m 51s\tremaining: 3m 45s\n",
      "3384:\tlearn: 0.0017333\ttotal: 7m 51s\tremaining: 3m 44s\n",
      "3385:\tlearn: 0.0017328\ttotal: 7m 51s\tremaining: 3m 44s\n",
      "3386:\tlearn: 0.0017325\ttotal: 7m 51s\tremaining: 3m 44s\n",
      "3387:\tlearn: 0.0017322\ttotal: 7m 51s\tremaining: 3m 44s\n",
      "3388:\tlearn: 0.0017316\ttotal: 7m 51s\tremaining: 3m 44s\n",
      "3389:\tlearn: 0.0017307\ttotal: 7m 51s\tremaining: 3m 44s\n",
      "3390:\tlearn: 0.0017302\ttotal: 7m 52s\tremaining: 3m 44s\n",
      "3391:\tlearn: 0.0017281\ttotal: 7m 52s\tremaining: 3m 43s\n",
      "3392:\tlearn: 0.0017275\ttotal: 7m 52s\tremaining: 3m 43s\n",
      "3393:\tlearn: 0.0017272\ttotal: 7m 52s\tremaining: 3m 43s\n",
      "3394:\tlearn: 0.0017268\ttotal: 7m 52s\tremaining: 3m 43s\n",
      "3395:\tlearn: 0.0017266\ttotal: 7m 52s\tremaining: 3m 43s\n",
      "3396:\tlearn: 0.0017266\ttotal: 7m 52s\tremaining: 3m 43s\n",
      "3397:\tlearn: 0.0017265\ttotal: 7m 52s\tremaining: 3m 42s\n",
      "3398:\tlearn: 0.0017265\ttotal: 7m 53s\tremaining: 3m 42s\n",
      "3399:\tlearn: 0.0017254\ttotal: 7m 53s\tremaining: 3m 42s\n",
      "3400:\tlearn: 0.0017250\ttotal: 7m 53s\tremaining: 3m 42s\n",
      "3401:\tlearn: 0.0017238\ttotal: 7m 53s\tremaining: 3m 42s\n",
      "3402:\tlearn: 0.0017237\ttotal: 7m 53s\tremaining: 3m 42s\n",
      "3403:\tlearn: 0.0017234\ttotal: 7m 53s\tremaining: 3m 42s\n",
      "3404:\tlearn: 0.0017230\ttotal: 7m 53s\tremaining: 3m 41s\n",
      "3405:\tlearn: 0.0017215\ttotal: 7m 53s\tremaining: 3m 41s\n",
      "3406:\tlearn: 0.0017210\ttotal: 7m 53s\tremaining: 3m 41s\n",
      "3407:\tlearn: 0.0017194\ttotal: 7m 54s\tremaining: 3m 41s\n",
      "3408:\tlearn: 0.0017192\ttotal: 7m 54s\tremaining: 3m 41s\n",
      "3409:\tlearn: 0.0017187\ttotal: 7m 54s\tremaining: 3m 41s\n",
      "3410:\tlearn: 0.0017185\ttotal: 7m 54s\tremaining: 3m 41s\n",
      "3411:\tlearn: 0.0017178\ttotal: 7m 54s\tremaining: 3m 40s\n",
      "3412:\tlearn: 0.0017177\ttotal: 7m 54s\tremaining: 3m 40s\n",
      "3413:\tlearn: 0.0017174\ttotal: 7m 54s\tremaining: 3m 40s\n",
      "3414:\tlearn: 0.0017172\ttotal: 7m 54s\tremaining: 3m 40s\n",
      "3415:\tlearn: 0.0017170\ttotal: 7m 55s\tremaining: 3m 40s\n",
      "3416:\tlearn: 0.0017168\ttotal: 7m 55s\tremaining: 3m 40s\n",
      "3417:\tlearn: 0.0017165\ttotal: 7m 55s\tremaining: 3m 39s\n",
      "3418:\tlearn: 0.0017163\ttotal: 7m 55s\tremaining: 3m 39s\n",
      "3419:\tlearn: 0.0017163\ttotal: 7m 55s\tremaining: 3m 39s\n",
      "3420:\tlearn: 0.0017154\ttotal: 7m 55s\tremaining: 3m 39s\n",
      "3421:\tlearn: 0.0017149\ttotal: 7m 55s\tremaining: 3m 39s\n",
      "3422:\tlearn: 0.0017149\ttotal: 7m 55s\tremaining: 3m 39s\n",
      "3423:\tlearn: 0.0017134\ttotal: 7m 55s\tremaining: 3m 39s\n",
      "3424:\tlearn: 0.0017131\ttotal: 7m 56s\tremaining: 3m 38s\n",
      "3425:\tlearn: 0.0017130\ttotal: 7m 56s\tremaining: 3m 38s\n",
      "3426:\tlearn: 0.0017129\ttotal: 7m 56s\tremaining: 3m 38s\n",
      "3427:\tlearn: 0.0017125\ttotal: 7m 56s\tremaining: 3m 38s\n",
      "3428:\tlearn: 0.0017111\ttotal: 7m 56s\tremaining: 3m 38s\n",
      "3429:\tlearn: 0.0017104\ttotal: 7m 56s\tremaining: 3m 38s\n",
      "3430:\tlearn: 0.0017097\ttotal: 7m 56s\tremaining: 3m 38s\n",
      "3431:\tlearn: 0.0017095\ttotal: 7m 57s\tremaining: 3m 37s\n",
      "3432:\tlearn: 0.0017092\ttotal: 7m 57s\tremaining: 3m 37s\n",
      "3433:\tlearn: 0.0017092\ttotal: 7m 57s\tremaining: 3m 37s\n",
      "3434:\tlearn: 0.0017089\ttotal: 7m 57s\tremaining: 3m 37s\n",
      "3435:\tlearn: 0.0017087\ttotal: 7m 57s\tremaining: 3m 37s\n",
      "3436:\tlearn: 0.0017085\ttotal: 7m 57s\tremaining: 3m 37s\n",
      "3437:\tlearn: 0.0017084\ttotal: 7m 57s\tremaining: 3m 37s\n",
      "3438:\tlearn: 0.0017084\ttotal: 7m 57s\tremaining: 3m 36s\n",
      "3439:\tlearn: 0.0017069\ttotal: 7m 58s\tremaining: 3m 36s\n",
      "3440:\tlearn: 0.0017068\ttotal: 7m 58s\tremaining: 3m 36s\n",
      "3441:\tlearn: 0.0017053\ttotal: 7m 58s\tremaining: 3m 36s\n",
      "3442:\tlearn: 0.0017053\ttotal: 7m 58s\tremaining: 3m 36s\n",
      "3443:\tlearn: 0.0017046\ttotal: 7m 58s\tremaining: 3m 36s\n",
      "3444:\tlearn: 0.0017021\ttotal: 7m 58s\tremaining: 3m 36s\n",
      "3445:\tlearn: 0.0017020\ttotal: 7m 59s\tremaining: 3m 36s\n",
      "3446:\tlearn: 0.0017020\ttotal: 7m 59s\tremaining: 3m 35s\n",
      "3447:\tlearn: 0.0017019\ttotal: 7m 59s\tremaining: 3m 35s\n",
      "3448:\tlearn: 0.0017012\ttotal: 7m 59s\tremaining: 3m 35s\n",
      "3449:\tlearn: 0.0017011\ttotal: 7m 59s\tremaining: 3m 35s\n",
      "3450:\tlearn: 0.0017009\ttotal: 7m 59s\tremaining: 3m 35s\n",
      "3451:\tlearn: 0.0017009\ttotal: 7m 59s\tremaining: 3m 35s\n",
      "3452:\tlearn: 0.0017008\ttotal: 8m\tremaining: 3m 35s\n",
      "3453:\tlearn: 0.0017008\ttotal: 8m\tremaining: 3m 34s\n",
      "3454:\tlearn: 0.0017004\ttotal: 8m\tremaining: 3m 34s\n",
      "3455:\tlearn: 0.0017004\ttotal: 8m\tremaining: 3m 34s\n",
      "3456:\tlearn: 0.0017002\ttotal: 8m\tremaining: 3m 34s\n",
      "3457:\tlearn: 0.0017002\ttotal: 8m\tremaining: 3m 34s\n",
      "3458:\tlearn: 0.0016998\ttotal: 8m\tremaining: 3m 34s\n",
      "3459:\tlearn: 0.0016993\ttotal: 8m\tremaining: 3m 34s\n",
      "3460:\tlearn: 0.0016993\ttotal: 8m 1s\tremaining: 3m 33s\n",
      "3461:\tlearn: 0.0016981\ttotal: 8m 1s\tremaining: 3m 33s\n",
      "3462:\tlearn: 0.0016980\ttotal: 8m 1s\tremaining: 3m 33s\n",
      "3463:\tlearn: 0.0016977\ttotal: 8m 1s\tremaining: 3m 33s\n",
      "3464:\tlearn: 0.0016945\ttotal: 8m 1s\tremaining: 3m 33s\n",
      "3465:\tlearn: 0.0016945\ttotal: 8m 1s\tremaining: 3m 33s\n",
      "3466:\tlearn: 0.0016928\ttotal: 8m 1s\tremaining: 3m 33s\n",
      "3467:\tlearn: 0.0016926\ttotal: 8m 1s\tremaining: 3m 32s\n",
      "3468:\tlearn: 0.0016896\ttotal: 8m 2s\tremaining: 3m 32s\n",
      "3469:\tlearn: 0.0016893\ttotal: 8m 2s\tremaining: 3m 32s\n",
      "3470:\tlearn: 0.0016891\ttotal: 8m 2s\tremaining: 3m 32s\n",
      "3471:\tlearn: 0.0016890\ttotal: 8m 2s\tremaining: 3m 32s\n",
      "3472:\tlearn: 0.0016888\ttotal: 8m 2s\tremaining: 3m 32s\n",
      "3473:\tlearn: 0.0016888\ttotal: 8m 2s\tremaining: 3m 32s\n",
      "3474:\tlearn: 0.0016887\ttotal: 8m 2s\tremaining: 3m 31s\n",
      "3475:\tlearn: 0.0016887\ttotal: 8m 2s\tremaining: 3m 31s\n",
      "3476:\tlearn: 0.0016887\ttotal: 8m 3s\tremaining: 3m 31s\n",
      "3477:\tlearn: 0.0016870\ttotal: 8m 3s\tremaining: 3m 31s\n",
      "3478:\tlearn: 0.0016869\ttotal: 8m 3s\tremaining: 3m 31s\n",
      "3479:\tlearn: 0.0016864\ttotal: 8m 3s\tremaining: 3m 31s\n",
      "3480:\tlearn: 0.0016864\ttotal: 8m 3s\tremaining: 3m 31s\n",
      "3481:\tlearn: 0.0016860\ttotal: 8m 3s\tremaining: 3m 30s\n",
      "3482:\tlearn: 0.0016857\ttotal: 8m 3s\tremaining: 3m 30s\n",
      "3483:\tlearn: 0.0016856\ttotal: 8m 3s\tremaining: 3m 30s\n",
      "3484:\tlearn: 0.0016852\ttotal: 8m 4s\tremaining: 3m 30s\n",
      "3485:\tlearn: 0.0016850\ttotal: 8m 4s\tremaining: 3m 30s\n",
      "3486:\tlearn: 0.0016849\ttotal: 8m 4s\tremaining: 3m 30s\n",
      "3487:\tlearn: 0.0016845\ttotal: 8m 4s\tremaining: 3m 30s\n",
      "3488:\tlearn: 0.0016842\ttotal: 8m 4s\tremaining: 3m 29s\n",
      "3489:\tlearn: 0.0016839\ttotal: 8m 4s\tremaining: 3m 29s\n",
      "3490:\tlearn: 0.0016830\ttotal: 8m 4s\tremaining: 3m 29s\n",
      "3491:\tlearn: 0.0016827\ttotal: 8m 5s\tremaining: 3m 29s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3492:\tlearn: 0.0016826\ttotal: 8m 5s\tremaining: 3m 29s\n",
      "3493:\tlearn: 0.0016823\ttotal: 8m 5s\tremaining: 3m 29s\n",
      "3494:\tlearn: 0.0016819\ttotal: 8m 5s\tremaining: 3m 29s\n",
      "3495:\tlearn: 0.0016816\ttotal: 8m 5s\tremaining: 3m 28s\n",
      "3496:\tlearn: 0.0016816\ttotal: 8m 5s\tremaining: 3m 28s\n",
      "3497:\tlearn: 0.0016811\ttotal: 8m 5s\tremaining: 3m 28s\n",
      "3498:\tlearn: 0.0016800\ttotal: 8m 5s\tremaining: 3m 28s\n",
      "3499:\tlearn: 0.0016798\ttotal: 8m 6s\tremaining: 3m 28s\n",
      "3500:\tlearn: 0.0016798\ttotal: 8m 6s\tremaining: 3m 28s\n",
      "3501:\tlearn: 0.0016797\ttotal: 8m 6s\tremaining: 3m 28s\n",
      "3502:\tlearn: 0.0016797\ttotal: 8m 6s\tremaining: 3m 27s\n",
      "3503:\tlearn: 0.0016797\ttotal: 8m 6s\tremaining: 3m 27s\n",
      "3504:\tlearn: 0.0016796\ttotal: 8m 6s\tremaining: 3m 27s\n",
      "3505:\tlearn: 0.0016796\ttotal: 8m 6s\tremaining: 3m 27s\n",
      "3506:\tlearn: 0.0016790\ttotal: 8m 7s\tremaining: 3m 27s\n",
      "3507:\tlearn: 0.0016785\ttotal: 8m 7s\tremaining: 3m 27s\n",
      "3508:\tlearn: 0.0016783\ttotal: 8m 7s\tremaining: 3m 27s\n",
      "3509:\tlearn: 0.0016783\ttotal: 8m 7s\tremaining: 3m 26s\n",
      "3510:\tlearn: 0.0016780\ttotal: 8m 7s\tremaining: 3m 26s\n",
      "3511:\tlearn: 0.0016766\ttotal: 8m 7s\tremaining: 3m 26s\n",
      "3512:\tlearn: 0.0016759\ttotal: 8m 8s\tremaining: 3m 26s\n",
      "3513:\tlearn: 0.0016756\ttotal: 8m 8s\tremaining: 3m 26s\n",
      "3514:\tlearn: 0.0016750\ttotal: 8m 8s\tremaining: 3m 26s\n",
      "3515:\tlearn: 0.0016735\ttotal: 8m 8s\tremaining: 3m 26s\n",
      "3516:\tlearn: 0.0016733\ttotal: 8m 8s\tremaining: 3m 26s\n",
      "3517:\tlearn: 0.0016733\ttotal: 8m 8s\tremaining: 3m 25s\n",
      "3518:\tlearn: 0.0016728\ttotal: 8m 8s\tremaining: 3m 25s\n",
      "3519:\tlearn: 0.0016719\ttotal: 8m 9s\tremaining: 3m 25s\n",
      "3520:\tlearn: 0.0016718\ttotal: 8m 9s\tremaining: 3m 25s\n",
      "3521:\tlearn: 0.0016718\ttotal: 8m 9s\tremaining: 3m 25s\n",
      "3522:\tlearn: 0.0016717\ttotal: 8m 9s\tremaining: 3m 25s\n",
      "3523:\tlearn: 0.0016715\ttotal: 8m 9s\tremaining: 3m 25s\n",
      "3524:\tlearn: 0.0016714\ttotal: 8m 9s\tremaining: 3m 24s\n",
      "3525:\tlearn: 0.0016710\ttotal: 8m 9s\tremaining: 3m 24s\n",
      "3526:\tlearn: 0.0016700\ttotal: 8m 9s\tremaining: 3m 24s\n",
      "3527:\tlearn: 0.0016699\ttotal: 8m 9s\tremaining: 3m 24s\n",
      "3528:\tlearn: 0.0016692\ttotal: 8m 10s\tremaining: 3m 24s\n",
      "3529:\tlearn: 0.0016692\ttotal: 8m 10s\tremaining: 3m 24s\n",
      "3530:\tlearn: 0.0016687\ttotal: 8m 10s\tremaining: 3m 24s\n",
      "3531:\tlearn: 0.0016681\ttotal: 8m 10s\tremaining: 3m 23s\n",
      "3532:\tlearn: 0.0016680\ttotal: 8m 10s\tremaining: 3m 23s\n",
      "3533:\tlearn: 0.0016671\ttotal: 8m 10s\tremaining: 3m 23s\n",
      "3534:\tlearn: 0.0016665\ttotal: 8m 11s\tremaining: 3m 23s\n",
      "3535:\tlearn: 0.0016655\ttotal: 8m 11s\tremaining: 3m 23s\n",
      "3536:\tlearn: 0.0016653\ttotal: 8m 11s\tremaining: 3m 23s\n",
      "3537:\tlearn: 0.0016652\ttotal: 8m 11s\tremaining: 3m 23s\n",
      "3538:\tlearn: 0.0016650\ttotal: 8m 11s\tremaining: 3m 22s\n",
      "3539:\tlearn: 0.0016649\ttotal: 8m 11s\tremaining: 3m 22s\n",
      "3540:\tlearn: 0.0016641\ttotal: 8m 11s\tremaining: 3m 22s\n",
      "3541:\tlearn: 0.0016633\ttotal: 8m 11s\tremaining: 3m 22s\n",
      "3542:\tlearn: 0.0016632\ttotal: 8m 11s\tremaining: 3m 22s\n",
      "3543:\tlearn: 0.0016631\ttotal: 8m 12s\tremaining: 3m 22s\n",
      "3544:\tlearn: 0.0016627\ttotal: 8m 12s\tremaining: 3m 22s\n",
      "3545:\tlearn: 0.0016626\ttotal: 8m 12s\tremaining: 3m 21s\n",
      "3546:\tlearn: 0.0016625\ttotal: 8m 12s\tremaining: 3m 21s\n",
      "3547:\tlearn: 0.0016624\ttotal: 8m 12s\tremaining: 3m 21s\n",
      "3548:\tlearn: 0.0016622\ttotal: 8m 12s\tremaining: 3m 21s\n",
      "3549:\tlearn: 0.0016622\ttotal: 8m 12s\tremaining: 3m 21s\n",
      "3550:\tlearn: 0.0016621\ttotal: 8m 12s\tremaining: 3m 21s\n",
      "3551:\tlearn: 0.0016619\ttotal: 8m 13s\tremaining: 3m 20s\n",
      "3552:\tlearn: 0.0016618\ttotal: 8m 13s\tremaining: 3m 20s\n",
      "3553:\tlearn: 0.0016617\ttotal: 8m 13s\tremaining: 3m 20s\n",
      "3554:\tlearn: 0.0016613\ttotal: 8m 13s\tremaining: 3m 20s\n",
      "3555:\tlearn: 0.0016609\ttotal: 8m 13s\tremaining: 3m 20s\n",
      "3556:\tlearn: 0.0016607\ttotal: 8m 13s\tremaining: 3m 20s\n",
      "3557:\tlearn: 0.0016606\ttotal: 8m 13s\tremaining: 3m 20s\n",
      "3558:\tlearn: 0.0016605\ttotal: 8m 13s\tremaining: 3m 19s\n",
      "3559:\tlearn: 0.0016605\ttotal: 8m 14s\tremaining: 3m 19s\n",
      "3560:\tlearn: 0.0016604\ttotal: 8m 14s\tremaining: 3m 19s\n",
      "3561:\tlearn: 0.0016600\ttotal: 8m 14s\tremaining: 3m 19s\n",
      "3562:\tlearn: 0.0016596\ttotal: 8m 14s\tremaining: 3m 19s\n",
      "3563:\tlearn: 0.0016596\ttotal: 8m 14s\tremaining: 3m 19s\n",
      "3564:\tlearn: 0.0016586\ttotal: 8m 14s\tremaining: 3m 19s\n",
      "3565:\tlearn: 0.0016584\ttotal: 8m 14s\tremaining: 3m 18s\n",
      "3566:\tlearn: 0.0016582\ttotal: 8m 14s\tremaining: 3m 18s\n",
      "3567:\tlearn: 0.0016579\ttotal: 8m 15s\tremaining: 3m 18s\n",
      "3568:\tlearn: 0.0016576\ttotal: 8m 15s\tremaining: 3m 18s\n",
      "3569:\tlearn: 0.0016576\ttotal: 8m 15s\tremaining: 3m 18s\n",
      "3570:\tlearn: 0.0016576\ttotal: 8m 15s\tremaining: 3m 18s\n",
      "3571:\tlearn: 0.0016573\ttotal: 8m 15s\tremaining: 3m 18s\n",
      "3572:\tlearn: 0.0016565\ttotal: 8m 15s\tremaining: 3m 18s\n",
      "3573:\tlearn: 0.0016561\ttotal: 8m 15s\tremaining: 3m 17s\n",
      "3574:\tlearn: 0.0016560\ttotal: 8m 16s\tremaining: 3m 17s\n",
      "3575:\tlearn: 0.0016558\ttotal: 8m 16s\tremaining: 3m 17s\n",
      "3576:\tlearn: 0.0016557\ttotal: 8m 16s\tremaining: 3m 17s\n",
      "3577:\tlearn: 0.0016552\ttotal: 8m 16s\tremaining: 3m 17s\n",
      "3578:\tlearn: 0.0016551\ttotal: 8m 16s\tremaining: 3m 17s\n",
      "3579:\tlearn: 0.0016551\ttotal: 8m 16s\tremaining: 3m 17s\n",
      "3580:\tlearn: 0.0016547\ttotal: 8m 16s\tremaining: 3m 16s\n",
      "3581:\tlearn: 0.0016547\ttotal: 8m 17s\tremaining: 3m 16s\n",
      "3582:\tlearn: 0.0016535\ttotal: 8m 17s\tremaining: 3m 16s\n",
      "3583:\tlearn: 0.0016533\ttotal: 8m 17s\tremaining: 3m 16s\n",
      "3584:\tlearn: 0.0016533\ttotal: 8m 17s\tremaining: 3m 16s\n",
      "3585:\tlearn: 0.0016531\ttotal: 8m 17s\tremaining: 3m 16s\n",
      "3586:\tlearn: 0.0016516\ttotal: 8m 17s\tremaining: 3m 16s\n",
      "3587:\tlearn: 0.0016514\ttotal: 8m 17s\tremaining: 3m 15s\n",
      "3588:\tlearn: 0.0016512\ttotal: 8m 18s\tremaining: 3m 15s\n",
      "3589:\tlearn: 0.0016512\ttotal: 8m 18s\tremaining: 3m 15s\n",
      "3590:\tlearn: 0.0016506\ttotal: 8m 18s\tremaining: 3m 15s\n",
      "3591:\tlearn: 0.0016506\ttotal: 8m 18s\tremaining: 3m 15s\n",
      "3592:\tlearn: 0.0016504\ttotal: 8m 18s\tremaining: 3m 15s\n",
      "3593:\tlearn: 0.0016504\ttotal: 8m 18s\tremaining: 3m 15s\n",
      "3594:\tlearn: 0.0016504\ttotal: 8m 18s\tremaining: 3m 15s\n",
      "3595:\tlearn: 0.0016501\ttotal: 8m 19s\tremaining: 3m 14s\n",
      "3596:\tlearn: 0.0016501\ttotal: 8m 19s\tremaining: 3m 14s\n",
      "3597:\tlearn: 0.0016498\ttotal: 8m 19s\tremaining: 3m 14s\n",
      "3598:\tlearn: 0.0016497\ttotal: 8m 19s\tremaining: 3m 14s\n",
      "3599:\tlearn: 0.0016496\ttotal: 8m 19s\tremaining: 3m 14s\n",
      "3600:\tlearn: 0.0016495\ttotal: 8m 19s\tremaining: 3m 14s\n",
      "3601:\tlearn: 0.0016488\ttotal: 8m 20s\tremaining: 3m 14s\n",
      "3602:\tlearn: 0.0016488\ttotal: 8m 20s\tremaining: 3m 13s\n",
      "3603:\tlearn: 0.0016487\ttotal: 8m 20s\tremaining: 3m 13s\n",
      "3604:\tlearn: 0.0016482\ttotal: 8m 20s\tremaining: 3m 13s\n",
      "3605:\tlearn: 0.0016470\ttotal: 8m 20s\tremaining: 3m 13s\n",
      "3606:\tlearn: 0.0016469\ttotal: 8m 20s\tremaining: 3m 13s\n",
      "3607:\tlearn: 0.0016466\ttotal: 8m 20s\tremaining: 3m 13s\n",
      "3608:\tlearn: 0.0016465\ttotal: 8m 21s\tremaining: 3m 13s\n",
      "3609:\tlearn: 0.0016462\ttotal: 8m 21s\tremaining: 3m 13s\n",
      "3610:\tlearn: 0.0016458\ttotal: 8m 21s\tremaining: 3m 12s\n",
      "3611:\tlearn: 0.0016451\ttotal: 8m 21s\tremaining: 3m 12s\n",
      "3612:\tlearn: 0.0016438\ttotal: 8m 21s\tremaining: 3m 12s\n",
      "3613:\tlearn: 0.0016437\ttotal: 8m 21s\tremaining: 3m 12s\n",
      "3614:\tlearn: 0.0016436\ttotal: 8m 21s\tremaining: 3m 12s\n",
      "3615:\tlearn: 0.0016434\ttotal: 8m 22s\tremaining: 3m 12s\n",
      "3616:\tlearn: 0.0016433\ttotal: 8m 22s\tremaining: 3m 12s\n",
      "3617:\tlearn: 0.0016432\ttotal: 8m 22s\tremaining: 3m 11s\n",
      "3618:\tlearn: 0.0016428\ttotal: 8m 22s\tremaining: 3m 11s\n",
      "3619:\tlearn: 0.0016424\ttotal: 8m 22s\tremaining: 3m 11s\n",
      "3620:\tlearn: 0.0016423\ttotal: 8m 22s\tremaining: 3m 11s\n",
      "3621:\tlearn: 0.0016421\ttotal: 8m 22s\tremaining: 3m 11s\n",
      "3622:\tlearn: 0.0016420\ttotal: 8m 22s\tremaining: 3m 11s\n",
      "3623:\tlearn: 0.0016416\ttotal: 8m 23s\tremaining: 3m 10s\n",
      "3624:\tlearn: 0.0016415\ttotal: 8m 23s\tremaining: 3m 10s\n",
      "3625:\tlearn: 0.0016411\ttotal: 8m 23s\tremaining: 3m 10s\n",
      "3626:\tlearn: 0.0016411\ttotal: 8m 23s\tremaining: 3m 10s\n",
      "3627:\tlearn: 0.0016402\ttotal: 8m 23s\tremaining: 3m 10s\n",
      "3628:\tlearn: 0.0016399\ttotal: 8m 23s\tremaining: 3m 10s\n",
      "3629:\tlearn: 0.0016399\ttotal: 8m 23s\tremaining: 3m 10s\n",
      "3630:\tlearn: 0.0016398\ttotal: 8m 23s\tremaining: 3m 9s\n",
      "3631:\tlearn: 0.0016398\ttotal: 8m 24s\tremaining: 3m 9s\n",
      "3632:\tlearn: 0.0016397\ttotal: 8m 24s\tremaining: 3m 9s\n",
      "3633:\tlearn: 0.0016397\ttotal: 8m 24s\tremaining: 3m 9s\n",
      "3634:\tlearn: 0.0016396\ttotal: 8m 24s\tremaining: 3m 9s\n",
      "3635:\tlearn: 0.0016396\ttotal: 8m 24s\tremaining: 3m 9s\n",
      "3636:\tlearn: 0.0016392\ttotal: 8m 24s\tremaining: 3m 9s\n",
      "3637:\tlearn: 0.0016390\ttotal: 8m 24s\tremaining: 3m 9s\n",
      "3638:\tlearn: 0.0016386\ttotal: 8m 24s\tremaining: 3m 8s\n",
      "3639:\tlearn: 0.0016386\ttotal: 8m 25s\tremaining: 3m 8s\n",
      "3640:\tlearn: 0.0016374\ttotal: 8m 25s\tremaining: 3m 8s\n",
      "3641:\tlearn: 0.0016351\ttotal: 8m 25s\tremaining: 3m 8s\n",
      "3642:\tlearn: 0.0016342\ttotal: 8m 25s\tremaining: 3m 8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3643:\tlearn: 0.0016329\ttotal: 8m 25s\tremaining: 3m 8s\n",
      "3644:\tlearn: 0.0016329\ttotal: 8m 25s\tremaining: 3m 8s\n",
      "3645:\tlearn: 0.0016317\ttotal: 8m 25s\tremaining: 3m 7s\n",
      "3646:\tlearn: 0.0016315\ttotal: 8m 26s\tremaining: 3m 7s\n",
      "3647:\tlearn: 0.0016315\ttotal: 8m 26s\tremaining: 3m 7s\n",
      "3648:\tlearn: 0.0016312\ttotal: 8m 26s\tremaining: 3m 7s\n",
      "3649:\tlearn: 0.0016304\ttotal: 8m 26s\tremaining: 3m 7s\n",
      "3650:\tlearn: 0.0016304\ttotal: 8m 26s\tremaining: 3m 7s\n",
      "3651:\tlearn: 0.0016298\ttotal: 8m 26s\tremaining: 3m 7s\n",
      "3652:\tlearn: 0.0016297\ttotal: 8m 26s\tremaining: 3m 6s\n",
      "3653:\tlearn: 0.0016295\ttotal: 8m 26s\tremaining: 3m 6s\n",
      "3654:\tlearn: 0.0016294\ttotal: 8m 27s\tremaining: 3m 6s\n",
      "3655:\tlearn: 0.0016294\ttotal: 8m 27s\tremaining: 3m 6s\n",
      "3656:\tlearn: 0.0016294\ttotal: 8m 27s\tremaining: 3m 6s\n",
      "3657:\tlearn: 0.0016293\ttotal: 8m 27s\tremaining: 3m 6s\n",
      "3658:\tlearn: 0.0016291\ttotal: 8m 27s\tremaining: 3m 6s\n",
      "3659:\tlearn: 0.0016283\ttotal: 8m 27s\tremaining: 3m 5s\n",
      "3660:\tlearn: 0.0016275\ttotal: 8m 28s\tremaining: 3m 5s\n",
      "3661:\tlearn: 0.0016274\ttotal: 8m 28s\tremaining: 3m 5s\n",
      "3662:\tlearn: 0.0016262\ttotal: 8m 28s\tremaining: 3m 5s\n",
      "3663:\tlearn: 0.0016258\ttotal: 8m 28s\tremaining: 3m 5s\n",
      "3664:\tlearn: 0.0016257\ttotal: 8m 28s\tremaining: 3m 5s\n",
      "3665:\tlearn: 0.0016250\ttotal: 8m 28s\tremaining: 3m 5s\n",
      "3666:\tlearn: 0.0016248\ttotal: 8m 28s\tremaining: 3m 4s\n",
      "3667:\tlearn: 0.0016248\ttotal: 8m 28s\tremaining: 3m 4s\n",
      "3668:\tlearn: 0.0016246\ttotal: 8m 29s\tremaining: 3m 4s\n",
      "3669:\tlearn: 0.0016244\ttotal: 8m 29s\tremaining: 3m 4s\n",
      "3670:\tlearn: 0.0016234\ttotal: 8m 29s\tremaining: 3m 4s\n",
      "3671:\tlearn: 0.0016233\ttotal: 8m 29s\tremaining: 3m 4s\n",
      "3672:\tlearn: 0.0016233\ttotal: 8m 29s\tremaining: 3m 4s\n",
      "3673:\tlearn: 0.0016233\ttotal: 8m 29s\tremaining: 3m 3s\n",
      "3674:\tlearn: 0.0016232\ttotal: 8m 29s\tremaining: 3m 3s\n",
      "3675:\tlearn: 0.0016230\ttotal: 8m 30s\tremaining: 3m 3s\n",
      "3676:\tlearn: 0.0016217\ttotal: 8m 30s\tremaining: 3m 3s\n",
      "3677:\tlearn: 0.0016216\ttotal: 8m 30s\tremaining: 3m 3s\n",
      "3678:\tlearn: 0.0016215\ttotal: 8m 30s\tremaining: 3m 3s\n",
      "3679:\tlearn: 0.0016215\ttotal: 8m 30s\tremaining: 3m 3s\n",
      "3680:\tlearn: 0.0016214\ttotal: 8m 30s\tremaining: 3m 2s\n",
      "3681:\tlearn: 0.0016214\ttotal: 8m 30s\tremaining: 3m 2s\n",
      "3682:\tlearn: 0.0016209\ttotal: 8m 30s\tremaining: 3m 2s\n",
      "3683:\tlearn: 0.0016204\ttotal: 8m 30s\tremaining: 3m 2s\n",
      "3684:\tlearn: 0.0016204\ttotal: 8m 31s\tremaining: 3m 2s\n",
      "3685:\tlearn: 0.0016192\ttotal: 8m 31s\tremaining: 3m 2s\n",
      "3686:\tlearn: 0.0016177\ttotal: 8m 31s\tremaining: 3m 2s\n",
      "3687:\tlearn: 0.0016176\ttotal: 8m 31s\tremaining: 3m 1s\n",
      "3688:\tlearn: 0.0016175\ttotal: 8m 31s\tremaining: 3m 1s\n",
      "3689:\tlearn: 0.0016172\ttotal: 8m 31s\tremaining: 3m 1s\n",
      "3690:\tlearn: 0.0016168\ttotal: 8m 31s\tremaining: 3m 1s\n",
      "3691:\tlearn: 0.0016165\ttotal: 8m 31s\tremaining: 3m 1s\n",
      "3692:\tlearn: 0.0016161\ttotal: 8m 31s\tremaining: 3m 1s\n",
      "3693:\tlearn: 0.0016155\ttotal: 8m 32s\tremaining: 3m 1s\n",
      "3694:\tlearn: 0.0016154\ttotal: 8m 32s\tremaining: 3m\n",
      "3695:\tlearn: 0.0016154\ttotal: 8m 32s\tremaining: 3m\n",
      "3696:\tlearn: 0.0016150\ttotal: 8m 32s\tremaining: 3m\n",
      "3697:\tlearn: 0.0016149\ttotal: 8m 32s\tremaining: 3m\n",
      "3698:\tlearn: 0.0016147\ttotal: 8m 32s\tremaining: 3m\n",
      "3699:\tlearn: 0.0016142\ttotal: 8m 32s\tremaining: 3m\n",
      "3700:\tlearn: 0.0016141\ttotal: 8m 33s\tremaining: 3m\n",
      "3701:\tlearn: 0.0016139\ttotal: 8m 33s\tremaining: 2m 59s\n",
      "3702:\tlearn: 0.0016117\ttotal: 8m 33s\tremaining: 2m 59s\n",
      "3703:\tlearn: 0.0016116\ttotal: 8m 33s\tremaining: 2m 59s\n",
      "3704:\tlearn: 0.0016115\ttotal: 8m 33s\tremaining: 2m 59s\n",
      "3705:\tlearn: 0.0016115\ttotal: 8m 33s\tremaining: 2m 59s\n",
      "3706:\tlearn: 0.0016114\ttotal: 8m 33s\tremaining: 2m 59s\n",
      "3707:\tlearn: 0.0016110\ttotal: 8m 34s\tremaining: 2m 59s\n",
      "3708:\tlearn: 0.0016105\ttotal: 8m 34s\tremaining: 2m 59s\n",
      "3709:\tlearn: 0.0016089\ttotal: 8m 34s\tremaining: 2m 58s\n",
      "3710:\tlearn: 0.0016084\ttotal: 8m 34s\tremaining: 2m 58s\n",
      "3711:\tlearn: 0.0016083\ttotal: 8m 34s\tremaining: 2m 58s\n",
      "3712:\tlearn: 0.0016081\ttotal: 8m 34s\tremaining: 2m 58s\n",
      "3713:\tlearn: 0.0016076\ttotal: 8m 34s\tremaining: 2m 58s\n",
      "3714:\tlearn: 0.0016076\ttotal: 8m 35s\tremaining: 2m 58s\n",
      "3715:\tlearn: 0.0016076\ttotal: 8m 35s\tremaining: 2m 58s\n",
      "3716:\tlearn: 0.0016071\ttotal: 8m 35s\tremaining: 2m 57s\n",
      "3717:\tlearn: 0.0016070\ttotal: 8m 35s\tremaining: 2m 57s\n",
      "3718:\tlearn: 0.0016070\ttotal: 8m 35s\tremaining: 2m 57s\n",
      "3719:\tlearn: 0.0016070\ttotal: 8m 35s\tremaining: 2m 57s\n",
      "3720:\tlearn: 0.0016066\ttotal: 8m 35s\tremaining: 2m 57s\n",
      "3721:\tlearn: 0.0016061\ttotal: 8m 36s\tremaining: 2m 57s\n",
      "3722:\tlearn: 0.0016050\ttotal: 8m 36s\tremaining: 2m 57s\n",
      "3723:\tlearn: 0.0016048\ttotal: 8m 36s\tremaining: 2m 56s\n",
      "3724:\tlearn: 0.0016047\ttotal: 8m 36s\tremaining: 2m 56s\n",
      "3725:\tlearn: 0.0016044\ttotal: 8m 36s\tremaining: 2m 56s\n",
      "3726:\tlearn: 0.0016041\ttotal: 8m 37s\tremaining: 2m 56s\n",
      "3727:\tlearn: 0.0016030\ttotal: 8m 37s\tremaining: 2m 56s\n",
      "3728:\tlearn: 0.0016029\ttotal: 8m 37s\tremaining: 2m 56s\n",
      "3729:\tlearn: 0.0016028\ttotal: 8m 37s\tremaining: 2m 56s\n",
      "3730:\tlearn: 0.0016026\ttotal: 8m 37s\tremaining: 2m 56s\n",
      "3731:\tlearn: 0.0016018\ttotal: 8m 37s\tremaining: 2m 55s\n",
      "3732:\tlearn: 0.0016016\ttotal: 8m 37s\tremaining: 2m 55s\n",
      "3733:\tlearn: 0.0016011\ttotal: 8m 38s\tremaining: 2m 55s\n",
      "3734:\tlearn: 0.0016005\ttotal: 8m 38s\tremaining: 2m 55s\n",
      "3735:\tlearn: 0.0016000\ttotal: 8m 38s\tremaining: 2m 55s\n",
      "3736:\tlearn: 0.0015998\ttotal: 8m 38s\tremaining: 2m 55s\n",
      "3737:\tlearn: 0.0015998\ttotal: 8m 38s\tremaining: 2m 55s\n",
      "3738:\tlearn: 0.0015997\ttotal: 8m 38s\tremaining: 2m 54s\n",
      "3739:\tlearn: 0.0015997\ttotal: 8m 38s\tremaining: 2m 54s\n",
      "3740:\tlearn: 0.0015996\ttotal: 8m 38s\tremaining: 2m 54s\n",
      "3741:\tlearn: 0.0015989\ttotal: 8m 39s\tremaining: 2m 54s\n",
      "3742:\tlearn: 0.0015989\ttotal: 8m 39s\tremaining: 2m 54s\n",
      "3743:\tlearn: 0.0015988\ttotal: 8m 39s\tremaining: 2m 54s\n",
      "3744:\tlearn: 0.0015987\ttotal: 8m 39s\tremaining: 2m 54s\n",
      "3745:\tlearn: 0.0015986\ttotal: 8m 39s\tremaining: 2m 53s\n",
      "3746:\tlearn: 0.0015984\ttotal: 8m 39s\tremaining: 2m 53s\n",
      "3747:\tlearn: 0.0015982\ttotal: 8m 40s\tremaining: 2m 53s\n",
      "3748:\tlearn: 0.0015980\ttotal: 8m 40s\tremaining: 2m 53s\n",
      "3749:\tlearn: 0.0015976\ttotal: 8m 40s\tremaining: 2m 53s\n",
      "3750:\tlearn: 0.0015974\ttotal: 8m 40s\tremaining: 2m 53s\n",
      "3751:\tlearn: 0.0015973\ttotal: 8m 40s\tremaining: 2m 53s\n",
      "3752:\tlearn: 0.0015972\ttotal: 8m 41s\tremaining: 2m 53s\n",
      "3753:\tlearn: 0.0015971\ttotal: 8m 41s\tremaining: 2m 53s\n",
      "3754:\tlearn: 0.0015971\ttotal: 8m 41s\tremaining: 2m 52s\n",
      "3755:\tlearn: 0.0015967\ttotal: 8m 41s\tremaining: 2m 52s\n",
      "3756:\tlearn: 0.0015967\ttotal: 8m 41s\tremaining: 2m 52s\n",
      "3757:\tlearn: 0.0015966\ttotal: 8m 41s\tremaining: 2m 52s\n",
      "3758:\tlearn: 0.0015964\ttotal: 8m 42s\tremaining: 2m 52s\n",
      "3759:\tlearn: 0.0015959\ttotal: 8m 42s\tremaining: 2m 52s\n",
      "3760:\tlearn: 0.0015957\ttotal: 8m 42s\tremaining: 2m 52s\n",
      "3761:\tlearn: 0.0015957\ttotal: 8m 42s\tremaining: 2m 51s\n",
      "3762:\tlearn: 0.0015945\ttotal: 8m 42s\tremaining: 2m 51s\n",
      "3763:\tlearn: 0.0015945\ttotal: 8m 42s\tremaining: 2m 51s\n",
      "3764:\tlearn: 0.0015941\ttotal: 8m 42s\tremaining: 2m 51s\n",
      "3765:\tlearn: 0.0015939\ttotal: 8m 42s\tremaining: 2m 51s\n",
      "3766:\tlearn: 0.0015938\ttotal: 8m 43s\tremaining: 2m 51s\n",
      "3767:\tlearn: 0.0015916\ttotal: 8m 43s\tremaining: 2m 51s\n",
      "3768:\tlearn: 0.0015914\ttotal: 8m 43s\tremaining: 2m 50s\n",
      "3769:\tlearn: 0.0015914\ttotal: 8m 43s\tremaining: 2m 50s\n",
      "3770:\tlearn: 0.0015909\ttotal: 8m 43s\tremaining: 2m 50s\n",
      "3771:\tlearn: 0.0015909\ttotal: 8m 43s\tremaining: 2m 50s\n",
      "3772:\tlearn: 0.0015906\ttotal: 8m 44s\tremaining: 2m 50s\n",
      "3773:\tlearn: 0.0015903\ttotal: 8m 44s\tremaining: 2m 50s\n",
      "3774:\tlearn: 0.0015899\ttotal: 8m 44s\tremaining: 2m 50s\n",
      "3775:\tlearn: 0.0015887\ttotal: 8m 44s\tremaining: 2m 49s\n",
      "3776:\tlearn: 0.0015887\ttotal: 8m 44s\tremaining: 2m 49s\n",
      "3777:\tlearn: 0.0015885\ttotal: 8m 44s\tremaining: 2m 49s\n",
      "3778:\tlearn: 0.0015879\ttotal: 8m 44s\tremaining: 2m 49s\n",
      "3779:\tlearn: 0.0015879\ttotal: 8m 45s\tremaining: 2m 49s\n",
      "3780:\tlearn: 0.0015879\ttotal: 8m 45s\tremaining: 2m 49s\n",
      "3781:\tlearn: 0.0015879\ttotal: 8m 45s\tremaining: 2m 49s\n",
      "3782:\tlearn: 0.0015878\ttotal: 8m 45s\tremaining: 2m 49s\n",
      "3783:\tlearn: 0.0015865\ttotal: 8m 45s\tremaining: 2m 48s\n",
      "3784:\tlearn: 0.0015861\ttotal: 8m 45s\tremaining: 2m 48s\n",
      "3785:\tlearn: 0.0015858\ttotal: 8m 45s\tremaining: 2m 48s\n",
      "3786:\tlearn: 0.0015857\ttotal: 8m 46s\tremaining: 2m 48s\n",
      "3787:\tlearn: 0.0015856\ttotal: 8m 46s\tremaining: 2m 48s\n",
      "3788:\tlearn: 0.0015850\ttotal: 8m 46s\tremaining: 2m 48s\n",
      "3789:\tlearn: 0.0015849\ttotal: 8m 46s\tremaining: 2m 48s\n",
      "3790:\tlearn: 0.0015848\ttotal: 8m 46s\tremaining: 2m 47s\n",
      "3791:\tlearn: 0.0015847\ttotal: 8m 46s\tremaining: 2m 47s\n",
      "3792:\tlearn: 0.0015842\ttotal: 8m 47s\tremaining: 2m 47s\n",
      "3793:\tlearn: 0.0015842\ttotal: 8m 47s\tremaining: 2m 47s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3794:\tlearn: 0.0015842\ttotal: 8m 47s\tremaining: 2m 47s\n",
      "3795:\tlearn: 0.0015842\ttotal: 8m 47s\tremaining: 2m 47s\n",
      "3796:\tlearn: 0.0015840\ttotal: 8m 47s\tremaining: 2m 47s\n",
      "3797:\tlearn: 0.0015838\ttotal: 8m 47s\tremaining: 2m 47s\n",
      "3798:\tlearn: 0.0015833\ttotal: 8m 48s\tremaining: 2m 46s\n",
      "3799:\tlearn: 0.0015822\ttotal: 8m 48s\tremaining: 2m 46s\n",
      "3800:\tlearn: 0.0015820\ttotal: 8m 48s\tremaining: 2m 46s\n",
      "3801:\tlearn: 0.0015818\ttotal: 8m 48s\tremaining: 2m 46s\n",
      "3802:\tlearn: 0.0015815\ttotal: 8m 48s\tremaining: 2m 46s\n",
      "3803:\tlearn: 0.0015815\ttotal: 8m 48s\tremaining: 2m 46s\n",
      "3804:\tlearn: 0.0015809\ttotal: 8m 48s\tremaining: 2m 46s\n",
      "3805:\tlearn: 0.0015804\ttotal: 8m 48s\tremaining: 2m 45s\n",
      "3806:\tlearn: 0.0015795\ttotal: 8m 49s\tremaining: 2m 45s\n",
      "3807:\tlearn: 0.0015794\ttotal: 8m 49s\tremaining: 2m 45s\n",
      "3808:\tlearn: 0.0015793\ttotal: 8m 49s\tremaining: 2m 45s\n",
      "3809:\tlearn: 0.0015793\ttotal: 8m 49s\tremaining: 2m 45s\n",
      "3810:\tlearn: 0.0015792\ttotal: 8m 49s\tremaining: 2m 45s\n",
      "3811:\tlearn: 0.0015791\ttotal: 8m 49s\tremaining: 2m 45s\n",
      "3812:\tlearn: 0.0015788\ttotal: 8m 50s\tremaining: 2m 45s\n",
      "3813:\tlearn: 0.0015783\ttotal: 8m 50s\tremaining: 2m 44s\n",
      "3814:\tlearn: 0.0015782\ttotal: 8m 50s\tremaining: 2m 44s\n",
      "3815:\tlearn: 0.0015779\ttotal: 8m 50s\tremaining: 2m 44s\n",
      "3816:\tlearn: 0.0015773\ttotal: 8m 50s\tremaining: 2m 44s\n",
      "3817:\tlearn: 0.0015770\ttotal: 8m 50s\tremaining: 2m 44s\n",
      "3818:\tlearn: 0.0015769\ttotal: 8m 50s\tremaining: 2m 44s\n",
      "3819:\tlearn: 0.0015768\ttotal: 8m 51s\tremaining: 2m 44s\n",
      "3820:\tlearn: 0.0015744\ttotal: 8m 51s\tremaining: 2m 43s\n",
      "3821:\tlearn: 0.0015740\ttotal: 8m 51s\tremaining: 2m 43s\n",
      "3822:\tlearn: 0.0015740\ttotal: 8m 51s\tremaining: 2m 43s\n",
      "3823:\tlearn: 0.0015736\ttotal: 8m 51s\tremaining: 2m 43s\n",
      "3824:\tlearn: 0.0015736\ttotal: 8m 51s\tremaining: 2m 43s\n",
      "3825:\tlearn: 0.0015729\ttotal: 8m 51s\tremaining: 2m 43s\n",
      "3826:\tlearn: 0.0015729\ttotal: 8m 52s\tremaining: 2m 43s\n",
      "3827:\tlearn: 0.0015729\ttotal: 8m 52s\tremaining: 2m 42s\n",
      "3828:\tlearn: 0.0015728\ttotal: 8m 52s\tremaining: 2m 42s\n",
      "3829:\tlearn: 0.0015718\ttotal: 8m 52s\tremaining: 2m 42s\n",
      "3830:\tlearn: 0.0015718\ttotal: 8m 52s\tremaining: 2m 42s\n",
      "3831:\tlearn: 0.0015718\ttotal: 8m 52s\tremaining: 2m 42s\n",
      "3832:\tlearn: 0.0015713\ttotal: 8m 52s\tremaining: 2m 42s\n",
      "3833:\tlearn: 0.0015710\ttotal: 8m 52s\tremaining: 2m 42s\n",
      "3834:\tlearn: 0.0015709\ttotal: 8m 53s\tremaining: 2m 41s\n",
      "3835:\tlearn: 0.0015709\ttotal: 8m 53s\tremaining: 2m 41s\n",
      "3836:\tlearn: 0.0015708\ttotal: 8m 53s\tremaining: 2m 41s\n",
      "3837:\tlearn: 0.0015706\ttotal: 8m 53s\tremaining: 2m 41s\n",
      "3838:\tlearn: 0.0015706\ttotal: 8m 53s\tremaining: 2m 41s\n",
      "3839:\tlearn: 0.0015705\ttotal: 8m 53s\tremaining: 2m 41s\n",
      "3840:\tlearn: 0.0015697\ttotal: 8m 53s\tremaining: 2m 41s\n",
      "3841:\tlearn: 0.0015694\ttotal: 8m 53s\tremaining: 2m 40s\n",
      "3842:\tlearn: 0.0015694\ttotal: 8m 53s\tremaining: 2m 40s\n",
      "3843:\tlearn: 0.0015692\ttotal: 8m 54s\tremaining: 2m 40s\n",
      "3844:\tlearn: 0.0015692\ttotal: 8m 54s\tremaining: 2m 40s\n",
      "3845:\tlearn: 0.0015690\ttotal: 8m 54s\tremaining: 2m 40s\n",
      "3846:\tlearn: 0.0015690\ttotal: 8m 54s\tremaining: 2m 40s\n",
      "3847:\tlearn: 0.0015689\ttotal: 8m 54s\tremaining: 2m 40s\n",
      "3848:\tlearn: 0.0015685\ttotal: 8m 54s\tremaining: 2m 39s\n",
      "3849:\tlearn: 0.0015683\ttotal: 8m 54s\tremaining: 2m 39s\n",
      "3850:\tlearn: 0.0015683\ttotal: 8m 54s\tremaining: 2m 39s\n",
      "3851:\tlearn: 0.0015683\ttotal: 8m 54s\tremaining: 2m 39s\n",
      "3852:\tlearn: 0.0015682\ttotal: 8m 55s\tremaining: 2m 39s\n",
      "3853:\tlearn: 0.0015682\ttotal: 8m 55s\tremaining: 2m 39s\n",
      "3854:\tlearn: 0.0015679\ttotal: 8m 55s\tremaining: 2m 39s\n",
      "3855:\tlearn: 0.0015678\ttotal: 8m 55s\tremaining: 2m 38s\n",
      "3856:\tlearn: 0.0015677\ttotal: 8m 55s\tremaining: 2m 38s\n",
      "3857:\tlearn: 0.0015673\ttotal: 8m 55s\tremaining: 2m 38s\n",
      "3858:\tlearn: 0.0015672\ttotal: 8m 55s\tremaining: 2m 38s\n",
      "3859:\tlearn: 0.0015670\ttotal: 8m 56s\tremaining: 2m 38s\n",
      "3860:\tlearn: 0.0015667\ttotal: 8m 56s\tremaining: 2m 38s\n",
      "3861:\tlearn: 0.0015666\ttotal: 8m 56s\tremaining: 2m 38s\n",
      "3862:\tlearn: 0.0015665\ttotal: 8m 56s\tremaining: 2m 37s\n",
      "3863:\tlearn: 0.0015656\ttotal: 8m 56s\tremaining: 2m 37s\n",
      "3864:\tlearn: 0.0015655\ttotal: 8m 56s\tremaining: 2m 37s\n",
      "3865:\tlearn: 0.0015625\ttotal: 8m 56s\tremaining: 2m 37s\n",
      "3866:\tlearn: 0.0015624\ttotal: 8m 57s\tremaining: 2m 37s\n",
      "3867:\tlearn: 0.0015623\ttotal: 8m 57s\tremaining: 2m 37s\n",
      "3868:\tlearn: 0.0015603\ttotal: 8m 57s\tremaining: 2m 37s\n",
      "3869:\tlearn: 0.0015597\ttotal: 8m 57s\tremaining: 2m 36s\n",
      "3870:\tlearn: 0.0015596\ttotal: 8m 57s\tremaining: 2m 36s\n",
      "3871:\tlearn: 0.0015595\ttotal: 8m 57s\tremaining: 2m 36s\n",
      "3872:\tlearn: 0.0015591\ttotal: 8m 57s\tremaining: 2m 36s\n",
      "3873:\tlearn: 0.0015584\ttotal: 8m 57s\tremaining: 2m 36s\n",
      "3874:\tlearn: 0.0015584\ttotal: 8m 58s\tremaining: 2m 36s\n",
      "3875:\tlearn: 0.0015583\ttotal: 8m 58s\tremaining: 2m 36s\n",
      "3876:\tlearn: 0.0015572\ttotal: 8m 58s\tremaining: 2m 36s\n",
      "3877:\tlearn: 0.0015571\ttotal: 8m 58s\tremaining: 2m 35s\n",
      "3878:\tlearn: 0.0015570\ttotal: 8m 58s\tremaining: 2m 35s\n",
      "3879:\tlearn: 0.0015564\ttotal: 8m 59s\tremaining: 2m 35s\n",
      "3880:\tlearn: 0.0015562\ttotal: 8m 59s\tremaining: 2m 35s\n",
      "3881:\tlearn: 0.0015562\ttotal: 8m 59s\tremaining: 2m 35s\n",
      "3882:\tlearn: 0.0015558\ttotal: 8m 59s\tremaining: 2m 35s\n",
      "3883:\tlearn: 0.0015553\ttotal: 8m 59s\tremaining: 2m 35s\n",
      "3884:\tlearn: 0.0015545\ttotal: 8m 59s\tremaining: 2m 34s\n",
      "3885:\tlearn: 0.0015545\ttotal: 8m 59s\tremaining: 2m 34s\n",
      "3886:\tlearn: 0.0015544\ttotal: 9m\tremaining: 2m 34s\n",
      "3887:\tlearn: 0.0015542\ttotal: 9m\tremaining: 2m 34s\n",
      "3888:\tlearn: 0.0015541\ttotal: 9m\tremaining: 2m 34s\n",
      "3889:\tlearn: 0.0015533\ttotal: 9m\tremaining: 2m 34s\n",
      "3890:\tlearn: 0.0015533\ttotal: 9m\tremaining: 2m 34s\n",
      "3891:\tlearn: 0.0015531\ttotal: 9m\tremaining: 2m 33s\n",
      "3892:\tlearn: 0.0015530\ttotal: 9m\tremaining: 2m 33s\n",
      "3893:\tlearn: 0.0015529\ttotal: 9m 1s\tremaining: 2m 33s\n",
      "3894:\tlearn: 0.0015527\ttotal: 9m 1s\tremaining: 2m 33s\n",
      "3895:\tlearn: 0.0015526\ttotal: 9m 1s\tremaining: 2m 33s\n",
      "3896:\tlearn: 0.0015523\ttotal: 9m 1s\tremaining: 2m 33s\n",
      "3897:\tlearn: 0.0015520\ttotal: 9m 1s\tremaining: 2m 33s\n",
      "3898:\tlearn: 0.0015517\ttotal: 9m 1s\tremaining: 2m 33s\n",
      "3899:\tlearn: 0.0015517\ttotal: 9m 2s\tremaining: 2m 32s\n",
      "3900:\tlearn: 0.0015517\ttotal: 9m 2s\tremaining: 2m 32s\n",
      "3901:\tlearn: 0.0015514\ttotal: 9m 2s\tremaining: 2m 32s\n",
      "3902:\tlearn: 0.0015472\ttotal: 9m 2s\tremaining: 2m 32s\n",
      "3903:\tlearn: 0.0015471\ttotal: 9m 2s\tremaining: 2m 32s\n",
      "3904:\tlearn: 0.0015468\ttotal: 9m 2s\tremaining: 2m 32s\n",
      "3905:\tlearn: 0.0015467\ttotal: 9m 2s\tremaining: 2m 32s\n",
      "3906:\tlearn: 0.0015451\ttotal: 9m 3s\tremaining: 2m 31s\n",
      "3907:\tlearn: 0.0015451\ttotal: 9m 3s\tremaining: 2m 31s\n",
      "3908:\tlearn: 0.0015443\ttotal: 9m 3s\tremaining: 2m 31s\n",
      "3909:\tlearn: 0.0015434\ttotal: 9m 3s\tremaining: 2m 31s\n",
      "3910:\tlearn: 0.0015428\ttotal: 9m 3s\tremaining: 2m 31s\n",
      "3911:\tlearn: 0.0015427\ttotal: 9m 3s\tremaining: 2m 31s\n",
      "3912:\tlearn: 0.0015426\ttotal: 9m 4s\tremaining: 2m 31s\n",
      "3913:\tlearn: 0.0015424\ttotal: 9m 4s\tremaining: 2m 31s\n",
      "3914:\tlearn: 0.0015423\ttotal: 9m 4s\tremaining: 2m 30s\n",
      "3915:\tlearn: 0.0015423\ttotal: 9m 4s\tremaining: 2m 30s\n",
      "3916:\tlearn: 0.0015406\ttotal: 9m 4s\tremaining: 2m 30s\n",
      "3917:\tlearn: 0.0015406\ttotal: 9m 4s\tremaining: 2m 30s\n",
      "3918:\tlearn: 0.0015401\ttotal: 9m 5s\tremaining: 2m 30s\n",
      "3919:\tlearn: 0.0015399\ttotal: 9m 5s\tremaining: 2m 30s\n",
      "3920:\tlearn: 0.0015398\ttotal: 9m 5s\tremaining: 2m 30s\n",
      "3921:\tlearn: 0.0015398\ttotal: 9m 5s\tremaining: 2m 29s\n",
      "3922:\tlearn: 0.0015397\ttotal: 9m 5s\tremaining: 2m 29s\n",
      "3923:\tlearn: 0.0015397\ttotal: 9m 5s\tremaining: 2m 29s\n",
      "3924:\tlearn: 0.0015397\ttotal: 9m 5s\tremaining: 2m 29s\n",
      "3925:\tlearn: 0.0015393\ttotal: 9m 6s\tremaining: 2m 29s\n",
      "3926:\tlearn: 0.0015389\ttotal: 9m 6s\tremaining: 2m 29s\n",
      "3927:\tlearn: 0.0015388\ttotal: 9m 6s\tremaining: 2m 29s\n",
      "3928:\tlearn: 0.0015387\ttotal: 9m 6s\tremaining: 2m 28s\n",
      "3929:\tlearn: 0.0015387\ttotal: 9m 6s\tremaining: 2m 28s\n",
      "3930:\tlearn: 0.0015387\ttotal: 9m 6s\tremaining: 2m 28s\n",
      "3931:\tlearn: 0.0015383\ttotal: 9m 6s\tremaining: 2m 28s\n",
      "3932:\tlearn: 0.0015381\ttotal: 9m 7s\tremaining: 2m 28s\n",
      "3933:\tlearn: 0.0015380\ttotal: 9m 7s\tremaining: 2m 28s\n",
      "3934:\tlearn: 0.0015379\ttotal: 9m 7s\tremaining: 2m 28s\n",
      "3935:\tlearn: 0.0015372\ttotal: 9m 7s\tremaining: 2m 28s\n",
      "3936:\tlearn: 0.0015372\ttotal: 9m 7s\tremaining: 2m 27s\n",
      "3937:\tlearn: 0.0015372\ttotal: 9m 7s\tremaining: 2m 27s\n",
      "3938:\tlearn: 0.0015371\ttotal: 9m 7s\tremaining: 2m 27s\n",
      "3939:\tlearn: 0.0015367\ttotal: 9m 8s\tremaining: 2m 27s\n",
      "3940:\tlearn: 0.0015360\ttotal: 9m 8s\tremaining: 2m 27s\n",
      "3941:\tlearn: 0.0015354\ttotal: 9m 8s\tremaining: 2m 27s\n",
      "3942:\tlearn: 0.0015352\ttotal: 9m 8s\tremaining: 2m 27s\n",
      "3943:\tlearn: 0.0015350\ttotal: 9m 8s\tremaining: 2m 26s\n",
      "3944:\tlearn: 0.0015345\ttotal: 9m 8s\tremaining: 2m 26s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3945:\tlearn: 0.0015344\ttotal: 9m 9s\tremaining: 2m 26s\n",
      "3946:\tlearn: 0.0015339\ttotal: 9m 9s\tremaining: 2m 26s\n",
      "3947:\tlearn: 0.0015337\ttotal: 9m 9s\tremaining: 2m 26s\n",
      "3948:\tlearn: 0.0015337\ttotal: 9m 9s\tremaining: 2m 26s\n",
      "3949:\tlearn: 0.0015337\ttotal: 9m 9s\tremaining: 2m 26s\n",
      "3950:\tlearn: 0.0015334\ttotal: 9m 9s\tremaining: 2m 25s\n",
      "3951:\tlearn: 0.0015324\ttotal: 9m 10s\tremaining: 2m 25s\n",
      "3952:\tlearn: 0.0015324\ttotal: 9m 10s\tremaining: 2m 25s\n",
      "3953:\tlearn: 0.0015322\ttotal: 9m 10s\tremaining: 2m 25s\n",
      "3954:\tlearn: 0.0015322\ttotal: 9m 10s\tremaining: 2m 25s\n",
      "3955:\tlearn: 0.0015317\ttotal: 9m 10s\tremaining: 2m 25s\n",
      "3956:\tlearn: 0.0015295\ttotal: 9m 10s\tremaining: 2m 25s\n",
      "3957:\tlearn: 0.0015289\ttotal: 9m 11s\tremaining: 2m 25s\n",
      "3958:\tlearn: 0.0015288\ttotal: 9m 11s\tremaining: 2m 24s\n",
      "3959:\tlearn: 0.0015286\ttotal: 9m 11s\tremaining: 2m 24s\n",
      "3960:\tlearn: 0.0015285\ttotal: 9m 11s\tremaining: 2m 24s\n",
      "3961:\tlearn: 0.0015279\ttotal: 9m 11s\tremaining: 2m 24s\n",
      "3962:\tlearn: 0.0015277\ttotal: 9m 11s\tremaining: 2m 24s\n",
      "3963:\tlearn: 0.0015277\ttotal: 9m 12s\tremaining: 2m 24s\n",
      "3964:\tlearn: 0.0015275\ttotal: 9m 12s\tremaining: 2m 24s\n",
      "3965:\tlearn: 0.0015274\ttotal: 9m 12s\tremaining: 2m 24s\n",
      "3966:\tlearn: 0.0015273\ttotal: 9m 12s\tremaining: 2m 23s\n",
      "3967:\tlearn: 0.0015268\ttotal: 9m 12s\tremaining: 2m 23s\n",
      "3968:\tlearn: 0.0015268\ttotal: 9m 12s\tremaining: 2m 23s\n",
      "3969:\tlearn: 0.0015264\ttotal: 9m 12s\tremaining: 2m 23s\n",
      "3970:\tlearn: 0.0015264\ttotal: 9m 13s\tremaining: 2m 23s\n",
      "3971:\tlearn: 0.0015263\ttotal: 9m 13s\tremaining: 2m 23s\n",
      "3972:\tlearn: 0.0015263\ttotal: 9m 13s\tremaining: 2m 23s\n",
      "3973:\tlearn: 0.0015262\ttotal: 9m 13s\tremaining: 2m 22s\n",
      "3974:\tlearn: 0.0015252\ttotal: 9m 13s\tremaining: 2m 22s\n",
      "3975:\tlearn: 0.0015251\ttotal: 9m 13s\tremaining: 2m 22s\n",
      "3976:\tlearn: 0.0015249\ttotal: 9m 13s\tremaining: 2m 22s\n",
      "3977:\tlearn: 0.0015248\ttotal: 9m 14s\tremaining: 2m 22s\n",
      "3978:\tlearn: 0.0015242\ttotal: 9m 14s\tremaining: 2m 22s\n",
      "3979:\tlearn: 0.0015232\ttotal: 9m 14s\tremaining: 2m 22s\n",
      "3980:\tlearn: 0.0015229\ttotal: 9m 14s\tremaining: 2m 21s\n",
      "3981:\tlearn: 0.0015227\ttotal: 9m 14s\tremaining: 2m 21s\n",
      "3982:\tlearn: 0.0015220\ttotal: 9m 14s\tremaining: 2m 21s\n",
      "3983:\tlearn: 0.0015220\ttotal: 9m 14s\tremaining: 2m 21s\n",
      "3984:\tlearn: 0.0015220\ttotal: 9m 14s\tremaining: 2m 21s\n",
      "3985:\tlearn: 0.0015219\ttotal: 9m 15s\tremaining: 2m 21s\n",
      "3986:\tlearn: 0.0015218\ttotal: 9m 15s\tremaining: 2m 21s\n",
      "3987:\tlearn: 0.0015214\ttotal: 9m 15s\tremaining: 2m 20s\n",
      "3988:\tlearn: 0.0015214\ttotal: 9m 15s\tremaining: 2m 20s\n",
      "3989:\tlearn: 0.0015213\ttotal: 9m 15s\tremaining: 2m 20s\n",
      "3990:\tlearn: 0.0015212\ttotal: 9m 15s\tremaining: 2m 20s\n",
      "3991:\tlearn: 0.0015211\ttotal: 9m 15s\tremaining: 2m 20s\n",
      "3992:\tlearn: 0.0015209\ttotal: 9m 15s\tremaining: 2m 20s\n",
      "3993:\tlearn: 0.0015209\ttotal: 9m 16s\tremaining: 2m 20s\n",
      "3994:\tlearn: 0.0015189\ttotal: 9m 16s\tremaining: 2m 19s\n",
      "3995:\tlearn: 0.0015184\ttotal: 9m 16s\tremaining: 2m 19s\n",
      "3996:\tlearn: 0.0015182\ttotal: 9m 16s\tremaining: 2m 19s\n",
      "3997:\tlearn: 0.0015174\ttotal: 9m 16s\tremaining: 2m 19s\n",
      "3998:\tlearn: 0.0015171\ttotal: 9m 16s\tremaining: 2m 19s\n",
      "3999:\tlearn: 0.0015167\ttotal: 9m 16s\tremaining: 2m 19s\n",
      "4000:\tlearn: 0.0015165\ttotal: 9m 17s\tremaining: 2m 19s\n",
      "4001:\tlearn: 0.0015163\ttotal: 9m 17s\tremaining: 2m 18s\n",
      "4002:\tlearn: 0.0015156\ttotal: 9m 17s\tremaining: 2m 18s\n",
      "4003:\tlearn: 0.0015154\ttotal: 9m 17s\tremaining: 2m 18s\n",
      "4004:\tlearn: 0.0015154\ttotal: 9m 17s\tremaining: 2m 18s\n",
      "4005:\tlearn: 0.0015153\ttotal: 9m 17s\tremaining: 2m 18s\n",
      "4006:\tlearn: 0.0015149\ttotal: 9m 17s\tremaining: 2m 18s\n",
      "4007:\tlearn: 0.0015147\ttotal: 9m 18s\tremaining: 2m 18s\n",
      "4008:\tlearn: 0.0015147\ttotal: 9m 18s\tremaining: 2m 17s\n",
      "4009:\tlearn: 0.0015147\ttotal: 9m 18s\tremaining: 2m 17s\n",
      "4010:\tlearn: 0.0015145\ttotal: 9m 18s\tremaining: 2m 17s\n",
      "4011:\tlearn: 0.0015145\ttotal: 9m 18s\tremaining: 2m 17s\n",
      "4012:\tlearn: 0.0015138\ttotal: 9m 18s\tremaining: 2m 17s\n",
      "4013:\tlearn: 0.0015123\ttotal: 9m 19s\tremaining: 2m 17s\n",
      "4014:\tlearn: 0.0015122\ttotal: 9m 19s\tremaining: 2m 17s\n",
      "4015:\tlearn: 0.0015102\ttotal: 9m 19s\tremaining: 2m 17s\n",
      "4016:\tlearn: 0.0015102\ttotal: 9m 19s\tremaining: 2m 16s\n",
      "4017:\tlearn: 0.0015098\ttotal: 9m 19s\tremaining: 2m 16s\n",
      "4018:\tlearn: 0.0015097\ttotal: 9m 19s\tremaining: 2m 16s\n",
      "4019:\tlearn: 0.0015096\ttotal: 9m 19s\tremaining: 2m 16s\n",
      "4020:\tlearn: 0.0015095\ttotal: 9m 20s\tremaining: 2m 16s\n",
      "4021:\tlearn: 0.0015089\ttotal: 9m 20s\tremaining: 2m 16s\n",
      "4022:\tlearn: 0.0015088\ttotal: 9m 20s\tremaining: 2m 16s\n",
      "4023:\tlearn: 0.0015085\ttotal: 9m 20s\tremaining: 2m 15s\n",
      "4024:\tlearn: 0.0015066\ttotal: 9m 20s\tremaining: 2m 15s\n",
      "4025:\tlearn: 0.0015066\ttotal: 9m 20s\tremaining: 2m 15s\n",
      "4026:\tlearn: 0.0015064\ttotal: 9m 20s\tremaining: 2m 15s\n",
      "4027:\tlearn: 0.0015058\ttotal: 9m 20s\tremaining: 2m 15s\n",
      "4028:\tlearn: 0.0015006\ttotal: 9m 21s\tremaining: 2m 15s\n",
      "4029:\tlearn: 0.0014999\ttotal: 9m 21s\tremaining: 2m 15s\n",
      "4030:\tlearn: 0.0014998\ttotal: 9m 21s\tremaining: 2m 14s\n",
      "4031:\tlearn: 0.0014997\ttotal: 9m 21s\tremaining: 2m 14s\n",
      "4032:\tlearn: 0.0014996\ttotal: 9m 21s\tremaining: 2m 14s\n",
      "4033:\tlearn: 0.0014991\ttotal: 9m 21s\tremaining: 2m 14s\n",
      "4034:\tlearn: 0.0014991\ttotal: 9m 21s\tremaining: 2m 14s\n",
      "4035:\tlearn: 0.0014986\ttotal: 9m 22s\tremaining: 2m 14s\n",
      "4036:\tlearn: 0.0014982\ttotal: 9m 22s\tremaining: 2m 14s\n",
      "4037:\tlearn: 0.0014973\ttotal: 9m 22s\tremaining: 2m 13s\n",
      "4038:\tlearn: 0.0014973\ttotal: 9m 22s\tremaining: 2m 13s\n",
      "4039:\tlearn: 0.0014968\ttotal: 9m 22s\tremaining: 2m 13s\n",
      "4040:\tlearn: 0.0014968\ttotal: 9m 22s\tremaining: 2m 13s\n",
      "4041:\tlearn: 0.0014963\ttotal: 9m 22s\tremaining: 2m 13s\n",
      "4042:\tlearn: 0.0014962\ttotal: 9m 23s\tremaining: 2m 13s\n",
      "4043:\tlearn: 0.0014962\ttotal: 9m 23s\tremaining: 2m 13s\n",
      "4044:\tlearn: 0.0014961\ttotal: 9m 23s\tremaining: 2m 13s\n",
      "4045:\tlearn: 0.0014955\ttotal: 9m 23s\tremaining: 2m 12s\n",
      "4046:\tlearn: 0.0014954\ttotal: 9m 23s\tremaining: 2m 12s\n",
      "4047:\tlearn: 0.0014951\ttotal: 9m 23s\tremaining: 2m 12s\n",
      "4048:\tlearn: 0.0014951\ttotal: 9m 24s\tremaining: 2m 12s\n",
      "4049:\tlearn: 0.0014948\ttotal: 9m 24s\tremaining: 2m 12s\n",
      "4050:\tlearn: 0.0014948\ttotal: 9m 24s\tremaining: 2m 12s\n",
      "4051:\tlearn: 0.0014948\ttotal: 9m 24s\tremaining: 2m 12s\n",
      "4052:\tlearn: 0.0014947\ttotal: 9m 24s\tremaining: 2m 11s\n",
      "4053:\tlearn: 0.0014937\ttotal: 9m 24s\tremaining: 2m 11s\n",
      "4054:\tlearn: 0.0014936\ttotal: 9m 24s\tremaining: 2m 11s\n",
      "4055:\tlearn: 0.0014934\ttotal: 9m 24s\tremaining: 2m 11s\n",
      "4056:\tlearn: 0.0014934\ttotal: 9m 25s\tremaining: 2m 11s\n",
      "4057:\tlearn: 0.0014926\ttotal: 9m 25s\tremaining: 2m 11s\n",
      "4058:\tlearn: 0.0014926\ttotal: 9m 25s\tremaining: 2m 11s\n",
      "4059:\tlearn: 0.0014924\ttotal: 9m 25s\tremaining: 2m 10s\n",
      "4060:\tlearn: 0.0014924\ttotal: 9m 25s\tremaining: 2m 10s\n",
      "4061:\tlearn: 0.0014923\ttotal: 9m 25s\tremaining: 2m 10s\n",
      "4062:\tlearn: 0.0014919\ttotal: 9m 25s\tremaining: 2m 10s\n",
      "4063:\tlearn: 0.0014911\ttotal: 9m 25s\tremaining: 2m 10s\n",
      "4064:\tlearn: 0.0014910\ttotal: 9m 26s\tremaining: 2m 10s\n",
      "4065:\tlearn: 0.0014902\ttotal: 9m 26s\tremaining: 2m 10s\n",
      "4066:\tlearn: 0.0014902\ttotal: 9m 26s\tremaining: 2m 9s\n",
      "4067:\tlearn: 0.0014892\ttotal: 9m 26s\tremaining: 2m 9s\n",
      "4068:\tlearn: 0.0014892\ttotal: 9m 26s\tremaining: 2m 9s\n",
      "4069:\tlearn: 0.0014890\ttotal: 9m 26s\tremaining: 2m 9s\n",
      "4070:\tlearn: 0.0014889\ttotal: 9m 26s\tremaining: 2m 9s\n",
      "4071:\tlearn: 0.0014888\ttotal: 9m 27s\tremaining: 2m 9s\n",
      "4072:\tlearn: 0.0014888\ttotal: 9m 27s\tremaining: 2m 9s\n",
      "4073:\tlearn: 0.0014885\ttotal: 9m 27s\tremaining: 2m 8s\n",
      "4074:\tlearn: 0.0014879\ttotal: 9m 27s\tremaining: 2m 8s\n",
      "4075:\tlearn: 0.0014876\ttotal: 9m 27s\tremaining: 2m 8s\n",
      "4076:\tlearn: 0.0014872\ttotal: 9m 27s\tremaining: 2m 8s\n",
      "4077:\tlearn: 0.0014858\ttotal: 9m 28s\tremaining: 2m 8s\n",
      "4078:\tlearn: 0.0014854\ttotal: 9m 28s\tremaining: 2m 8s\n",
      "4079:\tlearn: 0.0014849\ttotal: 9m 28s\tremaining: 2m 8s\n",
      "4080:\tlearn: 0.0014846\ttotal: 9m 28s\tremaining: 2m 8s\n",
      "4081:\tlearn: 0.0014846\ttotal: 9m 28s\tremaining: 2m 7s\n",
      "4082:\tlearn: 0.0014844\ttotal: 9m 28s\tremaining: 2m 7s\n",
      "4083:\tlearn: 0.0014844\ttotal: 9m 29s\tremaining: 2m 7s\n",
      "4084:\tlearn: 0.0014844\ttotal: 9m 29s\tremaining: 2m 7s\n",
      "4085:\tlearn: 0.0014841\ttotal: 9m 29s\tremaining: 2m 7s\n",
      "4086:\tlearn: 0.0014840\ttotal: 9m 29s\tremaining: 2m 7s\n",
      "4087:\tlearn: 0.0014840\ttotal: 9m 29s\tremaining: 2m 7s\n",
      "4088:\tlearn: 0.0014839\ttotal: 9m 30s\tremaining: 2m 6s\n",
      "4089:\tlearn: 0.0014832\ttotal: 9m 30s\tremaining: 2m 6s\n",
      "4090:\tlearn: 0.0014824\ttotal: 9m 30s\tremaining: 2m 6s\n",
      "4091:\tlearn: 0.0014823\ttotal: 9m 30s\tremaining: 2m 6s\n",
      "4092:\tlearn: 0.0014819\ttotal: 9m 30s\tremaining: 2m 6s\n",
      "4093:\tlearn: 0.0014818\ttotal: 9m 30s\tremaining: 2m 6s\n",
      "4094:\tlearn: 0.0014815\ttotal: 9m 30s\tremaining: 2m 6s\n",
      "4095:\tlearn: 0.0014813\ttotal: 9m 31s\tremaining: 2m 6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096:\tlearn: 0.0014791\ttotal: 9m 31s\tremaining: 2m 5s\n",
      "4097:\tlearn: 0.0014786\ttotal: 9m 31s\tremaining: 2m 5s\n",
      "4098:\tlearn: 0.0014786\ttotal: 9m 31s\tremaining: 2m 5s\n",
      "4099:\tlearn: 0.0014785\ttotal: 9m 31s\tremaining: 2m 5s\n",
      "4100:\tlearn: 0.0014783\ttotal: 9m 31s\tremaining: 2m 5s\n",
      "4101:\tlearn: 0.0014779\ttotal: 9m 31s\tremaining: 2m 5s\n",
      "4102:\tlearn: 0.0014779\ttotal: 9m 31s\tremaining: 2m 5s\n",
      "4103:\tlearn: 0.0014775\ttotal: 9m 32s\tremaining: 2m 4s\n",
      "4104:\tlearn: 0.0014773\ttotal: 9m 32s\tremaining: 2m 4s\n",
      "4105:\tlearn: 0.0014772\ttotal: 9m 32s\tremaining: 2m 4s\n",
      "4106:\tlearn: 0.0014767\ttotal: 9m 32s\tremaining: 2m 4s\n",
      "4107:\tlearn: 0.0014767\ttotal: 9m 32s\tremaining: 2m 4s\n",
      "4108:\tlearn: 0.0014763\ttotal: 9m 32s\tremaining: 2m 4s\n",
      "4109:\tlearn: 0.0014759\ttotal: 9m 32s\tremaining: 2m 4s\n",
      "4110:\tlearn: 0.0014752\ttotal: 9m 33s\tremaining: 2m 3s\n",
      "4111:\tlearn: 0.0014750\ttotal: 9m 33s\tremaining: 2m 3s\n",
      "4112:\tlearn: 0.0014748\ttotal: 9m 33s\tremaining: 2m 3s\n",
      "4113:\tlearn: 0.0014742\ttotal: 9m 33s\tremaining: 2m 3s\n",
      "4114:\tlearn: 0.0014742\ttotal: 9m 33s\tremaining: 2m 3s\n",
      "4115:\tlearn: 0.0014738\ttotal: 9m 33s\tremaining: 2m 3s\n",
      "4116:\tlearn: 0.0014703\ttotal: 9m 34s\tremaining: 2m 3s\n",
      "4117:\tlearn: 0.0014695\ttotal: 9m 34s\tremaining: 2m 3s\n",
      "4118:\tlearn: 0.0014692\ttotal: 9m 34s\tremaining: 2m 2s\n",
      "4119:\tlearn: 0.0014685\ttotal: 9m 34s\tremaining: 2m 2s\n",
      "4120:\tlearn: 0.0014684\ttotal: 9m 34s\tremaining: 2m 2s\n",
      "4121:\tlearn: 0.0014683\ttotal: 9m 35s\tremaining: 2m 2s\n",
      "4122:\tlearn: 0.0014682\ttotal: 9m 35s\tremaining: 2m 2s\n",
      "4123:\tlearn: 0.0014678\ttotal: 9m 35s\tremaining: 2m 2s\n",
      "4124:\tlearn: 0.0014678\ttotal: 9m 35s\tremaining: 2m 2s\n",
      "4125:\tlearn: 0.0014677\ttotal: 9m 35s\tremaining: 2m 1s\n",
      "4126:\tlearn: 0.0014677\ttotal: 9m 35s\tremaining: 2m 1s\n",
      "4127:\tlearn: 0.0014676\ttotal: 9m 36s\tremaining: 2m 1s\n",
      "4128:\tlearn: 0.0014676\ttotal: 9m 36s\tremaining: 2m 1s\n",
      "4129:\tlearn: 0.0014672\ttotal: 9m 36s\tremaining: 2m 1s\n",
      "4130:\tlearn: 0.0014671\ttotal: 9m 36s\tremaining: 2m 1s\n",
      "4131:\tlearn: 0.0014671\ttotal: 9m 36s\tremaining: 2m 1s\n",
      "4132:\tlearn: 0.0014671\ttotal: 9m 36s\tremaining: 2m\n",
      "4133:\tlearn: 0.0014665\ttotal: 9m 36s\tremaining: 2m\n",
      "4134:\tlearn: 0.0014661\ttotal: 9m 36s\tremaining: 2m\n",
      "4135:\tlearn: 0.0014661\ttotal: 9m 37s\tremaining: 2m\n",
      "4136:\tlearn: 0.0014643\ttotal: 9m 37s\tremaining: 2m\n",
      "4137:\tlearn: 0.0014641\ttotal: 9m 37s\tremaining: 2m\n",
      "4138:\tlearn: 0.0014639\ttotal: 9m 37s\tremaining: 2m\n",
      "4139:\tlearn: 0.0014638\ttotal: 9m 37s\tremaining: 1m 59s\n",
      "4140:\tlearn: 0.0014637\ttotal: 9m 37s\tremaining: 1m 59s\n",
      "4141:\tlearn: 0.0014636\ttotal: 9m 37s\tremaining: 1m 59s\n",
      "4142:\tlearn: 0.0014635\ttotal: 9m 37s\tremaining: 1m 59s\n",
      "4143:\tlearn: 0.0014635\ttotal: 9m 38s\tremaining: 1m 59s\n",
      "4144:\tlearn: 0.0014633\ttotal: 9m 38s\tremaining: 1m 59s\n",
      "4145:\tlearn: 0.0014633\ttotal: 9m 38s\tremaining: 1m 59s\n",
      "4146:\tlearn: 0.0014632\ttotal: 9m 38s\tremaining: 1m 58s\n",
      "4147:\tlearn: 0.0014631\ttotal: 9m 38s\tremaining: 1m 58s\n",
      "4148:\tlearn: 0.0014628\ttotal: 9m 38s\tremaining: 1m 58s\n",
      "4149:\tlearn: 0.0014620\ttotal: 9m 38s\tremaining: 1m 58s\n",
      "4150:\tlearn: 0.0014609\ttotal: 9m 38s\tremaining: 1m 58s\n",
      "4151:\tlearn: 0.0014609\ttotal: 9m 38s\tremaining: 1m 58s\n",
      "4152:\tlearn: 0.0014609\ttotal: 9m 39s\tremaining: 1m 58s\n",
      "4153:\tlearn: 0.0014606\ttotal: 9m 39s\tremaining: 1m 57s\n",
      "4154:\tlearn: 0.0014605\ttotal: 9m 39s\tremaining: 1m 57s\n",
      "4155:\tlearn: 0.0014605\ttotal: 9m 39s\tremaining: 1m 57s\n",
      "4156:\tlearn: 0.0014603\ttotal: 9m 39s\tremaining: 1m 57s\n",
      "4157:\tlearn: 0.0014598\ttotal: 9m 39s\tremaining: 1m 57s\n",
      "4158:\tlearn: 0.0014598\ttotal: 9m 39s\tremaining: 1m 57s\n",
      "4159:\tlearn: 0.0014597\ttotal: 9m 39s\tremaining: 1m 57s\n",
      "4160:\tlearn: 0.0014596\ttotal: 9m 40s\tremaining: 1m 56s\n",
      "4161:\tlearn: 0.0014588\ttotal: 9m 40s\tremaining: 1m 56s\n",
      "4162:\tlearn: 0.0014586\ttotal: 9m 40s\tremaining: 1m 56s\n",
      "4163:\tlearn: 0.0014584\ttotal: 9m 40s\tremaining: 1m 56s\n",
      "4164:\tlearn: 0.0014575\ttotal: 9m 40s\tremaining: 1m 56s\n",
      "4165:\tlearn: 0.0014574\ttotal: 9m 40s\tremaining: 1m 56s\n",
      "4166:\tlearn: 0.0014573\ttotal: 9m 40s\tremaining: 1m 56s\n",
      "4167:\tlearn: 0.0014573\ttotal: 9m 40s\tremaining: 1m 55s\n",
      "4168:\tlearn: 0.0014573\ttotal: 9m 41s\tremaining: 1m 55s\n",
      "4169:\tlearn: 0.0014572\ttotal: 9m 41s\tremaining: 1m 55s\n",
      "4170:\tlearn: 0.0014572\ttotal: 9m 41s\tremaining: 1m 55s\n",
      "4171:\tlearn: 0.0014570\ttotal: 9m 41s\tremaining: 1m 55s\n",
      "4172:\tlearn: 0.0014567\ttotal: 9m 41s\tremaining: 1m 55s\n",
      "4173:\tlearn: 0.0014567\ttotal: 9m 41s\tremaining: 1m 55s\n",
      "4174:\tlearn: 0.0014566\ttotal: 9m 41s\tremaining: 1m 54s\n",
      "4175:\tlearn: 0.0014561\ttotal: 9m 41s\tremaining: 1m 54s\n",
      "4176:\tlearn: 0.0014554\ttotal: 9m 41s\tremaining: 1m 54s\n",
      "4177:\tlearn: 0.0014538\ttotal: 9m 42s\tremaining: 1m 54s\n",
      "4178:\tlearn: 0.0014538\ttotal: 9m 42s\tremaining: 1m 54s\n",
      "4179:\tlearn: 0.0014537\ttotal: 9m 42s\tremaining: 1m 54s\n",
      "4180:\tlearn: 0.0014536\ttotal: 9m 42s\tremaining: 1m 54s\n",
      "4181:\tlearn: 0.0014536\ttotal: 9m 42s\tremaining: 1m 53s\n",
      "4182:\tlearn: 0.0014535\ttotal: 9m 42s\tremaining: 1m 53s\n",
      "4183:\tlearn: 0.0014533\ttotal: 9m 42s\tremaining: 1m 53s\n",
      "4184:\tlearn: 0.0014533\ttotal: 9m 42s\tremaining: 1m 53s\n",
      "4185:\tlearn: 0.0014524\ttotal: 9m 43s\tremaining: 1m 53s\n",
      "4186:\tlearn: 0.0014521\ttotal: 9m 43s\tremaining: 1m 53s\n",
      "4187:\tlearn: 0.0014505\ttotal: 9m 43s\tremaining: 1m 53s\n",
      "4188:\tlearn: 0.0014505\ttotal: 9m 43s\tremaining: 1m 52s\n",
      "4189:\tlearn: 0.0014505\ttotal: 9m 43s\tremaining: 1m 52s\n",
      "4190:\tlearn: 0.0014505\ttotal: 9m 43s\tremaining: 1m 52s\n",
      "4191:\tlearn: 0.0014502\ttotal: 9m 43s\tremaining: 1m 52s\n",
      "4192:\tlearn: 0.0014501\ttotal: 9m 43s\tremaining: 1m 52s\n",
      "4193:\tlearn: 0.0014501\ttotal: 9m 44s\tremaining: 1m 52s\n",
      "4194:\tlearn: 0.0014501\ttotal: 9m 44s\tremaining: 1m 52s\n",
      "4195:\tlearn: 0.0014499\ttotal: 9m 44s\tremaining: 1m 51s\n",
      "4196:\tlearn: 0.0014498\ttotal: 9m 44s\tremaining: 1m 51s\n",
      "4197:\tlearn: 0.0014496\ttotal: 9m 44s\tremaining: 1m 51s\n",
      "4198:\tlearn: 0.0014491\ttotal: 9m 44s\tremaining: 1m 51s\n",
      "4199:\tlearn: 0.0014488\ttotal: 9m 44s\tremaining: 1m 51s\n",
      "4200:\tlearn: 0.0014486\ttotal: 9m 44s\tremaining: 1m 51s\n",
      "4201:\tlearn: 0.0014486\ttotal: 9m 44s\tremaining: 1m 51s\n",
      "4202:\tlearn: 0.0014484\ttotal: 9m 45s\tremaining: 1m 50s\n",
      "4203:\tlearn: 0.0014483\ttotal: 9m 45s\tremaining: 1m 50s\n",
      "4204:\tlearn: 0.0014481\ttotal: 9m 45s\tremaining: 1m 50s\n",
      "4205:\tlearn: 0.0014479\ttotal: 9m 45s\tremaining: 1m 50s\n",
      "4206:\tlearn: 0.0014478\ttotal: 9m 45s\tremaining: 1m 50s\n",
      "4207:\tlearn: 0.0014476\ttotal: 9m 45s\tremaining: 1m 50s\n",
      "4208:\tlearn: 0.0014475\ttotal: 9m 45s\tremaining: 1m 50s\n",
      "4209:\tlearn: 0.0014475\ttotal: 9m 45s\tremaining: 1m 49s\n",
      "4210:\tlearn: 0.0014474\ttotal: 9m 46s\tremaining: 1m 49s\n",
      "4211:\tlearn: 0.0014473\ttotal: 9m 46s\tremaining: 1m 49s\n",
      "4212:\tlearn: 0.0014473\ttotal: 9m 46s\tremaining: 1m 49s\n",
      "4213:\tlearn: 0.0014465\ttotal: 9m 46s\tremaining: 1m 49s\n",
      "4214:\tlearn: 0.0014464\ttotal: 9m 46s\tremaining: 1m 49s\n",
      "4215:\tlearn: 0.0014464\ttotal: 9m 46s\tremaining: 1m 49s\n",
      "4216:\tlearn: 0.0014460\ttotal: 9m 46s\tremaining: 1m 48s\n",
      "4217:\tlearn: 0.0014460\ttotal: 9m 46s\tremaining: 1m 48s\n",
      "4218:\tlearn: 0.0014459\ttotal: 9m 46s\tremaining: 1m 48s\n",
      "4219:\tlearn: 0.0014456\ttotal: 9m 47s\tremaining: 1m 48s\n",
      "4220:\tlearn: 0.0014453\ttotal: 9m 47s\tremaining: 1m 48s\n",
      "4221:\tlearn: 0.0014448\ttotal: 9m 47s\tremaining: 1m 48s\n",
      "4222:\tlearn: 0.0014447\ttotal: 9m 47s\tremaining: 1m 48s\n",
      "4223:\tlearn: 0.0014442\ttotal: 9m 47s\tremaining: 1m 47s\n",
      "4224:\tlearn: 0.0014442\ttotal: 9m 47s\tremaining: 1m 47s\n",
      "4225:\tlearn: 0.0014437\ttotal: 9m 47s\tremaining: 1m 47s\n",
      "4226:\tlearn: 0.0014436\ttotal: 9m 47s\tremaining: 1m 47s\n",
      "4227:\tlearn: 0.0014435\ttotal: 9m 48s\tremaining: 1m 47s\n",
      "4228:\tlearn: 0.0014429\ttotal: 9m 48s\tremaining: 1m 47s\n",
      "4229:\tlearn: 0.0014429\ttotal: 9m 48s\tremaining: 1m 47s\n",
      "4230:\tlearn: 0.0014428\ttotal: 9m 48s\tremaining: 1m 46s\n",
      "4231:\tlearn: 0.0014428\ttotal: 9m 48s\tremaining: 1m 46s\n",
      "4232:\tlearn: 0.0014428\ttotal: 9m 48s\tremaining: 1m 46s\n",
      "4233:\tlearn: 0.0014426\ttotal: 9m 48s\tremaining: 1m 46s\n",
      "4234:\tlearn: 0.0014423\ttotal: 9m 48s\tremaining: 1m 46s\n",
      "4235:\tlearn: 0.0014415\ttotal: 9m 48s\tremaining: 1m 46s\n",
      "4236:\tlearn: 0.0014409\ttotal: 9m 49s\tremaining: 1m 46s\n",
      "4237:\tlearn: 0.0014407\ttotal: 9m 49s\tremaining: 1m 45s\n",
      "4238:\tlearn: 0.0014406\ttotal: 9m 49s\tremaining: 1m 45s\n",
      "4239:\tlearn: 0.0014406\ttotal: 9m 49s\tremaining: 1m 45s\n",
      "4240:\tlearn: 0.0014406\ttotal: 9m 49s\tremaining: 1m 45s\n",
      "4241:\tlearn: 0.0014404\ttotal: 9m 49s\tremaining: 1m 45s\n",
      "4242:\tlearn: 0.0014404\ttotal: 9m 49s\tremaining: 1m 45s\n",
      "4243:\tlearn: 0.0014400\ttotal: 9m 49s\tremaining: 1m 45s\n",
      "4244:\tlearn: 0.0014399\ttotal: 9m 50s\tremaining: 1m 44s\n",
      "4245:\tlearn: 0.0014393\ttotal: 9m 50s\tremaining: 1m 44s\n",
      "4246:\tlearn: 0.0014386\ttotal: 9m 50s\tremaining: 1m 44s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4247:\tlearn: 0.0014380\ttotal: 9m 50s\tremaining: 1m 44s\n",
      "4248:\tlearn: 0.0014378\ttotal: 9m 50s\tremaining: 1m 44s\n",
      "4249:\tlearn: 0.0014377\ttotal: 9m 50s\tremaining: 1m 44s\n",
      "4250:\tlearn: 0.0014377\ttotal: 9m 50s\tremaining: 1m 44s\n",
      "4251:\tlearn: 0.0014375\ttotal: 9m 50s\tremaining: 1m 43s\n",
      "4252:\tlearn: 0.0014374\ttotal: 9m 50s\tremaining: 1m 43s\n",
      "4253:\tlearn: 0.0014374\ttotal: 9m 51s\tremaining: 1m 43s\n",
      "4254:\tlearn: 0.0014372\ttotal: 9m 51s\tremaining: 1m 43s\n",
      "4255:\tlearn: 0.0014371\ttotal: 9m 51s\tremaining: 1m 43s\n",
      "4256:\tlearn: 0.0014369\ttotal: 9m 51s\tremaining: 1m 43s\n",
      "4257:\tlearn: 0.0014311\ttotal: 9m 51s\tremaining: 1m 43s\n",
      "4258:\tlearn: 0.0014311\ttotal: 9m 51s\tremaining: 1m 42s\n",
      "4259:\tlearn: 0.0014311\ttotal: 9m 51s\tremaining: 1m 42s\n",
      "4260:\tlearn: 0.0014307\ttotal: 9m 51s\tremaining: 1m 42s\n",
      "4261:\tlearn: 0.0014252\ttotal: 9m 52s\tremaining: 1m 42s\n",
      "4262:\tlearn: 0.0014251\ttotal: 9m 52s\tremaining: 1m 42s\n",
      "4263:\tlearn: 0.0014251\ttotal: 9m 52s\tremaining: 1m 42s\n",
      "4264:\tlearn: 0.0014250\ttotal: 9m 52s\tremaining: 1m 42s\n",
      "4265:\tlearn: 0.0014250\ttotal: 9m 52s\tremaining: 1m 41s\n",
      "4266:\tlearn: 0.0014249\ttotal: 9m 52s\tremaining: 1m 41s\n",
      "4267:\tlearn: 0.0014248\ttotal: 9m 52s\tremaining: 1m 41s\n",
      "4268:\tlearn: 0.0014247\ttotal: 9m 52s\tremaining: 1m 41s\n",
      "4269:\tlearn: 0.0014247\ttotal: 9m 52s\tremaining: 1m 41s\n",
      "4270:\tlearn: 0.0014246\ttotal: 9m 53s\tremaining: 1m 41s\n",
      "4271:\tlearn: 0.0014242\ttotal: 9m 53s\tremaining: 1m 41s\n",
      "4272:\tlearn: 0.0014240\ttotal: 9m 53s\tremaining: 1m 40s\n",
      "4273:\tlearn: 0.0014240\ttotal: 9m 53s\tremaining: 1m 40s\n",
      "4274:\tlearn: 0.0014238\ttotal: 9m 53s\tremaining: 1m 40s\n",
      "4275:\tlearn: 0.0014237\ttotal: 9m 53s\tremaining: 1m 40s\n",
      "4276:\tlearn: 0.0014231\ttotal: 9m 53s\tremaining: 1m 40s\n",
      "4277:\tlearn: 0.0014231\ttotal: 9m 53s\tremaining: 1m 40s\n",
      "4278:\tlearn: 0.0014231\ttotal: 9m 53s\tremaining: 1m 40s\n",
      "4279:\tlearn: 0.0014230\ttotal: 9m 54s\tremaining: 1m 39s\n",
      "4280:\tlearn: 0.0014223\ttotal: 9m 54s\tremaining: 1m 39s\n",
      "4281:\tlearn: 0.0014223\ttotal: 9m 54s\tremaining: 1m 39s\n",
      "4282:\tlearn: 0.0014222\ttotal: 9m 54s\tremaining: 1m 39s\n",
      "4283:\tlearn: 0.0014220\ttotal: 9m 54s\tremaining: 1m 39s\n",
      "4284:\tlearn: 0.0014216\ttotal: 9m 54s\tremaining: 1m 39s\n",
      "4285:\tlearn: 0.0014215\ttotal: 9m 54s\tremaining: 1m 39s\n",
      "4286:\tlearn: 0.0014195\ttotal: 9m 54s\tremaining: 1m 38s\n",
      "4287:\tlearn: 0.0014195\ttotal: 9m 55s\tremaining: 1m 38s\n",
      "4288:\tlearn: 0.0014193\ttotal: 9m 55s\tremaining: 1m 38s\n",
      "4289:\tlearn: 0.0014192\ttotal: 9m 55s\tremaining: 1m 38s\n",
      "4290:\tlearn: 0.0014191\ttotal: 9m 55s\tremaining: 1m 38s\n",
      "4291:\tlearn: 0.0014189\ttotal: 9m 55s\tremaining: 1m 38s\n",
      "4292:\tlearn: 0.0014189\ttotal: 9m 55s\tremaining: 1m 38s\n",
      "4293:\tlearn: 0.0014183\ttotal: 9m 55s\tremaining: 1m 37s\n",
      "4294:\tlearn: 0.0014181\ttotal: 9m 55s\tremaining: 1m 37s\n",
      "4295:\tlearn: 0.0014181\ttotal: 9m 56s\tremaining: 1m 37s\n",
      "4296:\tlearn: 0.0014180\ttotal: 9m 56s\tremaining: 1m 37s\n",
      "4297:\tlearn: 0.0014178\ttotal: 9m 56s\tremaining: 1m 37s\n",
      "4298:\tlearn: 0.0014177\ttotal: 9m 56s\tremaining: 1m 37s\n",
      "4299:\tlearn: 0.0014176\ttotal: 9m 56s\tremaining: 1m 37s\n",
      "4300:\tlearn: 0.0014172\ttotal: 9m 56s\tremaining: 1m 36s\n",
      "4301:\tlearn: 0.0014162\ttotal: 9m 56s\tremaining: 1m 36s\n",
      "4302:\tlearn: 0.0014161\ttotal: 9m 56s\tremaining: 1m 36s\n",
      "4303:\tlearn: 0.0014161\ttotal: 9m 56s\tremaining: 1m 36s\n",
      "4304:\tlearn: 0.0014159\ttotal: 9m 57s\tremaining: 1m 36s\n",
      "4305:\tlearn: 0.0014159\ttotal: 9m 57s\tremaining: 1m 36s\n",
      "4306:\tlearn: 0.0014155\ttotal: 9m 57s\tremaining: 1m 36s\n",
      "4307:\tlearn: 0.0014155\ttotal: 9m 57s\tremaining: 1m 35s\n",
      "4308:\tlearn: 0.0014154\ttotal: 9m 57s\tremaining: 1m 35s\n",
      "4309:\tlearn: 0.0014149\ttotal: 9m 57s\tremaining: 1m 35s\n",
      "4310:\tlearn: 0.0014131\ttotal: 9m 57s\tremaining: 1m 35s\n",
      "4311:\tlearn: 0.0014130\ttotal: 9m 58s\tremaining: 1m 35s\n",
      "4312:\tlearn: 0.0014130\ttotal: 9m 58s\tremaining: 1m 35s\n",
      "4313:\tlearn: 0.0014130\ttotal: 9m 58s\tremaining: 1m 35s\n",
      "4314:\tlearn: 0.0014129\ttotal: 9m 58s\tremaining: 1m 34s\n",
      "4315:\tlearn: 0.0014129\ttotal: 9m 58s\tremaining: 1m 34s\n",
      "4316:\tlearn: 0.0014128\ttotal: 9m 58s\tremaining: 1m 34s\n",
      "4317:\tlearn: 0.0014127\ttotal: 9m 58s\tremaining: 1m 34s\n",
      "4318:\tlearn: 0.0014124\ttotal: 9m 58s\tremaining: 1m 34s\n",
      "4319:\tlearn: 0.0014119\ttotal: 9m 59s\tremaining: 1m 34s\n",
      "4320:\tlearn: 0.0014119\ttotal: 9m 59s\tremaining: 1m 34s\n",
      "4321:\tlearn: 0.0014119\ttotal: 9m 59s\tremaining: 1m 34s\n",
      "4322:\tlearn: 0.0014118\ttotal: 9m 59s\tremaining: 1m 33s\n",
      "4323:\tlearn: 0.0014116\ttotal: 9m 59s\tremaining: 1m 33s\n",
      "4324:\tlearn: 0.0014110\ttotal: 9m 59s\tremaining: 1m 33s\n",
      "4325:\tlearn: 0.0014110\ttotal: 9m 59s\tremaining: 1m 33s\n",
      "4326:\tlearn: 0.0014109\ttotal: 9m 59s\tremaining: 1m 33s\n",
      "4327:\tlearn: 0.0014108\ttotal: 10m\tremaining: 1m 33s\n",
      "4328:\tlearn: 0.0014107\ttotal: 10m\tremaining: 1m 33s\n",
      "4329:\tlearn: 0.0014105\ttotal: 10m\tremaining: 1m 32s\n",
      "4330:\tlearn: 0.0014102\ttotal: 10m\tremaining: 1m 32s\n",
      "4331:\tlearn: 0.0014100\ttotal: 10m\tremaining: 1m 32s\n",
      "4332:\tlearn: 0.0014100\ttotal: 10m\tremaining: 1m 32s\n",
      "4333:\tlearn: 0.0014097\ttotal: 10m\tremaining: 1m 32s\n",
      "4334:\tlearn: 0.0014092\ttotal: 10m\tremaining: 1m 32s\n",
      "4335:\tlearn: 0.0014088\ttotal: 10m 1s\tremaining: 1m 32s\n",
      "4336:\tlearn: 0.0014088\ttotal: 10m 1s\tremaining: 1m 31s\n",
      "4337:\tlearn: 0.0014088\ttotal: 10m 1s\tremaining: 1m 31s\n",
      "4338:\tlearn: 0.0014086\ttotal: 10m 1s\tremaining: 1m 31s\n",
      "4339:\tlearn: 0.0014086\ttotal: 10m 1s\tremaining: 1m 31s\n",
      "4340:\tlearn: 0.0014086\ttotal: 10m 1s\tremaining: 1m 31s\n",
      "4341:\tlearn: 0.0014082\ttotal: 10m 1s\tremaining: 1m 31s\n",
      "4342:\tlearn: 0.0014080\ttotal: 10m 2s\tremaining: 1m 31s\n",
      "4343:\tlearn: 0.0014079\ttotal: 10m 2s\tremaining: 1m 30s\n",
      "4344:\tlearn: 0.0014078\ttotal: 10m 2s\tremaining: 1m 30s\n",
      "4345:\tlearn: 0.0014077\ttotal: 10m 2s\tremaining: 1m 30s\n",
      "4346:\tlearn: 0.0014075\ttotal: 10m 2s\tremaining: 1m 30s\n",
      "4347:\tlearn: 0.0014075\ttotal: 10m 2s\tremaining: 1m 30s\n",
      "4348:\tlearn: 0.0014070\ttotal: 10m 2s\tremaining: 1m 30s\n",
      "4349:\tlearn: 0.0014070\ttotal: 10m 3s\tremaining: 1m 30s\n",
      "4350:\tlearn: 0.0014070\ttotal: 10m 3s\tremaining: 1m 29s\n",
      "4351:\tlearn: 0.0014068\ttotal: 10m 3s\tremaining: 1m 29s\n",
      "4352:\tlearn: 0.0014068\ttotal: 10m 3s\tremaining: 1m 29s\n",
      "4353:\tlearn: 0.0014066\ttotal: 10m 3s\tremaining: 1m 29s\n",
      "4354:\tlearn: 0.0014066\ttotal: 10m 3s\tremaining: 1m 29s\n",
      "4355:\tlearn: 0.0014066\ttotal: 10m 3s\tremaining: 1m 29s\n",
      "4356:\tlearn: 0.0014066\ttotal: 10m 4s\tremaining: 1m 29s\n",
      "4357:\tlearn: 0.0014063\ttotal: 10m 4s\tremaining: 1m 29s\n",
      "4358:\tlearn: 0.0014062\ttotal: 10m 4s\tremaining: 1m 28s\n",
      "4359:\tlearn: 0.0014057\ttotal: 10m 4s\tremaining: 1m 28s\n",
      "4360:\tlearn: 0.0014049\ttotal: 10m 4s\tremaining: 1m 28s\n",
      "4361:\tlearn: 0.0014049\ttotal: 10m 4s\tremaining: 1m 28s\n",
      "4362:\tlearn: 0.0014048\ttotal: 10m 5s\tremaining: 1m 28s\n",
      "4363:\tlearn: 0.0014047\ttotal: 10m 5s\tremaining: 1m 28s\n",
      "4364:\tlearn: 0.0014034\ttotal: 10m 5s\tremaining: 1m 28s\n",
      "4365:\tlearn: 0.0014033\ttotal: 10m 5s\tremaining: 1m 27s\n",
      "4366:\tlearn: 0.0014032\ttotal: 10m 5s\tremaining: 1m 27s\n",
      "4367:\tlearn: 0.0014031\ttotal: 10m 6s\tremaining: 1m 27s\n",
      "4368:\tlearn: 0.0014030\ttotal: 10m 6s\tremaining: 1m 27s\n",
      "4369:\tlearn: 0.0014030\ttotal: 10m 6s\tremaining: 1m 27s\n",
      "4370:\tlearn: 0.0014028\ttotal: 10m 6s\tremaining: 1m 27s\n",
      "4371:\tlearn: 0.0014028\ttotal: 10m 6s\tremaining: 1m 27s\n",
      "4372:\tlearn: 0.0014021\ttotal: 10m 7s\tremaining: 1m 27s\n",
      "4373:\tlearn: 0.0014020\ttotal: 10m 7s\tremaining: 1m 26s\n",
      "4374:\tlearn: 0.0014019\ttotal: 10m 7s\tremaining: 1m 26s\n",
      "4375:\tlearn: 0.0014018\ttotal: 10m 7s\tremaining: 1m 26s\n",
      "4376:\tlearn: 0.0014018\ttotal: 10m 7s\tremaining: 1m 26s\n",
      "4377:\tlearn: 0.0014018\ttotal: 10m 7s\tremaining: 1m 26s\n",
      "4378:\tlearn: 0.0014017\ttotal: 10m 7s\tremaining: 1m 26s\n",
      "4379:\tlearn: 0.0014016\ttotal: 10m 7s\tremaining: 1m 26s\n",
      "4380:\tlearn: 0.0014011\ttotal: 10m 8s\tremaining: 1m 25s\n",
      "4381:\tlearn: 0.0014009\ttotal: 10m 8s\tremaining: 1m 25s\n",
      "4382:\tlearn: 0.0014008\ttotal: 10m 8s\tremaining: 1m 25s\n",
      "4383:\tlearn: 0.0014001\ttotal: 10m 8s\tremaining: 1m 25s\n",
      "4384:\tlearn: 0.0013992\ttotal: 10m 8s\tremaining: 1m 25s\n",
      "4385:\tlearn: 0.0013990\ttotal: 10m 8s\tremaining: 1m 25s\n",
      "4386:\tlearn: 0.0013984\ttotal: 10m 8s\tremaining: 1m 25s\n",
      "4387:\tlearn: 0.0013984\ttotal: 10m 8s\tremaining: 1m 24s\n",
      "4388:\tlearn: 0.0013984\ttotal: 10m 8s\tremaining: 1m 24s\n",
      "4389:\tlearn: 0.0013983\ttotal: 10m 9s\tremaining: 1m 24s\n",
      "4390:\tlearn: 0.0013983\ttotal: 10m 9s\tremaining: 1m 24s\n",
      "4391:\tlearn: 0.0013982\ttotal: 10m 9s\tremaining: 1m 24s\n",
      "4392:\tlearn: 0.0013978\ttotal: 10m 9s\tremaining: 1m 24s\n",
      "4393:\tlearn: 0.0013973\ttotal: 10m 9s\tremaining: 1m 24s\n",
      "4394:\tlearn: 0.0013972\ttotal: 10m 9s\tremaining: 1m 23s\n",
      "4395:\tlearn: 0.0013971\ttotal: 10m 9s\tremaining: 1m 23s\n",
      "4396:\tlearn: 0.0013971\ttotal: 10m 10s\tremaining: 1m 23s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4397:\tlearn: 0.0013970\ttotal: 10m 10s\tremaining: 1m 23s\n",
      "4398:\tlearn: 0.0013969\ttotal: 10m 10s\tremaining: 1m 23s\n",
      "4399:\tlearn: 0.0013964\ttotal: 10m 10s\tremaining: 1m 23s\n",
      "4400:\tlearn: 0.0013964\ttotal: 10m 10s\tremaining: 1m 23s\n",
      "4401:\tlearn: 0.0013964\ttotal: 10m 10s\tremaining: 1m 22s\n",
      "4402:\tlearn: 0.0013963\ttotal: 10m 11s\tremaining: 1m 22s\n",
      "4403:\tlearn: 0.0013963\ttotal: 10m 11s\tremaining: 1m 22s\n",
      "4404:\tlearn: 0.0013962\ttotal: 10m 11s\tremaining: 1m 22s\n",
      "4405:\tlearn: 0.0013962\ttotal: 10m 11s\tremaining: 1m 22s\n",
      "4406:\tlearn: 0.0013959\ttotal: 10m 11s\tremaining: 1m 22s\n",
      "4407:\tlearn: 0.0013958\ttotal: 10m 11s\tremaining: 1m 22s\n",
      "4408:\tlearn: 0.0013956\ttotal: 10m 11s\tremaining: 1m 22s\n",
      "4409:\tlearn: 0.0013956\ttotal: 10m 12s\tremaining: 1m 21s\n",
      "4410:\tlearn: 0.0013951\ttotal: 10m 12s\tremaining: 1m 21s\n",
      "4411:\tlearn: 0.0013950\ttotal: 10m 12s\tremaining: 1m 21s\n",
      "4412:\tlearn: 0.0013944\ttotal: 10m 12s\tremaining: 1m 21s\n",
      "4413:\tlearn: 0.0013943\ttotal: 10m 12s\tremaining: 1m 21s\n",
      "4414:\tlearn: 0.0013943\ttotal: 10m 12s\tremaining: 1m 21s\n",
      "4415:\tlearn: 0.0013942\ttotal: 10m 12s\tremaining: 1m 21s\n",
      "4416:\tlearn: 0.0013936\ttotal: 10m 13s\tremaining: 1m 20s\n",
      "4417:\tlearn: 0.0013935\ttotal: 10m 13s\tremaining: 1m 20s\n",
      "4418:\tlearn: 0.0013934\ttotal: 10m 13s\tremaining: 1m 20s\n",
      "4419:\tlearn: 0.0013933\ttotal: 10m 13s\tremaining: 1m 20s\n",
      "4420:\tlearn: 0.0013920\ttotal: 10m 13s\tremaining: 1m 20s\n",
      "4421:\tlearn: 0.0013916\ttotal: 10m 13s\tremaining: 1m 20s\n",
      "4422:\tlearn: 0.0013916\ttotal: 10m 14s\tremaining: 1m 20s\n",
      "4423:\tlearn: 0.0013915\ttotal: 10m 14s\tremaining: 1m 19s\n",
      "4424:\tlearn: 0.0013915\ttotal: 10m 14s\tremaining: 1m 19s\n",
      "4425:\tlearn: 0.0013909\ttotal: 10m 14s\tremaining: 1m 19s\n",
      "4426:\tlearn: 0.0013907\ttotal: 10m 14s\tremaining: 1m 19s\n",
      "4427:\tlearn: 0.0013906\ttotal: 10m 14s\tremaining: 1m 19s\n",
      "4428:\tlearn: 0.0013902\ttotal: 10m 14s\tremaining: 1m 19s\n",
      "4429:\tlearn: 0.0013895\ttotal: 10m 15s\tremaining: 1m 19s\n",
      "4430:\tlearn: 0.0013894\ttotal: 10m 15s\tremaining: 1m 19s\n",
      "4431:\tlearn: 0.0013894\ttotal: 10m 15s\tremaining: 1m 18s\n",
      "4432:\tlearn: 0.0013894\ttotal: 10m 15s\tremaining: 1m 18s\n",
      "4433:\tlearn: 0.0013894\ttotal: 10m 15s\tremaining: 1m 18s\n",
      "4434:\tlearn: 0.0013893\ttotal: 10m 15s\tremaining: 1m 18s\n",
      "4435:\tlearn: 0.0013893\ttotal: 10m 16s\tremaining: 1m 18s\n",
      "4436:\tlearn: 0.0013893\ttotal: 10m 16s\tremaining: 1m 18s\n",
      "4437:\tlearn: 0.0013885\ttotal: 10m 16s\tremaining: 1m 18s\n",
      "4438:\tlearn: 0.0013885\ttotal: 10m 16s\tremaining: 1m 17s\n",
      "4439:\tlearn: 0.0013885\ttotal: 10m 16s\tremaining: 1m 17s\n",
      "4440:\tlearn: 0.0013884\ttotal: 10m 16s\tremaining: 1m 17s\n",
      "4441:\tlearn: 0.0013881\ttotal: 10m 17s\tremaining: 1m 17s\n",
      "4442:\tlearn: 0.0013871\ttotal: 10m 17s\tremaining: 1m 17s\n",
      "4443:\tlearn: 0.0013869\ttotal: 10m 17s\tremaining: 1m 17s\n",
      "4444:\tlearn: 0.0013867\ttotal: 10m 17s\tremaining: 1m 17s\n",
      "4445:\tlearn: 0.0013864\ttotal: 10m 17s\tremaining: 1m 16s\n",
      "4446:\tlearn: 0.0013864\ttotal: 10m 17s\tremaining: 1m 16s\n",
      "4447:\tlearn: 0.0013862\ttotal: 10m 17s\tremaining: 1m 16s\n",
      "4448:\tlearn: 0.0013859\ttotal: 10m 18s\tremaining: 1m 16s\n",
      "4449:\tlearn: 0.0013858\ttotal: 10m 18s\tremaining: 1m 16s\n",
      "4450:\tlearn: 0.0013852\ttotal: 10m 18s\tremaining: 1m 16s\n",
      "4451:\tlearn: 0.0013850\ttotal: 10m 18s\tremaining: 1m 16s\n",
      "4452:\tlearn: 0.0013850\ttotal: 10m 18s\tremaining: 1m 15s\n",
      "4453:\tlearn: 0.0013849\ttotal: 10m 18s\tremaining: 1m 15s\n",
      "4454:\tlearn: 0.0013843\ttotal: 10m 18s\tremaining: 1m 15s\n",
      "4455:\tlearn: 0.0013843\ttotal: 10m 19s\tremaining: 1m 15s\n",
      "4456:\tlearn: 0.0013842\ttotal: 10m 19s\tremaining: 1m 15s\n",
      "4457:\tlearn: 0.0013839\ttotal: 10m 19s\tremaining: 1m 15s\n",
      "4458:\tlearn: 0.0013838\ttotal: 10m 19s\tremaining: 1m 15s\n",
      "4459:\tlearn: 0.0013835\ttotal: 10m 20s\tremaining: 1m 15s\n",
      "4460:\tlearn: 0.0013834\ttotal: 10m 20s\tremaining: 1m 14s\n",
      "4461:\tlearn: 0.0013833\ttotal: 10m 20s\tremaining: 1m 14s\n",
      "4462:\tlearn: 0.0013833\ttotal: 10m 20s\tremaining: 1m 14s\n",
      "4463:\tlearn: 0.0013831\ttotal: 10m 20s\tremaining: 1m 14s\n",
      "4464:\tlearn: 0.0013831\ttotal: 10m 20s\tremaining: 1m 14s\n",
      "4465:\tlearn: 0.0013825\ttotal: 10m 20s\tremaining: 1m 14s\n",
      "4466:\tlearn: 0.0013824\ttotal: 10m 21s\tremaining: 1m 14s\n",
      "4467:\tlearn: 0.0013819\ttotal: 10m 21s\tremaining: 1m 13s\n",
      "4468:\tlearn: 0.0013811\ttotal: 10m 21s\tremaining: 1m 13s\n",
      "4469:\tlearn: 0.0013811\ttotal: 10m 21s\tremaining: 1m 13s\n",
      "4470:\tlearn: 0.0013811\ttotal: 10m 21s\tremaining: 1m 13s\n",
      "4471:\tlearn: 0.0013805\ttotal: 10m 21s\tremaining: 1m 13s\n",
      "4472:\tlearn: 0.0013802\ttotal: 10m 21s\tremaining: 1m 13s\n",
      "4473:\tlearn: 0.0013801\ttotal: 10m 21s\tremaining: 1m 13s\n",
      "4474:\tlearn: 0.0013800\ttotal: 10m 22s\tremaining: 1m 12s\n",
      "4475:\tlearn: 0.0013771\ttotal: 10m 22s\tremaining: 1m 12s\n",
      "4476:\tlearn: 0.0013771\ttotal: 10m 22s\tremaining: 1m 12s\n",
      "4477:\tlearn: 0.0013771\ttotal: 10m 22s\tremaining: 1m 12s\n",
      "4478:\tlearn: 0.0013753\ttotal: 10m 22s\tremaining: 1m 12s\n",
      "4479:\tlearn: 0.0013750\ttotal: 10m 23s\tremaining: 1m 12s\n",
      "4480:\tlearn: 0.0013750\ttotal: 10m 23s\tremaining: 1m 12s\n",
      "4481:\tlearn: 0.0013750\ttotal: 10m 23s\tremaining: 1m 12s\n",
      "4482:\tlearn: 0.0013743\ttotal: 10m 23s\tremaining: 1m 11s\n",
      "4483:\tlearn: 0.0013742\ttotal: 10m 23s\tremaining: 1m 11s\n",
      "4484:\tlearn: 0.0013741\ttotal: 10m 23s\tremaining: 1m 11s\n",
      "4485:\tlearn: 0.0013741\ttotal: 10m 23s\tremaining: 1m 11s\n",
      "4486:\tlearn: 0.0013732\ttotal: 10m 24s\tremaining: 1m 11s\n",
      "4487:\tlearn: 0.0013732\ttotal: 10m 24s\tremaining: 1m 11s\n",
      "4488:\tlearn: 0.0013730\ttotal: 10m 24s\tremaining: 1m 11s\n",
      "4489:\tlearn: 0.0013729\ttotal: 10m 24s\tremaining: 1m 10s\n",
      "4490:\tlearn: 0.0013729\ttotal: 10m 24s\tremaining: 1m 10s\n",
      "4491:\tlearn: 0.0013725\ttotal: 10m 24s\tremaining: 1m 10s\n",
      "4492:\tlearn: 0.0013725\ttotal: 10m 24s\tremaining: 1m 10s\n",
      "4493:\tlearn: 0.0013725\ttotal: 10m 25s\tremaining: 1m 10s\n",
      "4494:\tlearn: 0.0013723\ttotal: 10m 25s\tremaining: 1m 10s\n",
      "4495:\tlearn: 0.0013720\ttotal: 10m 25s\tremaining: 1m 10s\n",
      "4496:\tlearn: 0.0013718\ttotal: 10m 25s\tremaining: 1m 9s\n",
      "4497:\tlearn: 0.0013715\ttotal: 10m 25s\tremaining: 1m 9s\n",
      "4498:\tlearn: 0.0013706\ttotal: 10m 25s\tremaining: 1m 9s\n",
      "4499:\tlearn: 0.0013706\ttotal: 10m 26s\tremaining: 1m 9s\n",
      "4500:\tlearn: 0.0013704\ttotal: 10m 26s\tremaining: 1m 9s\n",
      "4501:\tlearn: 0.0013703\ttotal: 10m 26s\tremaining: 1m 9s\n",
      "4502:\tlearn: 0.0013699\ttotal: 10m 26s\tremaining: 1m 9s\n",
      "4503:\tlearn: 0.0013693\ttotal: 10m 26s\tremaining: 1m 9s\n",
      "4504:\tlearn: 0.0013691\ttotal: 10m 26s\tremaining: 1m 8s\n",
      "4505:\tlearn: 0.0013686\ttotal: 10m 27s\tremaining: 1m 8s\n",
      "4506:\tlearn: 0.0013686\ttotal: 10m 27s\tremaining: 1m 8s\n",
      "4507:\tlearn: 0.0013678\ttotal: 10m 27s\tremaining: 1m 8s\n",
      "4508:\tlearn: 0.0013677\ttotal: 10m 27s\tremaining: 1m 8s\n",
      "4509:\tlearn: 0.0013673\ttotal: 10m 27s\tremaining: 1m 8s\n",
      "4510:\tlearn: 0.0013673\ttotal: 10m 27s\tremaining: 1m 8s\n",
      "4511:\tlearn: 0.0013653\ttotal: 10m 27s\tremaining: 1m 7s\n",
      "4512:\tlearn: 0.0013649\ttotal: 10m 28s\tremaining: 1m 7s\n",
      "4513:\tlearn: 0.0013648\ttotal: 10m 28s\tremaining: 1m 7s\n",
      "4514:\tlearn: 0.0013647\ttotal: 10m 28s\tremaining: 1m 7s\n",
      "4515:\tlearn: 0.0013640\ttotal: 10m 28s\tremaining: 1m 7s\n",
      "4516:\tlearn: 0.0013640\ttotal: 10m 28s\tremaining: 1m 7s\n",
      "4517:\tlearn: 0.0013640\ttotal: 10m 28s\tremaining: 1m 7s\n",
      "4518:\tlearn: 0.0013636\ttotal: 10m 28s\tremaining: 1m 6s\n",
      "4519:\tlearn: 0.0013636\ttotal: 10m 29s\tremaining: 1m 6s\n",
      "4520:\tlearn: 0.0013636\ttotal: 10m 29s\tremaining: 1m 6s\n",
      "4521:\tlearn: 0.0013636\ttotal: 10m 29s\tremaining: 1m 6s\n",
      "4522:\tlearn: 0.0013632\ttotal: 10m 29s\tremaining: 1m 6s\n",
      "4523:\tlearn: 0.0013630\ttotal: 10m 29s\tremaining: 1m 6s\n",
      "4524:\tlearn: 0.0013622\ttotal: 10m 29s\tremaining: 1m 6s\n",
      "4525:\tlearn: 0.0013621\ttotal: 10m 29s\tremaining: 1m 5s\n",
      "4526:\tlearn: 0.0013621\ttotal: 10m 30s\tremaining: 1m 5s\n",
      "4527:\tlearn: 0.0013619\ttotal: 10m 30s\tremaining: 1m 5s\n",
      "4528:\tlearn: 0.0013611\ttotal: 10m 30s\tremaining: 1m 5s\n",
      "4529:\tlearn: 0.0013611\ttotal: 10m 30s\tremaining: 1m 5s\n",
      "4530:\tlearn: 0.0013611\ttotal: 10m 30s\tremaining: 1m 5s\n",
      "4531:\tlearn: 0.0013608\ttotal: 10m 30s\tremaining: 1m 5s\n",
      "4532:\tlearn: 0.0013607\ttotal: 10m 30s\tremaining: 1m 4s\n",
      "4533:\tlearn: 0.0013598\ttotal: 10m 31s\tremaining: 1m 4s\n",
      "4534:\tlearn: 0.0013596\ttotal: 10m 31s\tremaining: 1m 4s\n",
      "4535:\tlearn: 0.0013595\ttotal: 10m 31s\tremaining: 1m 4s\n",
      "4536:\tlearn: 0.0013589\ttotal: 10m 31s\tremaining: 1m 4s\n",
      "4537:\tlearn: 0.0013588\ttotal: 10m 31s\tremaining: 1m 4s\n",
      "4538:\tlearn: 0.0013581\ttotal: 10m 31s\tremaining: 1m 4s\n",
      "4539:\tlearn: 0.0013581\ttotal: 10m 32s\tremaining: 1m 4s\n",
      "4540:\tlearn: 0.0013580\ttotal: 10m 32s\tremaining: 1m 3s\n",
      "4541:\tlearn: 0.0013580\ttotal: 10m 32s\tremaining: 1m 3s\n",
      "4542:\tlearn: 0.0013579\ttotal: 10m 32s\tremaining: 1m 3s\n",
      "4543:\tlearn: 0.0013579\ttotal: 10m 32s\tremaining: 1m 3s\n",
      "4544:\tlearn: 0.0013556\ttotal: 10m 32s\tremaining: 1m 3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4545:\tlearn: 0.0013553\ttotal: 10m 32s\tremaining: 1m 3s\n",
      "4546:\tlearn: 0.0013553\ttotal: 10m 33s\tremaining: 1m 3s\n",
      "4547:\tlearn: 0.0013550\ttotal: 10m 33s\tremaining: 1m 2s\n",
      "4548:\tlearn: 0.0013548\ttotal: 10m 33s\tremaining: 1m 2s\n",
      "4549:\tlearn: 0.0013547\ttotal: 10m 33s\tremaining: 1m 2s\n",
      "4550:\tlearn: 0.0013547\ttotal: 10m 33s\tremaining: 1m 2s\n",
      "4551:\tlearn: 0.0013543\ttotal: 10m 33s\tremaining: 1m 2s\n",
      "4552:\tlearn: 0.0013536\ttotal: 10m 34s\tremaining: 1m 2s\n",
      "4553:\tlearn: 0.0013529\ttotal: 10m 34s\tremaining: 1m 2s\n",
      "4554:\tlearn: 0.0013529\ttotal: 10m 34s\tremaining: 1m 1s\n",
      "4555:\tlearn: 0.0013526\ttotal: 10m 34s\tremaining: 1m 1s\n",
      "4556:\tlearn: 0.0013523\ttotal: 10m 34s\tremaining: 1m 1s\n",
      "4557:\tlearn: 0.0013521\ttotal: 10m 34s\tremaining: 1m 1s\n",
      "4558:\tlearn: 0.0013519\ttotal: 10m 35s\tremaining: 1m 1s\n",
      "4559:\tlearn: 0.0013518\ttotal: 10m 35s\tremaining: 1m 1s\n",
      "4560:\tlearn: 0.0013518\ttotal: 10m 35s\tremaining: 1m 1s\n",
      "4561:\tlearn: 0.0013512\ttotal: 10m 35s\tremaining: 1m 1s\n",
      "4562:\tlearn: 0.0013511\ttotal: 10m 35s\tremaining: 1m\n",
      "4563:\tlearn: 0.0013511\ttotal: 10m 35s\tremaining: 1m\n",
      "4564:\tlearn: 0.0013509\ttotal: 10m 35s\tremaining: 1m\n",
      "4565:\tlearn: 0.0013508\ttotal: 10m 35s\tremaining: 1m\n",
      "4566:\tlearn: 0.0013507\ttotal: 10m 35s\tremaining: 1m\n",
      "4567:\tlearn: 0.0013507\ttotal: 10m 36s\tremaining: 1m\n",
      "4568:\tlearn: 0.0013505\ttotal: 10m 36s\tremaining: 1m\n",
      "4569:\tlearn: 0.0013505\ttotal: 10m 36s\tremaining: 59.9s\n",
      "4570:\tlearn: 0.0013501\ttotal: 10m 36s\tremaining: 59.7s\n",
      "4571:\tlearn: 0.0013498\ttotal: 10m 36s\tremaining: 59.6s\n",
      "4572:\tlearn: 0.0013497\ttotal: 10m 36s\tremaining: 59.4s\n",
      "4573:\tlearn: 0.0013497\ttotal: 10m 36s\tremaining: 59.3s\n",
      "4574:\tlearn: 0.0013497\ttotal: 10m 36s\tremaining: 59.2s\n",
      "4575:\tlearn: 0.0013481\ttotal: 10m 37s\tremaining: 59s\n",
      "4576:\tlearn: 0.0013480\ttotal: 10m 37s\tremaining: 58.9s\n",
      "4577:\tlearn: 0.0013478\ttotal: 10m 37s\tremaining: 58.7s\n",
      "4578:\tlearn: 0.0013478\ttotal: 10m 37s\tremaining: 58.6s\n",
      "4579:\tlearn: 0.0013477\ttotal: 10m 37s\tremaining: 58.5s\n",
      "4580:\tlearn: 0.0013476\ttotal: 10m 37s\tremaining: 58.3s\n",
      "4581:\tlearn: 0.0013475\ttotal: 10m 37s\tremaining: 58.2s\n",
      "4582:\tlearn: 0.0013474\ttotal: 10m 37s\tremaining: 58s\n",
      "4583:\tlearn: 0.0013474\ttotal: 10m 37s\tremaining: 57.9s\n",
      "4584:\tlearn: 0.0013473\ttotal: 10m 38s\tremaining: 57.8s\n",
      "4585:\tlearn: 0.0013468\ttotal: 10m 38s\tremaining: 57.6s\n",
      "4586:\tlearn: 0.0013463\ttotal: 10m 38s\tremaining: 57.5s\n",
      "4587:\tlearn: 0.0013462\ttotal: 10m 38s\tremaining: 57.3s\n",
      "4588:\tlearn: 0.0013462\ttotal: 10m 38s\tremaining: 57.2s\n",
      "4589:\tlearn: 0.0013462\ttotal: 10m 38s\tremaining: 57.1s\n",
      "4590:\tlearn: 0.0013462\ttotal: 10m 38s\tremaining: 56.9s\n",
      "4591:\tlearn: 0.0013462\ttotal: 10m 38s\tremaining: 56.8s\n",
      "4592:\tlearn: 0.0013461\ttotal: 10m 39s\tremaining: 56.6s\n",
      "4593:\tlearn: 0.0013461\ttotal: 10m 39s\tremaining: 56.5s\n",
      "4594:\tlearn: 0.0013459\ttotal: 10m 39s\tremaining: 56.3s\n",
      "4595:\tlearn: 0.0013459\ttotal: 10m 39s\tremaining: 56.2s\n",
      "4596:\tlearn: 0.0013459\ttotal: 10m 39s\tremaining: 56.1s\n",
      "4597:\tlearn: 0.0013458\ttotal: 10m 39s\tremaining: 55.9s\n",
      "4598:\tlearn: 0.0013424\ttotal: 10m 39s\tremaining: 55.8s\n",
      "4599:\tlearn: 0.0013418\ttotal: 10m 39s\tremaining: 55.6s\n",
      "4600:\tlearn: 0.0013417\ttotal: 10m 39s\tremaining: 55.5s\n",
      "4601:\tlearn: 0.0013415\ttotal: 10m 40s\tremaining: 55.4s\n",
      "4602:\tlearn: 0.0013413\ttotal: 10m 40s\tremaining: 55.2s\n",
      "4603:\tlearn: 0.0013410\ttotal: 10m 40s\tremaining: 55.1s\n",
      "4604:\tlearn: 0.0013410\ttotal: 10m 40s\tremaining: 54.9s\n",
      "4605:\tlearn: 0.0013403\ttotal: 10m 40s\tremaining: 54.8s\n",
      "4606:\tlearn: 0.0013403\ttotal: 10m 40s\tremaining: 54.7s\n",
      "4607:\tlearn: 0.0013403\ttotal: 10m 40s\tremaining: 54.5s\n",
      "4608:\tlearn: 0.0013402\ttotal: 10m 40s\tremaining: 54.4s\n",
      "4609:\tlearn: 0.0013401\ttotal: 10m 41s\tremaining: 54.2s\n",
      "4610:\tlearn: 0.0013399\ttotal: 10m 41s\tremaining: 54.1s\n",
      "4611:\tlearn: 0.0013394\ttotal: 10m 41s\tremaining: 53.9s\n",
      "4612:\tlearn: 0.0013394\ttotal: 10m 41s\tremaining: 53.8s\n",
      "4613:\tlearn: 0.0013393\ttotal: 10m 41s\tremaining: 53.7s\n",
      "4614:\tlearn: 0.0013387\ttotal: 10m 41s\tremaining: 53.5s\n",
      "4615:\tlearn: 0.0013387\ttotal: 10m 41s\tremaining: 53.4s\n",
      "4616:\tlearn: 0.0013387\ttotal: 10m 41s\tremaining: 53.2s\n",
      "4617:\tlearn: 0.0013385\ttotal: 10m 41s\tremaining: 53.1s\n",
      "4618:\tlearn: 0.0013384\ttotal: 10m 42s\tremaining: 53s\n",
      "4619:\tlearn: 0.0013384\ttotal: 10m 42s\tremaining: 52.8s\n",
      "4620:\tlearn: 0.0013384\ttotal: 10m 42s\tremaining: 52.7s\n",
      "4621:\tlearn: 0.0013383\ttotal: 10m 42s\tremaining: 52.5s\n",
      "4622:\tlearn: 0.0013380\ttotal: 10m 42s\tremaining: 52.4s\n",
      "4623:\tlearn: 0.0013377\ttotal: 10m 42s\tremaining: 52.3s\n",
      "4624:\tlearn: 0.0013373\ttotal: 10m 42s\tremaining: 52.1s\n",
      "4625:\tlearn: 0.0013373\ttotal: 10m 42s\tremaining: 52s\n",
      "4626:\tlearn: 0.0013373\ttotal: 10m 42s\tremaining: 51.8s\n",
      "4627:\tlearn: 0.0013371\ttotal: 10m 43s\tremaining: 51.7s\n",
      "4628:\tlearn: 0.0013371\ttotal: 10m 43s\tremaining: 51.6s\n",
      "4629:\tlearn: 0.0013371\ttotal: 10m 43s\tremaining: 51.4s\n",
      "4630:\tlearn: 0.0013371\ttotal: 10m 43s\tremaining: 51.3s\n",
      "4631:\tlearn: 0.0013370\ttotal: 10m 43s\tremaining: 51.1s\n",
      "4632:\tlearn: 0.0013370\ttotal: 10m 43s\tremaining: 51s\n",
      "4633:\tlearn: 0.0013369\ttotal: 10m 43s\tremaining: 50.9s\n",
      "4634:\tlearn: 0.0013362\ttotal: 10m 44s\tremaining: 50.7s\n",
      "4635:\tlearn: 0.0013360\ttotal: 10m 44s\tremaining: 50.6s\n",
      "4636:\tlearn: 0.0013359\ttotal: 10m 44s\tremaining: 50.4s\n",
      "4637:\tlearn: 0.0013358\ttotal: 10m 44s\tremaining: 50.3s\n",
      "4638:\tlearn: 0.0013357\ttotal: 10m 44s\tremaining: 50.2s\n",
      "4639:\tlearn: 0.0013357\ttotal: 10m 44s\tremaining: 50s\n",
      "4640:\tlearn: 0.0013355\ttotal: 10m 44s\tremaining: 49.9s\n",
      "4641:\tlearn: 0.0013353\ttotal: 10m 45s\tremaining: 49.8s\n",
      "4642:\tlearn: 0.0013352\ttotal: 10m 45s\tremaining: 49.6s\n",
      "4643:\tlearn: 0.0013347\ttotal: 10m 45s\tremaining: 49.5s\n",
      "4644:\tlearn: 0.0013343\ttotal: 10m 45s\tremaining: 49.3s\n",
      "4645:\tlearn: 0.0013342\ttotal: 10m 45s\tremaining: 49.2s\n",
      "4646:\tlearn: 0.0013341\ttotal: 10m 45s\tremaining: 49.1s\n",
      "4647:\tlearn: 0.0013340\ttotal: 10m 45s\tremaining: 48.9s\n",
      "4648:\tlearn: 0.0013340\ttotal: 10m 46s\tremaining: 48.8s\n",
      "4649:\tlearn: 0.0013340\ttotal: 10m 46s\tremaining: 48.6s\n",
      "4650:\tlearn: 0.0013340\ttotal: 10m 46s\tremaining: 48.5s\n",
      "4651:\tlearn: 0.0013340\ttotal: 10m 46s\tremaining: 48.4s\n",
      "4652:\tlearn: 0.0013339\ttotal: 10m 46s\tremaining: 48.2s\n",
      "4653:\tlearn: 0.0013338\ttotal: 10m 46s\tremaining: 48.1s\n",
      "4654:\tlearn: 0.0013328\ttotal: 10m 46s\tremaining: 47.9s\n",
      "4655:\tlearn: 0.0013307\ttotal: 10m 46s\tremaining: 47.8s\n",
      "4656:\tlearn: 0.0013307\ttotal: 10m 47s\tremaining: 47.7s\n",
      "4657:\tlearn: 0.0013305\ttotal: 10m 47s\tremaining: 47.5s\n",
      "4658:\tlearn: 0.0013304\ttotal: 10m 47s\tremaining: 47.4s\n",
      "4659:\tlearn: 0.0013304\ttotal: 10m 47s\tremaining: 47.2s\n",
      "4660:\tlearn: 0.0013304\ttotal: 10m 47s\tremaining: 47.1s\n",
      "4661:\tlearn: 0.0013304\ttotal: 10m 47s\tremaining: 47s\n",
      "4662:\tlearn: 0.0013303\ttotal: 10m 47s\tremaining: 46.8s\n",
      "4663:\tlearn: 0.0013303\ttotal: 10m 48s\tremaining: 46.7s\n",
      "4664:\tlearn: 0.0013298\ttotal: 10m 48s\tremaining: 46.5s\n",
      "4665:\tlearn: 0.0013298\ttotal: 10m 48s\tremaining: 46.4s\n",
      "4666:\tlearn: 0.0013297\ttotal: 10m 48s\tremaining: 46.3s\n",
      "4667:\tlearn: 0.0013278\ttotal: 10m 48s\tremaining: 46.1s\n",
      "4668:\tlearn: 0.0013277\ttotal: 10m 48s\tremaining: 46s\n",
      "4669:\tlearn: 0.0013274\ttotal: 10m 48s\tremaining: 45.9s\n",
      "4670:\tlearn: 0.0013274\ttotal: 10m 49s\tremaining: 45.7s\n",
      "4671:\tlearn: 0.0013273\ttotal: 10m 49s\tremaining: 45.6s\n",
      "4672:\tlearn: 0.0013273\ttotal: 10m 49s\tremaining: 45.4s\n",
      "4673:\tlearn: 0.0013272\ttotal: 10m 49s\tremaining: 45.3s\n",
      "4674:\tlearn: 0.0013271\ttotal: 10m 49s\tremaining: 45.2s\n",
      "4675:\tlearn: 0.0013268\ttotal: 10m 49s\tremaining: 45s\n",
      "4676:\tlearn: 0.0013268\ttotal: 10m 50s\tremaining: 44.9s\n",
      "4677:\tlearn: 0.0013267\ttotal: 10m 50s\tremaining: 44.8s\n",
      "4678:\tlearn: 0.0013266\ttotal: 10m 50s\tremaining: 44.6s\n",
      "4679:\tlearn: 0.0013261\ttotal: 10m 50s\tremaining: 44.5s\n",
      "4680:\tlearn: 0.0013242\ttotal: 10m 50s\tremaining: 44.4s\n",
      "4681:\tlearn: 0.0013242\ttotal: 10m 51s\tremaining: 44.2s\n",
      "4682:\tlearn: 0.0013239\ttotal: 10m 51s\tremaining: 44.1s\n",
      "4683:\tlearn: 0.0013239\ttotal: 10m 51s\tremaining: 43.9s\n",
      "4684:\tlearn: 0.0013239\ttotal: 10m 51s\tremaining: 43.8s\n",
      "4685:\tlearn: 0.0013239\ttotal: 10m 51s\tremaining: 43.7s\n",
      "4686:\tlearn: 0.0013238\ttotal: 10m 51s\tremaining: 43.5s\n",
      "4687:\tlearn: 0.0013238\ttotal: 10m 52s\tremaining: 43.4s\n",
      "4688:\tlearn: 0.0013237\ttotal: 10m 52s\tremaining: 43.3s\n",
      "4689:\tlearn: 0.0013235\ttotal: 10m 52s\tremaining: 43.1s\n",
      "4690:\tlearn: 0.0013234\ttotal: 10m 52s\tremaining: 43s\n",
      "4691:\tlearn: 0.0013233\ttotal: 10m 52s\tremaining: 42.8s\n",
      "4692:\tlearn: 0.0013232\ttotal: 10m 52s\tremaining: 42.7s\n",
      "4693:\tlearn: 0.0013232\ttotal: 10m 53s\tremaining: 42.6s\n",
      "4694:\tlearn: 0.0013232\ttotal: 10m 53s\tremaining: 42.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4695:\tlearn: 0.0013230\ttotal: 10m 53s\tremaining: 42.3s\n",
      "4696:\tlearn: 0.0013228\ttotal: 10m 53s\tremaining: 42.2s\n",
      "4697:\tlearn: 0.0013227\ttotal: 10m 53s\tremaining: 42s\n",
      "4698:\tlearn: 0.0013223\ttotal: 10m 53s\tremaining: 41.9s\n",
      "4699:\tlearn: 0.0013223\ttotal: 10m 53s\tremaining: 41.7s\n",
      "4700:\tlearn: 0.0013222\ttotal: 10m 54s\tremaining: 41.6s\n",
      "4701:\tlearn: 0.0013222\ttotal: 10m 54s\tremaining: 41.5s\n",
      "4702:\tlearn: 0.0013222\ttotal: 10m 54s\tremaining: 41.3s\n",
      "4703:\tlearn: 0.0013222\ttotal: 10m 54s\tremaining: 41.2s\n",
      "4704:\tlearn: 0.0013219\ttotal: 10m 54s\tremaining: 41.1s\n",
      "4705:\tlearn: 0.0013218\ttotal: 10m 54s\tremaining: 40.9s\n",
      "4706:\tlearn: 0.0013218\ttotal: 10m 55s\tremaining: 40.8s\n",
      "4707:\tlearn: 0.0013211\ttotal: 10m 55s\tremaining: 40.6s\n",
      "4708:\tlearn: 0.0013210\ttotal: 10m 55s\tremaining: 40.5s\n",
      "4709:\tlearn: 0.0013210\ttotal: 10m 55s\tremaining: 40.4s\n",
      "4710:\tlearn: 0.0013203\ttotal: 10m 55s\tremaining: 40.2s\n",
      "4711:\tlearn: 0.0013201\ttotal: 10m 55s\tremaining: 40.1s\n",
      "4712:\tlearn: 0.0013201\ttotal: 10m 55s\tremaining: 39.9s\n",
      "4713:\tlearn: 0.0013199\ttotal: 10m 56s\tremaining: 39.8s\n",
      "4714:\tlearn: 0.0013198\ttotal: 10m 56s\tremaining: 39.7s\n",
      "4715:\tlearn: 0.0013197\ttotal: 10m 56s\tremaining: 39.5s\n",
      "4716:\tlearn: 0.0013196\ttotal: 10m 56s\tremaining: 39.4s\n",
      "4717:\tlearn: 0.0013196\ttotal: 10m 56s\tremaining: 39.2s\n",
      "4718:\tlearn: 0.0013196\ttotal: 10m 56s\tremaining: 39.1s\n",
      "4719:\tlearn: 0.0013195\ttotal: 10m 56s\tremaining: 39s\n",
      "4720:\tlearn: 0.0013188\ttotal: 10m 56s\tremaining: 38.8s\n",
      "4721:\tlearn: 0.0013187\ttotal: 10m 57s\tremaining: 38.7s\n",
      "4722:\tlearn: 0.0013187\ttotal: 10m 57s\tremaining: 38.5s\n",
      "4723:\tlearn: 0.0013184\ttotal: 10m 57s\tremaining: 38.4s\n",
      "4724:\tlearn: 0.0013175\ttotal: 10m 57s\tremaining: 38.3s\n",
      "4725:\tlearn: 0.0013175\ttotal: 10m 57s\tremaining: 38.1s\n",
      "4726:\tlearn: 0.0013173\ttotal: 10m 57s\tremaining: 38s\n",
      "4727:\tlearn: 0.0013173\ttotal: 10m 57s\tremaining: 37.8s\n",
      "4728:\tlearn: 0.0013172\ttotal: 10m 57s\tremaining: 37.7s\n",
      "4729:\tlearn: 0.0013170\ttotal: 10m 58s\tremaining: 37.6s\n",
      "4730:\tlearn: 0.0013170\ttotal: 10m 58s\tremaining: 37.4s\n",
      "4731:\tlearn: 0.0013170\ttotal: 10m 58s\tremaining: 37.3s\n",
      "4732:\tlearn: 0.0013169\ttotal: 10m 58s\tremaining: 37.1s\n",
      "4733:\tlearn: 0.0013168\ttotal: 10m 58s\tremaining: 37s\n",
      "4734:\tlearn: 0.0013168\ttotal: 10m 58s\tremaining: 36.9s\n",
      "4735:\tlearn: 0.0013168\ttotal: 10m 58s\tremaining: 36.7s\n",
      "4736:\tlearn: 0.0013168\ttotal: 10m 58s\tremaining: 36.6s\n",
      "4737:\tlearn: 0.0013166\ttotal: 10m 58s\tremaining: 36.4s\n",
      "4738:\tlearn: 0.0013158\ttotal: 10m 59s\tremaining: 36.3s\n",
      "4739:\tlearn: 0.0013157\ttotal: 10m 59s\tremaining: 36.2s\n",
      "4740:\tlearn: 0.0013157\ttotal: 10m 59s\tremaining: 36s\n",
      "4741:\tlearn: 0.0013150\ttotal: 10m 59s\tremaining: 35.9s\n",
      "4742:\tlearn: 0.0013143\ttotal: 10m 59s\tremaining: 35.7s\n",
      "4743:\tlearn: 0.0013142\ttotal: 10m 59s\tremaining: 35.6s\n",
      "4744:\tlearn: 0.0013138\ttotal: 10m 59s\tremaining: 35.5s\n",
      "4745:\tlearn: 0.0013137\ttotal: 11m\tremaining: 35.3s\n",
      "4746:\tlearn: 0.0013131\ttotal: 11m\tremaining: 35.2s\n",
      "4747:\tlearn: 0.0013130\ttotal: 11m\tremaining: 35s\n",
      "4748:\tlearn: 0.0013129\ttotal: 11m\tremaining: 34.9s\n",
      "4749:\tlearn: 0.0013129\ttotal: 11m\tremaining: 34.8s\n",
      "4750:\tlearn: 0.0013106\ttotal: 11m\tremaining: 34.6s\n",
      "4751:\tlearn: 0.0013103\ttotal: 11m\tremaining: 34.5s\n",
      "4752:\tlearn: 0.0013102\ttotal: 11m 1s\tremaining: 34.4s\n",
      "4753:\tlearn: 0.0013102\ttotal: 11m 1s\tremaining: 34.2s\n",
      "4754:\tlearn: 0.0013101\ttotal: 11m 1s\tremaining: 34.1s\n",
      "4755:\tlearn: 0.0013101\ttotal: 11m 1s\tremaining: 33.9s\n",
      "4756:\tlearn: 0.0013101\ttotal: 11m 1s\tremaining: 33.8s\n",
      "4757:\tlearn: 0.0013101\ttotal: 11m 1s\tremaining: 33.7s\n",
      "4758:\tlearn: 0.0013100\ttotal: 11m 1s\tremaining: 33.5s\n",
      "4759:\tlearn: 0.0013100\ttotal: 11m 1s\tremaining: 33.4s\n",
      "4760:\tlearn: 0.0013100\ttotal: 11m 2s\tremaining: 33.2s\n",
      "4761:\tlearn: 0.0013095\ttotal: 11m 2s\tremaining: 33.1s\n",
      "4762:\tlearn: 0.0013090\ttotal: 11m 2s\tremaining: 33s\n",
      "4763:\tlearn: 0.0013089\ttotal: 11m 2s\tremaining: 32.8s\n",
      "4764:\tlearn: 0.0013089\ttotal: 11m 2s\tremaining: 32.7s\n",
      "4765:\tlearn: 0.0013084\ttotal: 11m 2s\tremaining: 32.5s\n",
      "4766:\tlearn: 0.0013082\ttotal: 11m 2s\tremaining: 32.4s\n",
      "4767:\tlearn: 0.0013081\ttotal: 11m 2s\tremaining: 32.3s\n",
      "4768:\tlearn: 0.0013076\ttotal: 11m 2s\tremaining: 32.1s\n",
      "4769:\tlearn: 0.0013069\ttotal: 11m 3s\tremaining: 32s\n",
      "4770:\tlearn: 0.0013068\ttotal: 11m 3s\tremaining: 31.8s\n",
      "4771:\tlearn: 0.0013068\ttotal: 11m 3s\tremaining: 31.7s\n",
      "4772:\tlearn: 0.0013068\ttotal: 11m 3s\tremaining: 31.6s\n",
      "4773:\tlearn: 0.0013068\ttotal: 11m 3s\tremaining: 31.4s\n",
      "4774:\tlearn: 0.0013068\ttotal: 11m 3s\tremaining: 31.3s\n",
      "4775:\tlearn: 0.0013067\ttotal: 11m 3s\tremaining: 31.1s\n",
      "4776:\tlearn: 0.0013066\ttotal: 11m 4s\tremaining: 31s\n",
      "4777:\tlearn: 0.0013066\ttotal: 11m 4s\tremaining: 30.9s\n",
      "4778:\tlearn: 0.0013066\ttotal: 11m 4s\tremaining: 30.7s\n",
      "4779:\tlearn: 0.0013066\ttotal: 11m 4s\tremaining: 30.6s\n",
      "4780:\tlearn: 0.0013065\ttotal: 11m 4s\tremaining: 30.4s\n",
      "4781:\tlearn: 0.0013064\ttotal: 11m 4s\tremaining: 30.3s\n",
      "4782:\tlearn: 0.0013050\ttotal: 11m 4s\tremaining: 30.2s\n",
      "4783:\tlearn: 0.0013049\ttotal: 11m 4s\tremaining: 30s\n",
      "4784:\tlearn: 0.0013048\ttotal: 11m 5s\tremaining: 29.9s\n",
      "4785:\tlearn: 0.0013039\ttotal: 11m 5s\tremaining: 29.7s\n",
      "4786:\tlearn: 0.0013038\ttotal: 11m 5s\tremaining: 29.6s\n",
      "4787:\tlearn: 0.0013037\ttotal: 11m 5s\tremaining: 29.5s\n",
      "4788:\tlearn: 0.0013036\ttotal: 11m 5s\tremaining: 29.3s\n",
      "4789:\tlearn: 0.0013036\ttotal: 11m 5s\tremaining: 29.2s\n",
      "4790:\tlearn: 0.0013033\ttotal: 11m 6s\tremaining: 29.1s\n",
      "4791:\tlearn: 0.0013023\ttotal: 11m 6s\tremaining: 28.9s\n",
      "4792:\tlearn: 0.0013023\ttotal: 11m 6s\tremaining: 28.8s\n",
      "4793:\tlearn: 0.0013019\ttotal: 11m 6s\tremaining: 28.6s\n",
      "4794:\tlearn: 0.0013017\ttotal: 11m 6s\tremaining: 28.5s\n",
      "4795:\tlearn: 0.0013017\ttotal: 11m 6s\tremaining: 28.4s\n",
      "4796:\tlearn: 0.0013017\ttotal: 11m 7s\tremaining: 28.2s\n",
      "4797:\tlearn: 0.0013015\ttotal: 11m 7s\tremaining: 28.1s\n",
      "4798:\tlearn: 0.0013013\ttotal: 11m 7s\tremaining: 27.9s\n",
      "4799:\tlearn: 0.0013006\ttotal: 11m 7s\tremaining: 27.8s\n",
      "4800:\tlearn: 0.0013002\ttotal: 11m 7s\tremaining: 27.7s\n",
      "4801:\tlearn: 0.0013001\ttotal: 11m 7s\tremaining: 27.5s\n",
      "4802:\tlearn: 0.0012996\ttotal: 11m 7s\tremaining: 27.4s\n",
      "4803:\tlearn: 0.0012987\ttotal: 11m 7s\tremaining: 27.3s\n",
      "4804:\tlearn: 0.0012985\ttotal: 11m 8s\tremaining: 27.1s\n",
      "4805:\tlearn: 0.0012984\ttotal: 11m 8s\tremaining: 27s\n",
      "4806:\tlearn: 0.0012960\ttotal: 11m 8s\tremaining: 26.8s\n",
      "4807:\tlearn: 0.0012959\ttotal: 11m 8s\tremaining: 26.7s\n",
      "4808:\tlearn: 0.0012956\ttotal: 11m 8s\tremaining: 26.6s\n",
      "4809:\tlearn: 0.0012950\ttotal: 11m 8s\tremaining: 26.4s\n",
      "4810:\tlearn: 0.0012948\ttotal: 11m 8s\tremaining: 26.3s\n",
      "4811:\tlearn: 0.0012947\ttotal: 11m 8s\tremaining: 26.1s\n",
      "4812:\tlearn: 0.0012947\ttotal: 11m 9s\tremaining: 26s\n",
      "4813:\tlearn: 0.0012947\ttotal: 11m 9s\tremaining: 25.9s\n",
      "4814:\tlearn: 0.0012941\ttotal: 11m 9s\tremaining: 25.7s\n",
      "4815:\tlearn: 0.0012940\ttotal: 11m 9s\tremaining: 25.6s\n",
      "4816:\tlearn: 0.0012936\ttotal: 11m 9s\tremaining: 25.4s\n",
      "4817:\tlearn: 0.0012936\ttotal: 11m 9s\tremaining: 25.3s\n",
      "4818:\tlearn: 0.0012935\ttotal: 11m 9s\tremaining: 25.2s\n",
      "4819:\tlearn: 0.0012935\ttotal: 11m 9s\tremaining: 25s\n",
      "4820:\tlearn: 0.0012935\ttotal: 11m 10s\tremaining: 24.9s\n",
      "4821:\tlearn: 0.0012932\ttotal: 11m 10s\tremaining: 24.7s\n",
      "4822:\tlearn: 0.0012929\ttotal: 11m 10s\tremaining: 24.6s\n",
      "4823:\tlearn: 0.0012926\ttotal: 11m 10s\tremaining: 24.5s\n",
      "4824:\tlearn: 0.0012918\ttotal: 11m 10s\tremaining: 24.3s\n",
      "4825:\tlearn: 0.0012918\ttotal: 11m 10s\tremaining: 24.2s\n",
      "4826:\tlearn: 0.0012916\ttotal: 11m 11s\tremaining: 24s\n",
      "4827:\tlearn: 0.0012914\ttotal: 11m 11s\tremaining: 23.9s\n",
      "4828:\tlearn: 0.0012914\ttotal: 11m 11s\tremaining: 23.8s\n",
      "4829:\tlearn: 0.0012912\ttotal: 11m 11s\tremaining: 23.6s\n",
      "4830:\tlearn: 0.0012911\ttotal: 11m 11s\tremaining: 23.5s\n",
      "4831:\tlearn: 0.0012910\ttotal: 11m 11s\tremaining: 23.4s\n",
      "4832:\tlearn: 0.0012907\ttotal: 11m 11s\tremaining: 23.2s\n",
      "4833:\tlearn: 0.0012901\ttotal: 11m 11s\tremaining: 23.1s\n",
      "4834:\tlearn: 0.0012899\ttotal: 11m 12s\tremaining: 22.9s\n",
      "4835:\tlearn: 0.0012899\ttotal: 11m 12s\tremaining: 22.8s\n",
      "4836:\tlearn: 0.0012898\ttotal: 11m 12s\tremaining: 22.7s\n",
      "4837:\tlearn: 0.0012898\ttotal: 11m 12s\tremaining: 22.5s\n",
      "4838:\tlearn: 0.0012898\ttotal: 11m 12s\tremaining: 22.4s\n",
      "4839:\tlearn: 0.0012897\ttotal: 11m 12s\tremaining: 22.2s\n",
      "4840:\tlearn: 0.0012897\ttotal: 11m 13s\tremaining: 22.1s\n",
      "4841:\tlearn: 0.0012894\ttotal: 11m 13s\tremaining: 22s\n",
      "4842:\tlearn: 0.0012894\ttotal: 11m 13s\tremaining: 21.8s\n",
      "4843:\tlearn: 0.0012888\ttotal: 11m 13s\tremaining: 21.7s\n",
      "4844:\tlearn: 0.0012886\ttotal: 11m 13s\tremaining: 21.6s\n",
      "4845:\tlearn: 0.0012886\ttotal: 11m 13s\tremaining: 21.4s\n",
      "4846:\tlearn: 0.0012878\ttotal: 11m 14s\tremaining: 21.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4847:\tlearn: 0.0012877\ttotal: 11m 14s\tremaining: 21.1s\n",
      "4848:\tlearn: 0.0012877\ttotal: 11m 14s\tremaining: 21s\n",
      "4849:\tlearn: 0.0012876\ttotal: 11m 14s\tremaining: 20.9s\n",
      "4850:\tlearn: 0.0012875\ttotal: 11m 14s\tremaining: 20.7s\n",
      "4851:\tlearn: 0.0012870\ttotal: 11m 14s\tremaining: 20.6s\n",
      "4852:\tlearn: 0.0012869\ttotal: 11m 14s\tremaining: 20.4s\n",
      "4853:\tlearn: 0.0012869\ttotal: 11m 15s\tremaining: 20.3s\n",
      "4854:\tlearn: 0.0012866\ttotal: 11m 15s\tremaining: 20.2s\n",
      "4855:\tlearn: 0.0012864\ttotal: 11m 15s\tremaining: 20s\n",
      "4856:\tlearn: 0.0012861\ttotal: 11m 15s\tremaining: 19.9s\n",
      "4857:\tlearn: 0.0012857\ttotal: 11m 15s\tremaining: 19.7s\n",
      "4858:\tlearn: 0.0012857\ttotal: 11m 15s\tremaining: 19.6s\n",
      "4859:\tlearn: 0.0012853\ttotal: 11m 15s\tremaining: 19.5s\n",
      "4860:\tlearn: 0.0012842\ttotal: 11m 16s\tremaining: 19.3s\n",
      "4861:\tlearn: 0.0012838\ttotal: 11m 16s\tremaining: 19.2s\n",
      "4862:\tlearn: 0.0012838\ttotal: 11m 16s\tremaining: 19.1s\n",
      "4863:\tlearn: 0.0012830\ttotal: 11m 16s\tremaining: 18.9s\n",
      "4864:\tlearn: 0.0012830\ttotal: 11m 16s\tremaining: 18.8s\n",
      "4865:\tlearn: 0.0012830\ttotal: 11m 16s\tremaining: 18.6s\n",
      "4866:\tlearn: 0.0012829\ttotal: 11m 16s\tremaining: 18.5s\n",
      "4867:\tlearn: 0.0012822\ttotal: 11m 16s\tremaining: 18.4s\n",
      "4868:\tlearn: 0.0012818\ttotal: 11m 17s\tremaining: 18.2s\n",
      "4869:\tlearn: 0.0012818\ttotal: 11m 17s\tremaining: 18.1s\n",
      "4870:\tlearn: 0.0012817\ttotal: 11m 17s\tremaining: 17.9s\n",
      "4871:\tlearn: 0.0012815\ttotal: 11m 17s\tremaining: 17.8s\n",
      "4872:\tlearn: 0.0012814\ttotal: 11m 17s\tremaining: 17.7s\n",
      "4873:\tlearn: 0.0012812\ttotal: 11m 17s\tremaining: 17.5s\n",
      "4874:\tlearn: 0.0012808\ttotal: 11m 18s\tremaining: 17.4s\n",
      "4875:\tlearn: 0.0012808\ttotal: 11m 18s\tremaining: 17.2s\n",
      "4876:\tlearn: 0.0012804\ttotal: 11m 18s\tremaining: 17.1s\n",
      "4877:\tlearn: 0.0012803\ttotal: 11m 18s\tremaining: 17s\n",
      "4878:\tlearn: 0.0012799\ttotal: 11m 18s\tremaining: 16.8s\n",
      "4879:\tlearn: 0.0012797\ttotal: 11m 18s\tremaining: 16.7s\n",
      "4880:\tlearn: 0.0012796\ttotal: 11m 19s\tremaining: 16.6s\n",
      "4881:\tlearn: 0.0012793\ttotal: 11m 19s\tremaining: 16.4s\n",
      "4882:\tlearn: 0.0012792\ttotal: 11m 19s\tremaining: 16.3s\n",
      "4883:\tlearn: 0.0012790\ttotal: 11m 19s\tremaining: 16.1s\n",
      "4884:\tlearn: 0.0012784\ttotal: 11m 19s\tremaining: 16s\n",
      "4885:\tlearn: 0.0012782\ttotal: 11m 19s\tremaining: 15.9s\n",
      "4886:\tlearn: 0.0012772\ttotal: 11m 20s\tremaining: 15.7s\n",
      "4887:\tlearn: 0.0012772\ttotal: 11m 20s\tremaining: 15.6s\n",
      "4888:\tlearn: 0.0012771\ttotal: 11m 20s\tremaining: 15.4s\n",
      "4889:\tlearn: 0.0012771\ttotal: 11m 20s\tremaining: 15.3s\n",
      "4890:\tlearn: 0.0012769\ttotal: 11m 20s\tremaining: 15.2s\n",
      "4891:\tlearn: 0.0012769\ttotal: 11m 20s\tremaining: 15s\n",
      "4892:\tlearn: 0.0012764\ttotal: 11m 20s\tremaining: 14.9s\n",
      "4893:\tlearn: 0.0012763\ttotal: 11m 21s\tremaining: 14.8s\n",
      "4894:\tlearn: 0.0012762\ttotal: 11m 21s\tremaining: 14.6s\n",
      "4895:\tlearn: 0.0012761\ttotal: 11m 21s\tremaining: 14.5s\n",
      "4896:\tlearn: 0.0012760\ttotal: 11m 21s\tremaining: 14.3s\n",
      "4897:\tlearn: 0.0012760\ttotal: 11m 21s\tremaining: 14.2s\n",
      "4898:\tlearn: 0.0012760\ttotal: 11m 21s\tremaining: 14.1s\n",
      "4899:\tlearn: 0.0012754\ttotal: 11m 21s\tremaining: 13.9s\n",
      "4900:\tlearn: 0.0012754\ttotal: 11m 22s\tremaining: 13.8s\n",
      "4901:\tlearn: 0.0012737\ttotal: 11m 22s\tremaining: 13.6s\n",
      "4902:\tlearn: 0.0012732\ttotal: 11m 22s\tremaining: 13.5s\n",
      "4903:\tlearn: 0.0012730\ttotal: 11m 22s\tremaining: 13.4s\n",
      "4904:\tlearn: 0.0012730\ttotal: 11m 22s\tremaining: 13.2s\n",
      "4905:\tlearn: 0.0012730\ttotal: 11m 22s\tremaining: 13.1s\n",
      "4906:\tlearn: 0.0012729\ttotal: 11m 22s\tremaining: 12.9s\n",
      "4907:\tlearn: 0.0012727\ttotal: 11m 23s\tremaining: 12.8s\n",
      "4908:\tlearn: 0.0012727\ttotal: 11m 23s\tremaining: 12.7s\n",
      "4909:\tlearn: 0.0012719\ttotal: 11m 23s\tremaining: 12.5s\n",
      "4910:\tlearn: 0.0012717\ttotal: 11m 23s\tremaining: 12.4s\n",
      "4911:\tlearn: 0.0012715\ttotal: 11m 23s\tremaining: 12.2s\n",
      "4912:\tlearn: 0.0012712\ttotal: 11m 23s\tremaining: 12.1s\n",
      "4913:\tlearn: 0.0012709\ttotal: 11m 23s\tremaining: 12s\n",
      "4914:\tlearn: 0.0012708\ttotal: 11m 24s\tremaining: 11.8s\n",
      "4915:\tlearn: 0.0012707\ttotal: 11m 24s\tremaining: 11.7s\n",
      "4916:\tlearn: 0.0012707\ttotal: 11m 24s\tremaining: 11.6s\n",
      "4917:\tlearn: 0.0012704\ttotal: 11m 24s\tremaining: 11.4s\n",
      "4918:\tlearn: 0.0012702\ttotal: 11m 24s\tremaining: 11.3s\n",
      "4919:\tlearn: 0.0012702\ttotal: 11m 24s\tremaining: 11.1s\n",
      "4920:\tlearn: 0.0012701\ttotal: 11m 24s\tremaining: 11s\n",
      "4921:\tlearn: 0.0012701\ttotal: 11m 24s\tremaining: 10.9s\n",
      "4922:\tlearn: 0.0012699\ttotal: 11m 25s\tremaining: 10.7s\n",
      "4923:\tlearn: 0.0012699\ttotal: 11m 25s\tremaining: 10.6s\n",
      "4924:\tlearn: 0.0012699\ttotal: 11m 25s\tremaining: 10.4s\n",
      "4925:\tlearn: 0.0012698\ttotal: 11m 25s\tremaining: 10.3s\n",
      "4926:\tlearn: 0.0012696\ttotal: 11m 25s\tremaining: 10.2s\n",
      "4927:\tlearn: 0.0012696\ttotal: 11m 25s\tremaining: 10s\n",
      "4928:\tlearn: 0.0012695\ttotal: 11m 25s\tremaining: 9.88s\n",
      "4929:\tlearn: 0.0012692\ttotal: 11m 25s\tremaining: 9.74s\n",
      "4930:\tlearn: 0.0012691\ttotal: 11m 26s\tremaining: 9.6s\n",
      "4931:\tlearn: 0.0012690\ttotal: 11m 26s\tremaining: 9.46s\n",
      "4932:\tlearn: 0.0012687\ttotal: 11m 26s\tremaining: 9.32s\n",
      "4933:\tlearn: 0.0012682\ttotal: 11m 26s\tremaining: 9.18s\n",
      "4934:\tlearn: 0.0012680\ttotal: 11m 26s\tremaining: 9.04s\n",
      "4935:\tlearn: 0.0012680\ttotal: 11m 26s\tremaining: 8.9s\n",
      "4936:\tlearn: 0.0012674\ttotal: 11m 26s\tremaining: 8.77s\n",
      "4937:\tlearn: 0.0012666\ttotal: 11m 27s\tremaining: 8.63s\n",
      "4938:\tlearn: 0.0012665\ttotal: 11m 27s\tremaining: 8.49s\n",
      "4939:\tlearn: 0.0012665\ttotal: 11m 27s\tremaining: 8.35s\n",
      "4940:\tlearn: 0.0012665\ttotal: 11m 27s\tremaining: 8.21s\n",
      "4941:\tlearn: 0.0012664\ttotal: 11m 27s\tremaining: 8.07s\n",
      "4942:\tlearn: 0.0012660\ttotal: 11m 27s\tremaining: 7.93s\n",
      "4943:\tlearn: 0.0012659\ttotal: 11m 27s\tremaining: 7.79s\n",
      "4944:\tlearn: 0.0012659\ttotal: 11m 28s\tremaining: 7.65s\n",
      "4945:\tlearn: 0.0012658\ttotal: 11m 28s\tremaining: 7.51s\n",
      "4946:\tlearn: 0.0012657\ttotal: 11m 28s\tremaining: 7.38s\n",
      "4947:\tlearn: 0.0012654\ttotal: 11m 28s\tremaining: 7.24s\n",
      "4948:\tlearn: 0.0012631\ttotal: 11m 28s\tremaining: 7.1s\n",
      "4949:\tlearn: 0.0012630\ttotal: 11m 28s\tremaining: 6.96s\n",
      "4950:\tlearn: 0.0012629\ttotal: 11m 29s\tremaining: 6.82s\n",
      "4951:\tlearn: 0.0012629\ttotal: 11m 29s\tremaining: 6.68s\n",
      "4952:\tlearn: 0.0012628\ttotal: 11m 29s\tremaining: 6.54s\n",
      "4953:\tlearn: 0.0012625\ttotal: 11m 29s\tremaining: 6.4s\n",
      "4954:\tlearn: 0.0012622\ttotal: 11m 29s\tremaining: 6.26s\n",
      "4955:\tlearn: 0.0012619\ttotal: 11m 29s\tremaining: 6.12s\n",
      "4956:\tlearn: 0.0012619\ttotal: 11m 29s\tremaining: 5.98s\n",
      "4957:\tlearn: 0.0012617\ttotal: 11m 29s\tremaining: 5.84s\n",
      "4958:\tlearn: 0.0012614\ttotal: 11m 30s\tremaining: 5.71s\n",
      "4959:\tlearn: 0.0012608\ttotal: 11m 30s\tremaining: 5.57s\n",
      "4960:\tlearn: 0.0012608\ttotal: 11m 30s\tremaining: 5.43s\n",
      "4961:\tlearn: 0.0012606\ttotal: 11m 30s\tremaining: 5.29s\n",
      "4962:\tlearn: 0.0012606\ttotal: 11m 30s\tremaining: 5.15s\n",
      "4963:\tlearn: 0.0012605\ttotal: 11m 30s\tremaining: 5.01s\n",
      "4964:\tlearn: 0.0012605\ttotal: 11m 30s\tremaining: 4.87s\n",
      "4965:\tlearn: 0.0012604\ttotal: 11m 31s\tremaining: 4.73s\n",
      "4966:\tlearn: 0.0012604\ttotal: 11m 31s\tremaining: 4.59s\n",
      "4967:\tlearn: 0.0012604\ttotal: 11m 31s\tremaining: 4.45s\n",
      "4968:\tlearn: 0.0012603\ttotal: 11m 31s\tremaining: 4.31s\n",
      "4969:\tlearn: 0.0012599\ttotal: 11m 31s\tremaining: 4.17s\n",
      "4970:\tlearn: 0.0012598\ttotal: 11m 31s\tremaining: 4.04s\n",
      "4971:\tlearn: 0.0012598\ttotal: 11m 31s\tremaining: 3.9s\n",
      "4972:\tlearn: 0.0012598\ttotal: 11m 31s\tremaining: 3.76s\n",
      "4973:\tlearn: 0.0012597\ttotal: 11m 32s\tremaining: 3.62s\n",
      "4974:\tlearn: 0.0012597\ttotal: 11m 32s\tremaining: 3.48s\n",
      "4975:\tlearn: 0.0012594\ttotal: 11m 32s\tremaining: 3.34s\n",
      "4976:\tlearn: 0.0012594\ttotal: 11m 32s\tremaining: 3.2s\n",
      "4977:\tlearn: 0.0012593\ttotal: 11m 32s\tremaining: 3.06s\n",
      "4978:\tlearn: 0.0012592\ttotal: 11m 32s\tremaining: 2.92s\n",
      "4979:\tlearn: 0.0012590\ttotal: 11m 32s\tremaining: 2.78s\n",
      "4980:\tlearn: 0.0012584\ttotal: 11m 33s\tremaining: 2.64s\n",
      "4981:\tlearn: 0.0012579\ttotal: 11m 33s\tremaining: 2.5s\n",
      "4982:\tlearn: 0.0012579\ttotal: 11m 33s\tremaining: 2.37s\n",
      "4983:\tlearn: 0.0012576\ttotal: 11m 33s\tremaining: 2.23s\n",
      "4984:\tlearn: 0.0012576\ttotal: 11m 33s\tremaining: 2.09s\n",
      "4985:\tlearn: 0.0012576\ttotal: 11m 33s\tremaining: 1.95s\n",
      "4986:\tlearn: 0.0012574\ttotal: 11m 34s\tremaining: 1.81s\n",
      "4987:\tlearn: 0.0012573\ttotal: 11m 34s\tremaining: 1.67s\n",
      "4988:\tlearn: 0.0012570\ttotal: 11m 34s\tremaining: 1.53s\n",
      "4989:\tlearn: 0.0012570\ttotal: 11m 34s\tremaining: 1.39s\n",
      "4990:\tlearn: 0.0012569\ttotal: 11m 34s\tremaining: 1.25s\n",
      "4991:\tlearn: 0.0012568\ttotal: 11m 34s\tremaining: 1.11s\n",
      "4992:\tlearn: 0.0012563\ttotal: 11m 34s\tremaining: 974ms\n",
      "4993:\tlearn: 0.0012563\ttotal: 11m 35s\tremaining: 835ms\n",
      "4994:\tlearn: 0.0012562\ttotal: 11m 35s\tremaining: 696ms\n",
      "4995:\tlearn: 0.0012562\ttotal: 11m 35s\tremaining: 557ms\n",
      "4996:\tlearn: 0.0012562\ttotal: 11m 35s\tremaining: 418ms\n",
      "4997:\tlearn: 0.0012557\ttotal: 11m 35s\tremaining: 278ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4998:\tlearn: 0.0012557\ttotal: 11m 35s\tremaining: 139ms\n",
      "4999:\tlearn: 0.0012555\ttotal: 11m 35s\tremaining: 0us\n",
      "Train Result:0.9998491740293555\n",
      "Test Result:0.8014105748757985\n",
      "Test Result:0.6221940928270042\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "cat=CatBoostClassifier(n_estimators=2000)\n",
    "cat.fit(X_train,y_train)\n",
    "print('Train Result:{}'.format(cat.score(X_train, y_train)))\n",
    "print('Test Result:{}'.format(cat.score(X_test, y_test)))\n",
    "print('Test Result:{}'.format(cat.score(X_test21, y_test21)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.031656\n",
      "0:\tlearn: 0.6138549\ttotal: 129ms\tremaining: 4m 18s\n",
      "1:\tlearn: 0.5501937\ttotal: 229ms\tremaining: 3m 48s\n",
      "2:\tlearn: 0.4969429\ttotal: 337ms\tremaining: 3m 44s\n",
      "3:\tlearn: 0.4536625\ttotal: 454ms\tremaining: 3m 46s\n",
      "4:\tlearn: 0.4088829\ttotal: 555ms\tremaining: 3m 41s\n",
      "5:\tlearn: 0.3662914\ttotal: 669ms\tremaining: 3m 42s\n",
      "6:\tlearn: 0.3281989\ttotal: 835ms\tremaining: 3m 57s\n",
      "7:\tlearn: 0.3018836\ttotal: 960ms\tremaining: 3m 59s\n",
      "8:\tlearn: 0.2785310\ttotal: 1.08s\tremaining: 3m 59s\n",
      "9:\tlearn: 0.2515260\ttotal: 1.2s\tremaining: 3m 59s\n",
      "10:\tlearn: 0.2373246\ttotal: 1.33s\tremaining: 3m 59s\n",
      "11:\tlearn: 0.2165728\ttotal: 1.44s\tremaining: 3m 58s\n",
      "12:\tlearn: 0.2034671\ttotal: 1.56s\tremaining: 3m 58s\n",
      "13:\tlearn: 0.1835909\ttotal: 1.68s\tremaining: 3m 57s\n",
      "14:\tlearn: 0.1677425\ttotal: 1.8s\tremaining: 3m 57s\n",
      "15:\tlearn: 0.1590776\ttotal: 1.91s\tremaining: 3m 56s\n",
      "16:\tlearn: 0.1515364\ttotal: 1.99s\tremaining: 3m 52s\n",
      "17:\tlearn: 0.1438994\ttotal: 2.1s\tremaining: 3m 51s\n",
      "18:\tlearn: 0.1370220\ttotal: 2.21s\tremaining: 3m 50s\n",
      "19:\tlearn: 0.1314288\ttotal: 2.32s\tremaining: 3m 49s\n",
      "20:\tlearn: 0.1242076\ttotal: 2.42s\tremaining: 3m 48s\n",
      "21:\tlearn: 0.1197262\ttotal: 2.53s\tremaining: 3m 47s\n",
      "22:\tlearn: 0.1139468\ttotal: 2.63s\tremaining: 3m 45s\n",
      "23:\tlearn: 0.1073492\ttotal: 2.75s\tremaining: 3m 46s\n",
      "24:\tlearn: 0.1018746\ttotal: 2.86s\tremaining: 3m 45s\n",
      "25:\tlearn: 0.0990548\ttotal: 2.96s\tremaining: 3m 44s\n",
      "26:\tlearn: 0.0938681\ttotal: 3.06s\tremaining: 3m 43s\n",
      "27:\tlearn: 0.0916487\ttotal: 3.16s\tremaining: 3m 42s\n",
      "28:\tlearn: 0.0880623\ttotal: 3.26s\tremaining: 3m 41s\n",
      "29:\tlearn: 0.0858767\ttotal: 3.37s\tremaining: 3m 41s\n",
      "30:\tlearn: 0.0831584\ttotal: 3.46s\tremaining: 3m 39s\n",
      "31:\tlearn: 0.0800514\ttotal: 3.58s\tremaining: 3m 40s\n",
      "32:\tlearn: 0.0776697\ttotal: 3.67s\tremaining: 3m 38s\n",
      "33:\tlearn: 0.0759903\ttotal: 3.78s\tremaining: 3m 38s\n",
      "34:\tlearn: 0.0741739\ttotal: 3.88s\tremaining: 3m 37s\n",
      "35:\tlearn: 0.0722277\ttotal: 3.99s\tremaining: 3m 37s\n",
      "36:\tlearn: 0.0704977\ttotal: 4.09s\tremaining: 3m 37s\n",
      "37:\tlearn: 0.0684186\ttotal: 4.2s\tremaining: 3m 36s\n",
      "38:\tlearn: 0.0670527\ttotal: 4.29s\tremaining: 3m 35s\n",
      "39:\tlearn: 0.0656731\ttotal: 4.39s\tremaining: 3m 35s\n",
      "40:\tlearn: 0.0641064\ttotal: 4.49s\tremaining: 3m 34s\n",
      "41:\tlearn: 0.0623661\ttotal: 4.6s\tremaining: 3m 34s\n",
      "42:\tlearn: 0.0607711\ttotal: 4.69s\tremaining: 3m 33s\n",
      "43:\tlearn: 0.0593336\ttotal: 4.81s\tremaining: 3m 33s\n",
      "44:\tlearn: 0.0574517\ttotal: 4.9s\tremaining: 3m 32s\n",
      "45:\tlearn: 0.0566494\ttotal: 4.99s\tremaining: 3m 32s\n",
      "46:\tlearn: 0.0552898\ttotal: 5.1s\tremaining: 3m 31s\n",
      "47:\tlearn: 0.0540902\ttotal: 5.19s\tremaining: 3m 31s\n",
      "48:\tlearn: 0.0531725\ttotal: 5.3s\tremaining: 3m 31s\n",
      "49:\tlearn: 0.0521855\ttotal: 5.4s\tremaining: 3m 30s\n",
      "50:\tlearn: 0.0510656\ttotal: 5.51s\tremaining: 3m 30s\n",
      "51:\tlearn: 0.0497386\ttotal: 5.62s\tremaining: 3m 30s\n",
      "52:\tlearn: 0.0487445\ttotal: 5.72s\tremaining: 3m 30s\n",
      "53:\tlearn: 0.0476252\ttotal: 5.81s\tremaining: 3m 29s\n",
      "54:\tlearn: 0.0465313\ttotal: 5.91s\tremaining: 3m 29s\n",
      "55:\tlearn: 0.0456488\ttotal: 6.02s\tremaining: 3m 29s\n",
      "56:\tlearn: 0.0450478\ttotal: 6.13s\tremaining: 3m 28s\n",
      "57:\tlearn: 0.0444551\ttotal: 6.23s\tremaining: 3m 28s\n",
      "58:\tlearn: 0.0439100\ttotal: 6.34s\tremaining: 3m 28s\n",
      "59:\tlearn: 0.0431580\ttotal: 6.44s\tremaining: 3m 28s\n",
      "60:\tlearn: 0.0420015\ttotal: 6.55s\tremaining: 3m 28s\n",
      "61:\tlearn: 0.0414223\ttotal: 6.66s\tremaining: 3m 28s\n",
      "62:\tlearn: 0.0408407\ttotal: 6.77s\tremaining: 3m 28s\n",
      "63:\tlearn: 0.0400739\ttotal: 6.87s\tremaining: 3m 27s\n",
      "64:\tlearn: 0.0394930\ttotal: 6.97s\tremaining: 3m 27s\n",
      "65:\tlearn: 0.0391149\ttotal: 7.05s\tremaining: 3m 26s\n",
      "66:\tlearn: 0.0388425\ttotal: 7.17s\tremaining: 3m 26s\n",
      "67:\tlearn: 0.0384123\ttotal: 7.25s\tremaining: 3m 25s\n",
      "68:\tlearn: 0.0380045\ttotal: 7.35s\tremaining: 3m 25s\n",
      "69:\tlearn: 0.0376034\ttotal: 7.44s\tremaining: 3m 25s\n",
      "70:\tlearn: 0.0369869\ttotal: 7.56s\tremaining: 3m 25s\n",
      "71:\tlearn: 0.0366366\ttotal: 7.65s\tremaining: 3m 24s\n",
      "72:\tlearn: 0.0362915\ttotal: 7.76s\tremaining: 3m 24s\n",
      "73:\tlearn: 0.0358818\ttotal: 7.86s\tremaining: 3m 24s\n",
      "74:\tlearn: 0.0355189\ttotal: 7.96s\tremaining: 3m 24s\n",
      "75:\tlearn: 0.0352177\ttotal: 8.06s\tremaining: 3m 24s\n",
      "76:\tlearn: 0.0349296\ttotal: 8.16s\tremaining: 3m 23s\n",
      "77:\tlearn: 0.0347359\ttotal: 8.24s\tremaining: 3m 22s\n",
      "78:\tlearn: 0.0343564\ttotal: 8.36s\tremaining: 3m 23s\n",
      "79:\tlearn: 0.0339030\ttotal: 8.45s\tremaining: 3m 22s\n",
      "80:\tlearn: 0.0336477\ttotal: 8.53s\tremaining: 3m 22s\n",
      "81:\tlearn: 0.0334101\ttotal: 8.64s\tremaining: 3m 22s\n",
      "82:\tlearn: 0.0330981\ttotal: 8.73s\tremaining: 3m 21s\n",
      "83:\tlearn: 0.0328248\ttotal: 8.81s\tremaining: 3m 20s\n",
      "84:\tlearn: 0.0324691\ttotal: 8.92s\tremaining: 3m 20s\n",
      "85:\tlearn: 0.0321136\ttotal: 9.01s\tremaining: 3m 20s\n",
      "86:\tlearn: 0.0319494\ttotal: 9.1s\tremaining: 3m 20s\n",
      "87:\tlearn: 0.0315345\ttotal: 9.21s\tremaining: 3m 20s\n",
      "88:\tlearn: 0.0312295\ttotal: 9.29s\tremaining: 3m 19s\n",
      "89:\tlearn: 0.0309108\ttotal: 9.41s\tremaining: 3m 19s\n",
      "90:\tlearn: 0.0307444\ttotal: 9.48s\tremaining: 3m 18s\n",
      "91:\tlearn: 0.0304801\ttotal: 9.59s\tremaining: 3m 18s\n",
      "92:\tlearn: 0.0302821\ttotal: 9.69s\tremaining: 3m 18s\n",
      "93:\tlearn: 0.0299175\ttotal: 9.8s\tremaining: 3m 18s\n",
      "94:\tlearn: 0.0297228\ttotal: 9.88s\tremaining: 3m 18s\n",
      "95:\tlearn: 0.0295192\ttotal: 10s\tremaining: 3m 18s\n",
      "96:\tlearn: 0.0291708\ttotal: 10.1s\tremaining: 3m 18s\n",
      "97:\tlearn: 0.0289365\ttotal: 10.2s\tremaining: 3m 18s\n",
      "98:\tlearn: 0.0285828\ttotal: 10.3s\tremaining: 3m 17s\n",
      "99:\tlearn: 0.0283733\ttotal: 10.4s\tremaining: 3m 17s\n",
      "100:\tlearn: 0.0282349\ttotal: 10.5s\tremaining: 3m 17s\n",
      "101:\tlearn: 0.0280256\ttotal: 10.6s\tremaining: 3m 16s\n",
      "102:\tlearn: 0.0279083\ttotal: 10.7s\tremaining: 3m 16s\n",
      "103:\tlearn: 0.0277365\ttotal: 10.8s\tremaining: 3m 16s\n",
      "104:\tlearn: 0.0275130\ttotal: 10.9s\tremaining: 3m 16s\n",
      "105:\tlearn: 0.0272950\ttotal: 11s\tremaining: 3m 16s\n",
      "106:\tlearn: 0.0271398\ttotal: 11.1s\tremaining: 3m 16s\n",
      "107:\tlearn: 0.0270232\ttotal: 11.2s\tremaining: 3m 16s\n",
      "108:\tlearn: 0.0268249\ttotal: 11.3s\tremaining: 3m 15s\n",
      "109:\tlearn: 0.0267148\ttotal: 11.4s\tremaining: 3m 15s\n",
      "110:\tlearn: 0.0266220\ttotal: 11.5s\tremaining: 3m 15s\n",
      "111:\tlearn: 0.0264775\ttotal: 11.5s\tremaining: 3m 14s\n",
      "112:\tlearn: 0.0263491\ttotal: 11.6s\tremaining: 3m 14s\n",
      "113:\tlearn: 0.0260698\ttotal: 11.7s\tremaining: 3m 14s\n",
      "114:\tlearn: 0.0257412\ttotal: 11.8s\tremaining: 3m 13s\n",
      "115:\tlearn: 0.0256815\ttotal: 11.9s\tremaining: 3m 13s\n",
      "116:\tlearn: 0.0254377\ttotal: 12s\tremaining: 3m 13s\n",
      "117:\tlearn: 0.0252487\ttotal: 12.1s\tremaining: 3m 12s\n",
      "118:\tlearn: 0.0249863\ttotal: 12.2s\tremaining: 3m 12s\n",
      "119:\tlearn: 0.0247512\ttotal: 12.3s\tremaining: 3m 12s\n",
      "120:\tlearn: 0.0246701\ttotal: 12.4s\tremaining: 3m 11s\n",
      "121:\tlearn: 0.0245293\ttotal: 12.5s\tremaining: 3m 11s\n",
      "122:\tlearn: 0.0244091\ttotal: 12.5s\tremaining: 3m 11s\n",
      "123:\tlearn: 0.0242095\ttotal: 12.6s\tremaining: 3m 10s\n",
      "124:\tlearn: 0.0240536\ttotal: 12.7s\tremaining: 3m 10s\n",
      "125:\tlearn: 0.0238323\ttotal: 12.8s\tremaining: 3m 10s\n",
      "126:\tlearn: 0.0237646\ttotal: 12.9s\tremaining: 3m 10s\n",
      "127:\tlearn: 0.0236256\ttotal: 13s\tremaining: 3m 10s\n",
      "128:\tlearn: 0.0236022\ttotal: 13.1s\tremaining: 3m 9s\n",
      "129:\tlearn: 0.0234862\ttotal: 13.2s\tremaining: 3m 9s\n",
      "130:\tlearn: 0.0233957\ttotal: 13.3s\tremaining: 3m 9s\n",
      "131:\tlearn: 0.0233215\ttotal: 13.3s\tremaining: 3m 8s\n",
      "132:\tlearn: 0.0231379\ttotal: 13.4s\tremaining: 3m 8s\n",
      "133:\tlearn: 0.0230546\ttotal: 13.5s\tremaining: 3m 8s\n",
      "134:\tlearn: 0.0229450\ttotal: 13.6s\tremaining: 3m 7s\n",
      "135:\tlearn: 0.0228312\ttotal: 13.7s\tremaining: 3m 7s\n",
      "136:\tlearn: 0.0227781\ttotal: 13.8s\tremaining: 3m 7s\n",
      "137:\tlearn: 0.0226191\ttotal: 13.9s\tremaining: 3m 7s\n",
      "138:\tlearn: 0.0225279\ttotal: 14s\tremaining: 3m 6s\n",
      "139:\tlearn: 0.0224928\ttotal: 14.1s\tremaining: 3m 6s\n",
      "140:\tlearn: 0.0223765\ttotal: 14.1s\tremaining: 3m 6s\n",
      "141:\tlearn: 0.0222731\ttotal: 14.2s\tremaining: 3m 6s\n",
      "142:\tlearn: 0.0221805\ttotal: 14.3s\tremaining: 3m 6s\n",
      "143:\tlearn: 0.0220178\ttotal: 14.4s\tremaining: 3m 5s\n",
      "144:\tlearn: 0.0219918\ttotal: 14.5s\tremaining: 3m 5s\n",
      "145:\tlearn: 0.0218453\ttotal: 14.6s\tremaining: 3m 5s\n",
      "146:\tlearn: 0.0216491\ttotal: 14.7s\tremaining: 3m 5s\n",
      "147:\tlearn: 0.0215794\ttotal: 14.8s\tremaining: 3m 4s\n",
      "148:\tlearn: 0.0215731\ttotal: 14.9s\tremaining: 3m 4s\n",
      "149:\tlearn: 0.0214960\ttotal: 14.9s\tremaining: 3m 4s\n",
      "150:\tlearn: 0.0214072\ttotal: 15s\tremaining: 3m 4s\n",
      "151:\tlearn: 0.0213781\ttotal: 15.1s\tremaining: 3m 3s\n",
      "152:\tlearn: 0.0213017\ttotal: 15.2s\tremaining: 3m 3s\n",
      "153:\tlearn: 0.0212368\ttotal: 15.3s\tremaining: 3m 3s\n",
      "154:\tlearn: 0.0210645\ttotal: 15.4s\tremaining: 3m 3s\n",
      "155:\tlearn: 0.0209240\ttotal: 15.5s\tremaining: 3m 2s\n",
      "156:\tlearn: 0.0208830\ttotal: 15.6s\tremaining: 3m 2s\n",
      "157:\tlearn: 0.0208601\ttotal: 15.6s\tremaining: 3m 2s\n",
      "158:\tlearn: 0.0208002\ttotal: 15.7s\tremaining: 3m 2s\n",
      "159:\tlearn: 0.0207351\ttotal: 15.8s\tremaining: 3m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160:\tlearn: 0.0206678\ttotal: 15.9s\tremaining: 3m 1s\n",
      "161:\tlearn: 0.0206038\ttotal: 16s\tremaining: 3m 1s\n",
      "162:\tlearn: 0.0205732\ttotal: 16.1s\tremaining: 3m 1s\n",
      "163:\tlearn: 0.0205266\ttotal: 16.2s\tremaining: 3m\n",
      "164:\tlearn: 0.0203659\ttotal: 16.2s\tremaining: 3m\n",
      "165:\tlearn: 0.0203054\ttotal: 16.3s\tremaining: 3m\n",
      "166:\tlearn: 0.0202655\ttotal: 16.4s\tremaining: 3m\n",
      "167:\tlearn: 0.0201994\ttotal: 16.5s\tremaining: 3m\n",
      "168:\tlearn: 0.0201390\ttotal: 16.6s\tremaining: 2m 59s\n",
      "169:\tlearn: 0.0200460\ttotal: 16.7s\tremaining: 2m 59s\n",
      "170:\tlearn: 0.0200237\ttotal: 16.8s\tremaining: 2m 59s\n",
      "171:\tlearn: 0.0198437\ttotal: 16.9s\tremaining: 2m 59s\n",
      "172:\tlearn: 0.0198071\ttotal: 16.9s\tremaining: 2m 58s\n",
      "173:\tlearn: 0.0197440\ttotal: 17s\tremaining: 2m 58s\n",
      "174:\tlearn: 0.0195788\ttotal: 17.1s\tremaining: 2m 58s\n",
      "175:\tlearn: 0.0194679\ttotal: 17.2s\tremaining: 2m 58s\n",
      "176:\tlearn: 0.0193947\ttotal: 17.3s\tremaining: 2m 58s\n",
      "177:\tlearn: 0.0193729\ttotal: 17.4s\tremaining: 2m 57s\n",
      "178:\tlearn: 0.0192873\ttotal: 17.5s\tremaining: 2m 57s\n",
      "179:\tlearn: 0.0191809\ttotal: 17.6s\tremaining: 2m 57s\n",
      "180:\tlearn: 0.0191596\ttotal: 17.6s\tremaining: 2m 57s\n",
      "181:\tlearn: 0.0191367\ttotal: 17.7s\tremaining: 2m 57s\n",
      "182:\tlearn: 0.0190452\ttotal: 17.8s\tremaining: 2m 56s\n",
      "183:\tlearn: 0.0190018\ttotal: 17.9s\tremaining: 2m 56s\n",
      "184:\tlearn: 0.0189831\ttotal: 18s\tremaining: 2m 56s\n",
      "185:\tlearn: 0.0188937\ttotal: 18.1s\tremaining: 2m 56s\n",
      "186:\tlearn: 0.0188734\ttotal: 18.2s\tremaining: 2m 56s\n",
      "187:\tlearn: 0.0188485\ttotal: 18.2s\tremaining: 2m 55s\n",
      "188:\tlearn: 0.0187659\ttotal: 18.3s\tremaining: 2m 55s\n",
      "189:\tlearn: 0.0186479\ttotal: 18.4s\tremaining: 2m 55s\n",
      "190:\tlearn: 0.0186028\ttotal: 18.5s\tremaining: 2m 55s\n",
      "191:\tlearn: 0.0185481\ttotal: 18.6s\tremaining: 2m 55s\n",
      "192:\tlearn: 0.0185129\ttotal: 18.7s\tremaining: 2m 54s\n",
      "193:\tlearn: 0.0184409\ttotal: 18.8s\tremaining: 2m 54s\n",
      "194:\tlearn: 0.0183517\ttotal: 18.9s\tremaining: 2m 54s\n",
      "195:\tlearn: 0.0182751\ttotal: 19s\tremaining: 2m 54s\n",
      "196:\tlearn: 0.0182152\ttotal: 19.1s\tremaining: 2m 54s\n",
      "197:\tlearn: 0.0181555\ttotal: 19.1s\tremaining: 2m 54s\n",
      "198:\tlearn: 0.0181260\ttotal: 19.2s\tremaining: 2m 53s\n",
      "199:\tlearn: 0.0180790\ttotal: 19.3s\tremaining: 2m 53s\n",
      "200:\tlearn: 0.0179778\ttotal: 19.4s\tremaining: 2m 53s\n",
      "201:\tlearn: 0.0179622\ttotal: 19.5s\tremaining: 2m 53s\n",
      "202:\tlearn: 0.0179126\ttotal: 19.6s\tremaining: 2m 53s\n",
      "203:\tlearn: 0.0178190\ttotal: 19.7s\tremaining: 2m 53s\n",
      "204:\tlearn: 0.0178034\ttotal: 19.7s\tremaining: 2m 52s\n",
      "205:\tlearn: 0.0177533\ttotal: 19.8s\tremaining: 2m 52s\n",
      "206:\tlearn: 0.0177301\ttotal: 19.9s\tremaining: 2m 52s\n",
      "207:\tlearn: 0.0176802\ttotal: 20s\tremaining: 2m 52s\n",
      "208:\tlearn: 0.0176441\ttotal: 20.1s\tremaining: 2m 52s\n",
      "209:\tlearn: 0.0175935\ttotal: 20.2s\tremaining: 2m 51s\n",
      "210:\tlearn: 0.0175238\ttotal: 20.3s\tremaining: 2m 51s\n",
      "211:\tlearn: 0.0174881\ttotal: 20.3s\tremaining: 2m 51s\n",
      "212:\tlearn: 0.0174017\ttotal: 20.4s\tremaining: 2m 51s\n",
      "213:\tlearn: 0.0173828\ttotal: 20.5s\tremaining: 2m 51s\n",
      "214:\tlearn: 0.0173238\ttotal: 20.6s\tremaining: 2m 51s\n",
      "215:\tlearn: 0.0172806\ttotal: 20.7s\tremaining: 2m 51s\n",
      "216:\tlearn: 0.0172123\ttotal: 20.8s\tremaining: 2m 50s\n",
      "217:\tlearn: 0.0171682\ttotal: 20.9s\tremaining: 2m 50s\n",
      "218:\tlearn: 0.0171157\ttotal: 21s\tremaining: 2m 50s\n",
      "219:\tlearn: 0.0170684\ttotal: 21.1s\tremaining: 2m 50s\n",
      "220:\tlearn: 0.0170586\ttotal: 21.2s\tremaining: 2m 50s\n",
      "221:\tlearn: 0.0170258\ttotal: 21.2s\tremaining: 2m 50s\n",
      "222:\tlearn: 0.0169793\ttotal: 21.3s\tremaining: 2m 50s\n",
      "223:\tlearn: 0.0169726\ttotal: 21.4s\tremaining: 2m 49s\n",
      "224:\tlearn: 0.0169314\ttotal: 21.5s\tremaining: 2m 49s\n",
      "225:\tlearn: 0.0168637\ttotal: 21.6s\tremaining: 2m 49s\n",
      "226:\tlearn: 0.0168146\ttotal: 21.7s\tremaining: 2m 49s\n",
      "227:\tlearn: 0.0167861\ttotal: 21.8s\tremaining: 2m 49s\n",
      "228:\tlearn: 0.0167508\ttotal: 21.9s\tremaining: 2m 49s\n",
      "229:\tlearn: 0.0167338\ttotal: 21.9s\tremaining: 2m 48s\n",
      "230:\tlearn: 0.0167065\ttotal: 22s\tremaining: 2m 48s\n",
      "231:\tlearn: 0.0166547\ttotal: 22.1s\tremaining: 2m 48s\n",
      "232:\tlearn: 0.0166043\ttotal: 22.2s\tremaining: 2m 48s\n",
      "233:\tlearn: 0.0165089\ttotal: 22.3s\tremaining: 2m 48s\n",
      "234:\tlearn: 0.0164661\ttotal: 22.4s\tremaining: 2m 48s\n",
      "235:\tlearn: 0.0164225\ttotal: 22.5s\tremaining: 2m 47s\n",
      "236:\tlearn: 0.0164165\ttotal: 22.5s\tremaining: 2m 47s\n",
      "237:\tlearn: 0.0164116\ttotal: 22.6s\tremaining: 2m 47s\n",
      "238:\tlearn: 0.0163999\ttotal: 22.7s\tremaining: 2m 47s\n",
      "239:\tlearn: 0.0163343\ttotal: 22.8s\tremaining: 2m 47s\n",
      "240:\tlearn: 0.0163219\ttotal: 22.9s\tremaining: 2m 47s\n",
      "241:\tlearn: 0.0162938\ttotal: 23s\tremaining: 2m 46s\n",
      "242:\tlearn: 0.0162125\ttotal: 23.1s\tremaining: 2m 46s\n",
      "243:\tlearn: 0.0161698\ttotal: 23.2s\tremaining: 2m 46s\n",
      "244:\tlearn: 0.0161310\ttotal: 23.2s\tremaining: 2m 46s\n",
      "245:\tlearn: 0.0160969\ttotal: 23.3s\tremaining: 2m 46s\n",
      "246:\tlearn: 0.0160592\ttotal: 23.4s\tremaining: 2m 46s\n",
      "247:\tlearn: 0.0160245\ttotal: 23.5s\tremaining: 2m 46s\n",
      "248:\tlearn: 0.0159401\ttotal: 23.6s\tremaining: 2m 45s\n",
      "249:\tlearn: 0.0159361\ttotal: 23.7s\tremaining: 2m 45s\n",
      "250:\tlearn: 0.0158388\ttotal: 23.8s\tremaining: 2m 45s\n",
      "251:\tlearn: 0.0158060\ttotal: 23.9s\tremaining: 2m 45s\n",
      "252:\tlearn: 0.0157873\ttotal: 24s\tremaining: 2m 45s\n",
      "253:\tlearn: 0.0157654\ttotal: 24s\tremaining: 2m 45s\n",
      "254:\tlearn: 0.0157116\ttotal: 24.1s\tremaining: 2m 45s\n",
      "255:\tlearn: 0.0156757\ttotal: 24.2s\tremaining: 2m 45s\n",
      "256:\tlearn: 0.0156624\ttotal: 24.3s\tremaining: 2m 44s\n",
      "257:\tlearn: 0.0156367\ttotal: 24.4s\tremaining: 2m 44s\n",
      "258:\tlearn: 0.0156167\ttotal: 24.5s\tremaining: 2m 44s\n",
      "259:\tlearn: 0.0155986\ttotal: 24.6s\tremaining: 2m 44s\n",
      "260:\tlearn: 0.0155818\ttotal: 24.6s\tremaining: 2m 44s\n",
      "261:\tlearn: 0.0155361\ttotal: 24.7s\tremaining: 2m 44s\n",
      "262:\tlearn: 0.0154854\ttotal: 24.8s\tremaining: 2m 43s\n",
      "263:\tlearn: 0.0154195\ttotal: 24.9s\tremaining: 2m 43s\n",
      "264:\tlearn: 0.0153659\ttotal: 25s\tremaining: 2m 43s\n",
      "265:\tlearn: 0.0153357\ttotal: 25.1s\tremaining: 2m 43s\n",
      "266:\tlearn: 0.0153094\ttotal: 25.2s\tremaining: 2m 43s\n",
      "267:\tlearn: 0.0152688\ttotal: 25.3s\tremaining: 2m 43s\n",
      "268:\tlearn: 0.0152456\ttotal: 25.4s\tremaining: 2m 43s\n",
      "269:\tlearn: 0.0152139\ttotal: 25.4s\tremaining: 2m 43s\n",
      "270:\tlearn: 0.0151902\ttotal: 25.5s\tremaining: 2m 42s\n",
      "271:\tlearn: 0.0151402\ttotal: 25.6s\tremaining: 2m 42s\n",
      "272:\tlearn: 0.0151267\ttotal: 25.7s\tremaining: 2m 42s\n",
      "273:\tlearn: 0.0150713\ttotal: 25.8s\tremaining: 2m 42s\n",
      "274:\tlearn: 0.0150569\ttotal: 25.9s\tremaining: 2m 42s\n",
      "275:\tlearn: 0.0150037\ttotal: 25.9s\tremaining: 2m 42s\n",
      "276:\tlearn: 0.0149602\ttotal: 26.1s\tremaining: 2m 42s\n",
      "277:\tlearn: 0.0149275\ttotal: 26.1s\tremaining: 2m 41s\n",
      "278:\tlearn: 0.0148726\ttotal: 26.2s\tremaining: 2m 41s\n",
      "279:\tlearn: 0.0148493\ttotal: 26.3s\tremaining: 2m 41s\n",
      "280:\tlearn: 0.0148352\ttotal: 26.4s\tremaining: 2m 41s\n",
      "281:\tlearn: 0.0148258\ttotal: 26.5s\tremaining: 2m 41s\n",
      "282:\tlearn: 0.0148114\ttotal: 26.6s\tremaining: 2m 41s\n",
      "283:\tlearn: 0.0148012\ttotal: 26.7s\tremaining: 2m 41s\n",
      "284:\tlearn: 0.0147893\ttotal: 26.7s\tremaining: 2m 40s\n",
      "285:\tlearn: 0.0147354\ttotal: 26.8s\tremaining: 2m 40s\n",
      "286:\tlearn: 0.0147242\ttotal: 26.9s\tremaining: 2m 40s\n",
      "287:\tlearn: 0.0146844\ttotal: 27s\tremaining: 2m 40s\n",
      "288:\tlearn: 0.0146601\ttotal: 27.1s\tremaining: 2m 40s\n",
      "289:\tlearn: 0.0146360\ttotal: 27.2s\tremaining: 2m 40s\n",
      "290:\tlearn: 0.0146208\ttotal: 27.3s\tremaining: 2m 40s\n",
      "291:\tlearn: 0.0145924\ttotal: 27.4s\tremaining: 2m 40s\n",
      "292:\tlearn: 0.0145650\ttotal: 27.4s\tremaining: 2m 39s\n",
      "293:\tlearn: 0.0145382\ttotal: 27.5s\tremaining: 2m 39s\n",
      "294:\tlearn: 0.0145160\ttotal: 27.6s\tremaining: 2m 39s\n",
      "295:\tlearn: 0.0144876\ttotal: 27.7s\tremaining: 2m 39s\n",
      "296:\tlearn: 0.0144437\ttotal: 27.8s\tremaining: 2m 39s\n",
      "297:\tlearn: 0.0144268\ttotal: 27.9s\tremaining: 2m 39s\n",
      "298:\tlearn: 0.0144106\ttotal: 28s\tremaining: 2m 39s\n",
      "299:\tlearn: 0.0143979\ttotal: 28s\tremaining: 2m 38s\n",
      "300:\tlearn: 0.0143411\ttotal: 28.2s\tremaining: 2m 38s\n",
      "301:\tlearn: 0.0143368\ttotal: 28.2s\tremaining: 2m 38s\n",
      "302:\tlearn: 0.0143050\ttotal: 28.3s\tremaining: 2m 38s\n",
      "303:\tlearn: 0.0142429\ttotal: 28.4s\tremaining: 2m 38s\n",
      "304:\tlearn: 0.0141959\ttotal: 28.5s\tremaining: 2m 38s\n",
      "305:\tlearn: 0.0141711\ttotal: 28.6s\tremaining: 2m 38s\n",
      "306:\tlearn: 0.0141450\ttotal: 28.7s\tremaining: 2m 38s\n",
      "307:\tlearn: 0.0141272\ttotal: 28.8s\tremaining: 2m 38s\n",
      "308:\tlearn: 0.0140904\ttotal: 28.8s\tremaining: 2m 37s\n",
      "309:\tlearn: 0.0140533\ttotal: 29s\tremaining: 2m 37s\n",
      "310:\tlearn: 0.0140492\ttotal: 29s\tremaining: 2m 37s\n",
      "311:\tlearn: 0.0140115\ttotal: 29.2s\tremaining: 2m 37s\n",
      "312:\tlearn: 0.0139822\ttotal: 29.3s\tremaining: 2m 38s\n",
      "313:\tlearn: 0.0139686\ttotal: 29.5s\tremaining: 2m 38s\n",
      "314:\tlearn: 0.0139493\ttotal: 29.6s\tremaining: 2m 38s\n",
      "315:\tlearn: 0.0139201\ttotal: 29.7s\tremaining: 2m 38s\n",
      "316:\tlearn: 0.0139047\ttotal: 29.9s\tremaining: 2m 38s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "317:\tlearn: 0.0138867\ttotal: 30s\tremaining: 2m 38s\n",
      "318:\tlearn: 0.0138783\ttotal: 30.1s\tremaining: 2m 38s\n",
      "319:\tlearn: 0.0138639\ttotal: 30.2s\tremaining: 2m 38s\n",
      "320:\tlearn: 0.0138468\ttotal: 30.3s\tremaining: 2m 38s\n",
      "321:\tlearn: 0.0137825\ttotal: 30.4s\tremaining: 2m 38s\n",
      "322:\tlearn: 0.0137591\ttotal: 30.5s\tremaining: 2m 38s\n",
      "323:\tlearn: 0.0137510\ttotal: 30.6s\tremaining: 2m 38s\n",
      "324:\tlearn: 0.0137411\ttotal: 30.7s\tremaining: 2m 38s\n",
      "325:\tlearn: 0.0137116\ttotal: 30.8s\tremaining: 2m 38s\n",
      "326:\tlearn: 0.0136941\ttotal: 30.9s\tremaining: 2m 37s\n",
      "327:\tlearn: 0.0136824\ttotal: 31s\tremaining: 2m 37s\n",
      "328:\tlearn: 0.0136516\ttotal: 31s\tremaining: 2m 37s\n",
      "329:\tlearn: 0.0136294\ttotal: 31.1s\tremaining: 2m 37s\n",
      "330:\tlearn: 0.0135674\ttotal: 31.2s\tremaining: 2m 37s\n",
      "331:\tlearn: 0.0135500\ttotal: 31.3s\tremaining: 2m 37s\n",
      "332:\tlearn: 0.0135345\ttotal: 31.4s\tremaining: 2m 37s\n",
      "333:\tlearn: 0.0135240\ttotal: 31.5s\tremaining: 2m 36s\n",
      "334:\tlearn: 0.0135049\ttotal: 31.6s\tremaining: 2m 36s\n",
      "335:\tlearn: 0.0134799\ttotal: 31.6s\tremaining: 2m 36s\n",
      "336:\tlearn: 0.0134609\ttotal: 31.7s\tremaining: 2m 36s\n",
      "337:\tlearn: 0.0134443\ttotal: 31.8s\tremaining: 2m 36s\n",
      "338:\tlearn: 0.0134162\ttotal: 31.9s\tremaining: 2m 36s\n",
      "339:\tlearn: 0.0133998\ttotal: 32s\tremaining: 2m 36s\n",
      "340:\tlearn: 0.0133602\ttotal: 32.1s\tremaining: 2m 35s\n",
      "341:\tlearn: 0.0133340\ttotal: 32.2s\tremaining: 2m 35s\n",
      "342:\tlearn: 0.0133210\ttotal: 32.2s\tremaining: 2m 35s\n",
      "343:\tlearn: 0.0132526\ttotal: 32.3s\tremaining: 2m 35s\n",
      "344:\tlearn: 0.0132334\ttotal: 32.4s\tremaining: 2m 35s\n",
      "345:\tlearn: 0.0132092\ttotal: 32.5s\tremaining: 2m 35s\n",
      "346:\tlearn: 0.0131888\ttotal: 32.6s\tremaining: 2m 35s\n",
      "347:\tlearn: 0.0131762\ttotal: 32.7s\tremaining: 2m 35s\n",
      "348:\tlearn: 0.0131395\ttotal: 32.8s\tremaining: 2m 34s\n",
      "349:\tlearn: 0.0131044\ttotal: 32.9s\tremaining: 2m 34s\n",
      "350:\tlearn: 0.0130754\ttotal: 32.9s\tremaining: 2m 34s\n",
      "351:\tlearn: 0.0130615\ttotal: 33s\tremaining: 2m 34s\n",
      "352:\tlearn: 0.0130415\ttotal: 33.1s\tremaining: 2m 34s\n",
      "353:\tlearn: 0.0130070\ttotal: 33.2s\tremaining: 2m 34s\n",
      "354:\tlearn: 0.0129817\ttotal: 33.3s\tremaining: 2m 34s\n",
      "355:\tlearn: 0.0129717\ttotal: 33.4s\tremaining: 2m 34s\n",
      "356:\tlearn: 0.0129238\ttotal: 33.5s\tremaining: 2m 34s\n",
      "357:\tlearn: 0.0128766\ttotal: 33.6s\tremaining: 2m 34s\n",
      "358:\tlearn: 0.0128582\ttotal: 33.7s\tremaining: 2m 33s\n",
      "359:\tlearn: 0.0128507\ttotal: 33.7s\tremaining: 2m 33s\n",
      "360:\tlearn: 0.0128127\ttotal: 33.8s\tremaining: 2m 33s\n",
      "361:\tlearn: 0.0128012\ttotal: 33.9s\tremaining: 2m 33s\n",
      "362:\tlearn: 0.0127947\ttotal: 34s\tremaining: 2m 33s\n",
      "363:\tlearn: 0.0127875\ttotal: 34.1s\tremaining: 2m 33s\n",
      "364:\tlearn: 0.0127672\ttotal: 34.2s\tremaining: 2m 33s\n",
      "365:\tlearn: 0.0127609\ttotal: 34.2s\tremaining: 2m 32s\n",
      "366:\tlearn: 0.0127396\ttotal: 34.3s\tremaining: 2m 32s\n",
      "367:\tlearn: 0.0126853\ttotal: 34.4s\tremaining: 2m 32s\n",
      "368:\tlearn: 0.0126712\ttotal: 34.5s\tremaining: 2m 32s\n",
      "369:\tlearn: 0.0126488\ttotal: 34.6s\tremaining: 2m 32s\n",
      "370:\tlearn: 0.0126199\ttotal: 34.7s\tremaining: 2m 32s\n",
      "371:\tlearn: 0.0125851\ttotal: 34.8s\tremaining: 2m 32s\n",
      "372:\tlearn: 0.0125641\ttotal: 34.9s\tremaining: 2m 32s\n",
      "373:\tlearn: 0.0125357\ttotal: 35s\tremaining: 2m 32s\n",
      "374:\tlearn: 0.0125074\ttotal: 35.1s\tremaining: 2m 32s\n",
      "375:\tlearn: 0.0124835\ttotal: 35.2s\tremaining: 2m 32s\n",
      "376:\tlearn: 0.0124538\ttotal: 35.3s\tremaining: 2m 32s\n",
      "377:\tlearn: 0.0124064\ttotal: 35.4s\tremaining: 2m 32s\n",
      "378:\tlearn: 0.0123757\ttotal: 35.6s\tremaining: 2m 32s\n",
      "379:\tlearn: 0.0123690\ttotal: 35.7s\tremaining: 2m 32s\n",
      "380:\tlearn: 0.0123431\ttotal: 35.8s\tremaining: 2m 32s\n",
      "381:\tlearn: 0.0123246\ttotal: 35.9s\tremaining: 2m 32s\n",
      "382:\tlearn: 0.0123080\ttotal: 36s\tremaining: 2m 32s\n",
      "383:\tlearn: 0.0122981\ttotal: 36.1s\tremaining: 2m 31s\n",
      "384:\tlearn: 0.0122717\ttotal: 36.2s\tremaining: 2m 31s\n",
      "385:\tlearn: 0.0122540\ttotal: 36.3s\tremaining: 2m 31s\n",
      "386:\tlearn: 0.0122054\ttotal: 36.4s\tremaining: 2m 31s\n",
      "387:\tlearn: 0.0121586\ttotal: 36.5s\tremaining: 2m 31s\n",
      "388:\tlearn: 0.0121330\ttotal: 36.6s\tremaining: 2m 31s\n",
      "389:\tlearn: 0.0120985\ttotal: 36.6s\tremaining: 2m 31s\n",
      "390:\tlearn: 0.0120674\ttotal: 36.7s\tremaining: 2m 31s\n",
      "391:\tlearn: 0.0120549\ttotal: 36.8s\tremaining: 2m 31s\n",
      "392:\tlearn: 0.0120077\ttotal: 36.9s\tremaining: 2m 30s\n",
      "393:\tlearn: 0.0119972\ttotal: 37s\tremaining: 2m 30s\n",
      "394:\tlearn: 0.0119798\ttotal: 37.1s\tremaining: 2m 30s\n",
      "395:\tlearn: 0.0119534\ttotal: 37.2s\tremaining: 2m 30s\n",
      "396:\tlearn: 0.0119175\ttotal: 37.3s\tremaining: 2m 30s\n",
      "397:\tlearn: 0.0118988\ttotal: 37.3s\tremaining: 2m 30s\n",
      "398:\tlearn: 0.0118713\ttotal: 37.4s\tremaining: 2m 30s\n",
      "399:\tlearn: 0.0118348\ttotal: 37.5s\tremaining: 2m 30s\n",
      "400:\tlearn: 0.0118173\ttotal: 37.6s\tremaining: 2m 29s\n",
      "401:\tlearn: 0.0118099\ttotal: 37.7s\tremaining: 2m 29s\n",
      "402:\tlearn: 0.0117850\ttotal: 37.8s\tremaining: 2m 29s\n",
      "403:\tlearn: 0.0117625\ttotal: 37.9s\tremaining: 2m 29s\n",
      "404:\tlearn: 0.0117447\ttotal: 38s\tremaining: 2m 29s\n",
      "405:\tlearn: 0.0117156\ttotal: 38.1s\tremaining: 2m 29s\n",
      "406:\tlearn: 0.0117100\ttotal: 38.2s\tremaining: 2m 29s\n",
      "407:\tlearn: 0.0116811\ttotal: 38.3s\tremaining: 2m 29s\n",
      "408:\tlearn: 0.0116763\ttotal: 38.4s\tremaining: 2m 29s\n",
      "409:\tlearn: 0.0116521\ttotal: 38.5s\tremaining: 2m 29s\n",
      "410:\tlearn: 0.0116424\ttotal: 38.6s\tremaining: 2m 29s\n",
      "411:\tlearn: 0.0116206\ttotal: 38.7s\tremaining: 2m 29s\n",
      "412:\tlearn: 0.0116106\ttotal: 38.8s\tremaining: 2m 29s\n",
      "413:\tlearn: 0.0115923\ttotal: 38.9s\tremaining: 2m 28s\n",
      "414:\tlearn: 0.0115742\ttotal: 39s\tremaining: 2m 28s\n",
      "415:\tlearn: 0.0115429\ttotal: 39.1s\tremaining: 2m 28s\n",
      "416:\tlearn: 0.0115243\ttotal: 39.2s\tremaining: 2m 28s\n",
      "417:\tlearn: 0.0115147\ttotal: 39.3s\tremaining: 2m 28s\n",
      "418:\tlearn: 0.0115042\ttotal: 39.4s\tremaining: 2m 28s\n",
      "419:\tlearn: 0.0114729\ttotal: 39.4s\tremaining: 2m 28s\n",
      "420:\tlearn: 0.0114577\ttotal: 39.5s\tremaining: 2m 28s\n",
      "421:\tlearn: 0.0114462\ttotal: 39.6s\tremaining: 2m 28s\n",
      "422:\tlearn: 0.0114234\ttotal: 39.7s\tremaining: 2m 27s\n",
      "423:\tlearn: 0.0114155\ttotal: 39.8s\tremaining: 2m 27s\n",
      "424:\tlearn: 0.0113997\ttotal: 39.9s\tremaining: 2m 27s\n",
      "425:\tlearn: 0.0113659\ttotal: 40s\tremaining: 2m 27s\n",
      "426:\tlearn: 0.0113572\ttotal: 40.1s\tremaining: 2m 27s\n",
      "427:\tlearn: 0.0113444\ttotal: 40.2s\tremaining: 2m 27s\n",
      "428:\tlearn: 0.0113349\ttotal: 40.2s\tremaining: 2m 27s\n",
      "429:\tlearn: 0.0113015\ttotal: 40.3s\tremaining: 2m 27s\n",
      "430:\tlearn: 0.0112868\ttotal: 40.4s\tremaining: 2m 27s\n",
      "431:\tlearn: 0.0112642\ttotal: 40.5s\tremaining: 2m 27s\n",
      "432:\tlearn: 0.0112192\ttotal: 40.6s\tremaining: 2m 26s\n",
      "433:\tlearn: 0.0111654\ttotal: 40.7s\tremaining: 2m 26s\n",
      "434:\tlearn: 0.0111351\ttotal: 40.8s\tremaining: 2m 26s\n",
      "435:\tlearn: 0.0111183\ttotal: 40.9s\tremaining: 2m 26s\n",
      "436:\tlearn: 0.0111021\ttotal: 41s\tremaining: 2m 26s\n",
      "437:\tlearn: 0.0110657\ttotal: 41.1s\tremaining: 2m 26s\n",
      "438:\tlearn: 0.0110522\ttotal: 41.2s\tremaining: 2m 26s\n",
      "439:\tlearn: 0.0110484\ttotal: 41.2s\tremaining: 2m 26s\n",
      "440:\tlearn: 0.0110290\ttotal: 41.3s\tremaining: 2m 26s\n",
      "441:\tlearn: 0.0110070\ttotal: 41.4s\tremaining: 2m 25s\n",
      "442:\tlearn: 0.0109943\ttotal: 41.5s\tremaining: 2m 25s\n",
      "443:\tlearn: 0.0109729\ttotal: 41.6s\tremaining: 2m 25s\n",
      "444:\tlearn: 0.0109572\ttotal: 41.7s\tremaining: 2m 25s\n",
      "445:\tlearn: 0.0109503\ttotal: 41.8s\tremaining: 2m 25s\n",
      "446:\tlearn: 0.0109241\ttotal: 41.9s\tremaining: 2m 25s\n",
      "447:\tlearn: 0.0108970\ttotal: 42s\tremaining: 2m 25s\n",
      "448:\tlearn: 0.0108802\ttotal: 42.1s\tremaining: 2m 25s\n",
      "449:\tlearn: 0.0108603\ttotal: 42.1s\tremaining: 2m 25s\n",
      "450:\tlearn: 0.0108534\ttotal: 42.2s\tremaining: 2m 25s\n",
      "451:\tlearn: 0.0108340\ttotal: 42.3s\tremaining: 2m 25s\n",
      "452:\tlearn: 0.0108138\ttotal: 42.4s\tremaining: 2m 24s\n",
      "453:\tlearn: 0.0107904\ttotal: 42.5s\tremaining: 2m 24s\n",
      "454:\tlearn: 0.0107540\ttotal: 42.6s\tremaining: 2m 24s\n",
      "455:\tlearn: 0.0107511\ttotal: 42.7s\tremaining: 2m 24s\n",
      "456:\tlearn: 0.0107431\ttotal: 42.8s\tremaining: 2m 24s\n",
      "457:\tlearn: 0.0107322\ttotal: 42.9s\tremaining: 2m 24s\n",
      "458:\tlearn: 0.0107225\ttotal: 42.9s\tremaining: 2m 24s\n",
      "459:\tlearn: 0.0107069\ttotal: 43s\tremaining: 2m 24s\n",
      "460:\tlearn: 0.0106879\ttotal: 43.1s\tremaining: 2m 23s\n",
      "461:\tlearn: 0.0106774\ttotal: 43.2s\tremaining: 2m 23s\n",
      "462:\tlearn: 0.0106656\ttotal: 43.3s\tremaining: 2m 23s\n",
      "463:\tlearn: 0.0106518\ttotal: 43.4s\tremaining: 2m 23s\n",
      "464:\tlearn: 0.0106394\ttotal: 43.5s\tremaining: 2m 23s\n",
      "465:\tlearn: 0.0106247\ttotal: 43.6s\tremaining: 2m 23s\n",
      "466:\tlearn: 0.0105806\ttotal: 43.6s\tremaining: 2m 23s\n",
      "467:\tlearn: 0.0105713\ttotal: 43.7s\tremaining: 2m 23s\n",
      "468:\tlearn: 0.0105706\ttotal: 43.8s\tremaining: 2m 23s\n",
      "469:\tlearn: 0.0105359\ttotal: 43.9s\tremaining: 2m 22s\n",
      "470:\tlearn: 0.0105246\ttotal: 44s\tremaining: 2m 22s\n",
      "471:\tlearn: 0.0105105\ttotal: 44.1s\tremaining: 2m 22s\n",
      "472:\tlearn: 0.0105071\ttotal: 44.2s\tremaining: 2m 22s\n",
      "473:\tlearn: 0.0104912\ttotal: 44.2s\tremaining: 2m 22s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "474:\tlearn: 0.0104723\ttotal: 44.3s\tremaining: 2m 22s\n",
      "475:\tlearn: 0.0104594\ttotal: 44.4s\tremaining: 2m 22s\n",
      "476:\tlearn: 0.0104529\ttotal: 44.5s\tremaining: 2m 22s\n",
      "477:\tlearn: 0.0104202\ttotal: 44.6s\tremaining: 2m 21s\n",
      "478:\tlearn: 0.0103898\ttotal: 44.7s\tremaining: 2m 21s\n",
      "479:\tlearn: 0.0103683\ttotal: 44.8s\tremaining: 2m 21s\n",
      "480:\tlearn: 0.0103468\ttotal: 44.9s\tremaining: 2m 21s\n",
      "481:\tlearn: 0.0103408\ttotal: 44.9s\tremaining: 2m 21s\n",
      "482:\tlearn: 0.0103375\ttotal: 45s\tremaining: 2m 21s\n",
      "483:\tlearn: 0.0103234\ttotal: 45.1s\tremaining: 2m 21s\n",
      "484:\tlearn: 0.0103139\ttotal: 45.2s\tremaining: 2m 21s\n",
      "485:\tlearn: 0.0102802\ttotal: 45.3s\tremaining: 2m 21s\n",
      "486:\tlearn: 0.0102682\ttotal: 45.4s\tremaining: 2m 20s\n",
      "487:\tlearn: 0.0102481\ttotal: 45.5s\tremaining: 2m 20s\n",
      "488:\tlearn: 0.0102178\ttotal: 45.6s\tremaining: 2m 20s\n",
      "489:\tlearn: 0.0101913\ttotal: 45.7s\tremaining: 2m 20s\n",
      "490:\tlearn: 0.0101859\ttotal: 45.8s\tremaining: 2m 20s\n",
      "491:\tlearn: 0.0101726\ttotal: 45.9s\tremaining: 2m 20s\n",
      "492:\tlearn: 0.0101485\ttotal: 45.9s\tremaining: 2m 20s\n",
      "493:\tlearn: 0.0101406\ttotal: 46s\tremaining: 2m 20s\n",
      "494:\tlearn: 0.0101350\ttotal: 46.1s\tremaining: 2m 20s\n",
      "495:\tlearn: 0.0101139\ttotal: 46.2s\tremaining: 2m 20s\n",
      "496:\tlearn: 0.0101057\ttotal: 46.3s\tremaining: 2m 19s\n",
      "497:\tlearn: 0.0101024\ttotal: 46.4s\tremaining: 2m 19s\n",
      "498:\tlearn: 0.0100902\ttotal: 46.5s\tremaining: 2m 19s\n",
      "499:\tlearn: 0.0100838\ttotal: 46.5s\tremaining: 2m 19s\n",
      "500:\tlearn: 0.0100782\ttotal: 46.6s\tremaining: 2m 19s\n",
      "501:\tlearn: 0.0100738\ttotal: 46.7s\tremaining: 2m 19s\n",
      "502:\tlearn: 0.0100637\ttotal: 46.8s\tremaining: 2m 19s\n",
      "503:\tlearn: 0.0100455\ttotal: 46.9s\tremaining: 2m 19s\n",
      "504:\tlearn: 0.0100287\ttotal: 46.9s\tremaining: 2m 18s\n",
      "505:\tlearn: 0.0100210\ttotal: 47s\tremaining: 2m 18s\n",
      "506:\tlearn: 0.0100155\ttotal: 47.1s\tremaining: 2m 18s\n",
      "507:\tlearn: 0.0100000\ttotal: 47.2s\tremaining: 2m 18s\n",
      "508:\tlearn: 0.0099929\ttotal: 47.3s\tremaining: 2m 18s\n",
      "509:\tlearn: 0.0099840\ttotal: 47.4s\tremaining: 2m 18s\n",
      "510:\tlearn: 0.0099498\ttotal: 47.5s\tremaining: 2m 18s\n",
      "511:\tlearn: 0.0099352\ttotal: 47.6s\tremaining: 2m 18s\n",
      "512:\tlearn: 0.0099190\ttotal: 47.6s\tremaining: 2m 18s\n",
      "513:\tlearn: 0.0099142\ttotal: 47.7s\tremaining: 2m 18s\n",
      "514:\tlearn: 0.0099084\ttotal: 47.8s\tremaining: 2m 17s\n",
      "515:\tlearn: 0.0098893\ttotal: 47.9s\tremaining: 2m 17s\n",
      "516:\tlearn: 0.0098653\ttotal: 48s\tremaining: 2m 17s\n",
      "517:\tlearn: 0.0098609\ttotal: 48.1s\tremaining: 2m 17s\n",
      "518:\tlearn: 0.0098555\ttotal: 48.1s\tremaining: 2m 17s\n",
      "519:\tlearn: 0.0098459\ttotal: 48.2s\tremaining: 2m 17s\n",
      "520:\tlearn: 0.0098318\ttotal: 48.3s\tremaining: 2m 17s\n",
      "521:\tlearn: 0.0097974\ttotal: 48.4s\tremaining: 2m 17s\n",
      "522:\tlearn: 0.0097933\ttotal: 48.5s\tremaining: 2m 16s\n",
      "523:\tlearn: 0.0097868\ttotal: 48.6s\tremaining: 2m 16s\n",
      "524:\tlearn: 0.0097480\ttotal: 48.7s\tremaining: 2m 16s\n",
      "525:\tlearn: 0.0097205\ttotal: 48.8s\tremaining: 2m 16s\n",
      "526:\tlearn: 0.0096981\ttotal: 48.8s\tremaining: 2m 16s\n",
      "527:\tlearn: 0.0096885\ttotal: 48.9s\tremaining: 2m 16s\n",
      "528:\tlearn: 0.0096786\ttotal: 49s\tremaining: 2m 16s\n",
      "529:\tlearn: 0.0096611\ttotal: 49.1s\tremaining: 2m 16s\n",
      "530:\tlearn: 0.0096542\ttotal: 49.2s\tremaining: 2m 16s\n",
      "531:\tlearn: 0.0096465\ttotal: 49.3s\tremaining: 2m 15s\n",
      "532:\tlearn: 0.0096214\ttotal: 49.4s\tremaining: 2m 15s\n",
      "533:\tlearn: 0.0096065\ttotal: 49.4s\tremaining: 2m 15s\n",
      "534:\tlearn: 0.0095952\ttotal: 49.5s\tremaining: 2m 15s\n",
      "535:\tlearn: 0.0095851\ttotal: 49.6s\tremaining: 2m 15s\n",
      "536:\tlearn: 0.0095808\ttotal: 49.7s\tremaining: 2m 15s\n",
      "537:\tlearn: 0.0095714\ttotal: 49.8s\tremaining: 2m 15s\n",
      "538:\tlearn: 0.0095678\ttotal: 49.9s\tremaining: 2m 15s\n",
      "539:\tlearn: 0.0095600\ttotal: 50s\tremaining: 2m 15s\n",
      "540:\tlearn: 0.0095558\ttotal: 50.1s\tremaining: 2m 14s\n",
      "541:\tlearn: 0.0095347\ttotal: 50.1s\tremaining: 2m 14s\n",
      "542:\tlearn: 0.0095230\ttotal: 50.2s\tremaining: 2m 14s\n",
      "543:\tlearn: 0.0095001\ttotal: 50.3s\tremaining: 2m 14s\n",
      "544:\tlearn: 0.0094766\ttotal: 50.4s\tremaining: 2m 14s\n",
      "545:\tlearn: 0.0094567\ttotal: 50.5s\tremaining: 2m 14s\n",
      "546:\tlearn: 0.0094513\ttotal: 50.6s\tremaining: 2m 14s\n",
      "547:\tlearn: 0.0094430\ttotal: 50.7s\tremaining: 2m 14s\n",
      "548:\tlearn: 0.0094297\ttotal: 50.7s\tremaining: 2m 14s\n",
      "549:\tlearn: 0.0094179\ttotal: 50.8s\tremaining: 2m 14s\n",
      "550:\tlearn: 0.0094122\ttotal: 50.9s\tremaining: 2m 13s\n",
      "551:\tlearn: 0.0094002\ttotal: 51s\tremaining: 2m 13s\n",
      "552:\tlearn: 0.0093856\ttotal: 51.1s\tremaining: 2m 13s\n",
      "553:\tlearn: 0.0093586\ttotal: 51.2s\tremaining: 2m 13s\n",
      "554:\tlearn: 0.0093478\ttotal: 51.3s\tremaining: 2m 13s\n",
      "555:\tlearn: 0.0093419\ttotal: 51.4s\tremaining: 2m 13s\n",
      "556:\tlearn: 0.0093336\ttotal: 51.4s\tremaining: 2m 13s\n",
      "557:\tlearn: 0.0093298\ttotal: 51.5s\tremaining: 2m 13s\n",
      "558:\tlearn: 0.0093174\ttotal: 51.6s\tremaining: 2m 13s\n",
      "559:\tlearn: 0.0092906\ttotal: 51.7s\tremaining: 2m 12s\n",
      "560:\tlearn: 0.0092868\ttotal: 51.8s\tremaining: 2m 12s\n",
      "561:\tlearn: 0.0092739\ttotal: 51.9s\tremaining: 2m 12s\n",
      "562:\tlearn: 0.0092660\ttotal: 52s\tremaining: 2m 12s\n",
      "563:\tlearn: 0.0092601\ttotal: 52s\tremaining: 2m 12s\n",
      "564:\tlearn: 0.0092518\ttotal: 52.1s\tremaining: 2m 12s\n",
      "565:\tlearn: 0.0092430\ttotal: 52.2s\tremaining: 2m 12s\n",
      "566:\tlearn: 0.0092210\ttotal: 52.3s\tremaining: 2m 12s\n",
      "567:\tlearn: 0.0092130\ttotal: 52.4s\tremaining: 2m 12s\n",
      "568:\tlearn: 0.0092068\ttotal: 52.5s\tremaining: 2m 11s\n",
      "569:\tlearn: 0.0092059\ttotal: 52.6s\tremaining: 2m 11s\n",
      "570:\tlearn: 0.0091908\ttotal: 52.7s\tremaining: 2m 11s\n",
      "571:\tlearn: 0.0091689\ttotal: 52.8s\tremaining: 2m 11s\n",
      "572:\tlearn: 0.0091643\ttotal: 52.9s\tremaining: 2m 11s\n",
      "573:\tlearn: 0.0091510\ttotal: 53s\tremaining: 2m 11s\n",
      "574:\tlearn: 0.0091492\ttotal: 53.1s\tremaining: 2m 11s\n",
      "575:\tlearn: 0.0091347\ttotal: 53.3s\tremaining: 2m 11s\n",
      "576:\tlearn: 0.0091293\ttotal: 53.4s\tremaining: 2m 11s\n",
      "577:\tlearn: 0.0091268\ttotal: 53.5s\tremaining: 2m 11s\n",
      "578:\tlearn: 0.0091047\ttotal: 53.6s\tremaining: 2m 11s\n",
      "579:\tlearn: 0.0090822\ttotal: 53.7s\tremaining: 2m 11s\n",
      "580:\tlearn: 0.0090619\ttotal: 53.8s\tremaining: 2m 11s\n",
      "581:\tlearn: 0.0090473\ttotal: 53.9s\tremaining: 2m 11s\n",
      "582:\tlearn: 0.0090355\ttotal: 54s\tremaining: 2m 11s\n",
      "583:\tlearn: 0.0090255\ttotal: 54s\tremaining: 2m 11s\n",
      "584:\tlearn: 0.0090185\ttotal: 54.1s\tremaining: 2m 10s\n",
      "585:\tlearn: 0.0089798\ttotal: 54.2s\tremaining: 2m 10s\n",
      "586:\tlearn: 0.0089471\ttotal: 54.3s\tremaining: 2m 10s\n",
      "587:\tlearn: 0.0089391\ttotal: 54.4s\tremaining: 2m 10s\n",
      "588:\tlearn: 0.0089272\ttotal: 54.5s\tremaining: 2m 10s\n",
      "589:\tlearn: 0.0089022\ttotal: 54.6s\tremaining: 2m 10s\n",
      "590:\tlearn: 0.0088980\ttotal: 54.7s\tremaining: 2m 10s\n",
      "591:\tlearn: 0.0088816\ttotal: 54.8s\tremaining: 2m 10s\n",
      "592:\tlearn: 0.0088796\ttotal: 54.9s\tremaining: 2m 10s\n",
      "593:\tlearn: 0.0088750\ttotal: 54.9s\tremaining: 2m 10s\n",
      "594:\tlearn: 0.0088626\ttotal: 55s\tremaining: 2m 9s\n",
      "595:\tlearn: 0.0088464\ttotal: 55.1s\tremaining: 2m 9s\n",
      "596:\tlearn: 0.0088363\ttotal: 55.2s\tremaining: 2m 9s\n",
      "597:\tlearn: 0.0088049\ttotal: 55.3s\tremaining: 2m 9s\n",
      "598:\tlearn: 0.0087888\ttotal: 55.4s\tremaining: 2m 9s\n",
      "599:\tlearn: 0.0087719\ttotal: 55.5s\tremaining: 2m 9s\n",
      "600:\tlearn: 0.0087658\ttotal: 55.6s\tremaining: 2m 9s\n",
      "601:\tlearn: 0.0087619\ttotal: 55.7s\tremaining: 2m 9s\n",
      "602:\tlearn: 0.0087493\ttotal: 55.8s\tremaining: 2m 9s\n",
      "603:\tlearn: 0.0087305\ttotal: 55.9s\tremaining: 2m 9s\n",
      "604:\tlearn: 0.0087247\ttotal: 56s\tremaining: 2m 9s\n",
      "605:\tlearn: 0.0087148\ttotal: 56.1s\tremaining: 2m 8s\n",
      "606:\tlearn: 0.0087069\ttotal: 56.1s\tremaining: 2m 8s\n",
      "607:\tlearn: 0.0086565\ttotal: 56.2s\tremaining: 2m 8s\n",
      "608:\tlearn: 0.0086521\ttotal: 56.3s\tremaining: 2m 8s\n",
      "609:\tlearn: 0.0086473\ttotal: 56.4s\tremaining: 2m 8s\n",
      "610:\tlearn: 0.0086212\ttotal: 56.5s\tremaining: 2m 8s\n",
      "611:\tlearn: 0.0086008\ttotal: 56.6s\tremaining: 2m 8s\n",
      "612:\tlearn: 0.0085793\ttotal: 56.7s\tremaining: 2m 8s\n",
      "613:\tlearn: 0.0085687\ttotal: 56.8s\tremaining: 2m 8s\n",
      "614:\tlearn: 0.0085644\ttotal: 56.9s\tremaining: 2m 8s\n",
      "615:\tlearn: 0.0085621\ttotal: 56.9s\tremaining: 2m 7s\n",
      "616:\tlearn: 0.0085480\ttotal: 57s\tremaining: 2m 7s\n",
      "617:\tlearn: 0.0085386\ttotal: 57.1s\tremaining: 2m 7s\n",
      "618:\tlearn: 0.0085020\ttotal: 57.2s\tremaining: 2m 7s\n",
      "619:\tlearn: 0.0084945\ttotal: 57.3s\tremaining: 2m 7s\n",
      "620:\tlearn: 0.0084900\ttotal: 57.4s\tremaining: 2m 7s\n",
      "621:\tlearn: 0.0084852\ttotal: 57.5s\tremaining: 2m 7s\n",
      "622:\tlearn: 0.0084741\ttotal: 57.6s\tremaining: 2m 7s\n",
      "623:\tlearn: 0.0084423\ttotal: 57.6s\tremaining: 2m 7s\n",
      "624:\tlearn: 0.0084240\ttotal: 57.8s\tremaining: 2m 7s\n",
      "625:\tlearn: 0.0084161\ttotal: 57.8s\tremaining: 2m 6s\n",
      "626:\tlearn: 0.0084129\ttotal: 57.9s\tremaining: 2m 6s\n",
      "627:\tlearn: 0.0084097\ttotal: 58s\tremaining: 2m 6s\n",
      "628:\tlearn: 0.0084023\ttotal: 58.1s\tremaining: 2m 6s\n",
      "629:\tlearn: 0.0083981\ttotal: 58.2s\tremaining: 2m 6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630:\tlearn: 0.0083893\ttotal: 58.3s\tremaining: 2m 6s\n",
      "631:\tlearn: 0.0083875\ttotal: 58.3s\tremaining: 2m 6s\n",
      "632:\tlearn: 0.0083771\ttotal: 58.5s\tremaining: 2m 6s\n",
      "633:\tlearn: 0.0083750\ttotal: 58.6s\tremaining: 2m 6s\n",
      "634:\tlearn: 0.0083567\ttotal: 58.7s\tremaining: 2m 6s\n",
      "635:\tlearn: 0.0083491\ttotal: 58.8s\tremaining: 2m 6s\n",
      "636:\tlearn: 0.0083437\ttotal: 58.9s\tremaining: 2m 5s\n",
      "637:\tlearn: 0.0083391\ttotal: 59s\tremaining: 2m 5s\n",
      "638:\tlearn: 0.0083256\ttotal: 59.1s\tremaining: 2m 5s\n",
      "639:\tlearn: 0.0083210\ttotal: 59.2s\tremaining: 2m 5s\n",
      "640:\tlearn: 0.0083183\ttotal: 59.3s\tremaining: 2m 5s\n",
      "641:\tlearn: 0.0083155\ttotal: 59.4s\tremaining: 2m 5s\n",
      "642:\tlearn: 0.0083010\ttotal: 59.5s\tremaining: 2m 5s\n",
      "643:\tlearn: 0.0082969\ttotal: 59.6s\tremaining: 2m 5s\n",
      "644:\tlearn: 0.0082948\ttotal: 59.7s\tremaining: 2m 5s\n",
      "645:\tlearn: 0.0082796\ttotal: 59.8s\tremaining: 2m 5s\n",
      "646:\tlearn: 0.0082742\ttotal: 59.9s\tremaining: 2m 5s\n",
      "647:\tlearn: 0.0082685\ttotal: 59.9s\tremaining: 2m 5s\n",
      "648:\tlearn: 0.0082571\ttotal: 1m\tremaining: 2m 4s\n",
      "649:\tlearn: 0.0082504\ttotal: 1m\tremaining: 2m 4s\n",
      "650:\tlearn: 0.0082293\ttotal: 1m\tremaining: 2m 4s\n",
      "651:\tlearn: 0.0082086\ttotal: 1m\tremaining: 2m 4s\n",
      "652:\tlearn: 0.0082007\ttotal: 1m\tremaining: 2m 4s\n",
      "653:\tlearn: 0.0081834\ttotal: 1m\tremaining: 2m 4s\n",
      "654:\tlearn: 0.0081468\ttotal: 1m\tremaining: 2m 4s\n",
      "655:\tlearn: 0.0081329\ttotal: 1m\tremaining: 2m 4s\n",
      "656:\tlearn: 0.0081283\ttotal: 1m\tremaining: 2m 4s\n",
      "657:\tlearn: 0.0081234\ttotal: 1m\tremaining: 2m 4s\n",
      "658:\tlearn: 0.0081029\ttotal: 1m\tremaining: 2m 3s\n",
      "659:\tlearn: 0.0080983\ttotal: 1m 1s\tremaining: 2m 3s\n",
      "660:\tlearn: 0.0080800\ttotal: 1m 1s\tremaining: 2m 3s\n",
      "661:\tlearn: 0.0080649\ttotal: 1m 1s\tremaining: 2m 3s\n",
      "662:\tlearn: 0.0080617\ttotal: 1m 1s\tremaining: 2m 3s\n",
      "663:\tlearn: 0.0080566\ttotal: 1m 1s\tremaining: 2m 3s\n",
      "664:\tlearn: 0.0080546\ttotal: 1m 1s\tremaining: 2m 3s\n",
      "665:\tlearn: 0.0080307\ttotal: 1m 1s\tremaining: 2m 3s\n",
      "666:\tlearn: 0.0080227\ttotal: 1m 1s\tremaining: 2m 3s\n",
      "667:\tlearn: 0.0080191\ttotal: 1m 1s\tremaining: 2m 3s\n",
      "668:\tlearn: 0.0080147\ttotal: 1m 1s\tremaining: 2m 3s\n",
      "669:\tlearn: 0.0080110\ttotal: 1m 1s\tremaining: 2m 2s\n",
      "670:\tlearn: 0.0079978\ttotal: 1m 2s\tremaining: 2m 2s\n",
      "671:\tlearn: 0.0079795\ttotal: 1m 2s\tremaining: 2m 2s\n",
      "672:\tlearn: 0.0079742\ttotal: 1m 2s\tremaining: 2m 2s\n",
      "673:\tlearn: 0.0079572\ttotal: 1m 2s\tremaining: 2m 2s\n",
      "674:\tlearn: 0.0079562\ttotal: 1m 2s\tremaining: 2m 2s\n",
      "675:\tlearn: 0.0079369\ttotal: 1m 2s\tremaining: 2m 2s\n",
      "676:\tlearn: 0.0079278\ttotal: 1m 2s\tremaining: 2m 2s\n",
      "677:\tlearn: 0.0079220\ttotal: 1m 2s\tremaining: 2m 2s\n",
      "678:\tlearn: 0.0079195\ttotal: 1m 2s\tremaining: 2m 1s\n",
      "679:\tlearn: 0.0079147\ttotal: 1m 2s\tremaining: 2m 1s\n",
      "680:\tlearn: 0.0079033\ttotal: 1m 2s\tremaining: 2m 1s\n",
      "681:\tlearn: 0.0078954\ttotal: 1m 2s\tremaining: 2m 1s\n",
      "682:\tlearn: 0.0078734\ttotal: 1m 3s\tremaining: 2m 1s\n",
      "683:\tlearn: 0.0078660\ttotal: 1m 3s\tremaining: 2m 1s\n",
      "684:\tlearn: 0.0078637\ttotal: 1m 3s\tremaining: 2m 1s\n",
      "685:\tlearn: 0.0078542\ttotal: 1m 3s\tremaining: 2m 1s\n",
      "686:\tlearn: 0.0078125\ttotal: 1m 3s\tremaining: 2m 1s\n",
      "687:\tlearn: 0.0078095\ttotal: 1m 3s\tremaining: 2m 1s\n",
      "688:\tlearn: 0.0078039\ttotal: 1m 3s\tremaining: 2m 1s\n",
      "689:\tlearn: 0.0077963\ttotal: 1m 3s\tremaining: 2m\n",
      "690:\tlearn: 0.0077872\ttotal: 1m 3s\tremaining: 2m\n",
      "691:\tlearn: 0.0077732\ttotal: 1m 3s\tremaining: 2m\n",
      "692:\tlearn: 0.0077615\ttotal: 1m 3s\tremaining: 2m\n",
      "693:\tlearn: 0.0077577\ttotal: 1m 4s\tremaining: 2m\n",
      "694:\tlearn: 0.0077501\ttotal: 1m 4s\tremaining: 2m\n",
      "695:\tlearn: 0.0077474\ttotal: 1m 4s\tremaining: 2m\n",
      "696:\tlearn: 0.0077405\ttotal: 1m 4s\tremaining: 2m\n",
      "697:\tlearn: 0.0077340\ttotal: 1m 4s\tremaining: 2m\n",
      "698:\tlearn: 0.0077153\ttotal: 1m 4s\tremaining: 1m 59s\n",
      "699:\tlearn: 0.0077150\ttotal: 1m 4s\tremaining: 1m 59s\n",
      "700:\tlearn: 0.0077104\ttotal: 1m 4s\tremaining: 1m 59s\n",
      "701:\tlearn: 0.0076986\ttotal: 1m 4s\tremaining: 1m 59s\n",
      "702:\tlearn: 0.0076917\ttotal: 1m 4s\tremaining: 1m 59s\n",
      "703:\tlearn: 0.0076881\ttotal: 1m 4s\tremaining: 1m 59s\n",
      "704:\tlearn: 0.0076871\ttotal: 1m 4s\tremaining: 1m 59s\n",
      "705:\tlearn: 0.0076836\ttotal: 1m 5s\tremaining: 1m 59s\n",
      "706:\tlearn: 0.0076805\ttotal: 1m 5s\tremaining: 1m 59s\n",
      "707:\tlearn: 0.0076744\ttotal: 1m 5s\tremaining: 1m 59s\n",
      "708:\tlearn: 0.0076660\ttotal: 1m 5s\tremaining: 1m 58s\n",
      "709:\tlearn: 0.0076606\ttotal: 1m 5s\tremaining: 1m 58s\n",
      "710:\tlearn: 0.0076462\ttotal: 1m 5s\tremaining: 1m 58s\n",
      "711:\tlearn: 0.0076401\ttotal: 1m 5s\tremaining: 1m 58s\n",
      "712:\tlearn: 0.0076362\ttotal: 1m 5s\tremaining: 1m 58s\n",
      "713:\tlearn: 0.0076270\ttotal: 1m 5s\tremaining: 1m 58s\n",
      "714:\tlearn: 0.0076223\ttotal: 1m 5s\tremaining: 1m 58s\n",
      "715:\tlearn: 0.0076196\ttotal: 1m 5s\tremaining: 1m 58s\n",
      "716:\tlearn: 0.0076030\ttotal: 1m 5s\tremaining: 1m 58s\n",
      "717:\tlearn: 0.0075990\ttotal: 1m 6s\tremaining: 1m 57s\n",
      "718:\tlearn: 0.0075939\ttotal: 1m 6s\tremaining: 1m 57s\n",
      "719:\tlearn: 0.0075912\ttotal: 1m 6s\tremaining: 1m 57s\n",
      "720:\tlearn: 0.0075744\ttotal: 1m 6s\tremaining: 1m 57s\n",
      "721:\tlearn: 0.0075508\ttotal: 1m 6s\tremaining: 1m 57s\n",
      "722:\tlearn: 0.0075503\ttotal: 1m 6s\tremaining: 1m 57s\n",
      "723:\tlearn: 0.0075447\ttotal: 1m 6s\tremaining: 1m 57s\n",
      "724:\tlearn: 0.0075259\ttotal: 1m 6s\tremaining: 1m 57s\n",
      "725:\tlearn: 0.0074848\ttotal: 1m 6s\tremaining: 1m 57s\n",
      "726:\tlearn: 0.0074576\ttotal: 1m 6s\tremaining: 1m 57s\n",
      "727:\tlearn: 0.0074528\ttotal: 1m 6s\tremaining: 1m 57s\n",
      "728:\tlearn: 0.0074450\ttotal: 1m 7s\tremaining: 1m 56s\n",
      "729:\tlearn: 0.0074351\ttotal: 1m 7s\tremaining: 1m 56s\n",
      "730:\tlearn: 0.0074212\ttotal: 1m 7s\tremaining: 1m 56s\n",
      "731:\tlearn: 0.0074049\ttotal: 1m 7s\tremaining: 1m 56s\n",
      "732:\tlearn: 0.0073902\ttotal: 1m 7s\tremaining: 1m 56s\n",
      "733:\tlearn: 0.0073773\ttotal: 1m 7s\tremaining: 1m 56s\n",
      "734:\tlearn: 0.0073583\ttotal: 1m 7s\tremaining: 1m 56s\n",
      "735:\tlearn: 0.0073480\ttotal: 1m 7s\tremaining: 1m 56s\n",
      "736:\tlearn: 0.0073443\ttotal: 1m 7s\tremaining: 1m 56s\n",
      "737:\tlearn: 0.0073375\ttotal: 1m 7s\tremaining: 1m 56s\n",
      "738:\tlearn: 0.0073261\ttotal: 1m 7s\tremaining: 1m 55s\n",
      "739:\tlearn: 0.0073237\ttotal: 1m 8s\tremaining: 1m 55s\n",
      "740:\tlearn: 0.0073147\ttotal: 1m 8s\tremaining: 1m 55s\n",
      "741:\tlearn: 0.0073042\ttotal: 1m 8s\tremaining: 1m 55s\n",
      "742:\tlearn: 0.0073007\ttotal: 1m 8s\tremaining: 1m 55s\n",
      "743:\tlearn: 0.0072948\ttotal: 1m 8s\tremaining: 1m 55s\n",
      "744:\tlearn: 0.0072831\ttotal: 1m 8s\tremaining: 1m 55s\n",
      "745:\tlearn: 0.0072803\ttotal: 1m 8s\tremaining: 1m 55s\n",
      "746:\tlearn: 0.0072780\ttotal: 1m 8s\tremaining: 1m 55s\n",
      "747:\tlearn: 0.0072751\ttotal: 1m 8s\tremaining: 1m 55s\n",
      "748:\tlearn: 0.0072724\ttotal: 1m 8s\tremaining: 1m 54s\n",
      "749:\tlearn: 0.0072651\ttotal: 1m 8s\tremaining: 1m 54s\n",
      "750:\tlearn: 0.0072597\ttotal: 1m 9s\tremaining: 1m 54s\n",
      "751:\tlearn: 0.0072538\ttotal: 1m 9s\tremaining: 1m 54s\n",
      "752:\tlearn: 0.0072475\ttotal: 1m 9s\tremaining: 1m 54s\n",
      "753:\tlearn: 0.0072437\ttotal: 1m 9s\tremaining: 1m 54s\n",
      "754:\tlearn: 0.0072430\ttotal: 1m 9s\tremaining: 1m 54s\n",
      "755:\tlearn: 0.0072354\ttotal: 1m 9s\tremaining: 1m 54s\n",
      "756:\tlearn: 0.0072328\ttotal: 1m 9s\tremaining: 1m 54s\n",
      "757:\tlearn: 0.0072299\ttotal: 1m 9s\tremaining: 1m 54s\n",
      "758:\tlearn: 0.0072206\ttotal: 1m 9s\tremaining: 1m 53s\n",
      "759:\tlearn: 0.0072118\ttotal: 1m 9s\tremaining: 1m 53s\n",
      "760:\tlearn: 0.0072011\ttotal: 1m 9s\tremaining: 1m 53s\n",
      "761:\tlearn: 0.0071985\ttotal: 1m 9s\tremaining: 1m 53s\n",
      "762:\tlearn: 0.0071959\ttotal: 1m 10s\tremaining: 1m 53s\n",
      "763:\tlearn: 0.0071881\ttotal: 1m 10s\tremaining: 1m 53s\n",
      "764:\tlearn: 0.0071848\ttotal: 1m 10s\tremaining: 1m 53s\n",
      "765:\tlearn: 0.0071703\ttotal: 1m 10s\tremaining: 1m 53s\n",
      "766:\tlearn: 0.0071611\ttotal: 1m 10s\tremaining: 1m 53s\n",
      "767:\tlearn: 0.0071600\ttotal: 1m 10s\tremaining: 1m 53s\n",
      "768:\tlearn: 0.0071422\ttotal: 1m 10s\tremaining: 1m 52s\n",
      "769:\tlearn: 0.0071240\ttotal: 1m 10s\tremaining: 1m 52s\n",
      "770:\tlearn: 0.0071187\ttotal: 1m 10s\tremaining: 1m 52s\n",
      "771:\tlearn: 0.0071101\ttotal: 1m 10s\tremaining: 1m 52s\n",
      "772:\tlearn: 0.0071023\ttotal: 1m 10s\tremaining: 1m 52s\n",
      "773:\tlearn: 0.0070973\ttotal: 1m 11s\tremaining: 1m 52s\n",
      "774:\tlearn: 0.0070937\ttotal: 1m 11s\tremaining: 1m 52s\n",
      "775:\tlearn: 0.0070906\ttotal: 1m 11s\tremaining: 1m 52s\n",
      "776:\tlearn: 0.0070837\ttotal: 1m 11s\tremaining: 1m 52s\n",
      "777:\tlearn: 0.0070769\ttotal: 1m 11s\tremaining: 1m 52s\n",
      "778:\tlearn: 0.0070669\ttotal: 1m 11s\tremaining: 1m 52s\n",
      "779:\tlearn: 0.0070564\ttotal: 1m 11s\tremaining: 1m 51s\n",
      "780:\tlearn: 0.0070544\ttotal: 1m 11s\tremaining: 1m 51s\n",
      "781:\tlearn: 0.0070447\ttotal: 1m 11s\tremaining: 1m 51s\n",
      "782:\tlearn: 0.0070413\ttotal: 1m 11s\tremaining: 1m 51s\n",
      "783:\tlearn: 0.0070386\ttotal: 1m 11s\tremaining: 1m 51s\n",
      "784:\tlearn: 0.0070303\ttotal: 1m 12s\tremaining: 1m 51s\n",
      "785:\tlearn: 0.0070242\ttotal: 1m 12s\tremaining: 1m 51s\n",
      "786:\tlearn: 0.0070167\ttotal: 1m 12s\tremaining: 1m 51s\n",
      "787:\tlearn: 0.0070024\ttotal: 1m 12s\tremaining: 1m 51s\n",
      "788:\tlearn: 0.0069890\ttotal: 1m 12s\tremaining: 1m 51s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "789:\tlearn: 0.0069846\ttotal: 1m 12s\tremaining: 1m 50s\n",
      "790:\tlearn: 0.0069705\ttotal: 1m 12s\tremaining: 1m 50s\n",
      "791:\tlearn: 0.0069668\ttotal: 1m 12s\tremaining: 1m 50s\n",
      "792:\tlearn: 0.0069566\ttotal: 1m 12s\tremaining: 1m 50s\n",
      "793:\tlearn: 0.0069465\ttotal: 1m 12s\tremaining: 1m 50s\n",
      "794:\tlearn: 0.0069387\ttotal: 1m 12s\tremaining: 1m 50s\n",
      "795:\tlearn: 0.0069379\ttotal: 1m 12s\tremaining: 1m 50s\n",
      "796:\tlearn: 0.0069365\ttotal: 1m 13s\tremaining: 1m 50s\n",
      "797:\tlearn: 0.0069301\ttotal: 1m 13s\tremaining: 1m 50s\n",
      "798:\tlearn: 0.0069278\ttotal: 1m 13s\tremaining: 1m 50s\n",
      "799:\tlearn: 0.0069193\ttotal: 1m 13s\tremaining: 1m 50s\n",
      "800:\tlearn: 0.0069075\ttotal: 1m 13s\tremaining: 1m 49s\n",
      "801:\tlearn: 0.0069056\ttotal: 1m 13s\tremaining: 1m 49s\n",
      "802:\tlearn: 0.0069005\ttotal: 1m 13s\tremaining: 1m 49s\n",
      "803:\tlearn: 0.0068987\ttotal: 1m 13s\tremaining: 1m 49s\n",
      "804:\tlearn: 0.0068895\ttotal: 1m 13s\tremaining: 1m 49s\n",
      "805:\tlearn: 0.0068859\ttotal: 1m 13s\tremaining: 1m 49s\n",
      "806:\tlearn: 0.0068821\ttotal: 1m 13s\tremaining: 1m 49s\n",
      "807:\tlearn: 0.0068762\ttotal: 1m 14s\tremaining: 1m 49s\n",
      "808:\tlearn: 0.0068607\ttotal: 1m 14s\tremaining: 1m 49s\n",
      "809:\tlearn: 0.0068456\ttotal: 1m 14s\tremaining: 1m 49s\n",
      "810:\tlearn: 0.0068344\ttotal: 1m 14s\tremaining: 1m 48s\n",
      "811:\tlearn: 0.0068215\ttotal: 1m 14s\tremaining: 1m 48s\n",
      "812:\tlearn: 0.0068187\ttotal: 1m 14s\tremaining: 1m 48s\n",
      "813:\tlearn: 0.0068121\ttotal: 1m 14s\tremaining: 1m 48s\n",
      "814:\tlearn: 0.0068062\ttotal: 1m 14s\tremaining: 1m 48s\n",
      "815:\tlearn: 0.0067907\ttotal: 1m 14s\tremaining: 1m 48s\n",
      "816:\tlearn: 0.0067872\ttotal: 1m 14s\tremaining: 1m 48s\n",
      "817:\tlearn: 0.0067768\ttotal: 1m 14s\tremaining: 1m 48s\n",
      "818:\tlearn: 0.0067645\ttotal: 1m 15s\tremaining: 1m 48s\n",
      "819:\tlearn: 0.0067536\ttotal: 1m 15s\tremaining: 1m 48s\n",
      "820:\tlearn: 0.0067478\ttotal: 1m 15s\tremaining: 1m 47s\n",
      "821:\tlearn: 0.0067450\ttotal: 1m 15s\tremaining: 1m 47s\n",
      "822:\tlearn: 0.0067387\ttotal: 1m 15s\tremaining: 1m 47s\n",
      "823:\tlearn: 0.0067359\ttotal: 1m 15s\tremaining: 1m 47s\n",
      "824:\tlearn: 0.0067322\ttotal: 1m 15s\tremaining: 1m 47s\n",
      "825:\tlearn: 0.0067290\ttotal: 1m 15s\tremaining: 1m 47s\n",
      "826:\tlearn: 0.0067248\ttotal: 1m 15s\tremaining: 1m 47s\n",
      "827:\tlearn: 0.0067226\ttotal: 1m 15s\tremaining: 1m 47s\n",
      "828:\tlearn: 0.0067127\ttotal: 1m 15s\tremaining: 1m 47s\n",
      "829:\tlearn: 0.0067080\ttotal: 1m 15s\tremaining: 1m 47s\n",
      "830:\tlearn: 0.0067040\ttotal: 1m 16s\tremaining: 1m 46s\n",
      "831:\tlearn: 0.0067012\ttotal: 1m 16s\tremaining: 1m 46s\n",
      "832:\tlearn: 0.0066832\ttotal: 1m 16s\tremaining: 1m 46s\n",
      "833:\tlearn: 0.0066666\ttotal: 1m 16s\tremaining: 1m 46s\n",
      "834:\tlearn: 0.0066540\ttotal: 1m 16s\tremaining: 1m 46s\n",
      "835:\tlearn: 0.0066471\ttotal: 1m 16s\tremaining: 1m 46s\n",
      "836:\tlearn: 0.0066456\ttotal: 1m 16s\tremaining: 1m 46s\n",
      "837:\tlearn: 0.0066406\ttotal: 1m 16s\tremaining: 1m 46s\n",
      "838:\tlearn: 0.0066371\ttotal: 1m 16s\tremaining: 1m 46s\n",
      "839:\tlearn: 0.0066335\ttotal: 1m 16s\tremaining: 1m 46s\n",
      "840:\tlearn: 0.0066191\ttotal: 1m 16s\tremaining: 1m 46s\n",
      "841:\tlearn: 0.0066121\ttotal: 1m 16s\tremaining: 1m 45s\n",
      "842:\tlearn: 0.0066076\ttotal: 1m 17s\tremaining: 1m 45s\n",
      "843:\tlearn: 0.0066010\ttotal: 1m 17s\tremaining: 1m 45s\n",
      "844:\tlearn: 0.0065680\ttotal: 1m 17s\tremaining: 1m 45s\n",
      "845:\tlearn: 0.0065625\ttotal: 1m 17s\tremaining: 1m 45s\n",
      "846:\tlearn: 0.0065445\ttotal: 1m 17s\tremaining: 1m 45s\n",
      "847:\tlearn: 0.0065342\ttotal: 1m 17s\tremaining: 1m 45s\n",
      "848:\tlearn: 0.0065337\ttotal: 1m 17s\tremaining: 1m 45s\n",
      "849:\tlearn: 0.0065305\ttotal: 1m 17s\tremaining: 1m 45s\n",
      "850:\tlearn: 0.0065136\ttotal: 1m 17s\tremaining: 1m 45s\n",
      "851:\tlearn: 0.0065111\ttotal: 1m 17s\tremaining: 1m 44s\n",
      "852:\tlearn: 0.0065096\ttotal: 1m 17s\tremaining: 1m 44s\n",
      "853:\tlearn: 0.0065080\ttotal: 1m 18s\tremaining: 1m 44s\n",
      "854:\tlearn: 0.0065060\ttotal: 1m 18s\tremaining: 1m 44s\n",
      "855:\tlearn: 0.0064971\ttotal: 1m 18s\tremaining: 1m 44s\n",
      "856:\tlearn: 0.0064916\ttotal: 1m 18s\tremaining: 1m 44s\n",
      "857:\tlearn: 0.0064877\ttotal: 1m 18s\tremaining: 1m 44s\n",
      "858:\tlearn: 0.0064835\ttotal: 1m 18s\tremaining: 1m 44s\n",
      "859:\tlearn: 0.0064628\ttotal: 1m 18s\tremaining: 1m 44s\n",
      "860:\tlearn: 0.0064573\ttotal: 1m 18s\tremaining: 1m 44s\n",
      "861:\tlearn: 0.0064441\ttotal: 1m 18s\tremaining: 1m 44s\n",
      "862:\tlearn: 0.0064354\ttotal: 1m 18s\tremaining: 1m 43s\n",
      "863:\tlearn: 0.0064291\ttotal: 1m 18s\tremaining: 1m 43s\n",
      "864:\tlearn: 0.0064264\ttotal: 1m 19s\tremaining: 1m 43s\n",
      "865:\tlearn: 0.0064199\ttotal: 1m 19s\tremaining: 1m 43s\n",
      "866:\tlearn: 0.0064129\ttotal: 1m 19s\tremaining: 1m 43s\n",
      "867:\tlearn: 0.0064110\ttotal: 1m 19s\tremaining: 1m 43s\n",
      "868:\tlearn: 0.0064025\ttotal: 1m 19s\tremaining: 1m 43s\n",
      "869:\tlearn: 0.0063992\ttotal: 1m 19s\tremaining: 1m 43s\n",
      "870:\tlearn: 0.0063924\ttotal: 1m 19s\tremaining: 1m 43s\n",
      "871:\tlearn: 0.0063848\ttotal: 1m 19s\tremaining: 1m 43s\n",
      "872:\tlearn: 0.0063746\ttotal: 1m 19s\tremaining: 1m 42s\n",
      "873:\tlearn: 0.0063634\ttotal: 1m 19s\tremaining: 1m 42s\n",
      "874:\tlearn: 0.0063600\ttotal: 1m 19s\tremaining: 1m 42s\n",
      "875:\tlearn: 0.0063556\ttotal: 1m 20s\tremaining: 1m 42s\n",
      "876:\tlearn: 0.0063531\ttotal: 1m 20s\tremaining: 1m 42s\n",
      "877:\tlearn: 0.0063476\ttotal: 1m 20s\tremaining: 1m 42s\n",
      "878:\tlearn: 0.0063468\ttotal: 1m 20s\tremaining: 1m 42s\n",
      "879:\tlearn: 0.0063449\ttotal: 1m 20s\tremaining: 1m 42s\n",
      "880:\tlearn: 0.0063406\ttotal: 1m 20s\tremaining: 1m 42s\n",
      "881:\tlearn: 0.0063344\ttotal: 1m 20s\tremaining: 1m 42s\n",
      "882:\tlearn: 0.0063329\ttotal: 1m 20s\tremaining: 1m 42s\n",
      "883:\tlearn: 0.0063265\ttotal: 1m 20s\tremaining: 1m 41s\n",
      "884:\tlearn: 0.0063229\ttotal: 1m 20s\tremaining: 1m 41s\n",
      "885:\tlearn: 0.0063206\ttotal: 1m 20s\tremaining: 1m 41s\n",
      "886:\tlearn: 0.0063171\ttotal: 1m 21s\tremaining: 1m 41s\n",
      "887:\tlearn: 0.0063131\ttotal: 1m 21s\tremaining: 1m 41s\n",
      "888:\tlearn: 0.0063114\ttotal: 1m 21s\tremaining: 1m 41s\n",
      "889:\tlearn: 0.0063030\ttotal: 1m 21s\tremaining: 1m 41s\n",
      "890:\tlearn: 0.0062978\ttotal: 1m 21s\tremaining: 1m 41s\n",
      "891:\tlearn: 0.0062910\ttotal: 1m 21s\tremaining: 1m 41s\n",
      "892:\tlearn: 0.0062819\ttotal: 1m 21s\tremaining: 1m 41s\n",
      "893:\tlearn: 0.0062739\ttotal: 1m 21s\tremaining: 1m 40s\n",
      "894:\tlearn: 0.0062692\ttotal: 1m 21s\tremaining: 1m 40s\n",
      "895:\tlearn: 0.0062666\ttotal: 1m 21s\tremaining: 1m 40s\n",
      "896:\tlearn: 0.0062631\ttotal: 1m 21s\tremaining: 1m 40s\n",
      "897:\tlearn: 0.0062500\ttotal: 1m 21s\tremaining: 1m 40s\n",
      "898:\tlearn: 0.0062391\ttotal: 1m 22s\tremaining: 1m 40s\n",
      "899:\tlearn: 0.0062356\ttotal: 1m 22s\tremaining: 1m 40s\n",
      "900:\tlearn: 0.0062335\ttotal: 1m 22s\tremaining: 1m 40s\n",
      "901:\tlearn: 0.0062205\ttotal: 1m 22s\tremaining: 1m 40s\n",
      "902:\tlearn: 0.0062158\ttotal: 1m 22s\tremaining: 1m 40s\n",
      "903:\tlearn: 0.0062129\ttotal: 1m 22s\tremaining: 1m 40s\n",
      "904:\tlearn: 0.0062101\ttotal: 1m 22s\tremaining: 1m 39s\n",
      "905:\tlearn: 0.0062037\ttotal: 1m 22s\tremaining: 1m 39s\n",
      "906:\tlearn: 0.0061961\ttotal: 1m 22s\tremaining: 1m 39s\n",
      "907:\tlearn: 0.0061890\ttotal: 1m 22s\tremaining: 1m 39s\n",
      "908:\tlearn: 0.0061864\ttotal: 1m 22s\tremaining: 1m 39s\n",
      "909:\tlearn: 0.0061811\ttotal: 1m 23s\tremaining: 1m 39s\n",
      "910:\tlearn: 0.0061775\ttotal: 1m 23s\tremaining: 1m 39s\n",
      "911:\tlearn: 0.0061635\ttotal: 1m 23s\tremaining: 1m 39s\n",
      "912:\tlearn: 0.0061581\ttotal: 1m 23s\tremaining: 1m 39s\n",
      "913:\tlearn: 0.0061491\ttotal: 1m 23s\tremaining: 1m 39s\n",
      "914:\tlearn: 0.0061477\ttotal: 1m 23s\tremaining: 1m 38s\n",
      "915:\tlearn: 0.0061435\ttotal: 1m 23s\tremaining: 1m 38s\n",
      "916:\tlearn: 0.0061387\ttotal: 1m 23s\tremaining: 1m 38s\n",
      "917:\tlearn: 0.0061339\ttotal: 1m 23s\tremaining: 1m 38s\n",
      "918:\tlearn: 0.0061303\ttotal: 1m 23s\tremaining: 1m 38s\n",
      "919:\tlearn: 0.0061199\ttotal: 1m 23s\tremaining: 1m 38s\n",
      "920:\tlearn: 0.0061153\ttotal: 1m 23s\tremaining: 1m 38s\n",
      "921:\tlearn: 0.0061119\ttotal: 1m 24s\tremaining: 1m 38s\n",
      "922:\tlearn: 0.0060975\ttotal: 1m 24s\tremaining: 1m 38s\n",
      "923:\tlearn: 0.0060937\ttotal: 1m 24s\tremaining: 1m 38s\n",
      "924:\tlearn: 0.0060890\ttotal: 1m 24s\tremaining: 1m 38s\n",
      "925:\tlearn: 0.0060861\ttotal: 1m 24s\tremaining: 1m 37s\n",
      "926:\tlearn: 0.0060807\ttotal: 1m 24s\tremaining: 1m 37s\n",
      "927:\tlearn: 0.0060733\ttotal: 1m 24s\tremaining: 1m 37s\n",
      "928:\tlearn: 0.0060660\ttotal: 1m 24s\tremaining: 1m 37s\n",
      "929:\tlearn: 0.0060604\ttotal: 1m 24s\tremaining: 1m 37s\n",
      "930:\tlearn: 0.0060523\ttotal: 1m 24s\tremaining: 1m 37s\n",
      "931:\tlearn: 0.0060499\ttotal: 1m 24s\tremaining: 1m 37s\n",
      "932:\tlearn: 0.0060461\ttotal: 1m 25s\tremaining: 1m 37s\n",
      "933:\tlearn: 0.0060453\ttotal: 1m 25s\tremaining: 1m 37s\n",
      "934:\tlearn: 0.0060398\ttotal: 1m 25s\tremaining: 1m 37s\n",
      "935:\tlearn: 0.0060379\ttotal: 1m 25s\tremaining: 1m 37s\n",
      "936:\tlearn: 0.0060323\ttotal: 1m 25s\tremaining: 1m 36s\n",
      "937:\tlearn: 0.0060309\ttotal: 1m 25s\tremaining: 1m 36s\n",
      "938:\tlearn: 0.0060280\ttotal: 1m 25s\tremaining: 1m 36s\n",
      "939:\tlearn: 0.0060227\ttotal: 1m 25s\tremaining: 1m 36s\n",
      "940:\tlearn: 0.0060066\ttotal: 1m 25s\tremaining: 1m 36s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941:\tlearn: 0.0060043\ttotal: 1m 25s\tremaining: 1m 36s\n",
      "942:\tlearn: 0.0060004\ttotal: 1m 25s\tremaining: 1m 36s\n",
      "943:\tlearn: 0.0059982\ttotal: 1m 26s\tremaining: 1m 36s\n",
      "944:\tlearn: 0.0059861\ttotal: 1m 26s\tremaining: 1m 36s\n",
      "945:\tlearn: 0.0059793\ttotal: 1m 26s\tremaining: 1m 36s\n",
      "946:\tlearn: 0.0059762\ttotal: 1m 26s\tremaining: 1m 36s\n",
      "947:\tlearn: 0.0059727\ttotal: 1m 26s\tremaining: 1m 35s\n",
      "948:\tlearn: 0.0059716\ttotal: 1m 26s\tremaining: 1m 35s\n",
      "949:\tlearn: 0.0059677\ttotal: 1m 26s\tremaining: 1m 35s\n",
      "950:\tlearn: 0.0059667\ttotal: 1m 26s\tremaining: 1m 35s\n",
      "951:\tlearn: 0.0059634\ttotal: 1m 26s\tremaining: 1m 35s\n",
      "952:\tlearn: 0.0059609\ttotal: 1m 26s\tremaining: 1m 35s\n",
      "953:\tlearn: 0.0059586\ttotal: 1m 26s\tremaining: 1m 35s\n",
      "954:\tlearn: 0.0059516\ttotal: 1m 27s\tremaining: 1m 35s\n",
      "955:\tlearn: 0.0059491\ttotal: 1m 27s\tremaining: 1m 35s\n",
      "956:\tlearn: 0.0059464\ttotal: 1m 27s\tremaining: 1m 35s\n",
      "957:\tlearn: 0.0059408\ttotal: 1m 27s\tremaining: 1m 34s\n",
      "958:\tlearn: 0.0059394\ttotal: 1m 27s\tremaining: 1m 34s\n",
      "959:\tlearn: 0.0059358\ttotal: 1m 27s\tremaining: 1m 34s\n",
      "960:\tlearn: 0.0059306\ttotal: 1m 27s\tremaining: 1m 34s\n",
      "961:\tlearn: 0.0059176\ttotal: 1m 27s\tremaining: 1m 34s\n",
      "962:\tlearn: 0.0059098\ttotal: 1m 27s\tremaining: 1m 34s\n",
      "963:\tlearn: 0.0059048\ttotal: 1m 27s\tremaining: 1m 34s\n",
      "964:\tlearn: 0.0059023\ttotal: 1m 27s\tremaining: 1m 34s\n",
      "965:\tlearn: 0.0058898\ttotal: 1m 27s\tremaining: 1m 34s\n",
      "966:\tlearn: 0.0058867\ttotal: 1m 28s\tremaining: 1m 34s\n",
      "967:\tlearn: 0.0058752\ttotal: 1m 28s\tremaining: 1m 33s\n",
      "968:\tlearn: 0.0058650\ttotal: 1m 28s\tremaining: 1m 33s\n",
      "969:\tlearn: 0.0058535\ttotal: 1m 28s\tremaining: 1m 33s\n",
      "970:\tlearn: 0.0058483\ttotal: 1m 28s\tremaining: 1m 33s\n",
      "971:\tlearn: 0.0058397\ttotal: 1m 28s\tremaining: 1m 33s\n",
      "972:\tlearn: 0.0058365\ttotal: 1m 28s\tremaining: 1m 33s\n",
      "973:\tlearn: 0.0058356\ttotal: 1m 28s\tremaining: 1m 33s\n",
      "974:\tlearn: 0.0058226\ttotal: 1m 28s\tremaining: 1m 33s\n",
      "975:\tlearn: 0.0058197\ttotal: 1m 28s\tremaining: 1m 33s\n",
      "976:\tlearn: 0.0058149\ttotal: 1m 28s\tremaining: 1m 33s\n",
      "977:\tlearn: 0.0058021\ttotal: 1m 29s\tremaining: 1m 33s\n",
      "978:\tlearn: 0.0057979\ttotal: 1m 29s\tremaining: 1m 32s\n",
      "979:\tlearn: 0.0057878\ttotal: 1m 29s\tremaining: 1m 32s\n",
      "980:\tlearn: 0.0057852\ttotal: 1m 29s\tremaining: 1m 32s\n",
      "981:\tlearn: 0.0057805\ttotal: 1m 29s\tremaining: 1m 32s\n",
      "982:\tlearn: 0.0057792\ttotal: 1m 29s\tremaining: 1m 32s\n",
      "983:\tlearn: 0.0057642\ttotal: 1m 29s\tremaining: 1m 32s\n",
      "984:\tlearn: 0.0057559\ttotal: 1m 29s\tremaining: 1m 32s\n",
      "985:\tlearn: 0.0057547\ttotal: 1m 29s\tremaining: 1m 32s\n",
      "986:\tlearn: 0.0057412\ttotal: 1m 29s\tremaining: 1m 32s\n",
      "987:\tlearn: 0.0057305\ttotal: 1m 29s\tremaining: 1m 32s\n",
      "988:\tlearn: 0.0057270\ttotal: 1m 29s\tremaining: 1m 31s\n",
      "989:\tlearn: 0.0057243\ttotal: 1m 30s\tremaining: 1m 31s\n",
      "990:\tlearn: 0.0057213\ttotal: 1m 30s\tremaining: 1m 31s\n",
      "991:\tlearn: 0.0057174\ttotal: 1m 30s\tremaining: 1m 31s\n",
      "992:\tlearn: 0.0057147\ttotal: 1m 30s\tremaining: 1m 31s\n",
      "993:\tlearn: 0.0057136\ttotal: 1m 30s\tremaining: 1m 31s\n",
      "994:\tlearn: 0.0057050\ttotal: 1m 30s\tremaining: 1m 31s\n",
      "995:\tlearn: 0.0056929\ttotal: 1m 30s\tremaining: 1m 31s\n",
      "996:\tlearn: 0.0056826\ttotal: 1m 30s\tremaining: 1m 31s\n",
      "997:\tlearn: 0.0056730\ttotal: 1m 30s\tremaining: 1m 31s\n",
      "998:\tlearn: 0.0056695\ttotal: 1m 30s\tremaining: 1m 31s\n",
      "999:\tlearn: 0.0056629\ttotal: 1m 30s\tremaining: 1m 30s\n",
      "1000:\tlearn: 0.0056616\ttotal: 1m 31s\tremaining: 1m 30s\n",
      "1001:\tlearn: 0.0056575\ttotal: 1m 31s\tremaining: 1m 30s\n",
      "1002:\tlearn: 0.0056554\ttotal: 1m 31s\tremaining: 1m 30s\n",
      "1003:\tlearn: 0.0056352\ttotal: 1m 31s\tremaining: 1m 30s\n",
      "1004:\tlearn: 0.0056338\ttotal: 1m 31s\tremaining: 1m 30s\n",
      "1005:\tlearn: 0.0056201\ttotal: 1m 31s\tremaining: 1m 30s\n",
      "1006:\tlearn: 0.0056138\ttotal: 1m 31s\tremaining: 1m 30s\n",
      "1007:\tlearn: 0.0056109\ttotal: 1m 31s\tremaining: 1m 30s\n",
      "1008:\tlearn: 0.0056070\ttotal: 1m 31s\tremaining: 1m 30s\n",
      "1009:\tlearn: 0.0056052\ttotal: 1m 31s\tremaining: 1m 30s\n",
      "1010:\tlearn: 0.0055981\ttotal: 1m 31s\tremaining: 1m 29s\n",
      "1011:\tlearn: 0.0055956\ttotal: 1m 32s\tremaining: 1m 29s\n",
      "1012:\tlearn: 0.0055914\ttotal: 1m 32s\tremaining: 1m 29s\n",
      "1013:\tlearn: 0.0055876\ttotal: 1m 32s\tremaining: 1m 29s\n",
      "1014:\tlearn: 0.0055788\ttotal: 1m 32s\tremaining: 1m 29s\n",
      "1015:\tlearn: 0.0055759\ttotal: 1m 32s\tremaining: 1m 29s\n",
      "1016:\tlearn: 0.0055737\ttotal: 1m 32s\tremaining: 1m 29s\n",
      "1017:\tlearn: 0.0055674\ttotal: 1m 32s\tremaining: 1m 29s\n",
      "1018:\tlearn: 0.0055562\ttotal: 1m 32s\tremaining: 1m 29s\n",
      "1019:\tlearn: 0.0055498\ttotal: 1m 32s\tremaining: 1m 29s\n",
      "1020:\tlearn: 0.0055484\ttotal: 1m 32s\tremaining: 1m 28s\n",
      "1021:\tlearn: 0.0055328\ttotal: 1m 32s\tremaining: 1m 28s\n",
      "1022:\tlearn: 0.0055179\ttotal: 1m 32s\tremaining: 1m 28s\n",
      "1023:\tlearn: 0.0055132\ttotal: 1m 33s\tremaining: 1m 28s\n",
      "1024:\tlearn: 0.0055088\ttotal: 1m 33s\tremaining: 1m 28s\n",
      "1025:\tlearn: 0.0054912\ttotal: 1m 33s\tremaining: 1m 28s\n",
      "1026:\tlearn: 0.0054846\ttotal: 1m 33s\tremaining: 1m 28s\n",
      "1027:\tlearn: 0.0054794\ttotal: 1m 33s\tremaining: 1m 28s\n",
      "1028:\tlearn: 0.0054788\ttotal: 1m 33s\tremaining: 1m 28s\n",
      "1029:\tlearn: 0.0054732\ttotal: 1m 33s\tremaining: 1m 28s\n",
      "1030:\tlearn: 0.0054712\ttotal: 1m 33s\tremaining: 1m 28s\n",
      "1031:\tlearn: 0.0054688\ttotal: 1m 33s\tremaining: 1m 27s\n",
      "1032:\tlearn: 0.0054568\ttotal: 1m 33s\tremaining: 1m 27s\n",
      "1033:\tlearn: 0.0054531\ttotal: 1m 33s\tremaining: 1m 27s\n",
      "1034:\tlearn: 0.0054475\ttotal: 1m 34s\tremaining: 1m 27s\n",
      "1035:\tlearn: 0.0054435\ttotal: 1m 34s\tremaining: 1m 27s\n",
      "1036:\tlearn: 0.0054430\ttotal: 1m 34s\tremaining: 1m 27s\n",
      "1037:\tlearn: 0.0054403\ttotal: 1m 34s\tremaining: 1m 27s\n",
      "1038:\tlearn: 0.0054243\ttotal: 1m 34s\tremaining: 1m 27s\n",
      "1039:\tlearn: 0.0054225\ttotal: 1m 34s\tremaining: 1m 27s\n",
      "1040:\tlearn: 0.0054169\ttotal: 1m 34s\tremaining: 1m 27s\n",
      "1041:\tlearn: 0.0054129\ttotal: 1m 34s\tremaining: 1m 27s\n",
      "1042:\tlearn: 0.0054089\ttotal: 1m 34s\tremaining: 1m 26s\n",
      "1043:\tlearn: 0.0054045\ttotal: 1m 34s\tremaining: 1m 26s\n",
      "1044:\tlearn: 0.0054028\ttotal: 1m 34s\tremaining: 1m 26s\n",
      "1045:\tlearn: 0.0053996\ttotal: 1m 35s\tremaining: 1m 26s\n",
      "1046:\tlearn: 0.0053986\ttotal: 1m 35s\tremaining: 1m 26s\n",
      "1047:\tlearn: 0.0053975\ttotal: 1m 35s\tremaining: 1m 26s\n",
      "1048:\tlearn: 0.0053954\ttotal: 1m 35s\tremaining: 1m 26s\n",
      "1049:\tlearn: 0.0053917\ttotal: 1m 35s\tremaining: 1m 26s\n",
      "1050:\tlearn: 0.0053881\ttotal: 1m 35s\tremaining: 1m 26s\n",
      "1051:\tlearn: 0.0053843\ttotal: 1m 35s\tremaining: 1m 26s\n",
      "1052:\tlearn: 0.0053778\ttotal: 1m 35s\tremaining: 1m 26s\n",
      "1053:\tlearn: 0.0053760\ttotal: 1m 35s\tremaining: 1m 25s\n",
      "1054:\tlearn: 0.0053753\ttotal: 1m 35s\tremaining: 1m 25s\n",
      "1055:\tlearn: 0.0053734\ttotal: 1m 35s\tremaining: 1m 25s\n",
      "1056:\tlearn: 0.0053687\ttotal: 1m 35s\tremaining: 1m 25s\n",
      "1057:\tlearn: 0.0053652\ttotal: 1m 36s\tremaining: 1m 25s\n",
      "1058:\tlearn: 0.0053646\ttotal: 1m 36s\tremaining: 1m 25s\n",
      "1059:\tlearn: 0.0053605\ttotal: 1m 36s\tremaining: 1m 25s\n",
      "1060:\tlearn: 0.0053535\ttotal: 1m 36s\tremaining: 1m 25s\n",
      "1061:\tlearn: 0.0053500\ttotal: 1m 36s\tremaining: 1m 25s\n",
      "1062:\tlearn: 0.0053467\ttotal: 1m 36s\tremaining: 1m 25s\n",
      "1063:\tlearn: 0.0053437\ttotal: 1m 36s\tremaining: 1m 24s\n",
      "1064:\tlearn: 0.0053369\ttotal: 1m 36s\tremaining: 1m 24s\n",
      "1065:\tlearn: 0.0053346\ttotal: 1m 36s\tremaining: 1m 24s\n",
      "1066:\tlearn: 0.0053308\ttotal: 1m 36s\tremaining: 1m 24s\n",
      "1067:\tlearn: 0.0053284\ttotal: 1m 36s\tremaining: 1m 24s\n",
      "1068:\tlearn: 0.0053228\ttotal: 1m 36s\tremaining: 1m 24s\n",
      "1069:\tlearn: 0.0053208\ttotal: 1m 37s\tremaining: 1m 24s\n",
      "1070:\tlearn: 0.0053202\ttotal: 1m 37s\tremaining: 1m 24s\n",
      "1071:\tlearn: 0.0053192\ttotal: 1m 37s\tremaining: 1m 24s\n",
      "1072:\tlearn: 0.0053138\ttotal: 1m 37s\tremaining: 1m 24s\n",
      "1073:\tlearn: 0.0053101\ttotal: 1m 37s\tremaining: 1m 24s\n",
      "1074:\tlearn: 0.0053053\ttotal: 1m 37s\tremaining: 1m 23s\n",
      "1075:\tlearn: 0.0053040\ttotal: 1m 37s\tremaining: 1m 23s\n",
      "1076:\tlearn: 0.0053022\ttotal: 1m 37s\tremaining: 1m 23s\n",
      "1077:\tlearn: 0.0052993\ttotal: 1m 37s\tremaining: 1m 23s\n",
      "1078:\tlearn: 0.0052958\ttotal: 1m 37s\tremaining: 1m 23s\n",
      "1079:\tlearn: 0.0052858\ttotal: 1m 37s\tremaining: 1m 23s\n",
      "1080:\tlearn: 0.0052849\ttotal: 1m 38s\tremaining: 1m 23s\n",
      "1081:\tlearn: 0.0052846\ttotal: 1m 38s\tremaining: 1m 23s\n",
      "1082:\tlearn: 0.0052818\ttotal: 1m 38s\tremaining: 1m 23s\n",
      "1083:\tlearn: 0.0052797\ttotal: 1m 38s\tremaining: 1m 23s\n",
      "1084:\tlearn: 0.0052790\ttotal: 1m 38s\tremaining: 1m 22s\n",
      "1085:\tlearn: 0.0052784\ttotal: 1m 38s\tremaining: 1m 22s\n",
      "1086:\tlearn: 0.0052757\ttotal: 1m 38s\tremaining: 1m 22s\n",
      "1087:\tlearn: 0.0052721\ttotal: 1m 38s\tremaining: 1m 22s\n",
      "1088:\tlearn: 0.0052650\ttotal: 1m 38s\tremaining: 1m 22s\n",
      "1089:\tlearn: 0.0052587\ttotal: 1m 38s\tremaining: 1m 22s\n",
      "1090:\tlearn: 0.0052469\ttotal: 1m 38s\tremaining: 1m 22s\n",
      "1091:\tlearn: 0.0052438\ttotal: 1m 39s\tremaining: 1m 22s\n",
      "1092:\tlearn: 0.0052376\ttotal: 1m 39s\tremaining: 1m 22s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093:\tlearn: 0.0052351\ttotal: 1m 39s\tremaining: 1m 22s\n",
      "1094:\tlearn: 0.0052266\ttotal: 1m 39s\tremaining: 1m 22s\n",
      "1095:\tlearn: 0.0052230\ttotal: 1m 39s\tremaining: 1m 21s\n",
      "1096:\tlearn: 0.0052198\ttotal: 1m 39s\tremaining: 1m 21s\n",
      "1097:\tlearn: 0.0052191\ttotal: 1m 39s\tremaining: 1m 21s\n",
      "1098:\tlearn: 0.0052181\ttotal: 1m 39s\tremaining: 1m 21s\n",
      "1099:\tlearn: 0.0052142\ttotal: 1m 39s\tremaining: 1m 21s\n",
      "1100:\tlearn: 0.0052054\ttotal: 1m 39s\tremaining: 1m 21s\n",
      "1101:\tlearn: 0.0052019\ttotal: 1m 39s\tremaining: 1m 21s\n",
      "1102:\tlearn: 0.0052004\ttotal: 1m 39s\tremaining: 1m 21s\n",
      "1103:\tlearn: 0.0051977\ttotal: 1m 40s\tremaining: 1m 21s\n",
      "1104:\tlearn: 0.0051964\ttotal: 1m 40s\tremaining: 1m 21s\n",
      "1105:\tlearn: 0.0051935\ttotal: 1m 40s\tremaining: 1m 21s\n",
      "1106:\tlearn: 0.0051890\ttotal: 1m 40s\tremaining: 1m 20s\n",
      "1107:\tlearn: 0.0051840\ttotal: 1m 40s\tremaining: 1m 20s\n",
      "1108:\tlearn: 0.0051806\ttotal: 1m 40s\tremaining: 1m 20s\n",
      "1109:\tlearn: 0.0051714\ttotal: 1m 40s\tremaining: 1m 20s\n",
      "1110:\tlearn: 0.0051638\ttotal: 1m 40s\tremaining: 1m 20s\n",
      "1111:\tlearn: 0.0051631\ttotal: 1m 40s\tremaining: 1m 20s\n",
      "1112:\tlearn: 0.0051589\ttotal: 1m 40s\tremaining: 1m 20s\n",
      "1113:\tlearn: 0.0051580\ttotal: 1m 40s\tremaining: 1m 20s\n",
      "1114:\tlearn: 0.0051569\ttotal: 1m 41s\tremaining: 1m 20s\n",
      "1115:\tlearn: 0.0051477\ttotal: 1m 41s\tremaining: 1m 20s\n",
      "1116:\tlearn: 0.0051413\ttotal: 1m 41s\tremaining: 1m 20s\n",
      "1117:\tlearn: 0.0051403\ttotal: 1m 41s\tremaining: 1m 19s\n",
      "1118:\tlearn: 0.0051393\ttotal: 1m 41s\tremaining: 1m 19s\n",
      "1119:\tlearn: 0.0051369\ttotal: 1m 41s\tremaining: 1m 19s\n",
      "1120:\tlearn: 0.0051334\ttotal: 1m 41s\tremaining: 1m 19s\n",
      "1121:\tlearn: 0.0051293\ttotal: 1m 41s\tremaining: 1m 19s\n",
      "1122:\tlearn: 0.0051275\ttotal: 1m 41s\tremaining: 1m 19s\n",
      "1123:\tlearn: 0.0051238\ttotal: 1m 41s\tremaining: 1m 19s\n",
      "1124:\tlearn: 0.0051078\ttotal: 1m 41s\tremaining: 1m 19s\n",
      "1125:\tlearn: 0.0051064\ttotal: 1m 41s\tremaining: 1m 19s\n",
      "1126:\tlearn: 0.0051023\ttotal: 1m 42s\tremaining: 1m 19s\n",
      "1127:\tlearn: 0.0051013\ttotal: 1m 42s\tremaining: 1m 18s\n",
      "1128:\tlearn: 0.0050974\ttotal: 1m 42s\tremaining: 1m 18s\n",
      "1129:\tlearn: 0.0050958\ttotal: 1m 42s\tremaining: 1m 18s\n",
      "1130:\tlearn: 0.0050878\ttotal: 1m 42s\tremaining: 1m 18s\n",
      "1131:\tlearn: 0.0050766\ttotal: 1m 42s\tremaining: 1m 18s\n",
      "1132:\tlearn: 0.0050752\ttotal: 1m 42s\tremaining: 1m 18s\n",
      "1133:\tlearn: 0.0050702\ttotal: 1m 42s\tremaining: 1m 18s\n",
      "1134:\tlearn: 0.0050696\ttotal: 1m 42s\tremaining: 1m 18s\n",
      "1135:\tlearn: 0.0050691\ttotal: 1m 42s\tremaining: 1m 18s\n",
      "1136:\tlearn: 0.0050681\ttotal: 1m 42s\tremaining: 1m 18s\n",
      "1137:\tlearn: 0.0050662\ttotal: 1m 43s\tremaining: 1m 18s\n",
      "1138:\tlearn: 0.0050616\ttotal: 1m 43s\tremaining: 1m 17s\n",
      "1139:\tlearn: 0.0050567\ttotal: 1m 43s\tremaining: 1m 17s\n",
      "1140:\tlearn: 0.0050565\ttotal: 1m 43s\tremaining: 1m 17s\n",
      "1141:\tlearn: 0.0050554\ttotal: 1m 43s\tremaining: 1m 17s\n",
      "1142:\tlearn: 0.0050487\ttotal: 1m 43s\tremaining: 1m 17s\n",
      "1143:\tlearn: 0.0050469\ttotal: 1m 43s\tremaining: 1m 17s\n",
      "1144:\tlearn: 0.0050390\ttotal: 1m 43s\tremaining: 1m 17s\n",
      "1145:\tlearn: 0.0050345\ttotal: 1m 43s\tremaining: 1m 17s\n",
      "1146:\tlearn: 0.0050338\ttotal: 1m 43s\tremaining: 1m 17s\n",
      "1147:\tlearn: 0.0050230\ttotal: 1m 43s\tremaining: 1m 17s\n",
      "1148:\tlearn: 0.0050205\ttotal: 1m 44s\tremaining: 1m 17s\n",
      "1149:\tlearn: 0.0050173\ttotal: 1m 44s\tremaining: 1m 16s\n",
      "1150:\tlearn: 0.0050124\ttotal: 1m 44s\tremaining: 1m 16s\n",
      "1151:\tlearn: 0.0050053\ttotal: 1m 44s\tremaining: 1m 16s\n",
      "1152:\tlearn: 0.0050021\ttotal: 1m 44s\tremaining: 1m 16s\n",
      "1153:\tlearn: 0.0049963\ttotal: 1m 44s\tremaining: 1m 16s\n",
      "1154:\tlearn: 0.0049945\ttotal: 1m 44s\tremaining: 1m 16s\n",
      "1155:\tlearn: 0.0049927\ttotal: 1m 44s\tremaining: 1m 16s\n",
      "1156:\tlearn: 0.0049920\ttotal: 1m 44s\tremaining: 1m 16s\n",
      "1157:\tlearn: 0.0049818\ttotal: 1m 44s\tremaining: 1m 16s\n",
      "1158:\tlearn: 0.0049784\ttotal: 1m 44s\tremaining: 1m 16s\n",
      "1159:\tlearn: 0.0049772\ttotal: 1m 45s\tremaining: 1m 16s\n",
      "1160:\tlearn: 0.0049648\ttotal: 1m 45s\tremaining: 1m 15s\n",
      "1161:\tlearn: 0.0049640\ttotal: 1m 45s\tremaining: 1m 15s\n",
      "1162:\tlearn: 0.0049624\ttotal: 1m 45s\tremaining: 1m 15s\n",
      "1163:\tlearn: 0.0049575\ttotal: 1m 45s\tremaining: 1m 15s\n",
      "1164:\tlearn: 0.0049566\ttotal: 1m 45s\tremaining: 1m 15s\n",
      "1165:\tlearn: 0.0049546\ttotal: 1m 45s\tremaining: 1m 15s\n",
      "1166:\tlearn: 0.0049509\ttotal: 1m 45s\tremaining: 1m 15s\n",
      "1167:\tlearn: 0.0049479\ttotal: 1m 45s\tremaining: 1m 15s\n",
      "1168:\tlearn: 0.0049454\ttotal: 1m 45s\tremaining: 1m 15s\n",
      "1169:\tlearn: 0.0049439\ttotal: 1m 45s\tremaining: 1m 15s\n",
      "1170:\tlearn: 0.0049424\ttotal: 1m 45s\tremaining: 1m 15s\n",
      "1171:\tlearn: 0.0049396\ttotal: 1m 46s\tremaining: 1m 14s\n",
      "1172:\tlearn: 0.0049374\ttotal: 1m 46s\tremaining: 1m 14s\n",
      "1173:\tlearn: 0.0049358\ttotal: 1m 46s\tremaining: 1m 14s\n",
      "1174:\tlearn: 0.0049323\ttotal: 1m 46s\tremaining: 1m 14s\n",
      "1175:\tlearn: 0.0049281\ttotal: 1m 46s\tremaining: 1m 14s\n",
      "1176:\tlearn: 0.0049259\ttotal: 1m 46s\tremaining: 1m 14s\n",
      "1177:\tlearn: 0.0049243\ttotal: 1m 46s\tremaining: 1m 14s\n",
      "1178:\tlearn: 0.0049229\ttotal: 1m 46s\tremaining: 1m 14s\n",
      "1179:\tlearn: 0.0049209\ttotal: 1m 46s\tremaining: 1m 14s\n",
      "1180:\tlearn: 0.0049125\ttotal: 1m 46s\tremaining: 1m 14s\n",
      "1181:\tlearn: 0.0049096\ttotal: 1m 46s\tremaining: 1m 13s\n",
      "1182:\tlearn: 0.0049085\ttotal: 1m 47s\tremaining: 1m 13s\n",
      "1183:\tlearn: 0.0049066\ttotal: 1m 47s\tremaining: 1m 13s\n",
      "1184:\tlearn: 0.0049050\ttotal: 1m 47s\tremaining: 1m 13s\n",
      "1185:\tlearn: 0.0049044\ttotal: 1m 47s\tremaining: 1m 13s\n",
      "1186:\tlearn: 0.0049000\ttotal: 1m 47s\tremaining: 1m 13s\n",
      "1187:\tlearn: 0.0048883\ttotal: 1m 47s\tremaining: 1m 13s\n",
      "1188:\tlearn: 0.0048869\ttotal: 1m 47s\tremaining: 1m 13s\n",
      "1189:\tlearn: 0.0048848\ttotal: 1m 47s\tremaining: 1m 13s\n",
      "1190:\tlearn: 0.0048841\ttotal: 1m 47s\tremaining: 1m 13s\n",
      "1191:\tlearn: 0.0048834\ttotal: 1m 47s\tremaining: 1m 13s\n",
      "1192:\tlearn: 0.0048816\ttotal: 1m 47s\tremaining: 1m 12s\n",
      "1193:\tlearn: 0.0048808\ttotal: 1m 47s\tremaining: 1m 12s\n",
      "1194:\tlearn: 0.0048797\ttotal: 1m 48s\tremaining: 1m 12s\n",
      "1195:\tlearn: 0.0048762\ttotal: 1m 48s\tremaining: 1m 12s\n",
      "1196:\tlearn: 0.0048756\ttotal: 1m 48s\tremaining: 1m 12s\n",
      "1197:\tlearn: 0.0048725\ttotal: 1m 48s\tremaining: 1m 12s\n",
      "1198:\tlearn: 0.0048649\ttotal: 1m 48s\tremaining: 1m 12s\n",
      "1199:\tlearn: 0.0048612\ttotal: 1m 48s\tremaining: 1m 12s\n",
      "1200:\tlearn: 0.0048592\ttotal: 1m 48s\tremaining: 1m 12s\n",
      "1201:\tlearn: 0.0048561\ttotal: 1m 48s\tremaining: 1m 12s\n",
      "1202:\tlearn: 0.0048495\ttotal: 1m 48s\tremaining: 1m 12s\n",
      "1203:\tlearn: 0.0048484\ttotal: 1m 48s\tremaining: 1m 11s\n",
      "1204:\tlearn: 0.0048437\ttotal: 1m 48s\tremaining: 1m 11s\n",
      "1205:\tlearn: 0.0048411\ttotal: 1m 49s\tremaining: 1m 11s\n",
      "1206:\tlearn: 0.0048355\ttotal: 1m 49s\tremaining: 1m 11s\n",
      "1207:\tlearn: 0.0048312\ttotal: 1m 49s\tremaining: 1m 11s\n",
      "1208:\tlearn: 0.0048257\ttotal: 1m 49s\tremaining: 1m 11s\n",
      "1209:\tlearn: 0.0048231\ttotal: 1m 49s\tremaining: 1m 11s\n",
      "1210:\tlearn: 0.0048178\ttotal: 1m 49s\tremaining: 1m 11s\n",
      "1211:\tlearn: 0.0048173\ttotal: 1m 49s\tremaining: 1m 11s\n",
      "1212:\tlearn: 0.0048166\ttotal: 1m 49s\tremaining: 1m 11s\n",
      "1213:\tlearn: 0.0048099\ttotal: 1m 49s\tremaining: 1m 11s\n",
      "1214:\tlearn: 0.0048090\ttotal: 1m 49s\tremaining: 1m 10s\n",
      "1215:\tlearn: 0.0048072\ttotal: 1m 49s\tremaining: 1m 10s\n",
      "1216:\tlearn: 0.0048057\ttotal: 1m 50s\tremaining: 1m 10s\n",
      "1217:\tlearn: 0.0048051\ttotal: 1m 50s\tremaining: 1m 10s\n",
      "1218:\tlearn: 0.0048046\ttotal: 1m 50s\tremaining: 1m 10s\n",
      "1219:\tlearn: 0.0048037\ttotal: 1m 50s\tremaining: 1m 10s\n",
      "1220:\tlearn: 0.0048017\ttotal: 1m 50s\tremaining: 1m 10s\n",
      "1221:\tlearn: 0.0047995\ttotal: 1m 50s\tremaining: 1m 10s\n",
      "1222:\tlearn: 0.0047941\ttotal: 1m 50s\tremaining: 1m 10s\n",
      "1223:\tlearn: 0.0047908\ttotal: 1m 50s\tremaining: 1m 10s\n",
      "1224:\tlearn: 0.0047893\ttotal: 1m 50s\tremaining: 1m 10s\n",
      "1225:\tlearn: 0.0047884\ttotal: 1m 50s\tremaining: 1m 9s\n",
      "1226:\tlearn: 0.0047850\ttotal: 1m 50s\tremaining: 1m 9s\n",
      "1227:\tlearn: 0.0047790\ttotal: 1m 50s\tremaining: 1m 9s\n",
      "1228:\tlearn: 0.0047747\ttotal: 1m 51s\tremaining: 1m 9s\n",
      "1229:\tlearn: 0.0047711\ttotal: 1m 51s\tremaining: 1m 9s\n",
      "1230:\tlearn: 0.0047703\ttotal: 1m 51s\tremaining: 1m 9s\n",
      "1231:\tlearn: 0.0047564\ttotal: 1m 51s\tremaining: 1m 9s\n",
      "1232:\tlearn: 0.0047543\ttotal: 1m 51s\tremaining: 1m 9s\n",
      "1233:\tlearn: 0.0047493\ttotal: 1m 51s\tremaining: 1m 9s\n",
      "1234:\tlearn: 0.0047489\ttotal: 1m 51s\tremaining: 1m 9s\n",
      "1235:\tlearn: 0.0047479\ttotal: 1m 51s\tremaining: 1m 9s\n",
      "1236:\tlearn: 0.0047460\ttotal: 1m 51s\tremaining: 1m 8s\n",
      "1237:\tlearn: 0.0047445\ttotal: 1m 51s\tremaining: 1m 8s\n",
      "1238:\tlearn: 0.0047390\ttotal: 1m 51s\tremaining: 1m 8s\n",
      "1239:\tlearn: 0.0047385\ttotal: 1m 52s\tremaining: 1m 8s\n",
      "1240:\tlearn: 0.0047377\ttotal: 1m 52s\tremaining: 1m 8s\n",
      "1241:\tlearn: 0.0047358\ttotal: 1m 52s\tremaining: 1m 8s\n",
      "1242:\tlearn: 0.0047306\ttotal: 1m 52s\tremaining: 1m 8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1243:\tlearn: 0.0047275\ttotal: 1m 52s\tremaining: 1m 8s\n",
      "1244:\tlearn: 0.0047255\ttotal: 1m 52s\tremaining: 1m 8s\n",
      "1245:\tlearn: 0.0047253\ttotal: 1m 52s\tremaining: 1m 8s\n",
      "1246:\tlearn: 0.0047231\ttotal: 1m 52s\tremaining: 1m 8s\n",
      "1247:\tlearn: 0.0047227\ttotal: 1m 52s\tremaining: 1m 7s\n",
      "1248:\tlearn: 0.0047221\ttotal: 1m 52s\tremaining: 1m 7s\n",
      "1249:\tlearn: 0.0047171\ttotal: 1m 53s\tremaining: 1m 7s\n",
      "1250:\tlearn: 0.0047150\ttotal: 1m 53s\tremaining: 1m 7s\n",
      "1251:\tlearn: 0.0047132\ttotal: 1m 53s\tremaining: 1m 7s\n",
      "1252:\tlearn: 0.0047112\ttotal: 1m 53s\tremaining: 1m 7s\n",
      "1253:\tlearn: 0.0047074\ttotal: 1m 53s\tremaining: 1m 7s\n",
      "1254:\tlearn: 0.0047040\ttotal: 1m 53s\tremaining: 1m 7s\n",
      "1255:\tlearn: 0.0046998\ttotal: 1m 53s\tremaining: 1m 7s\n",
      "1256:\tlearn: 0.0046911\ttotal: 1m 53s\tremaining: 1m 7s\n",
      "1257:\tlearn: 0.0046879\ttotal: 1m 53s\tremaining: 1m 7s\n",
      "1258:\tlearn: 0.0046848\ttotal: 1m 54s\tremaining: 1m 7s\n",
      "1259:\tlearn: 0.0046779\ttotal: 1m 54s\tremaining: 1m 7s\n",
      "1260:\tlearn: 0.0046676\ttotal: 1m 54s\tremaining: 1m 6s\n",
      "1261:\tlearn: 0.0046619\ttotal: 1m 54s\tremaining: 1m 6s\n",
      "1262:\tlearn: 0.0046549\ttotal: 1m 54s\tremaining: 1m 6s\n",
      "1263:\tlearn: 0.0046514\ttotal: 1m 54s\tremaining: 1m 6s\n",
      "1264:\tlearn: 0.0046436\ttotal: 1m 54s\tremaining: 1m 6s\n",
      "1265:\tlearn: 0.0046423\ttotal: 1m 54s\tremaining: 1m 6s\n",
      "1266:\tlearn: 0.0046409\ttotal: 1m 54s\tremaining: 1m 6s\n",
      "1267:\tlearn: 0.0046352\ttotal: 1m 54s\tremaining: 1m 6s\n",
      "1268:\tlearn: 0.0046316\ttotal: 1m 54s\tremaining: 1m 6s\n",
      "1269:\tlearn: 0.0046300\ttotal: 1m 55s\tremaining: 1m 6s\n",
      "1270:\tlearn: 0.0046264\ttotal: 1m 55s\tremaining: 1m 6s\n",
      "1271:\tlearn: 0.0046258\ttotal: 1m 55s\tremaining: 1m 5s\n",
      "1272:\tlearn: 0.0046238\ttotal: 1m 55s\tremaining: 1m 5s\n",
      "1273:\tlearn: 0.0046207\ttotal: 1m 55s\tremaining: 1m 5s\n",
      "1274:\tlearn: 0.0046188\ttotal: 1m 55s\tremaining: 1m 5s\n",
      "1275:\tlearn: 0.0046182\ttotal: 1m 55s\tremaining: 1m 5s\n",
      "1276:\tlearn: 0.0046121\ttotal: 1m 55s\tremaining: 1m 5s\n",
      "1277:\tlearn: 0.0046116\ttotal: 1m 55s\tremaining: 1m 5s\n",
      "1278:\tlearn: 0.0046102\ttotal: 1m 55s\tremaining: 1m 5s\n",
      "1279:\tlearn: 0.0046026\ttotal: 1m 55s\tremaining: 1m 5s\n",
      "1280:\tlearn: 0.0046023\ttotal: 1m 55s\tremaining: 1m 5s\n",
      "1281:\tlearn: 0.0046006\ttotal: 1m 56s\tremaining: 1m 4s\n",
      "1282:\tlearn: 0.0045977\ttotal: 1m 56s\tremaining: 1m 4s\n",
      "1283:\tlearn: 0.0045966\ttotal: 1m 56s\tremaining: 1m 4s\n",
      "1284:\tlearn: 0.0045932\ttotal: 1m 56s\tremaining: 1m 4s\n",
      "1285:\tlearn: 0.0045921\ttotal: 1m 56s\tremaining: 1m 4s\n",
      "1286:\tlearn: 0.0045915\ttotal: 1m 56s\tremaining: 1m 4s\n",
      "1287:\tlearn: 0.0045909\ttotal: 1m 56s\tremaining: 1m 4s\n",
      "1288:\tlearn: 0.0045875\ttotal: 1m 56s\tremaining: 1m 4s\n",
      "1289:\tlearn: 0.0045815\ttotal: 1m 56s\tremaining: 1m 4s\n",
      "1290:\tlearn: 0.0045740\ttotal: 1m 56s\tremaining: 1m 4s\n",
      "1291:\tlearn: 0.0045706\ttotal: 1m 56s\tremaining: 1m 4s\n",
      "1292:\tlearn: 0.0045699\ttotal: 1m 57s\tremaining: 1m 3s\n",
      "1293:\tlearn: 0.0045667\ttotal: 1m 57s\tremaining: 1m 3s\n",
      "1294:\tlearn: 0.0045651\ttotal: 1m 57s\tremaining: 1m 3s\n",
      "1295:\tlearn: 0.0045593\ttotal: 1m 57s\tremaining: 1m 3s\n",
      "1296:\tlearn: 0.0045523\ttotal: 1m 57s\tremaining: 1m 3s\n",
      "1297:\tlearn: 0.0045431\ttotal: 1m 57s\tremaining: 1m 3s\n",
      "1298:\tlearn: 0.0045385\ttotal: 1m 57s\tremaining: 1m 3s\n",
      "1299:\tlearn: 0.0045330\ttotal: 1m 57s\tremaining: 1m 3s\n",
      "1300:\tlearn: 0.0045275\ttotal: 1m 57s\tremaining: 1m 3s\n",
      "1301:\tlearn: 0.0045259\ttotal: 1m 57s\tremaining: 1m 3s\n",
      "1302:\tlearn: 0.0045236\ttotal: 1m 57s\tremaining: 1m 3s\n",
      "1303:\tlearn: 0.0045215\ttotal: 1m 58s\tremaining: 1m 2s\n",
      "1304:\tlearn: 0.0045211\ttotal: 1m 58s\tremaining: 1m 2s\n",
      "1305:\tlearn: 0.0045185\ttotal: 1m 58s\tremaining: 1m 2s\n",
      "1306:\tlearn: 0.0045169\ttotal: 1m 58s\tremaining: 1m 2s\n",
      "1307:\tlearn: 0.0045160\ttotal: 1m 58s\tremaining: 1m 2s\n",
      "1308:\tlearn: 0.0045152\ttotal: 1m 58s\tremaining: 1m 2s\n",
      "1309:\tlearn: 0.0045147\ttotal: 1m 58s\tremaining: 1m 2s\n",
      "1310:\tlearn: 0.0045112\ttotal: 1m 58s\tremaining: 1m 2s\n",
      "1311:\tlearn: 0.0045102\ttotal: 1m 58s\tremaining: 1m 2s\n",
      "1312:\tlearn: 0.0045055\ttotal: 1m 58s\tremaining: 1m 2s\n",
      "1313:\tlearn: 0.0045028\ttotal: 1m 58s\tremaining: 1m 2s\n",
      "1314:\tlearn: 0.0045006\ttotal: 1m 58s\tremaining: 1m 1s\n",
      "1315:\tlearn: 0.0044993\ttotal: 1m 59s\tremaining: 1m 1s\n",
      "1316:\tlearn: 0.0044949\ttotal: 1m 59s\tremaining: 1m 1s\n",
      "1317:\tlearn: 0.0044931\ttotal: 1m 59s\tremaining: 1m 1s\n",
      "1318:\tlearn: 0.0044915\ttotal: 1m 59s\tremaining: 1m 1s\n",
      "1319:\tlearn: 0.0044890\ttotal: 1m 59s\tremaining: 1m 1s\n",
      "1320:\tlearn: 0.0044884\ttotal: 1m 59s\tremaining: 1m 1s\n",
      "1321:\tlearn: 0.0044821\ttotal: 1m 59s\tremaining: 1m 1s\n",
      "1322:\tlearn: 0.0044797\ttotal: 1m 59s\tremaining: 1m 1s\n",
      "1323:\tlearn: 0.0044770\ttotal: 1m 59s\tremaining: 1m 1s\n",
      "1324:\tlearn: 0.0044766\ttotal: 1m 59s\tremaining: 1m 1s\n",
      "1325:\tlearn: 0.0044738\ttotal: 1m 59s\tremaining: 1m\n",
      "1326:\tlearn: 0.0044730\ttotal: 2m\tremaining: 1m\n",
      "1327:\tlearn: 0.0044728\ttotal: 2m\tremaining: 1m\n",
      "1328:\tlearn: 0.0044623\ttotal: 2m\tremaining: 1m\n",
      "1329:\tlearn: 0.0044620\ttotal: 2m\tremaining: 1m\n",
      "1330:\tlearn: 0.0044562\ttotal: 2m\tremaining: 1m\n",
      "1331:\tlearn: 0.0044559\ttotal: 2m\tremaining: 1m\n",
      "1332:\tlearn: 0.0044538\ttotal: 2m\tremaining: 1m\n",
      "1333:\tlearn: 0.0044485\ttotal: 2m\tremaining: 1m\n",
      "1334:\tlearn: 0.0044469\ttotal: 2m\tremaining: 1m\n",
      "1335:\tlearn: 0.0044443\ttotal: 2m\tremaining: 1m\n",
      "1336:\tlearn: 0.0044400\ttotal: 2m\tremaining: 60s\n",
      "1337:\tlearn: 0.0044389\ttotal: 2m\tremaining: 59.9s\n",
      "1338:\tlearn: 0.0044379\ttotal: 2m 1s\tremaining: 59.8s\n",
      "1339:\tlearn: 0.0044364\ttotal: 2m 1s\tremaining: 59.7s\n",
      "1340:\tlearn: 0.0044355\ttotal: 2m 1s\tremaining: 59.6s\n",
      "1341:\tlearn: 0.0044344\ttotal: 2m 1s\tremaining: 59.5s\n",
      "1342:\tlearn: 0.0044335\ttotal: 2m 1s\tremaining: 59.4s\n",
      "1343:\tlearn: 0.0044310\ttotal: 2m 1s\tremaining: 59.3s\n",
      "1344:\tlearn: 0.0044288\ttotal: 2m 1s\tremaining: 59.2s\n",
      "1345:\tlearn: 0.0044273\ttotal: 2m 1s\tremaining: 59.1s\n",
      "1346:\tlearn: 0.0044265\ttotal: 2m 1s\tremaining: 59s\n",
      "1347:\tlearn: 0.0044230\ttotal: 2m 1s\tremaining: 59s\n",
      "1348:\tlearn: 0.0044166\ttotal: 2m 1s\tremaining: 58.9s\n",
      "1349:\tlearn: 0.0044142\ttotal: 2m 2s\tremaining: 58.8s\n",
      "1350:\tlearn: 0.0044125\ttotal: 2m 2s\tremaining: 58.7s\n",
      "1351:\tlearn: 0.0044123\ttotal: 2m 2s\tremaining: 58.6s\n",
      "1352:\tlearn: 0.0044090\ttotal: 2m 2s\tremaining: 58.5s\n",
      "1353:\tlearn: 0.0044063\ttotal: 2m 2s\tremaining: 58.4s\n",
      "1354:\tlearn: 0.0044061\ttotal: 2m 2s\tremaining: 58.3s\n",
      "1355:\tlearn: 0.0044048\ttotal: 2m 2s\tremaining: 58.2s\n",
      "1356:\tlearn: 0.0044042\ttotal: 2m 2s\tremaining: 58.1s\n",
      "1357:\tlearn: 0.0043925\ttotal: 2m 2s\tremaining: 58s\n",
      "1358:\tlearn: 0.0043916\ttotal: 2m 2s\tremaining: 58s\n",
      "1359:\tlearn: 0.0043912\ttotal: 2m 2s\tremaining: 57.9s\n",
      "1360:\tlearn: 0.0043835\ttotal: 2m 3s\tremaining: 57.8s\n",
      "1361:\tlearn: 0.0043763\ttotal: 2m 3s\tremaining: 57.7s\n",
      "1362:\tlearn: 0.0043722\ttotal: 2m 3s\tremaining: 57.6s\n",
      "1363:\tlearn: 0.0043689\ttotal: 2m 3s\tremaining: 57.5s\n",
      "1364:\tlearn: 0.0043606\ttotal: 2m 3s\tremaining: 57.4s\n",
      "1365:\tlearn: 0.0043498\ttotal: 2m 3s\tremaining: 57.3s\n",
      "1366:\tlearn: 0.0043483\ttotal: 2m 3s\tremaining: 57.2s\n",
      "1367:\tlearn: 0.0043379\ttotal: 2m 3s\tremaining: 57.1s\n",
      "1368:\tlearn: 0.0043335\ttotal: 2m 3s\tremaining: 57s\n",
      "1369:\tlearn: 0.0043277\ttotal: 2m 3s\tremaining: 57s\n",
      "1370:\tlearn: 0.0043204\ttotal: 2m 3s\tremaining: 56.9s\n",
      "1371:\tlearn: 0.0043134\ttotal: 2m 4s\tremaining: 56.8s\n",
      "1372:\tlearn: 0.0043117\ttotal: 2m 4s\tremaining: 56.7s\n",
      "1373:\tlearn: 0.0043111\ttotal: 2m 4s\tremaining: 56.6s\n",
      "1374:\tlearn: 0.0043108\ttotal: 2m 4s\tremaining: 56.5s\n",
      "1375:\tlearn: 0.0043041\ttotal: 2m 4s\tremaining: 56.4s\n",
      "1376:\tlearn: 0.0043013\ttotal: 2m 4s\tremaining: 56.3s\n",
      "1377:\tlearn: 0.0043005\ttotal: 2m 4s\tremaining: 56.2s\n",
      "1378:\tlearn: 0.0042960\ttotal: 2m 4s\tremaining: 56.1s\n",
      "1379:\tlearn: 0.0042945\ttotal: 2m 4s\tremaining: 56s\n",
      "1380:\tlearn: 0.0042940\ttotal: 2m 4s\tremaining: 56s\n",
      "1381:\tlearn: 0.0042936\ttotal: 2m 4s\tremaining: 55.9s\n",
      "1382:\tlearn: 0.0042932\ttotal: 2m 5s\tremaining: 55.8s\n",
      "1383:\tlearn: 0.0042926\ttotal: 2m 5s\tremaining: 55.7s\n",
      "1384:\tlearn: 0.0042915\ttotal: 2m 5s\tremaining: 55.6s\n",
      "1385:\tlearn: 0.0042890\ttotal: 2m 5s\tremaining: 55.5s\n",
      "1386:\tlearn: 0.0042866\ttotal: 2m 5s\tremaining: 55.4s\n",
      "1387:\tlearn: 0.0042862\ttotal: 2m 5s\tremaining: 55.3s\n",
      "1388:\tlearn: 0.0042857\ttotal: 2m 5s\tremaining: 55.2s\n",
      "1389:\tlearn: 0.0042842\ttotal: 2m 5s\tremaining: 55.1s\n",
      "1390:\tlearn: 0.0042827\ttotal: 2m 5s\tremaining: 55s\n",
      "1391:\tlearn: 0.0042820\ttotal: 2m 5s\tremaining: 54.9s\n",
      "1392:\tlearn: 0.0042806\ttotal: 2m 5s\tremaining: 54.9s\n",
      "1393:\tlearn: 0.0042798\ttotal: 2m 5s\tremaining: 54.8s\n",
      "1394:\tlearn: 0.0042756\ttotal: 2m 6s\tremaining: 54.7s\n",
      "1395:\tlearn: 0.0042691\ttotal: 2m 6s\tremaining: 54.6s\n",
      "1396:\tlearn: 0.0042667\ttotal: 2m 6s\tremaining: 54.5s\n",
      "1397:\tlearn: 0.0042647\ttotal: 2m 6s\tremaining: 54.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1398:\tlearn: 0.0042640\ttotal: 2m 6s\tremaining: 54.3s\n",
      "1399:\tlearn: 0.0042580\ttotal: 2m 6s\tremaining: 54.2s\n",
      "1400:\tlearn: 0.0042464\ttotal: 2m 6s\tremaining: 54.1s\n",
      "1401:\tlearn: 0.0042442\ttotal: 2m 6s\tremaining: 54s\n",
      "1402:\tlearn: 0.0042423\ttotal: 2m 6s\tremaining: 54s\n",
      "1403:\tlearn: 0.0042418\ttotal: 2m 6s\tremaining: 53.9s\n",
      "1404:\tlearn: 0.0042400\ttotal: 2m 6s\tremaining: 53.8s\n",
      "1405:\tlearn: 0.0042368\ttotal: 2m 7s\tremaining: 53.7s\n",
      "1406:\tlearn: 0.0042307\ttotal: 2m 7s\tremaining: 53.6s\n",
      "1407:\tlearn: 0.0042279\ttotal: 2m 7s\tremaining: 53.5s\n",
      "1408:\tlearn: 0.0042260\ttotal: 2m 7s\tremaining: 53.4s\n",
      "1409:\tlearn: 0.0042248\ttotal: 2m 7s\tremaining: 53.3s\n",
      "1410:\tlearn: 0.0042216\ttotal: 2m 7s\tremaining: 53.2s\n",
      "1411:\tlearn: 0.0042185\ttotal: 2m 7s\tremaining: 53.1s\n",
      "1412:\tlearn: 0.0042183\ttotal: 2m 7s\tremaining: 53s\n",
      "1413:\tlearn: 0.0042174\ttotal: 2m 7s\tremaining: 53s\n",
      "1414:\tlearn: 0.0042160\ttotal: 2m 7s\tremaining: 52.9s\n",
      "1415:\tlearn: 0.0042142\ttotal: 2m 7s\tremaining: 52.8s\n",
      "1416:\tlearn: 0.0042137\ttotal: 2m 8s\tremaining: 52.7s\n",
      "1417:\tlearn: 0.0042125\ttotal: 2m 8s\tremaining: 52.6s\n",
      "1418:\tlearn: 0.0042092\ttotal: 2m 8s\tremaining: 52.5s\n",
      "1419:\tlearn: 0.0042074\ttotal: 2m 8s\tremaining: 52.4s\n",
      "1420:\tlearn: 0.0042022\ttotal: 2m 8s\tremaining: 52.3s\n",
      "1421:\tlearn: 0.0042004\ttotal: 2m 8s\tremaining: 52.2s\n",
      "1422:\tlearn: 0.0041891\ttotal: 2m 8s\tremaining: 52.1s\n",
      "1423:\tlearn: 0.0041855\ttotal: 2m 8s\tremaining: 52s\n",
      "1424:\tlearn: 0.0041833\ttotal: 2m 8s\tremaining: 51.9s\n",
      "1425:\tlearn: 0.0041778\ttotal: 2m 8s\tremaining: 51.9s\n",
      "1426:\tlearn: 0.0041777\ttotal: 2m 8s\tremaining: 51.8s\n",
      "1427:\tlearn: 0.0041760\ttotal: 2m 9s\tremaining: 51.7s\n",
      "1428:\tlearn: 0.0041730\ttotal: 2m 9s\tremaining: 51.6s\n",
      "1429:\tlearn: 0.0041722\ttotal: 2m 9s\tremaining: 51.5s\n",
      "1430:\tlearn: 0.0041705\ttotal: 2m 9s\tremaining: 51.4s\n",
      "1431:\tlearn: 0.0041667\ttotal: 2m 9s\tremaining: 51.3s\n",
      "1432:\tlearn: 0.0041646\ttotal: 2m 9s\tremaining: 51.2s\n",
      "1433:\tlearn: 0.0041627\ttotal: 2m 9s\tremaining: 51.1s\n",
      "1434:\tlearn: 0.0041533\ttotal: 2m 9s\tremaining: 51s\n",
      "1435:\tlearn: 0.0041378\ttotal: 2m 9s\tremaining: 51s\n",
      "1436:\tlearn: 0.0041317\ttotal: 2m 9s\tremaining: 50.9s\n",
      "1437:\tlearn: 0.0041290\ttotal: 2m 9s\tremaining: 50.8s\n",
      "1438:\tlearn: 0.0041280\ttotal: 2m 10s\tremaining: 50.7s\n",
      "1439:\tlearn: 0.0041243\ttotal: 2m 10s\tremaining: 50.6s\n",
      "1440:\tlearn: 0.0041213\ttotal: 2m 10s\tremaining: 50.5s\n",
      "1441:\tlearn: 0.0041167\ttotal: 2m 10s\tremaining: 50.4s\n",
      "1442:\tlearn: 0.0041125\ttotal: 2m 10s\tremaining: 50.3s\n",
      "1443:\tlearn: 0.0041101\ttotal: 2m 10s\tremaining: 50.2s\n",
      "1444:\tlearn: 0.0041081\ttotal: 2m 10s\tremaining: 50.1s\n",
      "1445:\tlearn: 0.0041053\ttotal: 2m 10s\tremaining: 50s\n",
      "1446:\tlearn: 0.0040930\ttotal: 2m 10s\tremaining: 50s\n",
      "1447:\tlearn: 0.0040901\ttotal: 2m 10s\tremaining: 49.9s\n",
      "1448:\tlearn: 0.0040878\ttotal: 2m 10s\tremaining: 49.8s\n",
      "1449:\tlearn: 0.0040847\ttotal: 2m 11s\tremaining: 49.7s\n",
      "1450:\tlearn: 0.0040802\ttotal: 2m 11s\tremaining: 49.6s\n",
      "1451:\tlearn: 0.0040801\ttotal: 2m 11s\tremaining: 49.5s\n",
      "1452:\tlearn: 0.0040785\ttotal: 2m 11s\tremaining: 49.4s\n",
      "1453:\tlearn: 0.0040621\ttotal: 2m 11s\tremaining: 49.3s\n",
      "1454:\tlearn: 0.0040608\ttotal: 2m 11s\tremaining: 49.2s\n",
      "1455:\tlearn: 0.0040599\ttotal: 2m 11s\tremaining: 49.1s\n",
      "1456:\tlearn: 0.0040531\ttotal: 2m 11s\tremaining: 49s\n",
      "1457:\tlearn: 0.0040522\ttotal: 2m 11s\tremaining: 49s\n",
      "1458:\tlearn: 0.0040518\ttotal: 2m 11s\tremaining: 48.9s\n",
      "1459:\tlearn: 0.0040489\ttotal: 2m 11s\tremaining: 48.8s\n",
      "1460:\tlearn: 0.0040475\ttotal: 2m 11s\tremaining: 48.7s\n",
      "1461:\tlearn: 0.0040455\ttotal: 2m 12s\tremaining: 48.6s\n",
      "1462:\tlearn: 0.0040428\ttotal: 2m 12s\tremaining: 48.5s\n",
      "1463:\tlearn: 0.0040402\ttotal: 2m 12s\tremaining: 48.4s\n",
      "1464:\tlearn: 0.0040391\ttotal: 2m 12s\tremaining: 48.3s\n",
      "1465:\tlearn: 0.0040298\ttotal: 2m 12s\tremaining: 48.2s\n",
      "1466:\tlearn: 0.0040297\ttotal: 2m 12s\tremaining: 48.1s\n",
      "1467:\tlearn: 0.0040278\ttotal: 2m 12s\tremaining: 48s\n",
      "1468:\tlearn: 0.0040274\ttotal: 2m 12s\tremaining: 48s\n",
      "1469:\tlearn: 0.0040218\ttotal: 2m 12s\tremaining: 47.9s\n",
      "1470:\tlearn: 0.0040213\ttotal: 2m 12s\tremaining: 47.8s\n",
      "1471:\tlearn: 0.0040196\ttotal: 2m 12s\tremaining: 47.7s\n",
      "1472:\tlearn: 0.0040190\ttotal: 2m 13s\tremaining: 47.6s\n",
      "1473:\tlearn: 0.0040180\ttotal: 2m 13s\tremaining: 47.5s\n",
      "1474:\tlearn: 0.0040176\ttotal: 2m 13s\tremaining: 47.4s\n",
      "1475:\tlearn: 0.0040114\ttotal: 2m 13s\tremaining: 47.3s\n",
      "1476:\tlearn: 0.0040080\ttotal: 2m 13s\tremaining: 47.2s\n",
      "1477:\tlearn: 0.0040071\ttotal: 2m 13s\tremaining: 47.1s\n",
      "1478:\tlearn: 0.0040065\ttotal: 2m 13s\tremaining: 47s\n",
      "1479:\tlearn: 0.0039996\ttotal: 2m 13s\tremaining: 47s\n",
      "1480:\tlearn: 0.0039993\ttotal: 2m 13s\tremaining: 46.9s\n",
      "1481:\tlearn: 0.0039916\ttotal: 2m 13s\tremaining: 46.8s\n",
      "1482:\tlearn: 0.0039831\ttotal: 2m 13s\tremaining: 46.7s\n",
      "1483:\tlearn: 0.0039818\ttotal: 2m 14s\tremaining: 46.6s\n",
      "1484:\tlearn: 0.0039717\ttotal: 2m 14s\tremaining: 46.5s\n",
      "1485:\tlearn: 0.0039680\ttotal: 2m 14s\tremaining: 46.4s\n",
      "1486:\tlearn: 0.0039678\ttotal: 2m 14s\tremaining: 46.3s\n",
      "1487:\tlearn: 0.0039655\ttotal: 2m 14s\tremaining: 46.2s\n",
      "1488:\tlearn: 0.0039652\ttotal: 2m 14s\tremaining: 46.1s\n",
      "1489:\tlearn: 0.0039650\ttotal: 2m 14s\tremaining: 46.1s\n",
      "1490:\tlearn: 0.0039638\ttotal: 2m 14s\tremaining: 46s\n",
      "1491:\tlearn: 0.0039603\ttotal: 2m 14s\tremaining: 45.9s\n",
      "1492:\tlearn: 0.0039581\ttotal: 2m 14s\tremaining: 45.8s\n",
      "1493:\tlearn: 0.0039565\ttotal: 2m 14s\tremaining: 45.7s\n",
      "1494:\tlearn: 0.0039532\ttotal: 2m 14s\tremaining: 45.6s\n",
      "1495:\tlearn: 0.0039526\ttotal: 2m 15s\tremaining: 45.5s\n",
      "1496:\tlearn: 0.0039495\ttotal: 2m 15s\tremaining: 45.4s\n",
      "1497:\tlearn: 0.0039487\ttotal: 2m 15s\tremaining: 45.3s\n",
      "1498:\tlearn: 0.0039482\ttotal: 2m 15s\tremaining: 45.2s\n",
      "1499:\tlearn: 0.0039447\ttotal: 2m 15s\tremaining: 45.1s\n",
      "1500:\tlearn: 0.0039431\ttotal: 2m 15s\tremaining: 45s\n",
      "1501:\tlearn: 0.0039409\ttotal: 2m 15s\tremaining: 45s\n",
      "1502:\tlearn: 0.0039407\ttotal: 2m 15s\tremaining: 44.9s\n",
      "1503:\tlearn: 0.0039392\ttotal: 2m 15s\tremaining: 44.8s\n",
      "1504:\tlearn: 0.0039390\ttotal: 2m 15s\tremaining: 44.7s\n",
      "1505:\tlearn: 0.0039374\ttotal: 2m 15s\tremaining: 44.6s\n",
      "1506:\tlearn: 0.0039307\ttotal: 2m 16s\tremaining: 44.5s\n",
      "1507:\tlearn: 0.0039295\ttotal: 2m 16s\tremaining: 44.4s\n",
      "1508:\tlearn: 0.0039198\ttotal: 2m 16s\tremaining: 44.3s\n",
      "1509:\tlearn: 0.0039136\ttotal: 2m 16s\tremaining: 44.2s\n",
      "1510:\tlearn: 0.0039105\ttotal: 2m 16s\tremaining: 44.1s\n",
      "1511:\tlearn: 0.0039079\ttotal: 2m 16s\tremaining: 44s\n",
      "1512:\tlearn: 0.0039003\ttotal: 2m 16s\tremaining: 44s\n",
      "1513:\tlearn: 0.0038990\ttotal: 2m 16s\tremaining: 43.9s\n",
      "1514:\tlearn: 0.0038963\ttotal: 2m 16s\tremaining: 43.8s\n",
      "1515:\tlearn: 0.0038960\ttotal: 2m 16s\tremaining: 43.7s\n",
      "1516:\tlearn: 0.0038956\ttotal: 2m 16s\tremaining: 43.6s\n",
      "1517:\tlearn: 0.0038938\ttotal: 2m 17s\tremaining: 43.5s\n",
      "1518:\tlearn: 0.0038922\ttotal: 2m 17s\tremaining: 43.4s\n",
      "1519:\tlearn: 0.0038918\ttotal: 2m 17s\tremaining: 43.3s\n",
      "1520:\tlearn: 0.0038867\ttotal: 2m 17s\tremaining: 43.2s\n",
      "1521:\tlearn: 0.0038799\ttotal: 2m 17s\tremaining: 43.1s\n",
      "1522:\tlearn: 0.0038709\ttotal: 2m 17s\tremaining: 43s\n",
      "1523:\tlearn: 0.0038702\ttotal: 2m 17s\tremaining: 43s\n",
      "1524:\tlearn: 0.0038699\ttotal: 2m 17s\tremaining: 42.9s\n",
      "1525:\tlearn: 0.0038697\ttotal: 2m 17s\tremaining: 42.8s\n",
      "1526:\tlearn: 0.0038652\ttotal: 2m 17s\tremaining: 42.7s\n",
      "1527:\tlearn: 0.0038650\ttotal: 2m 17s\tremaining: 42.6s\n",
      "1528:\tlearn: 0.0038644\ttotal: 2m 17s\tremaining: 42.5s\n",
      "1529:\tlearn: 0.0038624\ttotal: 2m 18s\tremaining: 42.4s\n",
      "1530:\tlearn: 0.0038610\ttotal: 2m 18s\tremaining: 42.3s\n",
      "1531:\tlearn: 0.0038594\ttotal: 2m 18s\tremaining: 42.2s\n",
      "1532:\tlearn: 0.0038576\ttotal: 2m 18s\tremaining: 42.1s\n",
      "1533:\tlearn: 0.0038560\ttotal: 2m 18s\tremaining: 42s\n",
      "1534:\tlearn: 0.0038493\ttotal: 2m 18s\tremaining: 42s\n",
      "1535:\tlearn: 0.0038487\ttotal: 2m 18s\tremaining: 41.9s\n",
      "1536:\tlearn: 0.0038424\ttotal: 2m 18s\tremaining: 41.8s\n",
      "1537:\tlearn: 0.0038361\ttotal: 2m 18s\tremaining: 41.7s\n",
      "1538:\tlearn: 0.0038293\ttotal: 2m 18s\tremaining: 41.6s\n",
      "1539:\tlearn: 0.0038276\ttotal: 2m 18s\tremaining: 41.5s\n",
      "1540:\tlearn: 0.0038269\ttotal: 2m 19s\tremaining: 41.4s\n",
      "1541:\tlearn: 0.0038265\ttotal: 2m 19s\tremaining: 41.3s\n",
      "1542:\tlearn: 0.0038252\ttotal: 2m 19s\tremaining: 41.2s\n",
      "1543:\tlearn: 0.0038243\ttotal: 2m 19s\tremaining: 41.1s\n",
      "1544:\tlearn: 0.0038238\ttotal: 2m 19s\tremaining: 41s\n",
      "1545:\tlearn: 0.0038207\ttotal: 2m 19s\tremaining: 41s\n",
      "1546:\tlearn: 0.0038202\ttotal: 2m 19s\tremaining: 40.9s\n",
      "1547:\tlearn: 0.0038166\ttotal: 2m 19s\tremaining: 40.8s\n",
      "1548:\tlearn: 0.0038148\ttotal: 2m 19s\tremaining: 40.7s\n",
      "1549:\tlearn: 0.0038134\ttotal: 2m 19s\tremaining: 40.6s\n",
      "1550:\tlearn: 0.0038116\ttotal: 2m 19s\tremaining: 40.5s\n",
      "1551:\tlearn: 0.0038104\ttotal: 2m 19s\tremaining: 40.4s\n",
      "1552:\tlearn: 0.0038100\ttotal: 2m 20s\tremaining: 40.3s\n",
      "1553:\tlearn: 0.0038064\ttotal: 2m 20s\tremaining: 40.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1554:\tlearn: 0.0038056\ttotal: 2m 20s\tremaining: 40.1s\n",
      "1555:\tlearn: 0.0037998\ttotal: 2m 20s\tremaining: 40s\n",
      "1556:\tlearn: 0.0037979\ttotal: 2m 20s\tremaining: 40s\n",
      "1557:\tlearn: 0.0037969\ttotal: 2m 20s\tremaining: 39.9s\n",
      "1558:\tlearn: 0.0037942\ttotal: 2m 20s\tremaining: 39.8s\n",
      "1559:\tlearn: 0.0037931\ttotal: 2m 20s\tremaining: 39.7s\n",
      "1560:\tlearn: 0.0037918\ttotal: 2m 20s\tremaining: 39.6s\n",
      "1561:\tlearn: 0.0037907\ttotal: 2m 20s\tremaining: 39.5s\n",
      "1562:\tlearn: 0.0037897\ttotal: 2m 20s\tremaining: 39.4s\n",
      "1563:\tlearn: 0.0037889\ttotal: 2m 21s\tremaining: 39.3s\n",
      "1564:\tlearn: 0.0037878\ttotal: 2m 21s\tremaining: 39.2s\n",
      "1565:\tlearn: 0.0037858\ttotal: 2m 21s\tremaining: 39.1s\n",
      "1566:\tlearn: 0.0037834\ttotal: 2m 21s\tremaining: 39s\n",
      "1567:\tlearn: 0.0037795\ttotal: 2m 21s\tremaining: 39s\n",
      "1568:\tlearn: 0.0037788\ttotal: 2m 21s\tremaining: 38.9s\n",
      "1569:\tlearn: 0.0037771\ttotal: 2m 21s\tremaining: 38.8s\n",
      "1570:\tlearn: 0.0037768\ttotal: 2m 21s\tremaining: 38.7s\n",
      "1571:\tlearn: 0.0037757\ttotal: 2m 21s\tremaining: 38.6s\n",
      "1572:\tlearn: 0.0037710\ttotal: 2m 21s\tremaining: 38.5s\n",
      "1573:\tlearn: 0.0037672\ttotal: 2m 21s\tremaining: 38.4s\n",
      "1574:\tlearn: 0.0037660\ttotal: 2m 21s\tremaining: 38.3s\n",
      "1575:\tlearn: 0.0037651\ttotal: 2m 22s\tremaining: 38.2s\n",
      "1576:\tlearn: 0.0037648\ttotal: 2m 22s\tremaining: 38.1s\n",
      "1577:\tlearn: 0.0037642\ttotal: 2m 22s\tremaining: 38s\n",
      "1578:\tlearn: 0.0037636\ttotal: 2m 22s\tremaining: 38s\n",
      "1579:\tlearn: 0.0037563\ttotal: 2m 22s\tremaining: 37.9s\n",
      "1580:\tlearn: 0.0037546\ttotal: 2m 22s\tremaining: 37.8s\n",
      "1581:\tlearn: 0.0037465\ttotal: 2m 22s\tremaining: 37.7s\n",
      "1582:\tlearn: 0.0037462\ttotal: 2m 22s\tremaining: 37.6s\n",
      "1583:\tlearn: 0.0037452\ttotal: 2m 22s\tremaining: 37.5s\n",
      "1584:\tlearn: 0.0037406\ttotal: 2m 22s\tremaining: 37.4s\n",
      "1585:\tlearn: 0.0037391\ttotal: 2m 22s\tremaining: 37.3s\n",
      "1586:\tlearn: 0.0037386\ttotal: 2m 23s\tremaining: 37.2s\n",
      "1587:\tlearn: 0.0037377\ttotal: 2m 23s\tremaining: 37.1s\n",
      "1588:\tlearn: 0.0037331\ttotal: 2m 23s\tremaining: 37.1s\n",
      "1589:\tlearn: 0.0037287\ttotal: 2m 23s\tremaining: 37s\n",
      "1590:\tlearn: 0.0037272\ttotal: 2m 23s\tremaining: 36.9s\n",
      "1591:\tlearn: 0.0037269\ttotal: 2m 23s\tremaining: 36.8s\n",
      "1592:\tlearn: 0.0037254\ttotal: 2m 23s\tremaining: 36.7s\n",
      "1593:\tlearn: 0.0037221\ttotal: 2m 23s\tremaining: 36.6s\n",
      "1594:\tlearn: 0.0037214\ttotal: 2m 23s\tremaining: 36.5s\n",
      "1595:\tlearn: 0.0037153\ttotal: 2m 23s\tremaining: 36.4s\n",
      "1596:\tlearn: 0.0037115\ttotal: 2m 23s\tremaining: 36.3s\n",
      "1597:\tlearn: 0.0037055\ttotal: 2m 24s\tremaining: 36.2s\n",
      "1598:\tlearn: 0.0037052\ttotal: 2m 24s\tremaining: 36.1s\n",
      "1599:\tlearn: 0.0037050\ttotal: 2m 24s\tremaining: 36.1s\n",
      "1600:\tlearn: 0.0037046\ttotal: 2m 24s\tremaining: 36s\n",
      "1601:\tlearn: 0.0036997\ttotal: 2m 24s\tremaining: 35.9s\n",
      "1602:\tlearn: 0.0036984\ttotal: 2m 24s\tremaining: 35.8s\n",
      "1603:\tlearn: 0.0036954\ttotal: 2m 24s\tremaining: 35.7s\n",
      "1604:\tlearn: 0.0036944\ttotal: 2m 24s\tremaining: 35.6s\n",
      "1605:\tlearn: 0.0036929\ttotal: 2m 24s\tremaining: 35.5s\n",
      "1606:\tlearn: 0.0036925\ttotal: 2m 24s\tremaining: 35.4s\n",
      "1607:\tlearn: 0.0036915\ttotal: 2m 24s\tremaining: 35.3s\n",
      "1608:\tlearn: 0.0036859\ttotal: 2m 25s\tremaining: 35.2s\n",
      "1609:\tlearn: 0.0036846\ttotal: 2m 25s\tremaining: 35.1s\n",
      "1610:\tlearn: 0.0036818\ttotal: 2m 25s\tremaining: 35.1s\n",
      "1611:\tlearn: 0.0036817\ttotal: 2m 25s\tremaining: 35s\n",
      "1612:\tlearn: 0.0036796\ttotal: 2m 25s\tremaining: 34.9s\n",
      "1613:\tlearn: 0.0036781\ttotal: 2m 25s\tremaining: 34.8s\n",
      "1614:\tlearn: 0.0036714\ttotal: 2m 25s\tremaining: 34.7s\n",
      "1615:\tlearn: 0.0036664\ttotal: 2m 25s\tremaining: 34.6s\n",
      "1616:\tlearn: 0.0036663\ttotal: 2m 25s\tremaining: 34.5s\n",
      "1617:\tlearn: 0.0036636\ttotal: 2m 25s\tremaining: 34.4s\n",
      "1618:\tlearn: 0.0036634\ttotal: 2m 25s\tremaining: 34.3s\n",
      "1619:\tlearn: 0.0036593\ttotal: 2m 25s\tremaining: 34.2s\n",
      "1620:\tlearn: 0.0036580\ttotal: 2m 26s\tremaining: 34.2s\n",
      "1621:\tlearn: 0.0036551\ttotal: 2m 26s\tremaining: 34.1s\n",
      "1622:\tlearn: 0.0036548\ttotal: 2m 26s\tremaining: 34s\n",
      "1623:\tlearn: 0.0036527\ttotal: 2m 26s\tremaining: 33.9s\n",
      "1624:\tlearn: 0.0036514\ttotal: 2m 26s\tremaining: 33.8s\n",
      "1625:\tlearn: 0.0036510\ttotal: 2m 26s\tremaining: 33.7s\n",
      "1626:\tlearn: 0.0036505\ttotal: 2m 26s\tremaining: 33.6s\n",
      "1627:\tlearn: 0.0036502\ttotal: 2m 26s\tremaining: 33.5s\n",
      "1628:\tlearn: 0.0036479\ttotal: 2m 26s\tremaining: 33.4s\n",
      "1629:\tlearn: 0.0036454\ttotal: 2m 26s\tremaining: 33.3s\n",
      "1630:\tlearn: 0.0036449\ttotal: 2m 26s\tremaining: 33.3s\n",
      "1631:\tlearn: 0.0036437\ttotal: 2m 27s\tremaining: 33.2s\n",
      "1632:\tlearn: 0.0036429\ttotal: 2m 27s\tremaining: 33.1s\n",
      "1633:\tlearn: 0.0036396\ttotal: 2m 27s\tremaining: 33s\n",
      "1634:\tlearn: 0.0036379\ttotal: 2m 27s\tremaining: 32.9s\n",
      "1635:\tlearn: 0.0036357\ttotal: 2m 27s\tremaining: 32.8s\n",
      "1636:\tlearn: 0.0036321\ttotal: 2m 27s\tremaining: 32.7s\n",
      "1637:\tlearn: 0.0036310\ttotal: 2m 27s\tremaining: 32.6s\n",
      "1638:\tlearn: 0.0036296\ttotal: 2m 27s\tremaining: 32.5s\n",
      "1639:\tlearn: 0.0036257\ttotal: 2m 27s\tremaining: 32.4s\n",
      "1640:\tlearn: 0.0036254\ttotal: 2m 27s\tremaining: 32.3s\n",
      "1641:\tlearn: 0.0036196\ttotal: 2m 27s\tremaining: 32.3s\n",
      "1642:\tlearn: 0.0036161\ttotal: 2m 28s\tremaining: 32.2s\n",
      "1643:\tlearn: 0.0036138\ttotal: 2m 28s\tremaining: 32.1s\n",
      "1644:\tlearn: 0.0036111\ttotal: 2m 28s\tremaining: 32s\n",
      "1645:\tlearn: 0.0036104\ttotal: 2m 28s\tremaining: 31.9s\n",
      "1646:\tlearn: 0.0036099\ttotal: 2m 28s\tremaining: 31.8s\n",
      "1647:\tlearn: 0.0036091\ttotal: 2m 28s\tremaining: 31.8s\n",
      "1648:\tlearn: 0.0036060\ttotal: 2m 28s\tremaining: 31.7s\n",
      "1649:\tlearn: 0.0036040\ttotal: 2m 28s\tremaining: 31.6s\n",
      "1650:\tlearn: 0.0036012\ttotal: 2m 29s\tremaining: 31.5s\n",
      "1651:\tlearn: 0.0035980\ttotal: 2m 29s\tremaining: 31.4s\n",
      "1652:\tlearn: 0.0035968\ttotal: 2m 29s\tremaining: 31.3s\n",
      "1653:\tlearn: 0.0035959\ttotal: 2m 29s\tremaining: 31.2s\n",
      "1654:\tlearn: 0.0035946\ttotal: 2m 29s\tremaining: 31.1s\n",
      "1655:\tlearn: 0.0035923\ttotal: 2m 29s\tremaining: 31.1s\n",
      "1656:\tlearn: 0.0035920\ttotal: 2m 29s\tremaining: 31s\n",
      "1657:\tlearn: 0.0035906\ttotal: 2m 29s\tremaining: 30.9s\n",
      "1658:\tlearn: 0.0035877\ttotal: 2m 29s\tremaining: 30.8s\n",
      "1659:\tlearn: 0.0035848\ttotal: 2m 29s\tremaining: 30.7s\n",
      "1660:\tlearn: 0.0035844\ttotal: 2m 29s\tremaining: 30.6s\n",
      "1661:\tlearn: 0.0035836\ttotal: 2m 30s\tremaining: 30.5s\n",
      "1662:\tlearn: 0.0035808\ttotal: 2m 30s\tremaining: 30.4s\n",
      "1663:\tlearn: 0.0035806\ttotal: 2m 30s\tremaining: 30.4s\n",
      "1664:\tlearn: 0.0035777\ttotal: 2m 30s\tremaining: 30.3s\n",
      "1665:\tlearn: 0.0035726\ttotal: 2m 30s\tremaining: 30.2s\n",
      "1666:\tlearn: 0.0035600\ttotal: 2m 30s\tremaining: 30.1s\n",
      "1667:\tlearn: 0.0035598\ttotal: 2m 30s\tremaining: 30s\n",
      "1668:\tlearn: 0.0035543\ttotal: 2m 30s\tremaining: 29.9s\n",
      "1669:\tlearn: 0.0035507\ttotal: 2m 30s\tremaining: 29.8s\n",
      "1670:\tlearn: 0.0035487\ttotal: 2m 31s\tremaining: 29.7s\n",
      "1671:\tlearn: 0.0035477\ttotal: 2m 31s\tremaining: 29.7s\n",
      "1672:\tlearn: 0.0035464\ttotal: 2m 31s\tremaining: 29.6s\n",
      "1673:\tlearn: 0.0035460\ttotal: 2m 31s\tremaining: 29.5s\n",
      "1674:\tlearn: 0.0035452\ttotal: 2m 31s\tremaining: 29.4s\n",
      "1675:\tlearn: 0.0035421\ttotal: 2m 31s\tremaining: 29.3s\n",
      "1676:\tlearn: 0.0035415\ttotal: 2m 31s\tremaining: 29.2s\n",
      "1677:\tlearn: 0.0035379\ttotal: 2m 31s\tremaining: 29.1s\n",
      "1678:\tlearn: 0.0035367\ttotal: 2m 31s\tremaining: 29s\n",
      "1679:\tlearn: 0.0035366\ttotal: 2m 31s\tremaining: 28.9s\n",
      "1680:\tlearn: 0.0035331\ttotal: 2m 32s\tremaining: 28.9s\n",
      "1681:\tlearn: 0.0035289\ttotal: 2m 32s\tremaining: 28.8s\n",
      "1682:\tlearn: 0.0035259\ttotal: 2m 32s\tremaining: 28.7s\n",
      "1683:\tlearn: 0.0035243\ttotal: 2m 32s\tremaining: 28.6s\n",
      "1684:\tlearn: 0.0035242\ttotal: 2m 32s\tremaining: 28.5s\n",
      "1685:\tlearn: 0.0035206\ttotal: 2m 32s\tremaining: 28.4s\n",
      "1686:\tlearn: 0.0035203\ttotal: 2m 32s\tremaining: 28.3s\n",
      "1687:\tlearn: 0.0035200\ttotal: 2m 32s\tremaining: 28.2s\n",
      "1688:\tlearn: 0.0035192\ttotal: 2m 32s\tremaining: 28.1s\n",
      "1689:\tlearn: 0.0035129\ttotal: 2m 32s\tremaining: 28.1s\n",
      "1690:\tlearn: 0.0035091\ttotal: 2m 33s\tremaining: 28s\n",
      "1691:\tlearn: 0.0035062\ttotal: 2m 33s\tremaining: 27.9s\n",
      "1692:\tlearn: 0.0035060\ttotal: 2m 33s\tremaining: 27.8s\n",
      "1693:\tlearn: 0.0035055\ttotal: 2m 33s\tremaining: 27.7s\n",
      "1694:\tlearn: 0.0035007\ttotal: 2m 33s\tremaining: 27.6s\n",
      "1695:\tlearn: 0.0035001\ttotal: 2m 33s\tremaining: 27.5s\n",
      "1696:\tlearn: 0.0034984\ttotal: 2m 33s\tremaining: 27.5s\n",
      "1697:\tlearn: 0.0034973\ttotal: 2m 33s\tremaining: 27.4s\n",
      "1698:\tlearn: 0.0034970\ttotal: 2m 33s\tremaining: 27.3s\n",
      "1699:\tlearn: 0.0034927\ttotal: 2m 34s\tremaining: 27.2s\n",
      "1700:\tlearn: 0.0034895\ttotal: 2m 34s\tremaining: 27.1s\n",
      "1701:\tlearn: 0.0034887\ttotal: 2m 34s\tremaining: 27s\n",
      "1702:\tlearn: 0.0034880\ttotal: 2m 34s\tremaining: 26.9s\n",
      "1703:\tlearn: 0.0034871\ttotal: 2m 34s\tremaining: 26.8s\n",
      "1704:\tlearn: 0.0034865\ttotal: 2m 34s\tremaining: 26.7s\n",
      "1705:\tlearn: 0.0034825\ttotal: 2m 34s\tremaining: 26.6s\n",
      "1706:\tlearn: 0.0034805\ttotal: 2m 34s\tremaining: 26.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1707:\tlearn: 0.0034797\ttotal: 2m 34s\tremaining: 26.5s\n",
      "1708:\tlearn: 0.0034790\ttotal: 2m 34s\tremaining: 26.4s\n",
      "1709:\tlearn: 0.0034788\ttotal: 2m 34s\tremaining: 26.3s\n",
      "1710:\tlearn: 0.0034786\ttotal: 2m 35s\tremaining: 26.2s\n",
      "1711:\tlearn: 0.0034769\ttotal: 2m 35s\tremaining: 26.1s\n",
      "1712:\tlearn: 0.0034767\ttotal: 2m 35s\tremaining: 26s\n",
      "1713:\tlearn: 0.0034719\ttotal: 2m 35s\tremaining: 25.9s\n",
      "1714:\tlearn: 0.0034711\ttotal: 2m 35s\tremaining: 25.8s\n",
      "1715:\tlearn: 0.0034700\ttotal: 2m 35s\tremaining: 25.7s\n",
      "1716:\tlearn: 0.0034688\ttotal: 2m 35s\tremaining: 25.7s\n",
      "1717:\tlearn: 0.0034686\ttotal: 2m 35s\tremaining: 25.6s\n",
      "1718:\tlearn: 0.0034664\ttotal: 2m 35s\tremaining: 25.5s\n",
      "1719:\tlearn: 0.0034600\ttotal: 2m 35s\tremaining: 25.4s\n",
      "1720:\tlearn: 0.0034588\ttotal: 2m 36s\tremaining: 25.3s\n",
      "1721:\tlearn: 0.0034582\ttotal: 2m 36s\tremaining: 25.2s\n",
      "1722:\tlearn: 0.0034565\ttotal: 2m 36s\tremaining: 25.1s\n",
      "1723:\tlearn: 0.0034563\ttotal: 2m 36s\tremaining: 25s\n",
      "1724:\tlearn: 0.0034548\ttotal: 2m 36s\tremaining: 24.9s\n",
      "1725:\tlearn: 0.0034534\ttotal: 2m 36s\tremaining: 24.9s\n",
      "1726:\tlearn: 0.0034501\ttotal: 2m 36s\tremaining: 24.8s\n",
      "1727:\tlearn: 0.0034487\ttotal: 2m 36s\tremaining: 24.7s\n",
      "1728:\tlearn: 0.0034483\ttotal: 2m 36s\tremaining: 24.6s\n",
      "1729:\tlearn: 0.0034447\ttotal: 2m 37s\tremaining: 24.5s\n",
      "1730:\tlearn: 0.0034440\ttotal: 2m 37s\tremaining: 24.4s\n",
      "1731:\tlearn: 0.0034421\ttotal: 2m 37s\tremaining: 24.3s\n",
      "1732:\tlearn: 0.0034412\ttotal: 2m 37s\tremaining: 24.2s\n",
      "1733:\tlearn: 0.0034395\ttotal: 2m 37s\tremaining: 24.2s\n",
      "1734:\tlearn: 0.0034384\ttotal: 2m 37s\tremaining: 24.1s\n",
      "1735:\tlearn: 0.0034372\ttotal: 2m 37s\tremaining: 24s\n",
      "1736:\tlearn: 0.0034348\ttotal: 2m 37s\tremaining: 23.9s\n",
      "1737:\tlearn: 0.0034331\ttotal: 2m 37s\tremaining: 23.8s\n",
      "1738:\tlearn: 0.0034306\ttotal: 2m 37s\tremaining: 23.7s\n",
      "1739:\tlearn: 0.0034302\ttotal: 2m 38s\tremaining: 23.6s\n",
      "1740:\tlearn: 0.0034294\ttotal: 2m 38s\tremaining: 23.5s\n",
      "1741:\tlearn: 0.0034292\ttotal: 2m 38s\tremaining: 23.4s\n",
      "1742:\tlearn: 0.0034246\ttotal: 2m 38s\tremaining: 23.4s\n",
      "1743:\tlearn: 0.0034242\ttotal: 2m 38s\tremaining: 23.3s\n",
      "1744:\tlearn: 0.0034202\ttotal: 2m 38s\tremaining: 23.2s\n",
      "1745:\tlearn: 0.0034199\ttotal: 2m 38s\tremaining: 23.1s\n",
      "1746:\tlearn: 0.0034191\ttotal: 2m 38s\tremaining: 23s\n",
      "1747:\tlearn: 0.0034188\ttotal: 2m 38s\tremaining: 22.9s\n",
      "1748:\tlearn: 0.0034182\ttotal: 2m 39s\tremaining: 22.8s\n",
      "1749:\tlearn: 0.0034173\ttotal: 2m 39s\tremaining: 22.7s\n",
      "1750:\tlearn: 0.0034170\ttotal: 2m 39s\tremaining: 22.6s\n",
      "1751:\tlearn: 0.0034130\ttotal: 2m 39s\tremaining: 22.6s\n",
      "1752:\tlearn: 0.0034125\ttotal: 2m 39s\tremaining: 22.5s\n",
      "1753:\tlearn: 0.0034120\ttotal: 2m 39s\tremaining: 22.4s\n",
      "1754:\tlearn: 0.0034104\ttotal: 2m 39s\tremaining: 22.3s\n",
      "1755:\tlearn: 0.0034096\ttotal: 2m 39s\tremaining: 22.2s\n",
      "1756:\tlearn: 0.0034094\ttotal: 2m 39s\tremaining: 22.1s\n",
      "1757:\tlearn: 0.0034044\ttotal: 2m 39s\tremaining: 22s\n",
      "1758:\tlearn: 0.0034039\ttotal: 2m 40s\tremaining: 21.9s\n",
      "1759:\tlearn: 0.0034030\ttotal: 2m 40s\tremaining: 21.8s\n",
      "1760:\tlearn: 0.0034007\ttotal: 2m 40s\tremaining: 21.8s\n",
      "1761:\tlearn: 0.0033984\ttotal: 2m 40s\tremaining: 21.7s\n",
      "1762:\tlearn: 0.0033909\ttotal: 2m 40s\tremaining: 21.6s\n",
      "1763:\tlearn: 0.0033899\ttotal: 2m 40s\tremaining: 21.5s\n",
      "1764:\tlearn: 0.0033878\ttotal: 2m 40s\tremaining: 21.4s\n",
      "1765:\tlearn: 0.0033822\ttotal: 2m 40s\tremaining: 21.3s\n",
      "1766:\tlearn: 0.0033820\ttotal: 2m 40s\tremaining: 21.2s\n",
      "1767:\tlearn: 0.0033817\ttotal: 2m 41s\tremaining: 21.1s\n",
      "1768:\tlearn: 0.0033790\ttotal: 2m 41s\tremaining: 21s\n",
      "1769:\tlearn: 0.0033789\ttotal: 2m 41s\tremaining: 21s\n",
      "1770:\tlearn: 0.0033786\ttotal: 2m 41s\tremaining: 20.9s\n",
      "1771:\tlearn: 0.0033777\ttotal: 2m 41s\tremaining: 20.8s\n",
      "1772:\tlearn: 0.0033773\ttotal: 2m 41s\tremaining: 20.7s\n",
      "1773:\tlearn: 0.0033757\ttotal: 2m 41s\tremaining: 20.6s\n",
      "1774:\tlearn: 0.0033747\ttotal: 2m 41s\tremaining: 20.5s\n",
      "1775:\tlearn: 0.0033715\ttotal: 2m 41s\tremaining: 20.4s\n",
      "1776:\tlearn: 0.0033706\ttotal: 2m 41s\tremaining: 20.3s\n",
      "1777:\tlearn: 0.0033687\ttotal: 2m 42s\tremaining: 20.2s\n",
      "1778:\tlearn: 0.0033685\ttotal: 2m 42s\tremaining: 20.1s\n",
      "1779:\tlearn: 0.0033656\ttotal: 2m 42s\tremaining: 20s\n",
      "1780:\tlearn: 0.0033635\ttotal: 2m 42s\tremaining: 20s\n",
      "1781:\tlearn: 0.0033611\ttotal: 2m 42s\tremaining: 19.9s\n",
      "1782:\tlearn: 0.0033610\ttotal: 2m 42s\tremaining: 19.8s\n",
      "1783:\tlearn: 0.0033606\ttotal: 2m 42s\tremaining: 19.7s\n",
      "1784:\tlearn: 0.0033591\ttotal: 2m 42s\tremaining: 19.6s\n",
      "1785:\tlearn: 0.0033580\ttotal: 2m 42s\tremaining: 19.5s\n",
      "1786:\tlearn: 0.0033576\ttotal: 2m 42s\tremaining: 19.4s\n",
      "1787:\tlearn: 0.0033573\ttotal: 2m 43s\tremaining: 19.3s\n",
      "1788:\tlearn: 0.0033571\ttotal: 2m 43s\tremaining: 19.2s\n",
      "1789:\tlearn: 0.0033565\ttotal: 2m 43s\tremaining: 19.2s\n",
      "1790:\tlearn: 0.0033560\ttotal: 2m 43s\tremaining: 19.1s\n",
      "1791:\tlearn: 0.0033521\ttotal: 2m 43s\tremaining: 19s\n",
      "1792:\tlearn: 0.0033506\ttotal: 2m 43s\tremaining: 18.9s\n",
      "1793:\tlearn: 0.0033468\ttotal: 2m 43s\tremaining: 18.8s\n",
      "1794:\tlearn: 0.0033458\ttotal: 2m 43s\tremaining: 18.7s\n",
      "1795:\tlearn: 0.0033444\ttotal: 2m 43s\tremaining: 18.6s\n",
      "1796:\tlearn: 0.0033431\ttotal: 2m 43s\tremaining: 18.5s\n",
      "1797:\tlearn: 0.0033420\ttotal: 2m 44s\tremaining: 18.4s\n",
      "1798:\tlearn: 0.0033418\ttotal: 2m 44s\tremaining: 18.3s\n",
      "1799:\tlearn: 0.0033411\ttotal: 2m 44s\tremaining: 18.3s\n",
      "1800:\tlearn: 0.0033410\ttotal: 2m 44s\tremaining: 18.2s\n",
      "1801:\tlearn: 0.0033401\ttotal: 2m 44s\tremaining: 18.1s\n",
      "1802:\tlearn: 0.0033371\ttotal: 2m 44s\tremaining: 18s\n",
      "1803:\tlearn: 0.0033370\ttotal: 2m 44s\tremaining: 17.9s\n",
      "1804:\tlearn: 0.0033349\ttotal: 2m 44s\tremaining: 17.8s\n",
      "1805:\tlearn: 0.0033324\ttotal: 2m 44s\tremaining: 17.7s\n",
      "1806:\tlearn: 0.0033282\ttotal: 2m 44s\tremaining: 17.6s\n",
      "1807:\tlearn: 0.0033255\ttotal: 2m 45s\tremaining: 17.5s\n",
      "1808:\tlearn: 0.0033244\ttotal: 2m 45s\tremaining: 17.4s\n",
      "1809:\tlearn: 0.0033226\ttotal: 2m 45s\tremaining: 17.4s\n",
      "1810:\tlearn: 0.0033206\ttotal: 2m 45s\tremaining: 17.3s\n",
      "1811:\tlearn: 0.0033204\ttotal: 2m 45s\tremaining: 17.2s\n",
      "1812:\tlearn: 0.0033183\ttotal: 2m 45s\tremaining: 17.1s\n",
      "1813:\tlearn: 0.0033161\ttotal: 2m 45s\tremaining: 17s\n",
      "1814:\tlearn: 0.0033126\ttotal: 2m 45s\tremaining: 16.9s\n",
      "1815:\tlearn: 0.0033120\ttotal: 2m 45s\tremaining: 16.8s\n",
      "1816:\tlearn: 0.0033101\ttotal: 2m 46s\tremaining: 16.7s\n",
      "1817:\tlearn: 0.0033073\ttotal: 2m 46s\tremaining: 16.6s\n",
      "1818:\tlearn: 0.0033070\ttotal: 2m 46s\tremaining: 16.5s\n",
      "1819:\tlearn: 0.0033063\ttotal: 2m 46s\tremaining: 16.4s\n",
      "1820:\tlearn: 0.0033025\ttotal: 2m 46s\tremaining: 16.4s\n",
      "1821:\tlearn: 0.0033024\ttotal: 2m 46s\tremaining: 16.3s\n",
      "1822:\tlearn: 0.0032985\ttotal: 2m 46s\tremaining: 16.2s\n",
      "1823:\tlearn: 0.0032966\ttotal: 2m 46s\tremaining: 16.1s\n",
      "1824:\tlearn: 0.0032963\ttotal: 2m 46s\tremaining: 16s\n",
      "1825:\tlearn: 0.0032959\ttotal: 2m 46s\tremaining: 15.9s\n",
      "1826:\tlearn: 0.0032945\ttotal: 2m 47s\tremaining: 15.8s\n",
      "1827:\tlearn: 0.0032920\ttotal: 2m 47s\tremaining: 15.7s\n",
      "1828:\tlearn: 0.0032825\ttotal: 2m 47s\tremaining: 15.6s\n",
      "1829:\tlearn: 0.0032816\ttotal: 2m 47s\tremaining: 15.6s\n",
      "1830:\tlearn: 0.0032783\ttotal: 2m 47s\tremaining: 15.5s\n",
      "1831:\tlearn: 0.0032779\ttotal: 2m 47s\tremaining: 15.4s\n",
      "1832:\tlearn: 0.0032778\ttotal: 2m 47s\tremaining: 15.3s\n",
      "1833:\tlearn: 0.0032771\ttotal: 2m 47s\tremaining: 15.2s\n",
      "1834:\tlearn: 0.0032721\ttotal: 2m 47s\tremaining: 15.1s\n",
      "1835:\tlearn: 0.0032713\ttotal: 2m 48s\tremaining: 15s\n",
      "1836:\tlearn: 0.0032700\ttotal: 2m 48s\tremaining: 14.9s\n",
      "1837:\tlearn: 0.0032688\ttotal: 2m 48s\tremaining: 14.8s\n",
      "1838:\tlearn: 0.0032686\ttotal: 2m 48s\tremaining: 14.7s\n",
      "1839:\tlearn: 0.0032684\ttotal: 2m 48s\tremaining: 14.6s\n",
      "1840:\tlearn: 0.0032682\ttotal: 2m 48s\tremaining: 14.6s\n",
      "1841:\tlearn: 0.0032672\ttotal: 2m 48s\tremaining: 14.5s\n",
      "1842:\tlearn: 0.0032661\ttotal: 2m 48s\tremaining: 14.4s\n",
      "1843:\tlearn: 0.0032650\ttotal: 2m 48s\tremaining: 14.3s\n",
      "1844:\tlearn: 0.0032648\ttotal: 2m 48s\tremaining: 14.2s\n",
      "1845:\tlearn: 0.0032642\ttotal: 2m 49s\tremaining: 14.1s\n",
      "1846:\tlearn: 0.0032629\ttotal: 2m 49s\tremaining: 14s\n",
      "1847:\tlearn: 0.0032626\ttotal: 2m 49s\tremaining: 13.9s\n",
      "1848:\tlearn: 0.0032623\ttotal: 2m 49s\tremaining: 13.8s\n",
      "1849:\tlearn: 0.0032620\ttotal: 2m 49s\tremaining: 13.7s\n",
      "1850:\tlearn: 0.0032619\ttotal: 2m 49s\tremaining: 13.7s\n",
      "1851:\tlearn: 0.0032618\ttotal: 2m 49s\tremaining: 13.6s\n",
      "1852:\tlearn: 0.0032606\ttotal: 2m 49s\tremaining: 13.5s\n",
      "1853:\tlearn: 0.0032603\ttotal: 2m 49s\tremaining: 13.4s\n",
      "1854:\tlearn: 0.0032598\ttotal: 2m 49s\tremaining: 13.3s\n",
      "1855:\tlearn: 0.0032582\ttotal: 2m 50s\tremaining: 13.2s\n",
      "1856:\tlearn: 0.0032580\ttotal: 2m 50s\tremaining: 13.1s\n",
      "1857:\tlearn: 0.0032577\ttotal: 2m 50s\tremaining: 13s\n",
      "1858:\tlearn: 0.0032557\ttotal: 2m 50s\tremaining: 12.9s\n",
      "1859:\tlearn: 0.0032556\ttotal: 2m 50s\tremaining: 12.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1860:\tlearn: 0.0032554\ttotal: 2m 50s\tremaining: 12.7s\n",
      "1861:\tlearn: 0.0032542\ttotal: 2m 50s\tremaining: 12.6s\n",
      "1862:\tlearn: 0.0032533\ttotal: 2m 50s\tremaining: 12.6s\n",
      "1863:\tlearn: 0.0032527\ttotal: 2m 50s\tremaining: 12.5s\n",
      "1864:\tlearn: 0.0032505\ttotal: 2m 50s\tremaining: 12.4s\n",
      "1865:\tlearn: 0.0032503\ttotal: 2m 51s\tremaining: 12.3s\n",
      "1866:\tlearn: 0.0032499\ttotal: 2m 51s\tremaining: 12.2s\n",
      "1867:\tlearn: 0.0032403\ttotal: 2m 51s\tremaining: 12.1s\n",
      "1868:\tlearn: 0.0032388\ttotal: 2m 51s\tremaining: 12s\n",
      "1869:\tlearn: 0.0032387\ttotal: 2m 51s\tremaining: 11.9s\n",
      "1870:\tlearn: 0.0032386\ttotal: 2m 51s\tremaining: 11.8s\n",
      "1871:\tlearn: 0.0032360\ttotal: 2m 51s\tremaining: 11.7s\n",
      "1872:\tlearn: 0.0032353\ttotal: 2m 51s\tremaining: 11.6s\n",
      "1873:\tlearn: 0.0032351\ttotal: 2m 51s\tremaining: 11.5s\n",
      "1874:\tlearn: 0.0032328\ttotal: 2m 51s\tremaining: 11.5s\n",
      "1875:\tlearn: 0.0032321\ttotal: 2m 51s\tremaining: 11.4s\n",
      "1876:\tlearn: 0.0032303\ttotal: 2m 52s\tremaining: 11.3s\n",
      "1877:\tlearn: 0.0032295\ttotal: 2m 52s\tremaining: 11.2s\n",
      "1878:\tlearn: 0.0032257\ttotal: 2m 52s\tremaining: 11.1s\n",
      "1879:\tlearn: 0.0032203\ttotal: 2m 52s\tremaining: 11s\n",
      "1880:\tlearn: 0.0032175\ttotal: 2m 52s\tremaining: 10.9s\n",
      "1881:\tlearn: 0.0032170\ttotal: 2m 52s\tremaining: 10.8s\n",
      "1882:\tlearn: 0.0032153\ttotal: 2m 52s\tremaining: 10.7s\n",
      "1883:\tlearn: 0.0032148\ttotal: 2m 52s\tremaining: 10.6s\n",
      "1884:\tlearn: 0.0032142\ttotal: 2m 52s\tremaining: 10.5s\n",
      "1885:\tlearn: 0.0032139\ttotal: 2m 52s\tremaining: 10.4s\n",
      "1886:\tlearn: 0.0032124\ttotal: 2m 52s\tremaining: 10.4s\n",
      "1887:\tlearn: 0.0032110\ttotal: 2m 53s\tremaining: 10.3s\n",
      "1888:\tlearn: 0.0032106\ttotal: 2m 53s\tremaining: 10.2s\n",
      "1889:\tlearn: 0.0032096\ttotal: 2m 53s\tremaining: 10.1s\n",
      "1890:\tlearn: 0.0032094\ttotal: 2m 53s\tremaining: 9.99s\n",
      "1891:\tlearn: 0.0032090\ttotal: 2m 53s\tremaining: 9.9s\n",
      "1892:\tlearn: 0.0032084\ttotal: 2m 53s\tremaining: 9.8s\n",
      "1893:\tlearn: 0.0032079\ttotal: 2m 53s\tremaining: 9.71s\n",
      "1894:\tlearn: 0.0032041\ttotal: 2m 53s\tremaining: 9.62s\n",
      "1895:\tlearn: 0.0032033\ttotal: 2m 53s\tremaining: 9.53s\n",
      "1896:\tlearn: 0.0031989\ttotal: 2m 53s\tremaining: 9.44s\n",
      "1897:\tlearn: 0.0031981\ttotal: 2m 53s\tremaining: 9.35s\n",
      "1898:\tlearn: 0.0031947\ttotal: 2m 53s\tremaining: 9.25s\n",
      "1899:\tlearn: 0.0031940\ttotal: 2m 54s\tremaining: 9.16s\n",
      "1900:\tlearn: 0.0031938\ttotal: 2m 54s\tremaining: 9.07s\n",
      "1901:\tlearn: 0.0031882\ttotal: 2m 54s\tremaining: 8.98s\n",
      "1902:\tlearn: 0.0031861\ttotal: 2m 54s\tremaining: 8.89s\n",
      "1903:\tlearn: 0.0031831\ttotal: 2m 54s\tremaining: 8.8s\n",
      "1904:\tlearn: 0.0031810\ttotal: 2m 54s\tremaining: 8.7s\n",
      "1905:\tlearn: 0.0031778\ttotal: 2m 54s\tremaining: 8.61s\n",
      "1906:\tlearn: 0.0031772\ttotal: 2m 54s\tremaining: 8.52s\n",
      "1907:\tlearn: 0.0031770\ttotal: 2m 54s\tremaining: 8.43s\n",
      "1908:\tlearn: 0.0031755\ttotal: 2m 54s\tremaining: 8.34s\n",
      "1909:\tlearn: 0.0031753\ttotal: 2m 55s\tremaining: 8.25s\n",
      "1910:\tlearn: 0.0031746\ttotal: 2m 55s\tremaining: 8.15s\n",
      "1911:\tlearn: 0.0031741\ttotal: 2m 55s\tremaining: 8.06s\n",
      "1912:\tlearn: 0.0031737\ttotal: 2m 55s\tremaining: 7.97s\n",
      "1913:\tlearn: 0.0031733\ttotal: 2m 55s\tremaining: 7.88s\n",
      "1914:\tlearn: 0.0031719\ttotal: 2m 55s\tremaining: 7.79s\n",
      "1915:\tlearn: 0.0031718\ttotal: 2m 55s\tremaining: 7.7s\n",
      "1916:\tlearn: 0.0031717\ttotal: 2m 55s\tremaining: 7.6s\n",
      "1917:\tlearn: 0.0031672\ttotal: 2m 55s\tremaining: 7.51s\n",
      "1918:\tlearn: 0.0031656\ttotal: 2m 55s\tremaining: 7.42s\n",
      "1919:\tlearn: 0.0031654\ttotal: 2m 55s\tremaining: 7.33s\n",
      "1920:\tlearn: 0.0031654\ttotal: 2m 55s\tremaining: 7.24s\n",
      "1921:\tlearn: 0.0031606\ttotal: 2m 56s\tremaining: 7.14s\n",
      "1922:\tlearn: 0.0031539\ttotal: 2m 56s\tremaining: 7.05s\n",
      "1923:\tlearn: 0.0031504\ttotal: 2m 56s\tremaining: 6.96s\n",
      "1924:\tlearn: 0.0031494\ttotal: 2m 56s\tremaining: 6.87s\n",
      "1925:\tlearn: 0.0031486\ttotal: 2m 56s\tremaining: 6.78s\n",
      "1926:\tlearn: 0.0031473\ttotal: 2m 56s\tremaining: 6.69s\n",
      "1927:\tlearn: 0.0031437\ttotal: 2m 56s\tremaining: 6.59s\n",
      "1928:\tlearn: 0.0031436\ttotal: 2m 56s\tremaining: 6.5s\n",
      "1929:\tlearn: 0.0031417\ttotal: 2m 56s\tremaining: 6.41s\n",
      "1930:\tlearn: 0.0031413\ttotal: 2m 56s\tremaining: 6.32s\n",
      "1931:\tlearn: 0.0031397\ttotal: 2m 56s\tremaining: 6.23s\n",
      "1932:\tlearn: 0.0031385\ttotal: 2m 57s\tremaining: 6.14s\n",
      "1933:\tlearn: 0.0031384\ttotal: 2m 57s\tremaining: 6.05s\n",
      "1934:\tlearn: 0.0031373\ttotal: 2m 57s\tremaining: 5.96s\n",
      "1935:\tlearn: 0.0031344\ttotal: 2m 57s\tremaining: 5.87s\n",
      "1936:\tlearn: 0.0031314\ttotal: 2m 57s\tremaining: 5.77s\n",
      "1937:\tlearn: 0.0031287\ttotal: 2m 57s\tremaining: 5.68s\n",
      "1938:\tlearn: 0.0031274\ttotal: 2m 57s\tremaining: 5.59s\n",
      "1939:\tlearn: 0.0031251\ttotal: 2m 57s\tremaining: 5.5s\n",
      "1940:\tlearn: 0.0031247\ttotal: 2m 57s\tremaining: 5.41s\n",
      "1941:\tlearn: 0.0031242\ttotal: 2m 58s\tremaining: 5.32s\n",
      "1942:\tlearn: 0.0031154\ttotal: 2m 58s\tremaining: 5.23s\n",
      "1943:\tlearn: 0.0031113\ttotal: 2m 58s\tremaining: 5.13s\n",
      "1944:\tlearn: 0.0031112\ttotal: 2m 58s\tremaining: 5.04s\n",
      "1945:\tlearn: 0.0031046\ttotal: 2m 58s\tremaining: 4.95s\n",
      "1946:\tlearn: 0.0031041\ttotal: 2m 58s\tremaining: 4.86s\n",
      "1947:\tlearn: 0.0031040\ttotal: 2m 58s\tremaining: 4.77s\n",
      "1948:\tlearn: 0.0031037\ttotal: 2m 58s\tremaining: 4.68s\n",
      "1949:\tlearn: 0.0031006\ttotal: 2m 58s\tremaining: 4.59s\n",
      "1950:\tlearn: 0.0030980\ttotal: 2m 58s\tremaining: 4.5s\n",
      "1951:\tlearn: 0.0030977\ttotal: 2m 59s\tremaining: 4.4s\n",
      "1952:\tlearn: 0.0030973\ttotal: 2m 59s\tremaining: 4.31s\n",
      "1953:\tlearn: 0.0030956\ttotal: 2m 59s\tremaining: 4.22s\n",
      "1954:\tlearn: 0.0030930\ttotal: 2m 59s\tremaining: 4.13s\n",
      "1955:\tlearn: 0.0030920\ttotal: 2m 59s\tremaining: 4.04s\n",
      "1956:\tlearn: 0.0030864\ttotal: 2m 59s\tremaining: 3.95s\n",
      "1957:\tlearn: 0.0030817\ttotal: 2m 59s\tremaining: 3.85s\n",
      "1958:\tlearn: 0.0030802\ttotal: 2m 59s\tremaining: 3.76s\n",
      "1959:\tlearn: 0.0030801\ttotal: 2m 59s\tremaining: 3.67s\n",
      "1960:\tlearn: 0.0030796\ttotal: 3m\tremaining: 3.58s\n",
      "1961:\tlearn: 0.0030782\ttotal: 3m\tremaining: 3.49s\n",
      "1962:\tlearn: 0.0030775\ttotal: 3m\tremaining: 3.4s\n",
      "1963:\tlearn: 0.0030757\ttotal: 3m\tremaining: 3.31s\n",
      "1964:\tlearn: 0.0030751\ttotal: 3m\tremaining: 3.21s\n",
      "1965:\tlearn: 0.0030742\ttotal: 3m\tremaining: 3.12s\n",
      "1966:\tlearn: 0.0030723\ttotal: 3m\tremaining: 3.03s\n",
      "1967:\tlearn: 0.0030678\ttotal: 3m\tremaining: 2.94s\n",
      "1968:\tlearn: 0.0030666\ttotal: 3m\tremaining: 2.85s\n",
      "1969:\tlearn: 0.0030661\ttotal: 3m\tremaining: 2.76s\n",
      "1970:\tlearn: 0.0030660\ttotal: 3m 1s\tremaining: 2.66s\n",
      "1971:\tlearn: 0.0030640\ttotal: 3m 1s\tremaining: 2.57s\n",
      "1972:\tlearn: 0.0030637\ttotal: 3m 1s\tremaining: 2.48s\n",
      "1973:\tlearn: 0.0030636\ttotal: 3m 1s\tremaining: 2.39s\n",
      "1974:\tlearn: 0.0030630\ttotal: 3m 1s\tremaining: 2.3s\n",
      "1975:\tlearn: 0.0030615\ttotal: 3m 1s\tremaining: 2.21s\n",
      "1976:\tlearn: 0.0030612\ttotal: 3m 1s\tremaining: 2.11s\n",
      "1977:\tlearn: 0.0030609\ttotal: 3m 1s\tremaining: 2.02s\n",
      "1978:\tlearn: 0.0030593\ttotal: 3m 1s\tremaining: 1.93s\n",
      "1979:\tlearn: 0.0030565\ttotal: 3m 1s\tremaining: 1.84s\n",
      "1980:\tlearn: 0.0030548\ttotal: 3m 2s\tremaining: 1.75s\n",
      "1981:\tlearn: 0.0030545\ttotal: 3m 2s\tremaining: 1.65s\n",
      "1982:\tlearn: 0.0030543\ttotal: 3m 2s\tremaining: 1.56s\n",
      "1983:\tlearn: 0.0030522\ttotal: 3m 2s\tremaining: 1.47s\n",
      "1984:\tlearn: 0.0030518\ttotal: 3m 2s\tremaining: 1.38s\n",
      "1985:\tlearn: 0.0030489\ttotal: 3m 2s\tremaining: 1.29s\n",
      "1986:\tlearn: 0.0030469\ttotal: 3m 2s\tremaining: 1.2s\n",
      "1987:\tlearn: 0.0030433\ttotal: 3m 2s\tremaining: 1.1s\n",
      "1988:\tlearn: 0.0030431\ttotal: 3m 2s\tremaining: 1.01s\n",
      "1989:\tlearn: 0.0030424\ttotal: 3m 2s\tremaining: 920ms\n",
      "1990:\tlearn: 0.0030423\ttotal: 3m 3s\tremaining: 828ms\n",
      "1991:\tlearn: 0.0030408\ttotal: 3m 3s\tremaining: 736ms\n",
      "1992:\tlearn: 0.0030406\ttotal: 3m 3s\tremaining: 644ms\n",
      "1993:\tlearn: 0.0030395\ttotal: 3m 3s\tremaining: 552ms\n",
      "1994:\tlearn: 0.0030391\ttotal: 3m 3s\tremaining: 460ms\n",
      "1995:\tlearn: 0.0030385\ttotal: 3m 3s\tremaining: 368ms\n",
      "1996:\tlearn: 0.0030335\ttotal: 3m 3s\tremaining: 276ms\n",
      "1997:\tlearn: 0.0030335\ttotal: 3m 3s\tremaining: 184ms\n",
      "1998:\tlearn: 0.0030328\ttotal: 3m 3s\tremaining: 92ms\n",
      "1999:\tlearn: 0.0030326\ttotal: 3m 4s\tremaining: 0us\n",
      "Learning rate set to 0.031656\n",
      "0:\tlearn: 0.6129963\ttotal: 141ms\tremaining: 4m 41s\n",
      "1:\tlearn: 0.5450744\ttotal: 240ms\tremaining: 3m 59s\n",
      "2:\tlearn: 0.4868699\ttotal: 342ms\tremaining: 3m 47s\n",
      "3:\tlearn: 0.4344504\ttotal: 454ms\tremaining: 3m 46s\n",
      "4:\tlearn: 0.3962207\ttotal: 560ms\tremaining: 3m 43s\n",
      "5:\tlearn: 0.3631847\ttotal: 666ms\tremaining: 3m 41s\n",
      "6:\tlearn: 0.3287833\ttotal: 797ms\tremaining: 3m 46s\n",
      "7:\tlearn: 0.3034106\ttotal: 900ms\tremaining: 3m 44s\n",
      "8:\tlearn: 0.2732730\ttotal: 1.01s\tremaining: 3m 43s\n",
      "9:\tlearn: 0.2495762\ttotal: 1.14s\tremaining: 3m 47s\n",
      "10:\tlearn: 0.2274564\ttotal: 1.26s\tremaining: 3m 47s\n",
      "11:\tlearn: 0.2096815\ttotal: 1.37s\tremaining: 3m 46s\n",
      "12:\tlearn: 0.1954009\ttotal: 1.48s\tremaining: 3m 45s\n",
      "13:\tlearn: 0.1853845\ttotal: 1.58s\tremaining: 3m 44s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14:\tlearn: 0.1773964\ttotal: 1.68s\tremaining: 3m 42s\n",
      "15:\tlearn: 0.1683911\ttotal: 1.79s\tremaining: 3m 42s\n",
      "16:\tlearn: 0.1589982\ttotal: 1.9s\tremaining: 3m 41s\n",
      "17:\tlearn: 0.1487062\ttotal: 2s\tremaining: 3m 40s\n",
      "18:\tlearn: 0.1375562\ttotal: 2.11s\tremaining: 3m 40s\n",
      "19:\tlearn: 0.1289210\ttotal: 2.22s\tremaining: 3m 39s\n",
      "20:\tlearn: 0.1196478\ttotal: 2.33s\tremaining: 3m 40s\n",
      "21:\tlearn: 0.1120785\ttotal: 2.44s\tremaining: 3m 39s\n",
      "22:\tlearn: 0.1079969\ttotal: 2.53s\tremaining: 3m 37s\n",
      "23:\tlearn: 0.1028820\ttotal: 2.64s\tremaining: 3m 37s\n",
      "24:\tlearn: 0.0980708\ttotal: 2.76s\tremaining: 3m 37s\n",
      "25:\tlearn: 0.0933086\ttotal: 2.86s\tremaining: 3m 37s\n",
      "26:\tlearn: 0.0890316\ttotal: 2.95s\tremaining: 3m 35s\n",
      "27:\tlearn: 0.0850969\ttotal: 3.05s\tremaining: 3m 35s\n",
      "28:\tlearn: 0.0820012\ttotal: 3.15s\tremaining: 3m 33s\n",
      "29:\tlearn: 0.0803292\ttotal: 3.23s\tremaining: 3m 32s\n",
      "30:\tlearn: 0.0776011\ttotal: 3.33s\tremaining: 3m 31s\n",
      "31:\tlearn: 0.0754231\ttotal: 3.43s\tremaining: 3m 30s\n",
      "32:\tlearn: 0.0732004\ttotal: 3.53s\tremaining: 3m 30s\n",
      "33:\tlearn: 0.0709746\ttotal: 3.63s\tremaining: 3m 30s\n",
      "34:\tlearn: 0.0695956\ttotal: 3.73s\tremaining: 3m 29s\n",
      "35:\tlearn: 0.0669148\ttotal: 3.82s\tremaining: 3m 28s\n",
      "36:\tlearn: 0.0656142\ttotal: 3.92s\tremaining: 3m 28s\n",
      "37:\tlearn: 0.0641112\ttotal: 4.02s\tremaining: 3m 27s\n",
      "38:\tlearn: 0.0625078\ttotal: 4.13s\tremaining: 3m 27s\n",
      "39:\tlearn: 0.0613960\ttotal: 4.23s\tremaining: 3m 27s\n",
      "40:\tlearn: 0.0601196\ttotal: 4.33s\tremaining: 3m 26s\n",
      "41:\tlearn: 0.0591926\ttotal: 4.42s\tremaining: 3m 25s\n",
      "42:\tlearn: 0.0578068\ttotal: 4.52s\tremaining: 3m 25s\n",
      "43:\tlearn: 0.0566624\ttotal: 4.61s\tremaining: 3m 24s\n",
      "44:\tlearn: 0.0557452\ttotal: 4.71s\tremaining: 3m 24s\n",
      "45:\tlearn: 0.0545313\ttotal: 4.81s\tremaining: 3m 24s\n",
      "46:\tlearn: 0.0533669\ttotal: 4.91s\tremaining: 3m 23s\n",
      "47:\tlearn: 0.0522294\ttotal: 5s\tremaining: 3m 23s\n",
      "48:\tlearn: 0.0510613\ttotal: 5.1s\tremaining: 3m 23s\n",
      "49:\tlearn: 0.0504568\ttotal: 5.18s\tremaining: 3m 22s\n",
      "50:\tlearn: 0.0495959\ttotal: 5.27s\tremaining: 3m 21s\n",
      "51:\tlearn: 0.0488101\ttotal: 5.37s\tremaining: 3m 21s\n",
      "52:\tlearn: 0.0477945\ttotal: 5.46s\tremaining: 3m 20s\n",
      "53:\tlearn: 0.0466180\ttotal: 5.56s\tremaining: 3m 20s\n",
      "54:\tlearn: 0.0460134\ttotal: 5.66s\tremaining: 3m 20s\n",
      "55:\tlearn: 0.0453843\ttotal: 5.75s\tremaining: 3m 19s\n",
      "56:\tlearn: 0.0446283\ttotal: 5.84s\tremaining: 3m 19s\n",
      "57:\tlearn: 0.0437662\ttotal: 5.95s\tremaining: 3m 19s\n",
      "58:\tlearn: 0.0432627\ttotal: 6.02s\tremaining: 3m 18s\n",
      "59:\tlearn: 0.0427974\ttotal: 6.12s\tremaining: 3m 17s\n",
      "60:\tlearn: 0.0421494\ttotal: 6.2s\tremaining: 3m 17s\n",
      "61:\tlearn: 0.0416438\ttotal: 6.31s\tremaining: 3m 17s\n",
      "62:\tlearn: 0.0412014\ttotal: 6.39s\tremaining: 3m 16s\n",
      "63:\tlearn: 0.0407960\ttotal: 6.48s\tremaining: 3m 16s\n",
      "64:\tlearn: 0.0404301\ttotal: 6.58s\tremaining: 3m 15s\n",
      "65:\tlearn: 0.0399702\ttotal: 6.67s\tremaining: 3m 15s\n",
      "66:\tlearn: 0.0394063\ttotal: 6.76s\tremaining: 3m 14s\n",
      "67:\tlearn: 0.0390363\ttotal: 6.86s\tremaining: 3m 14s\n",
      "68:\tlearn: 0.0382125\ttotal: 6.95s\tremaining: 3m 14s\n",
      "69:\tlearn: 0.0377050\ttotal: 7.04s\tremaining: 3m 14s\n",
      "70:\tlearn: 0.0371061\ttotal: 7.14s\tremaining: 3m 14s\n",
      "71:\tlearn: 0.0365815\ttotal: 7.25s\tremaining: 3m 14s\n",
      "72:\tlearn: 0.0361377\ttotal: 7.36s\tremaining: 3m 14s\n",
      "73:\tlearn: 0.0359910\ttotal: 7.44s\tremaining: 3m 13s\n",
      "74:\tlearn: 0.0357104\ttotal: 7.53s\tremaining: 3m 13s\n",
      "75:\tlearn: 0.0353399\ttotal: 7.62s\tremaining: 3m 12s\n",
      "76:\tlearn: 0.0349360\ttotal: 7.72s\tremaining: 3m 12s\n",
      "77:\tlearn: 0.0346226\ttotal: 7.8s\tremaining: 3m 12s\n",
      "78:\tlearn: 0.0343296\ttotal: 7.9s\tremaining: 3m 12s\n",
      "79:\tlearn: 0.0340151\ttotal: 7.99s\tremaining: 3m 11s\n",
      "80:\tlearn: 0.0335983\ttotal: 8.07s\tremaining: 3m 11s\n",
      "81:\tlearn: 0.0334164\ttotal: 8.17s\tremaining: 3m 11s\n",
      "82:\tlearn: 0.0329277\ttotal: 8.26s\tremaining: 3m 10s\n",
      "83:\tlearn: 0.0326792\ttotal: 8.34s\tremaining: 3m 10s\n",
      "84:\tlearn: 0.0325103\ttotal: 8.43s\tremaining: 3m 9s\n",
      "85:\tlearn: 0.0323061\ttotal: 8.52s\tremaining: 3m 9s\n",
      "86:\tlearn: 0.0321710\ttotal: 8.6s\tremaining: 3m 9s\n",
      "87:\tlearn: 0.0318113\ttotal: 8.7s\tremaining: 3m 8s\n",
      "88:\tlearn: 0.0316231\ttotal: 8.77s\tremaining: 3m 8s\n",
      "89:\tlearn: 0.0313496\ttotal: 8.86s\tremaining: 3m 7s\n",
      "90:\tlearn: 0.0310568\ttotal: 8.96s\tremaining: 3m 8s\n",
      "91:\tlearn: 0.0306899\ttotal: 9.06s\tremaining: 3m 7s\n",
      "92:\tlearn: 0.0302643\ttotal: 9.15s\tremaining: 3m 7s\n",
      "93:\tlearn: 0.0300639\ttotal: 9.25s\tremaining: 3m 7s\n",
      "94:\tlearn: 0.0298912\ttotal: 9.33s\tremaining: 3m 7s\n",
      "95:\tlearn: 0.0295501\ttotal: 9.43s\tremaining: 3m 7s\n",
      "96:\tlearn: 0.0293262\ttotal: 9.51s\tremaining: 3m 6s\n",
      "97:\tlearn: 0.0292103\ttotal: 9.6s\tremaining: 3m 6s\n",
      "98:\tlearn: 0.0290634\ttotal: 9.69s\tremaining: 3m 6s\n",
      "99:\tlearn: 0.0288924\ttotal: 9.76s\tremaining: 3m 5s\n",
      "100:\tlearn: 0.0286030\ttotal: 9.87s\tremaining: 3m 5s\n",
      "101:\tlearn: 0.0284737\ttotal: 9.94s\tremaining: 3m 4s\n",
      "102:\tlearn: 0.0282204\ttotal: 10s\tremaining: 3m 4s\n",
      "103:\tlearn: 0.0280823\ttotal: 10.1s\tremaining: 3m 4s\n",
      "104:\tlearn: 0.0278513\ttotal: 10.2s\tremaining: 3m 4s\n",
      "105:\tlearn: 0.0277399\ttotal: 10.3s\tremaining: 3m 3s\n",
      "106:\tlearn: 0.0274430\ttotal: 10.4s\tremaining: 3m 3s\n",
      "107:\tlearn: 0.0272875\ttotal: 10.5s\tremaining: 3m 3s\n",
      "108:\tlearn: 0.0269976\ttotal: 10.6s\tremaining: 3m 3s\n",
      "109:\tlearn: 0.0268722\ttotal: 10.7s\tremaining: 3m 3s\n",
      "110:\tlearn: 0.0267993\ttotal: 10.7s\tremaining: 3m 2s\n",
      "111:\tlearn: 0.0265825\ttotal: 10.8s\tremaining: 3m 2s\n",
      "112:\tlearn: 0.0264263\ttotal: 10.9s\tremaining: 3m 2s\n",
      "113:\tlearn: 0.0263167\ttotal: 11s\tremaining: 3m 1s\n",
      "114:\tlearn: 0.0261020\ttotal: 11.1s\tremaining: 3m 1s\n",
      "115:\tlearn: 0.0259651\ttotal: 11.2s\tremaining: 3m 1s\n",
      "116:\tlearn: 0.0256956\ttotal: 11.3s\tremaining: 3m 1s\n",
      "117:\tlearn: 0.0253739\ttotal: 11.4s\tremaining: 3m 1s\n",
      "118:\tlearn: 0.0251403\ttotal: 11.5s\tremaining: 3m 1s\n",
      "119:\tlearn: 0.0250768\ttotal: 11.6s\tremaining: 3m 1s\n",
      "120:\tlearn: 0.0250276\ttotal: 11.6s\tremaining: 3m\n",
      "121:\tlearn: 0.0248628\ttotal: 11.7s\tremaining: 3m\n",
      "122:\tlearn: 0.0245542\ttotal: 11.8s\tremaining: 3m\n",
      "123:\tlearn: 0.0244500\ttotal: 11.9s\tremaining: 3m\n",
      "124:\tlearn: 0.0243042\ttotal: 12s\tremaining: 2m 59s\n",
      "125:\tlearn: 0.0242072\ttotal: 12.1s\tremaining: 2m 59s\n",
      "126:\tlearn: 0.0241423\ttotal: 12.2s\tremaining: 2m 59s\n",
      "127:\tlearn: 0.0240128\ttotal: 12.3s\tremaining: 2m 59s\n",
      "128:\tlearn: 0.0239306\ttotal: 12.4s\tremaining: 2m 59s\n",
      "129:\tlearn: 0.0237243\ttotal: 12.4s\tremaining: 2m 59s\n",
      "130:\tlearn: 0.0236426\ttotal: 12.5s\tremaining: 2m 58s\n",
      "131:\tlearn: 0.0235796\ttotal: 12.6s\tremaining: 2m 58s\n",
      "132:\tlearn: 0.0234385\ttotal: 12.7s\tremaining: 2m 58s\n",
      "133:\tlearn: 0.0232766\ttotal: 12.8s\tremaining: 2m 58s\n",
      "134:\tlearn: 0.0231484\ttotal: 12.9s\tremaining: 2m 58s\n",
      "135:\tlearn: 0.0230854\ttotal: 13s\tremaining: 2m 57s\n",
      "136:\tlearn: 0.0230362\ttotal: 13s\tremaining: 2m 57s\n",
      "137:\tlearn: 0.0229534\ttotal: 13.1s\tremaining: 2m 57s\n",
      "138:\tlearn: 0.0227261\ttotal: 13.2s\tremaining: 2m 57s\n",
      "139:\tlearn: 0.0226101\ttotal: 13.3s\tremaining: 2m 56s\n",
      "140:\tlearn: 0.0225271\ttotal: 13.4s\tremaining: 2m 56s\n",
      "141:\tlearn: 0.0223784\ttotal: 13.5s\tremaining: 2m 56s\n",
      "142:\tlearn: 0.0222798\ttotal: 13.6s\tremaining: 2m 56s\n",
      "143:\tlearn: 0.0220384\ttotal: 13.7s\tremaining: 2m 56s\n",
      "144:\tlearn: 0.0219635\ttotal: 13.8s\tremaining: 2m 56s\n",
      "145:\tlearn: 0.0219037\ttotal: 13.9s\tremaining: 2m 55s\n",
      "146:\tlearn: 0.0218313\ttotal: 13.9s\tremaining: 2m 55s\n",
      "147:\tlearn: 0.0217637\ttotal: 14s\tremaining: 2m 55s\n",
      "148:\tlearn: 0.0216793\ttotal: 14.1s\tremaining: 2m 55s\n",
      "149:\tlearn: 0.0214142\ttotal: 14.2s\tremaining: 2m 55s\n",
      "150:\tlearn: 0.0213170\ttotal: 14.3s\tremaining: 2m 55s\n",
      "151:\tlearn: 0.0212168\ttotal: 14.4s\tremaining: 2m 55s\n",
      "152:\tlearn: 0.0210711\ttotal: 14.5s\tremaining: 2m 54s\n",
      "153:\tlearn: 0.0209824\ttotal: 14.6s\tremaining: 2m 54s\n",
      "154:\tlearn: 0.0209103\ttotal: 14.7s\tremaining: 2m 54s\n",
      "155:\tlearn: 0.0208772\ttotal: 14.8s\tremaining: 2m 54s\n",
      "156:\tlearn: 0.0207928\ttotal: 14.9s\tremaining: 2m 54s\n",
      "157:\tlearn: 0.0207131\ttotal: 15s\tremaining: 2m 54s\n",
      "158:\tlearn: 0.0206346\ttotal: 15s\tremaining: 2m 54s\n",
      "159:\tlearn: 0.0205797\ttotal: 15.1s\tremaining: 2m 53s\n",
      "160:\tlearn: 0.0205469\ttotal: 15.2s\tremaining: 2m 53s\n",
      "161:\tlearn: 0.0204556\ttotal: 15.3s\tremaining: 2m 53s\n",
      "162:\tlearn: 0.0204435\ttotal: 15.4s\tremaining: 2m 53s\n",
      "163:\tlearn: 0.0203284\ttotal: 15.5s\tremaining: 2m 53s\n",
      "164:\tlearn: 0.0202484\ttotal: 15.6s\tremaining: 2m 53s\n",
      "165:\tlearn: 0.0201868\ttotal: 15.6s\tremaining: 2m 52s\n",
      "166:\tlearn: 0.0200762\ttotal: 15.7s\tremaining: 2m 52s\n",
      "167:\tlearn: 0.0200492\ttotal: 15.8s\tremaining: 2m 52s\n",
      "168:\tlearn: 0.0199345\ttotal: 15.9s\tremaining: 2m 52s\n",
      "169:\tlearn: 0.0197763\ttotal: 16s\tremaining: 2m 52s\n",
      "170:\tlearn: 0.0197503\ttotal: 16.1s\tremaining: 2m 52s\n",
      "171:\tlearn: 0.0197072\ttotal: 16.2s\tremaining: 2m 51s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172:\tlearn: 0.0196115\ttotal: 16.3s\tremaining: 2m 51s\n",
      "173:\tlearn: 0.0195677\ttotal: 16.3s\tremaining: 2m 51s\n",
      "174:\tlearn: 0.0194841\ttotal: 16.4s\tremaining: 2m 51s\n",
      "175:\tlearn: 0.0194088\ttotal: 16.5s\tremaining: 2m 51s\n",
      "176:\tlearn: 0.0193298\ttotal: 16.6s\tremaining: 2m 51s\n",
      "177:\tlearn: 0.0192686\ttotal: 16.7s\tremaining: 2m 50s\n",
      "178:\tlearn: 0.0191429\ttotal: 16.8s\tremaining: 2m 50s\n",
      "179:\tlearn: 0.0191111\ttotal: 16.9s\tremaining: 2m 50s\n",
      "180:\tlearn: 0.0190642\ttotal: 16.9s\tremaining: 2m 50s\n",
      "181:\tlearn: 0.0189875\ttotal: 17s\tremaining: 2m 50s\n",
      "182:\tlearn: 0.0189205\ttotal: 17.1s\tremaining: 2m 50s\n",
      "183:\tlearn: 0.0188974\ttotal: 17.2s\tremaining: 2m 49s\n",
      "184:\tlearn: 0.0188240\ttotal: 17.3s\tremaining: 2m 49s\n",
      "185:\tlearn: 0.0187647\ttotal: 17.4s\tremaining: 2m 49s\n",
      "186:\tlearn: 0.0187058\ttotal: 17.5s\tremaining: 2m 49s\n",
      "187:\tlearn: 0.0186836\ttotal: 17.5s\tremaining: 2m 49s\n",
      "188:\tlearn: 0.0186082\ttotal: 17.6s\tremaining: 2m 49s\n",
      "189:\tlearn: 0.0185545\ttotal: 17.7s\tremaining: 2m 48s\n",
      "190:\tlearn: 0.0184877\ttotal: 17.8s\tremaining: 2m 48s\n",
      "191:\tlearn: 0.0184647\ttotal: 17.9s\tremaining: 2m 48s\n",
      "192:\tlearn: 0.0184030\ttotal: 18s\tremaining: 2m 48s\n",
      "193:\tlearn: 0.0183203\ttotal: 18.1s\tremaining: 2m 48s\n",
      "194:\tlearn: 0.0182711\ttotal: 18.1s\tremaining: 2m 47s\n",
      "195:\tlearn: 0.0181705\ttotal: 18.2s\tremaining: 2m 47s\n",
      "196:\tlearn: 0.0181264\ttotal: 18.3s\tremaining: 2m 47s\n",
      "197:\tlearn: 0.0180706\ttotal: 18.4s\tremaining: 2m 47s\n",
      "198:\tlearn: 0.0180217\ttotal: 18.5s\tremaining: 2m 47s\n",
      "199:\tlearn: 0.0179750\ttotal: 18.6s\tremaining: 2m 47s\n",
      "200:\tlearn: 0.0179408\ttotal: 18.7s\tremaining: 2m 47s\n",
      "201:\tlearn: 0.0179176\ttotal: 18.7s\tremaining: 2m 46s\n",
      "202:\tlearn: 0.0178585\ttotal: 18.8s\tremaining: 2m 46s\n",
      "203:\tlearn: 0.0177929\ttotal: 18.9s\tremaining: 2m 46s\n",
      "204:\tlearn: 0.0176924\ttotal: 19s\tremaining: 2m 46s\n",
      "205:\tlearn: 0.0176509\ttotal: 19.1s\tremaining: 2m 46s\n",
      "206:\tlearn: 0.0175523\ttotal: 19.2s\tremaining: 2m 46s\n",
      "207:\tlearn: 0.0175059\ttotal: 19.3s\tremaining: 2m 46s\n",
      "208:\tlearn: 0.0174277\ttotal: 19.4s\tremaining: 2m 46s\n",
      "209:\tlearn: 0.0174247\ttotal: 19.5s\tremaining: 2m 45s\n",
      "210:\tlearn: 0.0173779\ttotal: 19.5s\tremaining: 2m 45s\n",
      "211:\tlearn: 0.0172932\ttotal: 19.6s\tremaining: 2m 45s\n",
      "212:\tlearn: 0.0172619\ttotal: 19.7s\tremaining: 2m 45s\n",
      "213:\tlearn: 0.0172314\ttotal: 19.8s\tremaining: 2m 45s\n",
      "214:\tlearn: 0.0171818\ttotal: 19.9s\tremaining: 2m 45s\n",
      "215:\tlearn: 0.0170109\ttotal: 20s\tremaining: 2m 45s\n",
      "216:\tlearn: 0.0169690\ttotal: 20.1s\tremaining: 2m 44s\n",
      "217:\tlearn: 0.0168947\ttotal: 20.2s\tremaining: 2m 44s\n",
      "218:\tlearn: 0.0168677\ttotal: 20.2s\tremaining: 2m 44s\n",
      "219:\tlearn: 0.0168245\ttotal: 20.3s\tremaining: 2m 44s\n",
      "220:\tlearn: 0.0167133\ttotal: 20.4s\tremaining: 2m 44s\n",
      "221:\tlearn: 0.0166502\ttotal: 20.5s\tremaining: 2m 44s\n",
      "222:\tlearn: 0.0166170\ttotal: 20.6s\tremaining: 2m 43s\n",
      "223:\tlearn: 0.0165884\ttotal: 20.7s\tremaining: 2m 43s\n",
      "224:\tlearn: 0.0165512\ttotal: 20.7s\tremaining: 2m 43s\n",
      "225:\tlearn: 0.0165199\ttotal: 20.8s\tremaining: 2m 43s\n",
      "226:\tlearn: 0.0164874\ttotal: 20.9s\tremaining: 2m 43s\n",
      "227:\tlearn: 0.0164107\ttotal: 21s\tremaining: 2m 43s\n",
      "228:\tlearn: 0.0163829\ttotal: 21.1s\tremaining: 2m 43s\n",
      "229:\tlearn: 0.0163723\ttotal: 21.2s\tremaining: 2m 43s\n",
      "230:\tlearn: 0.0162886\ttotal: 21.3s\tremaining: 2m 42s\n",
      "231:\tlearn: 0.0162533\ttotal: 21.4s\tremaining: 2m 42s\n",
      "232:\tlearn: 0.0162006\ttotal: 21.5s\tremaining: 2m 42s\n",
      "233:\tlearn: 0.0161575\ttotal: 21.5s\tremaining: 2m 42s\n",
      "234:\tlearn: 0.0161459\ttotal: 21.6s\tremaining: 2m 42s\n",
      "235:\tlearn: 0.0161127\ttotal: 21.7s\tremaining: 2m 42s\n",
      "236:\tlearn: 0.0161062\ttotal: 21.8s\tremaining: 2m 41s\n",
      "237:\tlearn: 0.0160962\ttotal: 21.9s\tremaining: 2m 41s\n",
      "238:\tlearn: 0.0160512\ttotal: 22s\tremaining: 2m 41s\n",
      "239:\tlearn: 0.0160374\ttotal: 22s\tremaining: 2m 41s\n",
      "240:\tlearn: 0.0160157\ttotal: 22.1s\tremaining: 2m 41s\n",
      "241:\tlearn: 0.0159766\ttotal: 22.2s\tremaining: 2m 41s\n",
      "242:\tlearn: 0.0159459\ttotal: 22.3s\tremaining: 2m 41s\n",
      "243:\tlearn: 0.0158246\ttotal: 22.4s\tremaining: 2m 41s\n",
      "244:\tlearn: 0.0157561\ttotal: 22.5s\tremaining: 2m 40s\n",
      "245:\tlearn: 0.0157138\ttotal: 22.6s\tremaining: 2m 40s\n",
      "246:\tlearn: 0.0156631\ttotal: 22.6s\tremaining: 2m 40s\n",
      "247:\tlearn: 0.0156218\ttotal: 22.7s\tremaining: 2m 40s\n",
      "248:\tlearn: 0.0155858\ttotal: 22.8s\tremaining: 2m 40s\n",
      "249:\tlearn: 0.0155678\ttotal: 22.9s\tremaining: 2m 40s\n",
      "250:\tlearn: 0.0155114\ttotal: 23s\tremaining: 2m 40s\n",
      "251:\tlearn: 0.0154922\ttotal: 23.1s\tremaining: 2m 40s\n",
      "252:\tlearn: 0.0154609\ttotal: 23.2s\tremaining: 2m 40s\n",
      "253:\tlearn: 0.0154302\ttotal: 23.3s\tremaining: 2m 39s\n",
      "254:\tlearn: 0.0154164\ttotal: 23.3s\tremaining: 2m 39s\n",
      "255:\tlearn: 0.0153743\ttotal: 23.4s\tremaining: 2m 39s\n",
      "256:\tlearn: 0.0153366\ttotal: 23.5s\tremaining: 2m 39s\n",
      "257:\tlearn: 0.0153028\ttotal: 23.6s\tremaining: 2m 39s\n",
      "258:\tlearn: 0.0152875\ttotal: 23.7s\tremaining: 2m 39s\n",
      "259:\tlearn: 0.0152676\ttotal: 23.8s\tremaining: 2m 39s\n",
      "260:\tlearn: 0.0152223\ttotal: 23.9s\tremaining: 2m 39s\n",
      "261:\tlearn: 0.0151869\ttotal: 24s\tremaining: 2m 39s\n",
      "262:\tlearn: 0.0151562\ttotal: 24.1s\tremaining: 2m 39s\n",
      "263:\tlearn: 0.0150688\ttotal: 24.2s\tremaining: 2m 38s\n",
      "264:\tlearn: 0.0150511\ttotal: 24.3s\tremaining: 2m 38s\n",
      "265:\tlearn: 0.0150032\ttotal: 24.3s\tremaining: 2m 38s\n",
      "266:\tlearn: 0.0149870\ttotal: 24.4s\tremaining: 2m 38s\n",
      "267:\tlearn: 0.0149685\ttotal: 24.5s\tremaining: 2m 38s\n",
      "268:\tlearn: 0.0149256\ttotal: 24.6s\tremaining: 2m 38s\n",
      "269:\tlearn: 0.0149069\ttotal: 24.7s\tremaining: 2m 38s\n",
      "270:\tlearn: 0.0148821\ttotal: 24.8s\tremaining: 2m 37s\n",
      "271:\tlearn: 0.0148393\ttotal: 24.8s\tremaining: 2m 37s\n",
      "272:\tlearn: 0.0148037\ttotal: 24.9s\tremaining: 2m 37s\n",
      "273:\tlearn: 0.0147885\ttotal: 25s\tremaining: 2m 37s\n",
      "274:\tlearn: 0.0147630\ttotal: 25.1s\tremaining: 2m 37s\n",
      "275:\tlearn: 0.0147446\ttotal: 25.2s\tremaining: 2m 37s\n",
      "276:\tlearn: 0.0147208\ttotal: 25.3s\tremaining: 2m 37s\n",
      "277:\tlearn: 0.0147135\ttotal: 25.4s\tremaining: 2m 37s\n",
      "278:\tlearn: 0.0146705\ttotal: 25.5s\tremaining: 2m 37s\n",
      "279:\tlearn: 0.0146432\ttotal: 25.5s\tremaining: 2m 36s\n",
      "280:\tlearn: 0.0146369\ttotal: 25.6s\tremaining: 2m 36s\n",
      "281:\tlearn: 0.0146252\ttotal: 25.7s\tremaining: 2m 36s\n",
      "282:\tlearn: 0.0146153\ttotal: 25.8s\tremaining: 2m 36s\n",
      "283:\tlearn: 0.0145946\ttotal: 25.9s\tremaining: 2m 36s\n",
      "284:\tlearn: 0.0145593\ttotal: 26s\tremaining: 2m 36s\n",
      "285:\tlearn: 0.0145007\ttotal: 26s\tremaining: 2m 36s\n",
      "286:\tlearn: 0.0144793\ttotal: 26.1s\tremaining: 2m 35s\n",
      "287:\tlearn: 0.0144467\ttotal: 26.2s\tremaining: 2m 35s\n",
      "288:\tlearn: 0.0144374\ttotal: 26.3s\tremaining: 2m 35s\n",
      "289:\tlearn: 0.0144255\ttotal: 26.4s\tremaining: 2m 35s\n",
      "290:\tlearn: 0.0144023\ttotal: 26.5s\tremaining: 2m 35s\n",
      "291:\tlearn: 0.0143702\ttotal: 26.6s\tremaining: 2m 35s\n",
      "292:\tlearn: 0.0142769\ttotal: 26.7s\tremaining: 2m 35s\n",
      "293:\tlearn: 0.0142695\ttotal: 26.8s\tremaining: 2m 35s\n",
      "294:\tlearn: 0.0142549\ttotal: 26.8s\tremaining: 2m 35s\n",
      "295:\tlearn: 0.0142270\ttotal: 26.9s\tremaining: 2m 34s\n",
      "296:\tlearn: 0.0142003\ttotal: 27s\tremaining: 2m 34s\n",
      "297:\tlearn: 0.0141512\ttotal: 27.1s\tremaining: 2m 34s\n",
      "298:\tlearn: 0.0141015\ttotal: 27.2s\tremaining: 2m 34s\n",
      "299:\tlearn: 0.0140764\ttotal: 27.3s\tremaining: 2m 34s\n",
      "300:\tlearn: 0.0140523\ttotal: 27.3s\tremaining: 2m 34s\n",
      "301:\tlearn: 0.0140279\ttotal: 27.4s\tremaining: 2m 34s\n",
      "302:\tlearn: 0.0140046\ttotal: 27.5s\tremaining: 2m 34s\n",
      "303:\tlearn: 0.0139877\ttotal: 27.6s\tremaining: 2m 33s\n",
      "304:\tlearn: 0.0139747\ttotal: 27.7s\tremaining: 2m 33s\n",
      "305:\tlearn: 0.0139330\ttotal: 27.8s\tremaining: 2m 33s\n",
      "306:\tlearn: 0.0138923\ttotal: 27.9s\tremaining: 2m 33s\n",
      "307:\tlearn: 0.0138522\ttotal: 27.9s\tremaining: 2m 33s\n",
      "308:\tlearn: 0.0138488\ttotal: 28s\tremaining: 2m 33s\n",
      "309:\tlearn: 0.0138460\ttotal: 28.1s\tremaining: 2m 33s\n",
      "310:\tlearn: 0.0138037\ttotal: 28.2s\tremaining: 2m 33s\n",
      "311:\tlearn: 0.0137736\ttotal: 28.3s\tremaining: 2m 32s\n",
      "312:\tlearn: 0.0137407\ttotal: 28.4s\tremaining: 2m 32s\n",
      "313:\tlearn: 0.0137270\ttotal: 28.4s\tremaining: 2m 32s\n",
      "314:\tlearn: 0.0137144\ttotal: 28.5s\tremaining: 2m 32s\n",
      "315:\tlearn: 0.0136938\ttotal: 28.6s\tremaining: 2m 32s\n",
      "316:\tlearn: 0.0136788\ttotal: 28.7s\tremaining: 2m 32s\n",
      "317:\tlearn: 0.0136597\ttotal: 28.8s\tremaining: 2m 32s\n",
      "318:\tlearn: 0.0136504\ttotal: 28.9s\tremaining: 2m 32s\n",
      "319:\tlearn: 0.0136255\ttotal: 29s\tremaining: 2m 32s\n",
      "320:\tlearn: 0.0135998\ttotal: 29.1s\tremaining: 2m 31s\n",
      "321:\tlearn: 0.0135719\ttotal: 29.1s\tremaining: 2m 31s\n",
      "322:\tlearn: 0.0135169\ttotal: 29.2s\tremaining: 2m 31s\n",
      "323:\tlearn: 0.0135023\ttotal: 29.3s\tremaining: 2m 31s\n",
      "324:\tlearn: 0.0134581\ttotal: 29.4s\tremaining: 2m 31s\n",
      "325:\tlearn: 0.0134456\ttotal: 29.5s\tremaining: 2m 31s\n",
      "326:\tlearn: 0.0134409\ttotal: 29.6s\tremaining: 2m 31s\n",
      "327:\tlearn: 0.0134248\ttotal: 29.7s\tremaining: 2m 31s\n",
      "328:\tlearn: 0.0133880\ttotal: 29.7s\tremaining: 2m 31s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329:\tlearn: 0.0133650\ttotal: 29.8s\tremaining: 2m 30s\n",
      "330:\tlearn: 0.0133203\ttotal: 29.9s\tremaining: 2m 30s\n",
      "331:\tlearn: 0.0132706\ttotal: 30s\tremaining: 2m 30s\n",
      "332:\tlearn: 0.0132561\ttotal: 30.1s\tremaining: 2m 30s\n",
      "333:\tlearn: 0.0132204\ttotal: 30.2s\tremaining: 2m 30s\n",
      "334:\tlearn: 0.0132129\ttotal: 30.3s\tremaining: 2m 30s\n",
      "335:\tlearn: 0.0131941\ttotal: 30.4s\tremaining: 2m 30s\n",
      "336:\tlearn: 0.0131815\ttotal: 30.5s\tremaining: 2m 30s\n",
      "337:\tlearn: 0.0131789\ttotal: 30.5s\tremaining: 2m 30s\n",
      "338:\tlearn: 0.0131339\ttotal: 30.6s\tremaining: 2m 30s\n",
      "339:\tlearn: 0.0131232\ttotal: 30.7s\tremaining: 2m 29s\n",
      "340:\tlearn: 0.0131061\ttotal: 30.8s\tremaining: 2m 29s\n",
      "341:\tlearn: 0.0130674\ttotal: 30.9s\tremaining: 2m 29s\n",
      "342:\tlearn: 0.0130245\ttotal: 31s\tremaining: 2m 29s\n",
      "343:\tlearn: 0.0130102\ttotal: 31.1s\tremaining: 2m 29s\n",
      "344:\tlearn: 0.0129667\ttotal: 31.2s\tremaining: 2m 29s\n",
      "345:\tlearn: 0.0129326\ttotal: 31.2s\tremaining: 2m 29s\n",
      "346:\tlearn: 0.0128680\ttotal: 31.3s\tremaining: 2m 29s\n",
      "347:\tlearn: 0.0128392\ttotal: 31.4s\tremaining: 2m 29s\n",
      "348:\tlearn: 0.0128114\ttotal: 31.5s\tremaining: 2m 29s\n",
      "349:\tlearn: 0.0127947\ttotal: 31.6s\tremaining: 2m 29s\n",
      "350:\tlearn: 0.0127720\ttotal: 31.7s\tremaining: 2m 28s\n",
      "351:\tlearn: 0.0127489\ttotal: 31.8s\tremaining: 2m 28s\n",
      "352:\tlearn: 0.0127333\ttotal: 31.9s\tremaining: 2m 28s\n",
      "353:\tlearn: 0.0126984\ttotal: 32s\tremaining: 2m 28s\n",
      "354:\tlearn: 0.0126734\ttotal: 32.1s\tremaining: 2m 28s\n",
      "355:\tlearn: 0.0126317\ttotal: 32.1s\tremaining: 2m 28s\n",
      "356:\tlearn: 0.0125522\ttotal: 32.2s\tremaining: 2m 28s\n",
      "357:\tlearn: 0.0125294\ttotal: 32.3s\tremaining: 2m 28s\n",
      "358:\tlearn: 0.0124873\ttotal: 32.4s\tremaining: 2m 28s\n",
      "359:\tlearn: 0.0124764\ttotal: 32.5s\tremaining: 2m 27s\n",
      "360:\tlearn: 0.0124567\ttotal: 32.6s\tremaining: 2m 27s\n",
      "361:\tlearn: 0.0124223\ttotal: 32.7s\tremaining: 2m 27s\n",
      "362:\tlearn: 0.0123946\ttotal: 32.7s\tremaining: 2m 27s\n",
      "363:\tlearn: 0.0123801\ttotal: 32.8s\tremaining: 2m 27s\n",
      "364:\tlearn: 0.0123647\ttotal: 32.9s\tremaining: 2m 27s\n",
      "365:\tlearn: 0.0123436\ttotal: 33s\tremaining: 2m 27s\n",
      "366:\tlearn: 0.0123241\ttotal: 33.1s\tremaining: 2m 27s\n",
      "367:\tlearn: 0.0123116\ttotal: 33.2s\tremaining: 2m 27s\n",
      "368:\tlearn: 0.0122890\ttotal: 33.2s\tremaining: 2m 26s\n",
      "369:\tlearn: 0.0122696\ttotal: 33.4s\tremaining: 2m 26s\n",
      "370:\tlearn: 0.0122397\ttotal: 33.4s\tremaining: 2m 26s\n",
      "371:\tlearn: 0.0121986\ttotal: 33.5s\tremaining: 2m 26s\n",
      "372:\tlearn: 0.0121637\ttotal: 33.6s\tremaining: 2m 26s\n",
      "373:\tlearn: 0.0121543\ttotal: 33.7s\tremaining: 2m 26s\n",
      "374:\tlearn: 0.0121197\ttotal: 33.8s\tremaining: 2m 26s\n",
      "375:\tlearn: 0.0121059\ttotal: 33.9s\tremaining: 2m 26s\n",
      "376:\tlearn: 0.0120595\ttotal: 33.9s\tremaining: 2m 26s\n",
      "377:\tlearn: 0.0120484\ttotal: 34s\tremaining: 2m 25s\n",
      "378:\tlearn: 0.0120237\ttotal: 34.1s\tremaining: 2m 25s\n",
      "379:\tlearn: 0.0119940\ttotal: 34.2s\tremaining: 2m 25s\n",
      "380:\tlearn: 0.0119756\ttotal: 34.3s\tremaining: 2m 25s\n",
      "381:\tlearn: 0.0119657\ttotal: 34.4s\tremaining: 2m 25s\n",
      "382:\tlearn: 0.0119245\ttotal: 34.5s\tremaining: 2m 25s\n",
      "383:\tlearn: 0.0119141\ttotal: 34.5s\tremaining: 2m 25s\n",
      "384:\tlearn: 0.0118809\ttotal: 34.6s\tremaining: 2m 25s\n",
      "385:\tlearn: 0.0118595\ttotal: 34.7s\tremaining: 2m 25s\n",
      "386:\tlearn: 0.0118354\ttotal: 34.8s\tremaining: 2m 25s\n",
      "387:\tlearn: 0.0118125\ttotal: 34.9s\tremaining: 2m 24s\n",
      "388:\tlearn: 0.0117840\ttotal: 35s\tremaining: 2m 24s\n",
      "389:\tlearn: 0.0117777\ttotal: 35s\tremaining: 2m 24s\n",
      "390:\tlearn: 0.0117602\ttotal: 35.1s\tremaining: 2m 24s\n",
      "391:\tlearn: 0.0117449\ttotal: 35.2s\tremaining: 2m 24s\n",
      "392:\tlearn: 0.0116809\ttotal: 35.3s\tremaining: 2m 24s\n",
      "393:\tlearn: 0.0116689\ttotal: 35.4s\tremaining: 2m 24s\n",
      "394:\tlearn: 0.0116496\ttotal: 35.5s\tremaining: 2m 24s\n",
      "395:\tlearn: 0.0116337\ttotal: 35.6s\tremaining: 2m 24s\n",
      "396:\tlearn: 0.0116118\ttotal: 35.7s\tremaining: 2m 24s\n",
      "397:\tlearn: 0.0116024\ttotal: 35.8s\tremaining: 2m 23s\n",
      "398:\tlearn: 0.0115858\ttotal: 35.8s\tremaining: 2m 23s\n",
      "399:\tlearn: 0.0115750\ttotal: 35.9s\tremaining: 2m 23s\n",
      "400:\tlearn: 0.0115677\ttotal: 36s\tremaining: 2m 23s\n",
      "401:\tlearn: 0.0115624\ttotal: 36.1s\tremaining: 2m 23s\n",
      "402:\tlearn: 0.0115376\ttotal: 36.2s\tremaining: 2m 23s\n",
      "403:\tlearn: 0.0115247\ttotal: 36.3s\tremaining: 2m 23s\n",
      "404:\tlearn: 0.0115167\ttotal: 36.3s\tremaining: 2m 23s\n",
      "405:\tlearn: 0.0114767\ttotal: 36.4s\tremaining: 2m 23s\n",
      "406:\tlearn: 0.0114507\ttotal: 36.5s\tremaining: 2m 22s\n",
      "407:\tlearn: 0.0114358\ttotal: 36.6s\tremaining: 2m 22s\n",
      "408:\tlearn: 0.0114128\ttotal: 36.7s\tremaining: 2m 22s\n",
      "409:\tlearn: 0.0113857\ttotal: 36.8s\tremaining: 2m 22s\n",
      "410:\tlearn: 0.0113809\ttotal: 36.9s\tremaining: 2m 22s\n",
      "411:\tlearn: 0.0113711\ttotal: 36.9s\tremaining: 2m 22s\n",
      "412:\tlearn: 0.0113540\ttotal: 37s\tremaining: 2m 22s\n",
      "413:\tlearn: 0.0113309\ttotal: 37.1s\tremaining: 2m 22s\n",
      "414:\tlearn: 0.0113061\ttotal: 37.2s\tremaining: 2m 22s\n",
      "415:\tlearn: 0.0112652\ttotal: 37.3s\tremaining: 2m 22s\n",
      "416:\tlearn: 0.0112596\ttotal: 37.4s\tremaining: 2m 21s\n",
      "417:\tlearn: 0.0112531\ttotal: 37.5s\tremaining: 2m 21s\n",
      "418:\tlearn: 0.0112449\ttotal: 37.6s\tremaining: 2m 21s\n",
      "419:\tlearn: 0.0111904\ttotal: 37.6s\tremaining: 2m 21s\n",
      "420:\tlearn: 0.0111819\ttotal: 37.7s\tremaining: 2m 21s\n",
      "421:\tlearn: 0.0111669\ttotal: 37.8s\tremaining: 2m 21s\n",
      "422:\tlearn: 0.0111541\ttotal: 37.9s\tremaining: 2m 21s\n",
      "423:\tlearn: 0.0111416\ttotal: 38s\tremaining: 2m 21s\n",
      "424:\tlearn: 0.0111350\ttotal: 38.1s\tremaining: 2m 21s\n",
      "425:\tlearn: 0.0111220\ttotal: 38.2s\tremaining: 2m 21s\n",
      "426:\tlearn: 0.0110940\ttotal: 38.3s\tremaining: 2m 21s\n",
      "427:\tlearn: 0.0110481\ttotal: 38.4s\tremaining: 2m 20s\n",
      "428:\tlearn: 0.0110403\ttotal: 38.4s\tremaining: 2m 20s\n",
      "429:\tlearn: 0.0110176\ttotal: 38.5s\tremaining: 2m 20s\n",
      "430:\tlearn: 0.0110035\ttotal: 38.6s\tremaining: 2m 20s\n",
      "431:\tlearn: 0.0109734\ttotal: 38.7s\tremaining: 2m 20s\n",
      "432:\tlearn: 0.0109536\ttotal: 38.8s\tremaining: 2m 20s\n",
      "433:\tlearn: 0.0109413\ttotal: 38.9s\tremaining: 2m 20s\n",
      "434:\tlearn: 0.0109125\ttotal: 39s\tremaining: 2m 20s\n",
      "435:\tlearn: 0.0109022\ttotal: 39.1s\tremaining: 2m 20s\n",
      "436:\tlearn: 0.0108828\ttotal: 39.1s\tremaining: 2m 20s\n",
      "437:\tlearn: 0.0108465\ttotal: 39.2s\tremaining: 2m 19s\n",
      "438:\tlearn: 0.0108241\ttotal: 39.3s\tremaining: 2m 19s\n",
      "439:\tlearn: 0.0108225\ttotal: 39.4s\tremaining: 2m 19s\n",
      "440:\tlearn: 0.0108104\ttotal: 39.5s\tremaining: 2m 19s\n",
      "441:\tlearn: 0.0107930\ttotal: 39.6s\tremaining: 2m 19s\n",
      "442:\tlearn: 0.0107707\ttotal: 39.7s\tremaining: 2m 19s\n",
      "443:\tlearn: 0.0107684\ttotal: 39.7s\tremaining: 2m 19s\n",
      "444:\tlearn: 0.0107524\ttotal: 39.8s\tremaining: 2m 19s\n",
      "445:\tlearn: 0.0107366\ttotal: 39.9s\tremaining: 2m 19s\n",
      "446:\tlearn: 0.0107282\ttotal: 40s\tremaining: 2m 18s\n",
      "447:\tlearn: 0.0106883\ttotal: 40.1s\tremaining: 2m 18s\n",
      "448:\tlearn: 0.0106729\ttotal: 40.2s\tremaining: 2m 18s\n",
      "449:\tlearn: 0.0106179\ttotal: 40.3s\tremaining: 2m 18s\n",
      "450:\tlearn: 0.0106144\ttotal: 40.4s\tremaining: 2m 18s\n",
      "451:\tlearn: 0.0106059\ttotal: 40.4s\tremaining: 2m 18s\n",
      "452:\tlearn: 0.0105854\ttotal: 40.5s\tremaining: 2m 18s\n",
      "453:\tlearn: 0.0105734\ttotal: 40.6s\tremaining: 2m 18s\n",
      "454:\tlearn: 0.0105593\ttotal: 40.7s\tremaining: 2m 18s\n",
      "455:\tlearn: 0.0105478\ttotal: 40.8s\tremaining: 2m 18s\n",
      "456:\tlearn: 0.0105397\ttotal: 40.9s\tremaining: 2m 17s\n",
      "457:\tlearn: 0.0104894\ttotal: 41s\tremaining: 2m 17s\n",
      "458:\tlearn: 0.0104736\ttotal: 41s\tremaining: 2m 17s\n",
      "459:\tlearn: 0.0104567\ttotal: 41.1s\tremaining: 2m 17s\n",
      "460:\tlearn: 0.0104449\ttotal: 41.2s\tremaining: 2m 17s\n",
      "461:\tlearn: 0.0104114\ttotal: 41.3s\tremaining: 2m 17s\n",
      "462:\tlearn: 0.0104069\ttotal: 41.4s\tremaining: 2m 17s\n",
      "463:\tlearn: 0.0103904\ttotal: 41.5s\tremaining: 2m 17s\n",
      "464:\tlearn: 0.0103750\ttotal: 41.6s\tremaining: 2m 17s\n",
      "465:\tlearn: 0.0103532\ttotal: 41.7s\tremaining: 2m 17s\n",
      "466:\tlearn: 0.0103234\ttotal: 41.8s\tremaining: 2m 17s\n",
      "467:\tlearn: 0.0103070\ttotal: 41.8s\tremaining: 2m 16s\n",
      "468:\tlearn: 0.0102830\ttotal: 41.9s\tremaining: 2m 16s\n",
      "469:\tlearn: 0.0102751\ttotal: 42s\tremaining: 2m 16s\n",
      "470:\tlearn: 0.0102621\ttotal: 42.1s\tremaining: 2m 16s\n",
      "471:\tlearn: 0.0102528\ttotal: 42.2s\tremaining: 2m 16s\n",
      "472:\tlearn: 0.0102373\ttotal: 42.3s\tremaining: 2m 16s\n",
      "473:\tlearn: 0.0102235\ttotal: 42.4s\tremaining: 2m 16s\n",
      "474:\tlearn: 0.0101960\ttotal: 42.5s\tremaining: 2m 16s\n",
      "475:\tlearn: 0.0101857\ttotal: 42.6s\tremaining: 2m 16s\n",
      "476:\tlearn: 0.0101778\ttotal: 42.7s\tremaining: 2m 16s\n",
      "477:\tlearn: 0.0101683\ttotal: 42.8s\tremaining: 2m 16s\n",
      "478:\tlearn: 0.0101519\ttotal: 42.9s\tremaining: 2m 16s\n",
      "479:\tlearn: 0.0101297\ttotal: 42.9s\tremaining: 2m 15s\n",
      "480:\tlearn: 0.0101169\ttotal: 43s\tremaining: 2m 15s\n",
      "481:\tlearn: 0.0101101\ttotal: 43.1s\tremaining: 2m 15s\n",
      "482:\tlearn: 0.0101023\ttotal: 43.2s\tremaining: 2m 15s\n",
      "483:\tlearn: 0.0100820\ttotal: 43.3s\tremaining: 2m 15s\n",
      "484:\tlearn: 0.0100565\ttotal: 43.4s\tremaining: 2m 15s\n",
      "485:\tlearn: 0.0100453\ttotal: 43.5s\tremaining: 2m 15s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486:\tlearn: 0.0100345\ttotal: 43.6s\tremaining: 2m 15s\n",
      "487:\tlearn: 0.0100312\ttotal: 43.7s\tremaining: 2m 15s\n",
      "488:\tlearn: 0.0100235\ttotal: 43.7s\tremaining: 2m 15s\n",
      "489:\tlearn: 0.0100020\ttotal: 43.8s\tremaining: 2m 15s\n",
      "490:\tlearn: 0.0099773\ttotal: 43.9s\tremaining: 2m 15s\n",
      "491:\tlearn: 0.0099697\ttotal: 44s\tremaining: 2m 14s\n",
      "492:\tlearn: 0.0099581\ttotal: 44.1s\tremaining: 2m 14s\n",
      "493:\tlearn: 0.0099531\ttotal: 44.2s\tremaining: 2m 14s\n",
      "494:\tlearn: 0.0099396\ttotal: 44.3s\tremaining: 2m 14s\n",
      "495:\tlearn: 0.0099288\ttotal: 44.4s\tremaining: 2m 14s\n",
      "496:\tlearn: 0.0099171\ttotal: 44.5s\tremaining: 2m 14s\n",
      "497:\tlearn: 0.0099003\ttotal: 44.6s\tremaining: 2m 14s\n",
      "498:\tlearn: 0.0098849\ttotal: 44.7s\tremaining: 2m 14s\n",
      "499:\tlearn: 0.0098728\ttotal: 44.7s\tremaining: 2m 14s\n",
      "500:\tlearn: 0.0098570\ttotal: 44.8s\tremaining: 2m 14s\n",
      "501:\tlearn: 0.0098458\ttotal: 44.9s\tremaining: 2m 14s\n",
      "502:\tlearn: 0.0098437\ttotal: 45s\tremaining: 2m 13s\n",
      "503:\tlearn: 0.0098298\ttotal: 45.1s\tremaining: 2m 13s\n",
      "504:\tlearn: 0.0098254\ttotal: 45.2s\tremaining: 2m 13s\n",
      "505:\tlearn: 0.0098169\ttotal: 45.2s\tremaining: 2m 13s\n",
      "506:\tlearn: 0.0097872\ttotal: 45.3s\tremaining: 2m 13s\n",
      "507:\tlearn: 0.0097813\ttotal: 45.4s\tremaining: 2m 13s\n",
      "508:\tlearn: 0.0097769\ttotal: 45.5s\tremaining: 2m 13s\n",
      "509:\tlearn: 0.0097714\ttotal: 45.6s\tremaining: 2m 13s\n",
      "510:\tlearn: 0.0097533\ttotal: 45.7s\tremaining: 2m 13s\n",
      "511:\tlearn: 0.0097309\ttotal: 45.8s\tremaining: 2m 13s\n",
      "512:\tlearn: 0.0097236\ttotal: 45.9s\tremaining: 2m 12s\n",
      "513:\tlearn: 0.0097193\ttotal: 45.9s\tremaining: 2m 12s\n",
      "514:\tlearn: 0.0096887\ttotal: 46s\tremaining: 2m 12s\n",
      "515:\tlearn: 0.0096859\ttotal: 46.1s\tremaining: 2m 12s\n",
      "516:\tlearn: 0.0096710\ttotal: 46.2s\tremaining: 2m 12s\n",
      "517:\tlearn: 0.0096587\ttotal: 46.3s\tremaining: 2m 12s\n",
      "518:\tlearn: 0.0096466\ttotal: 46.4s\tremaining: 2m 12s\n",
      "519:\tlearn: 0.0096228\ttotal: 46.5s\tremaining: 2m 12s\n",
      "520:\tlearn: 0.0096176\ttotal: 46.6s\tremaining: 2m 12s\n",
      "521:\tlearn: 0.0095938\ttotal: 46.7s\tremaining: 2m 12s\n",
      "522:\tlearn: 0.0095761\ttotal: 46.8s\tremaining: 2m 12s\n",
      "523:\tlearn: 0.0095636\ttotal: 46.9s\tremaining: 2m 12s\n",
      "524:\tlearn: 0.0095583\ttotal: 47s\tremaining: 2m 11s\n",
      "525:\tlearn: 0.0095472\ttotal: 47.1s\tremaining: 2m 11s\n",
      "526:\tlearn: 0.0095407\ttotal: 47.2s\tremaining: 2m 11s\n",
      "527:\tlearn: 0.0095218\ttotal: 47.2s\tremaining: 2m 11s\n",
      "528:\tlearn: 0.0095108\ttotal: 47.3s\tremaining: 2m 11s\n",
      "529:\tlearn: 0.0095022\ttotal: 47.4s\tremaining: 2m 11s\n",
      "530:\tlearn: 0.0094971\ttotal: 47.5s\tremaining: 2m 11s\n",
      "531:\tlearn: 0.0094840\ttotal: 47.6s\tremaining: 2m 11s\n",
      "532:\tlearn: 0.0094659\ttotal: 47.7s\tremaining: 2m 11s\n",
      "533:\tlearn: 0.0094597\ttotal: 47.7s\tremaining: 2m 11s\n",
      "534:\tlearn: 0.0094499\ttotal: 47.8s\tremaining: 2m 10s\n",
      "535:\tlearn: 0.0094378\ttotal: 47.9s\tremaining: 2m 10s\n",
      "536:\tlearn: 0.0094245\ttotal: 48s\tremaining: 2m 10s\n",
      "537:\tlearn: 0.0094174\ttotal: 48.1s\tremaining: 2m 10s\n",
      "538:\tlearn: 0.0094061\ttotal: 48.2s\tremaining: 2m 10s\n",
      "539:\tlearn: 0.0093755\ttotal: 48.3s\tremaining: 2m 10s\n",
      "540:\tlearn: 0.0093737\ttotal: 48.4s\tremaining: 2m 10s\n",
      "541:\tlearn: 0.0093589\ttotal: 48.5s\tremaining: 2m 10s\n",
      "542:\tlearn: 0.0093192\ttotal: 48.6s\tremaining: 2m 10s\n",
      "543:\tlearn: 0.0092798\ttotal: 48.6s\tremaining: 2m 10s\n",
      "544:\tlearn: 0.0092604\ttotal: 48.7s\tremaining: 2m 10s\n",
      "545:\tlearn: 0.0092421\ttotal: 48.8s\tremaining: 2m 10s\n",
      "546:\tlearn: 0.0091907\ttotal: 48.9s\tremaining: 2m 9s\n",
      "547:\tlearn: 0.0091610\ttotal: 49s\tremaining: 2m 9s\n",
      "548:\tlearn: 0.0091575\ttotal: 49.1s\tremaining: 2m 9s\n",
      "549:\tlearn: 0.0091524\ttotal: 49.2s\tremaining: 2m 9s\n",
      "550:\tlearn: 0.0091490\ttotal: 49.3s\tremaining: 2m 9s\n",
      "551:\tlearn: 0.0091338\ttotal: 49.4s\tremaining: 2m 9s\n",
      "552:\tlearn: 0.0091094\ttotal: 49.4s\tremaining: 2m 9s\n",
      "553:\tlearn: 0.0090828\ttotal: 49.5s\tremaining: 2m 9s\n",
      "554:\tlearn: 0.0090630\ttotal: 49.6s\tremaining: 2m 9s\n",
      "555:\tlearn: 0.0090415\ttotal: 49.7s\tremaining: 2m 9s\n",
      "556:\tlearn: 0.0090329\ttotal: 49.8s\tremaining: 2m 9s\n",
      "557:\tlearn: 0.0090301\ttotal: 49.9s\tremaining: 2m 8s\n",
      "558:\tlearn: 0.0090142\ttotal: 50s\tremaining: 2m 8s\n",
      "559:\tlearn: 0.0090045\ttotal: 50.1s\tremaining: 2m 8s\n",
      "560:\tlearn: 0.0089969\ttotal: 50.1s\tremaining: 2m 8s\n",
      "561:\tlearn: 0.0089909\ttotal: 50.2s\tremaining: 2m 8s\n",
      "562:\tlearn: 0.0089639\ttotal: 50.3s\tremaining: 2m 8s\n",
      "563:\tlearn: 0.0089424\ttotal: 50.4s\tremaining: 2m 8s\n",
      "564:\tlearn: 0.0089356\ttotal: 50.5s\tremaining: 2m 8s\n",
      "565:\tlearn: 0.0089149\ttotal: 50.6s\tremaining: 2m 8s\n",
      "566:\tlearn: 0.0089081\ttotal: 50.6s\tremaining: 2m 7s\n",
      "567:\tlearn: 0.0088872\ttotal: 50.7s\tremaining: 2m 7s\n",
      "568:\tlearn: 0.0088424\ttotal: 50.8s\tremaining: 2m 7s\n",
      "569:\tlearn: 0.0088362\ttotal: 50.9s\tremaining: 2m 7s\n",
      "570:\tlearn: 0.0088235\ttotal: 51s\tremaining: 2m 7s\n",
      "571:\tlearn: 0.0088171\ttotal: 51.1s\tremaining: 2m 7s\n",
      "572:\tlearn: 0.0088130\ttotal: 51.2s\tremaining: 2m 7s\n",
      "573:\tlearn: 0.0087895\ttotal: 51.3s\tremaining: 2m 7s\n",
      "574:\tlearn: 0.0087714\ttotal: 51.4s\tremaining: 2m 7s\n",
      "575:\tlearn: 0.0087680\ttotal: 51.4s\tremaining: 2m 7s\n",
      "576:\tlearn: 0.0087641\ttotal: 51.5s\tremaining: 2m 7s\n",
      "577:\tlearn: 0.0087400\ttotal: 51.6s\tremaining: 2m 7s\n",
      "578:\tlearn: 0.0087205\ttotal: 51.7s\tremaining: 2m 6s\n",
      "579:\tlearn: 0.0087004\ttotal: 51.8s\tremaining: 2m 6s\n",
      "580:\tlearn: 0.0086818\ttotal: 51.9s\tremaining: 2m 6s\n",
      "581:\tlearn: 0.0086693\ttotal: 52s\tremaining: 2m 6s\n",
      "582:\tlearn: 0.0086577\ttotal: 52.1s\tremaining: 2m 6s\n",
      "583:\tlearn: 0.0086547\ttotal: 52.1s\tremaining: 2m 6s\n",
      "584:\tlearn: 0.0086463\ttotal: 52.2s\tremaining: 2m 6s\n",
      "585:\tlearn: 0.0086410\ttotal: 52.3s\tremaining: 2m 6s\n",
      "586:\tlearn: 0.0086378\ttotal: 52.4s\tremaining: 2m 6s\n",
      "587:\tlearn: 0.0086314\ttotal: 52.5s\tremaining: 2m 6s\n",
      "588:\tlearn: 0.0086237\ttotal: 52.6s\tremaining: 2m 5s\n",
      "589:\tlearn: 0.0086144\ttotal: 52.7s\tremaining: 2m 5s\n",
      "590:\tlearn: 0.0086118\ttotal: 52.8s\tremaining: 2m 5s\n",
      "591:\tlearn: 0.0086088\ttotal: 52.8s\tremaining: 2m 5s\n",
      "592:\tlearn: 0.0086041\ttotal: 52.9s\tremaining: 2m 5s\n",
      "593:\tlearn: 0.0085792\ttotal: 53s\tremaining: 2m 5s\n",
      "594:\tlearn: 0.0085735\ttotal: 53.1s\tremaining: 2m 5s\n",
      "595:\tlearn: 0.0085559\ttotal: 53.2s\tremaining: 2m 5s\n",
      "596:\tlearn: 0.0085419\ttotal: 53.3s\tremaining: 2m 5s\n",
      "597:\tlearn: 0.0085358\ttotal: 53.4s\tremaining: 2m 5s\n",
      "598:\tlearn: 0.0085276\ttotal: 53.5s\tremaining: 2m 5s\n",
      "599:\tlearn: 0.0085234\ttotal: 53.5s\tremaining: 2m 4s\n",
      "600:\tlearn: 0.0085057\ttotal: 53.6s\tremaining: 2m 4s\n",
      "601:\tlearn: 0.0084902\ttotal: 53.7s\tremaining: 2m 4s\n",
      "602:\tlearn: 0.0084777\ttotal: 53.8s\tremaining: 2m 4s\n",
      "603:\tlearn: 0.0084695\ttotal: 53.9s\tremaining: 2m 4s\n",
      "604:\tlearn: 0.0084548\ttotal: 54s\tremaining: 2m 4s\n",
      "605:\tlearn: 0.0084496\ttotal: 54.1s\tremaining: 2m 4s\n",
      "606:\tlearn: 0.0084427\ttotal: 54.2s\tremaining: 2m 4s\n",
      "607:\tlearn: 0.0084417\ttotal: 54.2s\tremaining: 2m 4s\n",
      "608:\tlearn: 0.0084359\ttotal: 54.3s\tremaining: 2m 4s\n",
      "609:\tlearn: 0.0084158\ttotal: 54.4s\tremaining: 2m 4s\n",
      "610:\tlearn: 0.0084085\ttotal: 54.5s\tremaining: 2m 3s\n",
      "611:\tlearn: 0.0084063\ttotal: 54.6s\tremaining: 2m 3s\n",
      "612:\tlearn: 0.0084038\ttotal: 54.7s\tremaining: 2m 3s\n",
      "613:\tlearn: 0.0083929\ttotal: 54.8s\tremaining: 2m 3s\n",
      "614:\tlearn: 0.0083906\ttotal: 54.9s\tremaining: 2m 3s\n",
      "615:\tlearn: 0.0083792\ttotal: 54.9s\tremaining: 2m 3s\n",
      "616:\tlearn: 0.0083565\ttotal: 55s\tremaining: 2m 3s\n",
      "617:\tlearn: 0.0083523\ttotal: 55.1s\tremaining: 2m 3s\n",
      "618:\tlearn: 0.0083434\ttotal: 55.2s\tremaining: 2m 3s\n",
      "619:\tlearn: 0.0083363\ttotal: 55.3s\tremaining: 2m 3s\n",
      "620:\tlearn: 0.0083184\ttotal: 55.4s\tremaining: 2m 2s\n",
      "621:\tlearn: 0.0083166\ttotal: 55.5s\tremaining: 2m 2s\n",
      "622:\tlearn: 0.0082805\ttotal: 55.5s\tremaining: 2m 2s\n",
      "623:\tlearn: 0.0082756\ttotal: 55.6s\tremaining: 2m 2s\n",
      "624:\tlearn: 0.0082648\ttotal: 55.7s\tremaining: 2m 2s\n",
      "625:\tlearn: 0.0082514\ttotal: 55.8s\tremaining: 2m 2s\n",
      "626:\tlearn: 0.0082482\ttotal: 55.9s\tremaining: 2m 2s\n",
      "627:\tlearn: 0.0082447\ttotal: 56s\tremaining: 2m 2s\n",
      "628:\tlearn: 0.0082417\ttotal: 56.1s\tremaining: 2m 2s\n",
      "629:\tlearn: 0.0082287\ttotal: 56.2s\tremaining: 2m 2s\n",
      "630:\tlearn: 0.0082231\ttotal: 56.3s\tremaining: 2m 2s\n",
      "631:\tlearn: 0.0082152\ttotal: 56.4s\tremaining: 2m 1s\n",
      "632:\tlearn: 0.0082065\ttotal: 56.5s\tremaining: 2m 1s\n",
      "633:\tlearn: 0.0081926\ttotal: 56.5s\tremaining: 2m 1s\n",
      "634:\tlearn: 0.0081912\ttotal: 56.6s\tremaining: 2m 1s\n",
      "635:\tlearn: 0.0081731\ttotal: 56.7s\tremaining: 2m 1s\n",
      "636:\tlearn: 0.0081711\ttotal: 56.8s\tremaining: 2m 1s\n",
      "637:\tlearn: 0.0081647\ttotal: 56.9s\tremaining: 2m 1s\n",
      "638:\tlearn: 0.0081472\ttotal: 57s\tremaining: 2m 1s\n",
      "639:\tlearn: 0.0081436\ttotal: 57.1s\tremaining: 2m 1s\n",
      "640:\tlearn: 0.0081401\ttotal: 57.2s\tremaining: 2m 1s\n",
      "641:\tlearn: 0.0081271\ttotal: 57.3s\tremaining: 2m 1s\n",
      "642:\tlearn: 0.0081117\ttotal: 57.3s\tremaining: 2m 1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "643:\tlearn: 0.0081002\ttotal: 57.4s\tremaining: 2m\n",
      "644:\tlearn: 0.0080909\ttotal: 57.5s\tremaining: 2m\n",
      "645:\tlearn: 0.0080746\ttotal: 57.6s\tremaining: 2m\n",
      "646:\tlearn: 0.0080717\ttotal: 57.7s\tremaining: 2m\n",
      "647:\tlearn: 0.0080682\ttotal: 57.8s\tremaining: 2m\n",
      "648:\tlearn: 0.0080616\ttotal: 57.8s\tremaining: 2m\n",
      "649:\tlearn: 0.0080542\ttotal: 57.9s\tremaining: 2m\n",
      "650:\tlearn: 0.0080510\ttotal: 58s\tremaining: 2m\n",
      "651:\tlearn: 0.0080486\ttotal: 58.1s\tremaining: 2m\n",
      "652:\tlearn: 0.0080434\ttotal: 58.2s\tremaining: 1m 59s\n",
      "653:\tlearn: 0.0080363\ttotal: 58.2s\tremaining: 1m 59s\n",
      "654:\tlearn: 0.0080274\ttotal: 58.3s\tremaining: 1m 59s\n",
      "655:\tlearn: 0.0080214\ttotal: 58.4s\tremaining: 1m 59s\n",
      "656:\tlearn: 0.0080140\ttotal: 58.5s\tremaining: 1m 59s\n",
      "657:\tlearn: 0.0079893\ttotal: 58.6s\tremaining: 1m 59s\n",
      "658:\tlearn: 0.0079859\ttotal: 58.7s\tremaining: 1m 59s\n",
      "659:\tlearn: 0.0079828\ttotal: 58.8s\tremaining: 1m 59s\n",
      "660:\tlearn: 0.0079770\ttotal: 58.9s\tremaining: 1m 59s\n",
      "661:\tlearn: 0.0079585\ttotal: 59s\tremaining: 1m 59s\n",
      "662:\tlearn: 0.0079528\ttotal: 59s\tremaining: 1m 59s\n",
      "663:\tlearn: 0.0079491\ttotal: 59.1s\tremaining: 1m 58s\n",
      "664:\tlearn: 0.0079365\ttotal: 59.2s\tremaining: 1m 58s\n",
      "665:\tlearn: 0.0079334\ttotal: 59.3s\tremaining: 1m 58s\n",
      "666:\tlearn: 0.0079301\ttotal: 59.4s\tremaining: 1m 58s\n",
      "667:\tlearn: 0.0079236\ttotal: 59.5s\tremaining: 1m 58s\n",
      "668:\tlearn: 0.0079204\ttotal: 59.5s\tremaining: 1m 58s\n",
      "669:\tlearn: 0.0079179\ttotal: 59.6s\tremaining: 1m 58s\n",
      "670:\tlearn: 0.0079103\ttotal: 59.7s\tremaining: 1m 58s\n",
      "671:\tlearn: 0.0079065\ttotal: 59.8s\tremaining: 1m 58s\n",
      "672:\tlearn: 0.0079021\ttotal: 59.9s\tremaining: 1m 58s\n",
      "673:\tlearn: 0.0078999\ttotal: 60s\tremaining: 1m 57s\n",
      "674:\tlearn: 0.0078846\ttotal: 1m\tremaining: 1m 57s\n",
      "675:\tlearn: 0.0078731\ttotal: 1m\tremaining: 1m 57s\n",
      "676:\tlearn: 0.0078693\ttotal: 1m\tremaining: 1m 57s\n",
      "677:\tlearn: 0.0078597\ttotal: 1m\tremaining: 1m 57s\n",
      "678:\tlearn: 0.0078577\ttotal: 1m\tremaining: 1m 57s\n",
      "679:\tlearn: 0.0078523\ttotal: 1m\tremaining: 1m 57s\n",
      "680:\tlearn: 0.0078445\ttotal: 1m\tremaining: 1m 57s\n",
      "681:\tlearn: 0.0078342\ttotal: 1m\tremaining: 1m 57s\n",
      "682:\tlearn: 0.0078297\ttotal: 1m\tremaining: 1m 57s\n",
      "683:\tlearn: 0.0078231\ttotal: 1m\tremaining: 1m 57s\n",
      "684:\tlearn: 0.0078140\ttotal: 1m\tremaining: 1m 56s\n",
      "685:\tlearn: 0.0078012\ttotal: 1m 1s\tremaining: 1m 56s\n",
      "686:\tlearn: 0.0077924\ttotal: 1m 1s\tremaining: 1m 56s\n",
      "687:\tlearn: 0.0077905\ttotal: 1m 1s\tremaining: 1m 56s\n",
      "688:\tlearn: 0.0077828\ttotal: 1m 1s\tremaining: 1m 56s\n",
      "689:\tlearn: 0.0077779\ttotal: 1m 1s\tremaining: 1m 56s\n",
      "690:\tlearn: 0.0077599\ttotal: 1m 1s\tremaining: 1m 56s\n",
      "691:\tlearn: 0.0077555\ttotal: 1m 1s\tremaining: 1m 56s\n",
      "692:\tlearn: 0.0077474\ttotal: 1m 1s\tremaining: 1m 56s\n",
      "693:\tlearn: 0.0077380\ttotal: 1m 1s\tremaining: 1m 56s\n",
      "694:\tlearn: 0.0077145\ttotal: 1m 1s\tremaining: 1m 56s\n",
      "695:\tlearn: 0.0076803\ttotal: 1m 1s\tremaining: 1m 55s\n",
      "696:\tlearn: 0.0076794\ttotal: 1m 1s\tremaining: 1m 55s\n",
      "697:\tlearn: 0.0076730\ttotal: 1m 2s\tremaining: 1m 55s\n",
      "698:\tlearn: 0.0076652\ttotal: 1m 2s\tremaining: 1m 55s\n",
      "699:\tlearn: 0.0076528\ttotal: 1m 2s\tremaining: 1m 55s\n",
      "700:\tlearn: 0.0076210\ttotal: 1m 2s\tremaining: 1m 55s\n",
      "701:\tlearn: 0.0076135\ttotal: 1m 2s\tremaining: 1m 55s\n",
      "702:\tlearn: 0.0076067\ttotal: 1m 2s\tremaining: 1m 55s\n",
      "703:\tlearn: 0.0075986\ttotal: 1m 2s\tremaining: 1m 55s\n",
      "704:\tlearn: 0.0075882\ttotal: 1m 2s\tremaining: 1m 55s\n",
      "705:\tlearn: 0.0075836\ttotal: 1m 2s\tremaining: 1m 54s\n",
      "706:\tlearn: 0.0075819\ttotal: 1m 2s\tremaining: 1m 54s\n",
      "707:\tlearn: 0.0075752\ttotal: 1m 2s\tremaining: 1m 54s\n",
      "708:\tlearn: 0.0075695\ttotal: 1m 2s\tremaining: 1m 54s\n",
      "709:\tlearn: 0.0075600\ttotal: 1m 3s\tremaining: 1m 54s\n",
      "710:\tlearn: 0.0075549\ttotal: 1m 3s\tremaining: 1m 54s\n",
      "711:\tlearn: 0.0075401\ttotal: 1m 3s\tremaining: 1m 54s\n",
      "712:\tlearn: 0.0075310\ttotal: 1m 3s\tremaining: 1m 54s\n",
      "713:\tlearn: 0.0075144\ttotal: 1m 3s\tremaining: 1m 54s\n",
      "714:\tlearn: 0.0075094\ttotal: 1m 3s\tremaining: 1m 54s\n",
      "715:\tlearn: 0.0074884\ttotal: 1m 3s\tremaining: 1m 54s\n",
      "716:\tlearn: 0.0074803\ttotal: 1m 3s\tremaining: 1m 53s\n",
      "717:\tlearn: 0.0074750\ttotal: 1m 3s\tremaining: 1m 53s\n",
      "718:\tlearn: 0.0074693\ttotal: 1m 3s\tremaining: 1m 53s\n",
      "719:\tlearn: 0.0074601\ttotal: 1m 3s\tremaining: 1m 53s\n",
      "720:\tlearn: 0.0074559\ttotal: 1m 4s\tremaining: 1m 53s\n",
      "721:\tlearn: 0.0074551\ttotal: 1m 4s\tremaining: 1m 53s\n",
      "722:\tlearn: 0.0074528\ttotal: 1m 4s\tremaining: 1m 53s\n",
      "723:\tlearn: 0.0074461\ttotal: 1m 4s\tremaining: 1m 53s\n",
      "724:\tlearn: 0.0074425\ttotal: 1m 4s\tremaining: 1m 53s\n",
      "725:\tlearn: 0.0074315\ttotal: 1m 4s\tremaining: 1m 53s\n",
      "726:\tlearn: 0.0074264\ttotal: 1m 4s\tremaining: 1m 52s\n",
      "727:\tlearn: 0.0074214\ttotal: 1m 4s\tremaining: 1m 52s\n",
      "728:\tlearn: 0.0074090\ttotal: 1m 4s\tremaining: 1m 52s\n",
      "729:\tlearn: 0.0074070\ttotal: 1m 4s\tremaining: 1m 52s\n",
      "730:\tlearn: 0.0074050\ttotal: 1m 4s\tremaining: 1m 52s\n",
      "731:\tlearn: 0.0073855\ttotal: 1m 4s\tremaining: 1m 52s\n",
      "732:\tlearn: 0.0073802\ttotal: 1m 5s\tremaining: 1m 52s\n",
      "733:\tlearn: 0.0073726\ttotal: 1m 5s\tremaining: 1m 52s\n",
      "734:\tlearn: 0.0073612\ttotal: 1m 5s\tremaining: 1m 52s\n",
      "735:\tlearn: 0.0073521\ttotal: 1m 5s\tremaining: 1m 52s\n",
      "736:\tlearn: 0.0073266\ttotal: 1m 5s\tremaining: 1m 52s\n",
      "737:\tlearn: 0.0073219\ttotal: 1m 5s\tremaining: 1m 51s\n",
      "738:\tlearn: 0.0073197\ttotal: 1m 5s\tremaining: 1m 51s\n",
      "739:\tlearn: 0.0073148\ttotal: 1m 5s\tremaining: 1m 51s\n",
      "740:\tlearn: 0.0073096\ttotal: 1m 5s\tremaining: 1m 51s\n",
      "741:\tlearn: 0.0073024\ttotal: 1m 5s\tremaining: 1m 51s\n",
      "742:\tlearn: 0.0072981\ttotal: 1m 5s\tremaining: 1m 51s\n",
      "743:\tlearn: 0.0072891\ttotal: 1m 6s\tremaining: 1m 51s\n",
      "744:\tlearn: 0.0072878\ttotal: 1m 6s\tremaining: 1m 51s\n",
      "745:\tlearn: 0.0072835\ttotal: 1m 6s\tremaining: 1m 51s\n",
      "746:\tlearn: 0.0072677\ttotal: 1m 6s\tremaining: 1m 51s\n",
      "747:\tlearn: 0.0072558\ttotal: 1m 6s\tremaining: 1m 51s\n",
      "748:\tlearn: 0.0072527\ttotal: 1m 6s\tremaining: 1m 50s\n",
      "749:\tlearn: 0.0072463\ttotal: 1m 6s\tremaining: 1m 50s\n",
      "750:\tlearn: 0.0072319\ttotal: 1m 6s\tremaining: 1m 50s\n",
      "751:\tlearn: 0.0072131\ttotal: 1m 6s\tremaining: 1m 50s\n",
      "752:\tlearn: 0.0071974\ttotal: 1m 6s\tremaining: 1m 50s\n",
      "753:\tlearn: 0.0071882\ttotal: 1m 6s\tremaining: 1m 50s\n",
      "754:\tlearn: 0.0071846\ttotal: 1m 6s\tremaining: 1m 50s\n",
      "755:\tlearn: 0.0071819\ttotal: 1m 7s\tremaining: 1m 50s\n",
      "756:\tlearn: 0.0071715\ttotal: 1m 7s\tremaining: 1m 50s\n",
      "757:\tlearn: 0.0071639\ttotal: 1m 7s\tremaining: 1m 50s\n",
      "758:\tlearn: 0.0071607\ttotal: 1m 7s\tremaining: 1m 50s\n",
      "759:\tlearn: 0.0071590\ttotal: 1m 7s\tremaining: 1m 50s\n",
      "760:\tlearn: 0.0071426\ttotal: 1m 7s\tremaining: 1m 49s\n",
      "761:\tlearn: 0.0071385\ttotal: 1m 7s\tremaining: 1m 49s\n",
      "762:\tlearn: 0.0071351\ttotal: 1m 7s\tremaining: 1m 49s\n",
      "763:\tlearn: 0.0071317\ttotal: 1m 7s\tremaining: 1m 49s\n",
      "764:\tlearn: 0.0071272\ttotal: 1m 7s\tremaining: 1m 49s\n",
      "765:\tlearn: 0.0071178\ttotal: 1m 7s\tremaining: 1m 49s\n",
      "766:\tlearn: 0.0071019\ttotal: 1m 8s\tremaining: 1m 49s\n",
      "767:\tlearn: 0.0070987\ttotal: 1m 8s\tremaining: 1m 49s\n",
      "768:\tlearn: 0.0070855\ttotal: 1m 8s\tremaining: 1m 49s\n",
      "769:\tlearn: 0.0070837\ttotal: 1m 8s\tremaining: 1m 49s\n",
      "770:\tlearn: 0.0070806\ttotal: 1m 8s\tremaining: 1m 49s\n",
      "771:\tlearn: 0.0070777\ttotal: 1m 8s\tremaining: 1m 49s\n",
      "772:\tlearn: 0.0070728\ttotal: 1m 8s\tremaining: 1m 48s\n",
      "773:\tlearn: 0.0070494\ttotal: 1m 8s\tremaining: 1m 48s\n",
      "774:\tlearn: 0.0070409\ttotal: 1m 8s\tremaining: 1m 48s\n",
      "775:\tlearn: 0.0070376\ttotal: 1m 8s\tremaining: 1m 48s\n",
      "776:\tlearn: 0.0070348\ttotal: 1m 9s\tremaining: 1m 48s\n",
      "777:\tlearn: 0.0070236\ttotal: 1m 9s\tremaining: 1m 48s\n",
      "778:\tlearn: 0.0070093\ttotal: 1m 9s\tremaining: 1m 48s\n",
      "779:\tlearn: 0.0070047\ttotal: 1m 9s\tremaining: 1m 48s\n",
      "780:\tlearn: 0.0070009\ttotal: 1m 9s\tremaining: 1m 48s\n",
      "781:\tlearn: 0.0069931\ttotal: 1m 9s\tremaining: 1m 48s\n",
      "782:\tlearn: 0.0069785\ttotal: 1m 9s\tremaining: 1m 48s\n",
      "783:\tlearn: 0.0069769\ttotal: 1m 9s\tremaining: 1m 48s\n",
      "784:\tlearn: 0.0069718\ttotal: 1m 9s\tremaining: 1m 47s\n",
      "785:\tlearn: 0.0069580\ttotal: 1m 9s\tremaining: 1m 47s\n",
      "786:\tlearn: 0.0069516\ttotal: 1m 9s\tremaining: 1m 47s\n",
      "787:\tlearn: 0.0069478\ttotal: 1m 10s\tremaining: 1m 47s\n",
      "788:\tlearn: 0.0069444\ttotal: 1m 10s\tremaining: 1m 47s\n",
      "789:\tlearn: 0.0069352\ttotal: 1m 10s\tremaining: 1m 47s\n",
      "790:\tlearn: 0.0069293\ttotal: 1m 10s\tremaining: 1m 47s\n",
      "791:\tlearn: 0.0069212\ttotal: 1m 10s\tremaining: 1m 47s\n",
      "792:\tlearn: 0.0069053\ttotal: 1m 10s\tremaining: 1m 47s\n",
      "793:\tlearn: 0.0069004\ttotal: 1m 10s\tremaining: 1m 47s\n",
      "794:\tlearn: 0.0068981\ttotal: 1m 10s\tremaining: 1m 47s\n",
      "795:\tlearn: 0.0068954\ttotal: 1m 10s\tremaining: 1m 47s\n",
      "796:\tlearn: 0.0068923\ttotal: 1m 10s\tremaining: 1m 46s\n",
      "797:\tlearn: 0.0068899\ttotal: 1m 10s\tremaining: 1m 46s\n",
      "798:\tlearn: 0.0068774\ttotal: 1m 11s\tremaining: 1m 46s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799:\tlearn: 0.0068753\ttotal: 1m 11s\tremaining: 1m 46s\n",
      "800:\tlearn: 0.0068717\ttotal: 1m 11s\tremaining: 1m 46s\n",
      "801:\tlearn: 0.0068582\ttotal: 1m 11s\tremaining: 1m 46s\n",
      "802:\tlearn: 0.0068555\ttotal: 1m 11s\tremaining: 1m 46s\n",
      "803:\tlearn: 0.0068422\ttotal: 1m 11s\tremaining: 1m 46s\n",
      "804:\tlearn: 0.0068342\ttotal: 1m 11s\tremaining: 1m 46s\n",
      "805:\tlearn: 0.0068268\ttotal: 1m 11s\tremaining: 1m 46s\n",
      "806:\tlearn: 0.0068246\ttotal: 1m 11s\tremaining: 1m 46s\n",
      "807:\tlearn: 0.0068218\ttotal: 1m 11s\tremaining: 1m 45s\n",
      "808:\tlearn: 0.0068093\ttotal: 1m 11s\tremaining: 1m 45s\n",
      "809:\tlearn: 0.0068016\ttotal: 1m 11s\tremaining: 1m 45s\n",
      "810:\tlearn: 0.0067863\ttotal: 1m 12s\tremaining: 1m 45s\n",
      "811:\tlearn: 0.0067844\ttotal: 1m 12s\tremaining: 1m 45s\n",
      "812:\tlearn: 0.0067744\ttotal: 1m 12s\tremaining: 1m 45s\n",
      "813:\tlearn: 0.0067664\ttotal: 1m 12s\tremaining: 1m 45s\n",
      "814:\tlearn: 0.0067633\ttotal: 1m 12s\tremaining: 1m 45s\n",
      "815:\tlearn: 0.0067609\ttotal: 1m 12s\tremaining: 1m 45s\n",
      "816:\tlearn: 0.0067481\ttotal: 1m 12s\tremaining: 1m 45s\n",
      "817:\tlearn: 0.0067424\ttotal: 1m 12s\tremaining: 1m 45s\n",
      "818:\tlearn: 0.0067394\ttotal: 1m 12s\tremaining: 1m 44s\n",
      "819:\tlearn: 0.0067368\ttotal: 1m 12s\tremaining: 1m 44s\n",
      "820:\tlearn: 0.0067351\ttotal: 1m 12s\tremaining: 1m 44s\n",
      "821:\tlearn: 0.0067334\ttotal: 1m 12s\tremaining: 1m 44s\n",
      "822:\tlearn: 0.0067229\ttotal: 1m 13s\tremaining: 1m 44s\n",
      "823:\tlearn: 0.0067127\ttotal: 1m 13s\tremaining: 1m 44s\n",
      "824:\tlearn: 0.0066949\ttotal: 1m 13s\tremaining: 1m 44s\n",
      "825:\tlearn: 0.0066900\ttotal: 1m 13s\tremaining: 1m 44s\n",
      "826:\tlearn: 0.0066846\ttotal: 1m 13s\tremaining: 1m 44s\n",
      "827:\tlearn: 0.0066783\ttotal: 1m 13s\tremaining: 1m 44s\n",
      "828:\tlearn: 0.0066764\ttotal: 1m 13s\tremaining: 1m 43s\n",
      "829:\tlearn: 0.0066623\ttotal: 1m 13s\tremaining: 1m 43s\n",
      "830:\tlearn: 0.0066545\ttotal: 1m 13s\tremaining: 1m 43s\n",
      "831:\tlearn: 0.0066537\ttotal: 1m 13s\tremaining: 1m 43s\n",
      "832:\tlearn: 0.0066439\ttotal: 1m 13s\tremaining: 1m 43s\n",
      "833:\tlearn: 0.0066419\ttotal: 1m 14s\tremaining: 1m 43s\n",
      "834:\tlearn: 0.0066395\ttotal: 1m 14s\tremaining: 1m 43s\n",
      "835:\tlearn: 0.0066266\ttotal: 1m 14s\tremaining: 1m 43s\n",
      "836:\tlearn: 0.0066255\ttotal: 1m 14s\tremaining: 1m 43s\n",
      "837:\tlearn: 0.0066224\ttotal: 1m 14s\tremaining: 1m 43s\n",
      "838:\tlearn: 0.0066185\ttotal: 1m 14s\tremaining: 1m 43s\n",
      "839:\tlearn: 0.0066166\ttotal: 1m 14s\tremaining: 1m 42s\n",
      "840:\tlearn: 0.0066117\ttotal: 1m 14s\tremaining: 1m 42s\n",
      "841:\tlearn: 0.0066041\ttotal: 1m 14s\tremaining: 1m 42s\n",
      "842:\tlearn: 0.0066005\ttotal: 1m 14s\tremaining: 1m 42s\n",
      "843:\tlearn: 0.0065972\ttotal: 1m 14s\tremaining: 1m 42s\n",
      "844:\tlearn: 0.0065912\ttotal: 1m 14s\tremaining: 1m 42s\n",
      "845:\tlearn: 0.0065854\ttotal: 1m 15s\tremaining: 1m 42s\n",
      "846:\tlearn: 0.0065844\ttotal: 1m 15s\tremaining: 1m 42s\n",
      "847:\tlearn: 0.0065805\ttotal: 1m 15s\tremaining: 1m 42s\n",
      "848:\tlearn: 0.0065768\ttotal: 1m 15s\tremaining: 1m 42s\n",
      "849:\tlearn: 0.0065758\ttotal: 1m 15s\tremaining: 1m 41s\n",
      "850:\tlearn: 0.0065721\ttotal: 1m 15s\tremaining: 1m 41s\n",
      "851:\tlearn: 0.0065707\ttotal: 1m 15s\tremaining: 1m 41s\n",
      "852:\tlearn: 0.0065700\ttotal: 1m 15s\tremaining: 1m 41s\n",
      "853:\tlearn: 0.0065646\ttotal: 1m 15s\tremaining: 1m 41s\n",
      "854:\tlearn: 0.0065620\ttotal: 1m 15s\tremaining: 1m 41s\n",
      "855:\tlearn: 0.0065472\ttotal: 1m 15s\tremaining: 1m 41s\n",
      "856:\tlearn: 0.0065460\ttotal: 1m 15s\tremaining: 1m 41s\n",
      "857:\tlearn: 0.0065431\ttotal: 1m 16s\tremaining: 1m 41s\n",
      "858:\tlearn: 0.0065423\ttotal: 1m 16s\tremaining: 1m 41s\n",
      "859:\tlearn: 0.0065352\ttotal: 1m 16s\tremaining: 1m 41s\n",
      "860:\tlearn: 0.0065336\ttotal: 1m 16s\tremaining: 1m 40s\n",
      "861:\tlearn: 0.0065193\ttotal: 1m 16s\tremaining: 1m 40s\n",
      "862:\tlearn: 0.0065125\ttotal: 1m 16s\tremaining: 1m 40s\n",
      "863:\tlearn: 0.0065089\ttotal: 1m 16s\tremaining: 1m 40s\n",
      "864:\tlearn: 0.0065024\ttotal: 1m 16s\tremaining: 1m 40s\n",
      "865:\tlearn: 0.0064849\ttotal: 1m 16s\tremaining: 1m 40s\n",
      "866:\tlearn: 0.0064828\ttotal: 1m 16s\tremaining: 1m 40s\n",
      "867:\tlearn: 0.0064785\ttotal: 1m 16s\tremaining: 1m 40s\n",
      "868:\tlearn: 0.0064759\ttotal: 1m 17s\tremaining: 1m 40s\n",
      "869:\tlearn: 0.0064704\ttotal: 1m 17s\tremaining: 1m 40s\n",
      "870:\tlearn: 0.0064659\ttotal: 1m 17s\tremaining: 1m 40s\n",
      "871:\tlearn: 0.0064559\ttotal: 1m 17s\tremaining: 1m 39s\n",
      "872:\tlearn: 0.0064535\ttotal: 1m 17s\tremaining: 1m 39s\n",
      "873:\tlearn: 0.0064481\ttotal: 1m 17s\tremaining: 1m 39s\n",
      "874:\tlearn: 0.0064453\ttotal: 1m 17s\tremaining: 1m 39s\n",
      "875:\tlearn: 0.0064444\ttotal: 1m 17s\tremaining: 1m 39s\n",
      "876:\tlearn: 0.0064327\ttotal: 1m 17s\tremaining: 1m 39s\n",
      "877:\tlearn: 0.0064298\ttotal: 1m 17s\tremaining: 1m 39s\n",
      "878:\tlearn: 0.0064107\ttotal: 1m 17s\tremaining: 1m 39s\n",
      "879:\tlearn: 0.0064086\ttotal: 1m 18s\tremaining: 1m 39s\n",
      "880:\tlearn: 0.0064031\ttotal: 1m 18s\tremaining: 1m 39s\n",
      "881:\tlearn: 0.0064012\ttotal: 1m 18s\tremaining: 1m 39s\n",
      "882:\tlearn: 0.0063920\ttotal: 1m 18s\tremaining: 1m 39s\n",
      "883:\tlearn: 0.0063880\ttotal: 1m 18s\tremaining: 1m 38s\n",
      "884:\tlearn: 0.0063814\ttotal: 1m 18s\tremaining: 1m 38s\n",
      "885:\tlearn: 0.0063758\ttotal: 1m 18s\tremaining: 1m 38s\n",
      "886:\tlearn: 0.0063750\ttotal: 1m 18s\tremaining: 1m 38s\n",
      "887:\tlearn: 0.0063720\ttotal: 1m 18s\tremaining: 1m 38s\n",
      "888:\tlearn: 0.0063584\ttotal: 1m 18s\tremaining: 1m 38s\n",
      "889:\tlearn: 0.0063406\ttotal: 1m 18s\tremaining: 1m 38s\n",
      "890:\tlearn: 0.0063377\ttotal: 1m 18s\tremaining: 1m 38s\n",
      "891:\tlearn: 0.0063349\ttotal: 1m 19s\tremaining: 1m 38s\n",
      "892:\tlearn: 0.0063260\ttotal: 1m 19s\tremaining: 1m 38s\n",
      "893:\tlearn: 0.0063243\ttotal: 1m 19s\tremaining: 1m 38s\n",
      "894:\tlearn: 0.0063203\ttotal: 1m 19s\tremaining: 1m 37s\n",
      "895:\tlearn: 0.0063173\ttotal: 1m 19s\tremaining: 1m 37s\n",
      "896:\tlearn: 0.0063109\ttotal: 1m 19s\tremaining: 1m 37s\n",
      "897:\tlearn: 0.0063004\ttotal: 1m 19s\tremaining: 1m 37s\n",
      "898:\tlearn: 0.0062989\ttotal: 1m 19s\tremaining: 1m 37s\n",
      "899:\tlearn: 0.0062855\ttotal: 1m 19s\tremaining: 1m 37s\n",
      "900:\tlearn: 0.0062840\ttotal: 1m 19s\tremaining: 1m 37s\n",
      "901:\tlearn: 0.0062725\ttotal: 1m 19s\tremaining: 1m 37s\n",
      "902:\tlearn: 0.0062679\ttotal: 1m 20s\tremaining: 1m 37s\n",
      "903:\tlearn: 0.0062651\ttotal: 1m 20s\tremaining: 1m 37s\n",
      "904:\tlearn: 0.0062623\ttotal: 1m 20s\tremaining: 1m 37s\n",
      "905:\tlearn: 0.0062572\ttotal: 1m 20s\tremaining: 1m 36s\n",
      "906:\tlearn: 0.0062555\ttotal: 1m 20s\tremaining: 1m 36s\n",
      "907:\tlearn: 0.0062520\ttotal: 1m 20s\tremaining: 1m 36s\n",
      "908:\tlearn: 0.0062390\ttotal: 1m 20s\tremaining: 1m 36s\n",
      "909:\tlearn: 0.0062358\ttotal: 1m 20s\tremaining: 1m 36s\n",
      "910:\tlearn: 0.0062280\ttotal: 1m 20s\tremaining: 1m 36s\n",
      "911:\tlearn: 0.0062246\ttotal: 1m 20s\tremaining: 1m 36s\n",
      "912:\tlearn: 0.0062115\ttotal: 1m 20s\tremaining: 1m 36s\n",
      "913:\tlearn: 0.0062046\ttotal: 1m 20s\tremaining: 1m 36s\n",
      "914:\tlearn: 0.0062020\ttotal: 1m 21s\tremaining: 1m 36s\n",
      "915:\tlearn: 0.0062000\ttotal: 1m 21s\tremaining: 1m 36s\n",
      "916:\tlearn: 0.0061921\ttotal: 1m 21s\tremaining: 1m 35s\n",
      "917:\tlearn: 0.0061915\ttotal: 1m 21s\tremaining: 1m 35s\n",
      "918:\tlearn: 0.0061886\ttotal: 1m 21s\tremaining: 1m 35s\n",
      "919:\tlearn: 0.0061834\ttotal: 1m 21s\tremaining: 1m 35s\n",
      "920:\tlearn: 0.0061782\ttotal: 1m 21s\tremaining: 1m 35s\n",
      "921:\tlearn: 0.0061719\ttotal: 1m 21s\tremaining: 1m 35s\n",
      "922:\tlearn: 0.0061695\ttotal: 1m 21s\tremaining: 1m 35s\n",
      "923:\tlearn: 0.0061688\ttotal: 1m 21s\tremaining: 1m 35s\n",
      "924:\tlearn: 0.0061625\ttotal: 1m 21s\tremaining: 1m 35s\n",
      "925:\tlearn: 0.0061610\ttotal: 1m 22s\tremaining: 1m 35s\n",
      "926:\tlearn: 0.0061587\ttotal: 1m 22s\tremaining: 1m 35s\n",
      "927:\tlearn: 0.0061549\ttotal: 1m 22s\tremaining: 1m 34s\n",
      "928:\tlearn: 0.0061537\ttotal: 1m 22s\tremaining: 1m 34s\n",
      "929:\tlearn: 0.0061519\ttotal: 1m 22s\tremaining: 1m 34s\n",
      "930:\tlearn: 0.0061480\ttotal: 1m 22s\tremaining: 1m 34s\n",
      "931:\tlearn: 0.0061342\ttotal: 1m 22s\tremaining: 1m 34s\n",
      "932:\tlearn: 0.0061285\ttotal: 1m 22s\tremaining: 1m 34s\n",
      "933:\tlearn: 0.0061219\ttotal: 1m 22s\tremaining: 1m 34s\n",
      "934:\tlearn: 0.0061208\ttotal: 1m 22s\tremaining: 1m 34s\n",
      "935:\tlearn: 0.0061066\ttotal: 1m 22s\tremaining: 1m 34s\n",
      "936:\tlearn: 0.0060993\ttotal: 1m 22s\tremaining: 1m 34s\n",
      "937:\tlearn: 0.0060931\ttotal: 1m 23s\tremaining: 1m 34s\n",
      "938:\tlearn: 0.0060832\ttotal: 1m 23s\tremaining: 1m 33s\n",
      "939:\tlearn: 0.0060766\ttotal: 1m 23s\tremaining: 1m 33s\n",
      "940:\tlearn: 0.0060640\ttotal: 1m 23s\tremaining: 1m 33s\n",
      "941:\tlearn: 0.0060606\ttotal: 1m 23s\tremaining: 1m 33s\n",
      "942:\tlearn: 0.0060593\ttotal: 1m 23s\tremaining: 1m 33s\n",
      "943:\tlearn: 0.0060551\ttotal: 1m 23s\tremaining: 1m 33s\n",
      "944:\tlearn: 0.0060547\ttotal: 1m 23s\tremaining: 1m 33s\n",
      "945:\tlearn: 0.0060521\ttotal: 1m 23s\tremaining: 1m 33s\n",
      "946:\tlearn: 0.0060490\ttotal: 1m 23s\tremaining: 1m 33s\n",
      "947:\tlearn: 0.0060464\ttotal: 1m 23s\tremaining: 1m 33s\n",
      "948:\tlearn: 0.0060396\ttotal: 1m 24s\tremaining: 1m 33s\n",
      "949:\tlearn: 0.0060364\ttotal: 1m 24s\tremaining: 1m 32s\n",
      "950:\tlearn: 0.0060345\ttotal: 1m 24s\tremaining: 1m 32s\n",
      "951:\tlearn: 0.0060307\ttotal: 1m 24s\tremaining: 1m 32s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952:\tlearn: 0.0060279\ttotal: 1m 24s\tremaining: 1m 32s\n",
      "953:\tlearn: 0.0060255\ttotal: 1m 24s\tremaining: 1m 32s\n",
      "954:\tlearn: 0.0060233\ttotal: 1m 24s\tremaining: 1m 32s\n",
      "955:\tlearn: 0.0060161\ttotal: 1m 24s\tremaining: 1m 32s\n",
      "956:\tlearn: 0.0060063\ttotal: 1m 24s\tremaining: 1m 32s\n",
      "957:\tlearn: 0.0060038\ttotal: 1m 24s\tremaining: 1m 32s\n",
      "958:\tlearn: 0.0060011\ttotal: 1m 24s\tremaining: 1m 32s\n",
      "959:\tlearn: 0.0059927\ttotal: 1m 24s\tremaining: 1m 32s\n",
      "960:\tlearn: 0.0059892\ttotal: 1m 25s\tremaining: 1m 31s\n",
      "961:\tlearn: 0.0059877\ttotal: 1m 25s\tremaining: 1m 31s\n",
      "962:\tlearn: 0.0059821\ttotal: 1m 25s\tremaining: 1m 31s\n",
      "963:\tlearn: 0.0059800\ttotal: 1m 25s\tremaining: 1m 31s\n",
      "964:\tlearn: 0.0059785\ttotal: 1m 25s\tremaining: 1m 31s\n",
      "965:\tlearn: 0.0059774\ttotal: 1m 25s\tremaining: 1m 31s\n",
      "966:\tlearn: 0.0059745\ttotal: 1m 25s\tremaining: 1m 31s\n",
      "967:\tlearn: 0.0059723\ttotal: 1m 25s\tremaining: 1m 31s\n",
      "968:\tlearn: 0.0059697\ttotal: 1m 25s\tremaining: 1m 31s\n",
      "969:\tlearn: 0.0059680\ttotal: 1m 25s\tremaining: 1m 31s\n",
      "970:\tlearn: 0.0059651\ttotal: 1m 25s\tremaining: 1m 31s\n",
      "971:\tlearn: 0.0059609\ttotal: 1m 26s\tremaining: 1m 30s\n",
      "972:\tlearn: 0.0059599\ttotal: 1m 26s\tremaining: 1m 30s\n",
      "973:\tlearn: 0.0059548\ttotal: 1m 26s\tremaining: 1m 30s\n",
      "974:\tlearn: 0.0059506\ttotal: 1m 26s\tremaining: 1m 30s\n",
      "975:\tlearn: 0.0059261\ttotal: 1m 26s\tremaining: 1m 30s\n",
      "976:\tlearn: 0.0059236\ttotal: 1m 26s\tremaining: 1m 30s\n",
      "977:\tlearn: 0.0059100\ttotal: 1m 26s\tremaining: 1m 30s\n",
      "978:\tlearn: 0.0059077\ttotal: 1m 26s\tremaining: 1m 30s\n",
      "979:\tlearn: 0.0059017\ttotal: 1m 26s\tremaining: 1m 30s\n",
      "980:\tlearn: 0.0058939\ttotal: 1m 26s\tremaining: 1m 30s\n",
      "981:\tlearn: 0.0058880\ttotal: 1m 26s\tremaining: 1m 30s\n",
      "982:\tlearn: 0.0058833\ttotal: 1m 26s\tremaining: 1m 29s\n",
      "983:\tlearn: 0.0058763\ttotal: 1m 27s\tremaining: 1m 29s\n",
      "984:\tlearn: 0.0058740\ttotal: 1m 27s\tremaining: 1m 29s\n",
      "985:\tlearn: 0.0058729\ttotal: 1m 27s\tremaining: 1m 29s\n",
      "986:\tlearn: 0.0058718\ttotal: 1m 27s\tremaining: 1m 29s\n",
      "987:\tlearn: 0.0058639\ttotal: 1m 27s\tremaining: 1m 29s\n",
      "988:\tlearn: 0.0058609\ttotal: 1m 27s\tremaining: 1m 29s\n",
      "989:\tlearn: 0.0058585\ttotal: 1m 27s\tremaining: 1m 29s\n",
      "990:\tlearn: 0.0058551\ttotal: 1m 27s\tremaining: 1m 29s\n",
      "991:\tlearn: 0.0058535\ttotal: 1m 27s\tremaining: 1m 29s\n",
      "992:\tlearn: 0.0058504\ttotal: 1m 27s\tremaining: 1m 29s\n",
      "993:\tlearn: 0.0058439\ttotal: 1m 27s\tremaining: 1m 28s\n",
      "994:\tlearn: 0.0058404\ttotal: 1m 27s\tremaining: 1m 28s\n",
      "995:\tlearn: 0.0058325\ttotal: 1m 28s\tremaining: 1m 28s\n",
      "996:\tlearn: 0.0058286\ttotal: 1m 28s\tremaining: 1m 28s\n",
      "997:\tlearn: 0.0058233\ttotal: 1m 28s\tremaining: 1m 28s\n",
      "998:\tlearn: 0.0058223\ttotal: 1m 28s\tremaining: 1m 28s\n",
      "999:\tlearn: 0.0058186\ttotal: 1m 28s\tremaining: 1m 28s\n",
      "1000:\tlearn: 0.0058159\ttotal: 1m 28s\tremaining: 1m 28s\n",
      "1001:\tlearn: 0.0058144\ttotal: 1m 28s\tremaining: 1m 28s\n",
      "1002:\tlearn: 0.0058128\ttotal: 1m 28s\tremaining: 1m 28s\n",
      "1003:\tlearn: 0.0058119\ttotal: 1m 28s\tremaining: 1m 28s\n",
      "1004:\tlearn: 0.0058078\ttotal: 1m 28s\tremaining: 1m 27s\n",
      "1005:\tlearn: 0.0058055\ttotal: 1m 28s\tremaining: 1m 27s\n",
      "1006:\tlearn: 0.0058000\ttotal: 1m 29s\tremaining: 1m 27s\n",
      "1007:\tlearn: 0.0057923\ttotal: 1m 29s\tremaining: 1m 27s\n",
      "1008:\tlearn: 0.0057916\ttotal: 1m 29s\tremaining: 1m 27s\n",
      "1009:\tlearn: 0.0057855\ttotal: 1m 29s\tremaining: 1m 27s\n",
      "1010:\tlearn: 0.0057817\ttotal: 1m 29s\tremaining: 1m 27s\n",
      "1011:\tlearn: 0.0057803\ttotal: 1m 29s\tremaining: 1m 27s\n",
      "1012:\tlearn: 0.0057719\ttotal: 1m 29s\tremaining: 1m 27s\n",
      "1013:\tlearn: 0.0057709\ttotal: 1m 29s\tremaining: 1m 27s\n",
      "1014:\tlearn: 0.0057698\ttotal: 1m 29s\tremaining: 1m 27s\n",
      "1015:\tlearn: 0.0057621\ttotal: 1m 29s\tremaining: 1m 26s\n",
      "1016:\tlearn: 0.0057603\ttotal: 1m 29s\tremaining: 1m 26s\n",
      "1017:\tlearn: 0.0057594\ttotal: 1m 29s\tremaining: 1m 26s\n",
      "1018:\tlearn: 0.0057574\ttotal: 1m 30s\tremaining: 1m 26s\n",
      "1019:\tlearn: 0.0057557\ttotal: 1m 30s\tremaining: 1m 26s\n",
      "1020:\tlearn: 0.0057503\ttotal: 1m 30s\tremaining: 1m 26s\n",
      "1021:\tlearn: 0.0057493\ttotal: 1m 30s\tremaining: 1m 26s\n",
      "1022:\tlearn: 0.0057421\ttotal: 1m 30s\tremaining: 1m 26s\n",
      "1023:\tlearn: 0.0057407\ttotal: 1m 30s\tremaining: 1m 26s\n",
      "1024:\tlearn: 0.0057352\ttotal: 1m 30s\tremaining: 1m 26s\n",
      "1025:\tlearn: 0.0057286\ttotal: 1m 30s\tremaining: 1m 26s\n",
      "1026:\tlearn: 0.0057261\ttotal: 1m 30s\tremaining: 1m 26s\n",
      "1027:\tlearn: 0.0057247\ttotal: 1m 30s\tremaining: 1m 25s\n",
      "1028:\tlearn: 0.0057222\ttotal: 1m 30s\tremaining: 1m 25s\n",
      "1029:\tlearn: 0.0057111\ttotal: 1m 31s\tremaining: 1m 25s\n",
      "1030:\tlearn: 0.0057089\ttotal: 1m 31s\tremaining: 1m 25s\n",
      "1031:\tlearn: 0.0057075\ttotal: 1m 31s\tremaining: 1m 25s\n",
      "1032:\tlearn: 0.0057041\ttotal: 1m 31s\tremaining: 1m 25s\n",
      "1033:\tlearn: 0.0057030\ttotal: 1m 31s\tremaining: 1m 25s\n",
      "1034:\tlearn: 0.0056940\ttotal: 1m 31s\tremaining: 1m 25s\n",
      "1035:\tlearn: 0.0056922\ttotal: 1m 31s\tremaining: 1m 25s\n",
      "1036:\tlearn: 0.0056856\ttotal: 1m 31s\tremaining: 1m 25s\n",
      "1037:\tlearn: 0.0056843\ttotal: 1m 31s\tremaining: 1m 25s\n",
      "1038:\tlearn: 0.0056703\ttotal: 1m 31s\tremaining: 1m 24s\n",
      "1039:\tlearn: 0.0056694\ttotal: 1m 31s\tremaining: 1m 24s\n",
      "1040:\tlearn: 0.0056664\ttotal: 1m 32s\tremaining: 1m 24s\n",
      "1041:\tlearn: 0.0056472\ttotal: 1m 32s\tremaining: 1m 24s\n",
      "1042:\tlearn: 0.0056379\ttotal: 1m 32s\tremaining: 1m 24s\n",
      "1043:\tlearn: 0.0056361\ttotal: 1m 32s\tremaining: 1m 24s\n",
      "1044:\tlearn: 0.0056303\ttotal: 1m 32s\tremaining: 1m 24s\n",
      "1045:\tlearn: 0.0056272\ttotal: 1m 32s\tremaining: 1m 24s\n",
      "1046:\tlearn: 0.0056248\ttotal: 1m 32s\tremaining: 1m 24s\n",
      "1047:\tlearn: 0.0056231\ttotal: 1m 32s\tremaining: 1m 24s\n",
      "1048:\tlearn: 0.0056147\ttotal: 1m 32s\tremaining: 1m 24s\n",
      "1049:\tlearn: 0.0056093\ttotal: 1m 32s\tremaining: 1m 24s\n",
      "1050:\tlearn: 0.0056055\ttotal: 1m 32s\tremaining: 1m 23s\n",
      "1051:\tlearn: 0.0056007\ttotal: 1m 33s\tremaining: 1m 23s\n",
      "1052:\tlearn: 0.0055995\ttotal: 1m 33s\tremaining: 1m 23s\n",
      "1053:\tlearn: 0.0055984\ttotal: 1m 33s\tremaining: 1m 23s\n",
      "1054:\tlearn: 0.0055957\ttotal: 1m 33s\tremaining: 1m 23s\n",
      "1055:\tlearn: 0.0055895\ttotal: 1m 33s\tremaining: 1m 23s\n",
      "1056:\tlearn: 0.0055873\ttotal: 1m 33s\tremaining: 1m 23s\n",
      "1057:\tlearn: 0.0055869\ttotal: 1m 33s\tremaining: 1m 23s\n",
      "1058:\tlearn: 0.0055861\ttotal: 1m 33s\tremaining: 1m 23s\n",
      "1059:\tlearn: 0.0055830\ttotal: 1m 33s\tremaining: 1m 23s\n",
      "1060:\tlearn: 0.0055821\ttotal: 1m 33s\tremaining: 1m 23s\n",
      "1061:\tlearn: 0.0055801\ttotal: 1m 33s\tremaining: 1m 22s\n",
      "1062:\tlearn: 0.0055789\ttotal: 1m 33s\tremaining: 1m 22s\n",
      "1063:\tlearn: 0.0055698\ttotal: 1m 34s\tremaining: 1m 22s\n",
      "1064:\tlearn: 0.0055676\ttotal: 1m 34s\tremaining: 1m 22s\n",
      "1065:\tlearn: 0.0055658\ttotal: 1m 34s\tremaining: 1m 22s\n",
      "1066:\tlearn: 0.0055642\ttotal: 1m 34s\tremaining: 1m 22s\n",
      "1067:\tlearn: 0.0055614\ttotal: 1m 34s\tremaining: 1m 22s\n",
      "1068:\tlearn: 0.0055589\ttotal: 1m 34s\tremaining: 1m 22s\n",
      "1069:\tlearn: 0.0055582\ttotal: 1m 34s\tremaining: 1m 22s\n",
      "1070:\tlearn: 0.0055571\ttotal: 1m 34s\tremaining: 1m 22s\n",
      "1071:\tlearn: 0.0055510\ttotal: 1m 34s\tremaining: 1m 22s\n",
      "1072:\tlearn: 0.0055490\ttotal: 1m 34s\tremaining: 1m 21s\n",
      "1073:\tlearn: 0.0055436\ttotal: 1m 34s\tremaining: 1m 21s\n",
      "1074:\tlearn: 0.0055360\ttotal: 1m 35s\tremaining: 1m 21s\n",
      "1075:\tlearn: 0.0055332\ttotal: 1m 35s\tremaining: 1m 21s\n",
      "1076:\tlearn: 0.0055330\ttotal: 1m 35s\tremaining: 1m 21s\n",
      "1077:\tlearn: 0.0055298\ttotal: 1m 35s\tremaining: 1m 21s\n",
      "1078:\tlearn: 0.0055290\ttotal: 1m 35s\tremaining: 1m 21s\n",
      "1079:\tlearn: 0.0055259\ttotal: 1m 35s\tremaining: 1m 21s\n",
      "1080:\tlearn: 0.0055238\ttotal: 1m 35s\tremaining: 1m 21s\n",
      "1081:\tlearn: 0.0055062\ttotal: 1m 35s\tremaining: 1m 21s\n",
      "1082:\tlearn: 0.0055012\ttotal: 1m 35s\tremaining: 1m 21s\n",
      "1083:\tlearn: 0.0054955\ttotal: 1m 35s\tremaining: 1m 20s\n",
      "1084:\tlearn: 0.0054939\ttotal: 1m 35s\tremaining: 1m 20s\n",
      "1085:\tlearn: 0.0054874\ttotal: 1m 35s\tremaining: 1m 20s\n",
      "1086:\tlearn: 0.0054813\ttotal: 1m 36s\tremaining: 1m 20s\n",
      "1087:\tlearn: 0.0054810\ttotal: 1m 36s\tremaining: 1m 20s\n",
      "1088:\tlearn: 0.0054751\ttotal: 1m 36s\tremaining: 1m 20s\n",
      "1089:\tlearn: 0.0054605\ttotal: 1m 36s\tremaining: 1m 20s\n",
      "1090:\tlearn: 0.0054572\ttotal: 1m 36s\tremaining: 1m 20s\n",
      "1091:\tlearn: 0.0054491\ttotal: 1m 36s\tremaining: 1m 20s\n",
      "1092:\tlearn: 0.0054444\ttotal: 1m 36s\tremaining: 1m 20s\n",
      "1093:\tlearn: 0.0054420\ttotal: 1m 36s\tremaining: 1m 20s\n",
      "1094:\tlearn: 0.0054404\ttotal: 1m 36s\tremaining: 1m 19s\n",
      "1095:\tlearn: 0.0054390\ttotal: 1m 36s\tremaining: 1m 19s\n",
      "1096:\tlearn: 0.0054331\ttotal: 1m 36s\tremaining: 1m 19s\n",
      "1097:\tlearn: 0.0054303\ttotal: 1m 37s\tremaining: 1m 19s\n",
      "1098:\tlearn: 0.0054143\ttotal: 1m 37s\tremaining: 1m 19s\n",
      "1099:\tlearn: 0.0054109\ttotal: 1m 37s\tremaining: 1m 19s\n",
      "1100:\tlearn: 0.0054098\ttotal: 1m 37s\tremaining: 1m 19s\n",
      "1101:\tlearn: 0.0054071\ttotal: 1m 37s\tremaining: 1m 19s\n",
      "1102:\tlearn: 0.0054006\ttotal: 1m 37s\tremaining: 1m 19s\n",
      "1103:\tlearn: 0.0053944\ttotal: 1m 37s\tremaining: 1m 19s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1104:\tlearn: 0.0053923\ttotal: 1m 37s\tremaining: 1m 19s\n",
      "1105:\tlearn: 0.0053919\ttotal: 1m 37s\tremaining: 1m 19s\n",
      "1106:\tlearn: 0.0053908\ttotal: 1m 37s\tremaining: 1m 18s\n",
      "1107:\tlearn: 0.0053891\ttotal: 1m 38s\tremaining: 1m 18s\n",
      "1108:\tlearn: 0.0053850\ttotal: 1m 38s\tremaining: 1m 18s\n",
      "1109:\tlearn: 0.0053826\ttotal: 1m 38s\tremaining: 1m 18s\n",
      "1110:\tlearn: 0.0053818\ttotal: 1m 38s\tremaining: 1m 18s\n",
      "1111:\tlearn: 0.0053725\ttotal: 1m 38s\tremaining: 1m 18s\n",
      "1112:\tlearn: 0.0053716\ttotal: 1m 38s\tremaining: 1m 18s\n",
      "1113:\tlearn: 0.0053680\ttotal: 1m 38s\tremaining: 1m 18s\n",
      "1114:\tlearn: 0.0053603\ttotal: 1m 38s\tremaining: 1m 18s\n",
      "1115:\tlearn: 0.0053580\ttotal: 1m 38s\tremaining: 1m 18s\n",
      "1116:\tlearn: 0.0053503\ttotal: 1m 38s\tremaining: 1m 18s\n",
      "1117:\tlearn: 0.0053480\ttotal: 1m 38s\tremaining: 1m 17s\n",
      "1118:\tlearn: 0.0053420\ttotal: 1m 38s\tremaining: 1m 17s\n",
      "1119:\tlearn: 0.0053332\ttotal: 1m 39s\tremaining: 1m 17s\n",
      "1120:\tlearn: 0.0053318\ttotal: 1m 39s\tremaining: 1m 17s\n",
      "1121:\tlearn: 0.0053316\ttotal: 1m 39s\tremaining: 1m 17s\n",
      "1122:\tlearn: 0.0053297\ttotal: 1m 39s\tremaining: 1m 17s\n",
      "1123:\tlearn: 0.0053281\ttotal: 1m 39s\tremaining: 1m 17s\n",
      "1124:\tlearn: 0.0053118\ttotal: 1m 39s\tremaining: 1m 17s\n",
      "1125:\tlearn: 0.0053064\ttotal: 1m 39s\tremaining: 1m 17s\n",
      "1126:\tlearn: 0.0053011\ttotal: 1m 39s\tremaining: 1m 17s\n",
      "1127:\tlearn: 0.0052957\ttotal: 1m 39s\tremaining: 1m 17s\n",
      "1128:\tlearn: 0.0052888\ttotal: 1m 39s\tremaining: 1m 17s\n",
      "1129:\tlearn: 0.0052834\ttotal: 1m 39s\tremaining: 1m 16s\n",
      "1130:\tlearn: 0.0052820\ttotal: 1m 39s\tremaining: 1m 16s\n",
      "1131:\tlearn: 0.0052756\ttotal: 1m 40s\tremaining: 1m 16s\n",
      "1132:\tlearn: 0.0052745\ttotal: 1m 40s\tremaining: 1m 16s\n",
      "1133:\tlearn: 0.0052718\ttotal: 1m 40s\tremaining: 1m 16s\n",
      "1134:\tlearn: 0.0052701\ttotal: 1m 40s\tremaining: 1m 16s\n",
      "1135:\tlearn: 0.0052696\ttotal: 1m 40s\tremaining: 1m 16s\n",
      "1136:\tlearn: 0.0052674\ttotal: 1m 40s\tremaining: 1m 16s\n",
      "1137:\tlearn: 0.0052628\ttotal: 1m 40s\tremaining: 1m 16s\n",
      "1138:\tlearn: 0.0052601\ttotal: 1m 40s\tremaining: 1m 16s\n",
      "1139:\tlearn: 0.0052566\ttotal: 1m 40s\tremaining: 1m 16s\n",
      "1140:\tlearn: 0.0052552\ttotal: 1m 40s\tremaining: 1m 15s\n",
      "1141:\tlearn: 0.0052421\ttotal: 1m 40s\tremaining: 1m 15s\n",
      "1142:\tlearn: 0.0052359\ttotal: 1m 41s\tremaining: 1m 15s\n",
      "1143:\tlearn: 0.0052354\ttotal: 1m 41s\tremaining: 1m 15s\n",
      "1144:\tlearn: 0.0052341\ttotal: 1m 41s\tremaining: 1m 15s\n",
      "1145:\tlearn: 0.0052327\ttotal: 1m 41s\tremaining: 1m 15s\n",
      "1146:\tlearn: 0.0052306\ttotal: 1m 41s\tremaining: 1m 15s\n",
      "1147:\tlearn: 0.0052258\ttotal: 1m 41s\tremaining: 1m 15s\n",
      "1148:\tlearn: 0.0052232\ttotal: 1m 41s\tremaining: 1m 15s\n",
      "1149:\tlearn: 0.0052223\ttotal: 1m 41s\tremaining: 1m 15s\n",
      "1150:\tlearn: 0.0052190\ttotal: 1m 41s\tremaining: 1m 15s\n",
      "1151:\tlearn: 0.0052188\ttotal: 1m 41s\tremaining: 1m 14s\n",
      "1152:\tlearn: 0.0052104\ttotal: 1m 41s\tremaining: 1m 14s\n",
      "1153:\tlearn: 0.0052091\ttotal: 1m 41s\tremaining: 1m 14s\n",
      "1154:\tlearn: 0.0052079\ttotal: 1m 42s\tremaining: 1m 14s\n",
      "1155:\tlearn: 0.0052068\ttotal: 1m 42s\tremaining: 1m 14s\n",
      "1156:\tlearn: 0.0052043\ttotal: 1m 42s\tremaining: 1m 14s\n",
      "1157:\tlearn: 0.0052036\ttotal: 1m 42s\tremaining: 1m 14s\n",
      "1158:\tlearn: 0.0051961\ttotal: 1m 42s\tremaining: 1m 14s\n",
      "1159:\tlearn: 0.0051918\ttotal: 1m 42s\tremaining: 1m 14s\n",
      "1160:\tlearn: 0.0051877\ttotal: 1m 42s\tremaining: 1m 14s\n",
      "1161:\tlearn: 0.0051785\ttotal: 1m 42s\tremaining: 1m 14s\n",
      "1162:\tlearn: 0.0051730\ttotal: 1m 42s\tremaining: 1m 13s\n",
      "1163:\tlearn: 0.0051716\ttotal: 1m 42s\tremaining: 1m 13s\n",
      "1164:\tlearn: 0.0051683\ttotal: 1m 42s\tremaining: 1m 13s\n",
      "1165:\tlearn: 0.0051678\ttotal: 1m 43s\tremaining: 1m 13s\n",
      "1166:\tlearn: 0.0051553\ttotal: 1m 43s\tremaining: 1m 13s\n",
      "1167:\tlearn: 0.0051511\ttotal: 1m 43s\tremaining: 1m 13s\n",
      "1168:\tlearn: 0.0051492\ttotal: 1m 43s\tremaining: 1m 13s\n",
      "1169:\tlearn: 0.0051475\ttotal: 1m 43s\tremaining: 1m 13s\n",
      "1170:\tlearn: 0.0051466\ttotal: 1m 43s\tremaining: 1m 13s\n",
      "1171:\tlearn: 0.0051421\ttotal: 1m 43s\tremaining: 1m 13s\n",
      "1172:\tlearn: 0.0051402\ttotal: 1m 43s\tremaining: 1m 13s\n",
      "1173:\tlearn: 0.0051394\ttotal: 1m 43s\tremaining: 1m 12s\n",
      "1174:\tlearn: 0.0051389\ttotal: 1m 43s\tremaining: 1m 12s\n",
      "1175:\tlearn: 0.0051363\ttotal: 1m 43s\tremaining: 1m 12s\n",
      "1176:\tlearn: 0.0051312\ttotal: 1m 43s\tremaining: 1m 12s\n",
      "1177:\tlearn: 0.0051308\ttotal: 1m 44s\tremaining: 1m 12s\n",
      "1178:\tlearn: 0.0051239\ttotal: 1m 44s\tremaining: 1m 12s\n",
      "1179:\tlearn: 0.0051226\ttotal: 1m 44s\tremaining: 1m 12s\n",
      "1180:\tlearn: 0.0051217\ttotal: 1m 44s\tremaining: 1m 12s\n",
      "1181:\tlearn: 0.0051188\ttotal: 1m 44s\tremaining: 1m 12s\n",
      "1182:\tlearn: 0.0051133\ttotal: 1m 44s\tremaining: 1m 12s\n",
      "1183:\tlearn: 0.0051120\ttotal: 1m 44s\tremaining: 1m 12s\n",
      "1184:\tlearn: 0.0051073\ttotal: 1m 44s\tremaining: 1m 12s\n",
      "1185:\tlearn: 0.0051002\ttotal: 1m 44s\tremaining: 1m 11s\n",
      "1186:\tlearn: 0.0050996\ttotal: 1m 44s\tremaining: 1m 11s\n",
      "1187:\tlearn: 0.0050966\ttotal: 1m 45s\tremaining: 1m 11s\n",
      "1188:\tlearn: 0.0050956\ttotal: 1m 45s\tremaining: 1m 11s\n",
      "1189:\tlearn: 0.0050943\ttotal: 1m 45s\tremaining: 1m 11s\n",
      "1190:\tlearn: 0.0050939\ttotal: 1m 45s\tremaining: 1m 11s\n",
      "1191:\tlearn: 0.0050930\ttotal: 1m 45s\tremaining: 1m 11s\n",
      "1192:\tlearn: 0.0050925\ttotal: 1m 45s\tremaining: 1m 11s\n",
      "1193:\tlearn: 0.0050873\ttotal: 1m 45s\tremaining: 1m 11s\n",
      "1194:\tlearn: 0.0050865\ttotal: 1m 45s\tremaining: 1m 11s\n",
      "1195:\tlearn: 0.0050851\ttotal: 1m 45s\tremaining: 1m 11s\n",
      "1196:\tlearn: 0.0050825\ttotal: 1m 45s\tremaining: 1m 11s\n",
      "1197:\tlearn: 0.0050819\ttotal: 1m 46s\tremaining: 1m 10s\n",
      "1198:\tlearn: 0.0050794\ttotal: 1m 46s\tremaining: 1m 10s\n",
      "1199:\tlearn: 0.0050772\ttotal: 1m 46s\tremaining: 1m 10s\n",
      "1200:\tlearn: 0.0050641\ttotal: 1m 46s\tremaining: 1m 10s\n",
      "1201:\tlearn: 0.0050479\ttotal: 1m 46s\tremaining: 1m 10s\n",
      "1202:\tlearn: 0.0050434\ttotal: 1m 46s\tremaining: 1m 10s\n",
      "1203:\tlearn: 0.0050431\ttotal: 1m 46s\tremaining: 1m 10s\n",
      "1204:\tlearn: 0.0050419\ttotal: 1m 46s\tremaining: 1m 10s\n",
      "1205:\tlearn: 0.0050415\ttotal: 1m 46s\tremaining: 1m 10s\n",
      "1206:\tlearn: 0.0050405\ttotal: 1m 46s\tremaining: 1m 10s\n",
      "1207:\tlearn: 0.0050376\ttotal: 1m 46s\tremaining: 1m 10s\n",
      "1208:\tlearn: 0.0050333\ttotal: 1m 47s\tremaining: 1m 10s\n",
      "1209:\tlearn: 0.0050328\ttotal: 1m 47s\tremaining: 1m 9s\n",
      "1210:\tlearn: 0.0050306\ttotal: 1m 47s\tremaining: 1m 9s\n",
      "1211:\tlearn: 0.0050279\ttotal: 1m 47s\tremaining: 1m 9s\n",
      "1212:\tlearn: 0.0050215\ttotal: 1m 47s\tremaining: 1m 9s\n",
      "1213:\tlearn: 0.0050196\ttotal: 1m 47s\tremaining: 1m 9s\n",
      "1214:\tlearn: 0.0050191\ttotal: 1m 47s\tremaining: 1m 9s\n",
      "1215:\tlearn: 0.0050185\ttotal: 1m 47s\tremaining: 1m 9s\n",
      "1216:\tlearn: 0.0050168\ttotal: 1m 47s\tremaining: 1m 9s\n",
      "1217:\tlearn: 0.0050143\ttotal: 1m 47s\tremaining: 1m 9s\n",
      "1218:\tlearn: 0.0050137\ttotal: 1m 47s\tremaining: 1m 9s\n",
      "1219:\tlearn: 0.0050115\ttotal: 1m 48s\tremaining: 1m 9s\n",
      "1220:\tlearn: 0.0050089\ttotal: 1m 48s\tremaining: 1m 8s\n",
      "1221:\tlearn: 0.0050073\ttotal: 1m 48s\tremaining: 1m 8s\n",
      "1222:\tlearn: 0.0050058\ttotal: 1m 48s\tremaining: 1m 8s\n",
      "1223:\tlearn: 0.0050037\ttotal: 1m 48s\tremaining: 1m 8s\n",
      "1224:\tlearn: 0.0050029\ttotal: 1m 48s\tremaining: 1m 8s\n",
      "1225:\tlearn: 0.0049982\ttotal: 1m 48s\tremaining: 1m 8s\n",
      "1226:\tlearn: 0.0049977\ttotal: 1m 48s\tremaining: 1m 8s\n",
      "1227:\tlearn: 0.0049960\ttotal: 1m 48s\tremaining: 1m 8s\n",
      "1228:\tlearn: 0.0049942\ttotal: 1m 48s\tremaining: 1m 8s\n",
      "1229:\tlearn: 0.0049918\ttotal: 1m 48s\tremaining: 1m 8s\n",
      "1230:\tlearn: 0.0049888\ttotal: 1m 48s\tremaining: 1m 8s\n",
      "1231:\tlearn: 0.0049880\ttotal: 1m 49s\tremaining: 1m 7s\n",
      "1232:\tlearn: 0.0049865\ttotal: 1m 49s\tremaining: 1m 7s\n",
      "1233:\tlearn: 0.0049839\ttotal: 1m 49s\tremaining: 1m 7s\n",
      "1234:\tlearn: 0.0049822\ttotal: 1m 49s\tremaining: 1m 7s\n",
      "1235:\tlearn: 0.0049801\ttotal: 1m 49s\tremaining: 1m 7s\n",
      "1236:\tlearn: 0.0049764\ttotal: 1m 49s\tremaining: 1m 7s\n",
      "1237:\tlearn: 0.0049708\ttotal: 1m 49s\tremaining: 1m 7s\n",
      "1238:\tlearn: 0.0049686\ttotal: 1m 49s\tremaining: 1m 7s\n",
      "1239:\tlearn: 0.0049681\ttotal: 1m 49s\tremaining: 1m 7s\n",
      "1240:\tlearn: 0.0049663\ttotal: 1m 49s\tremaining: 1m 7s\n",
      "1241:\tlearn: 0.0049467\ttotal: 1m 49s\tremaining: 1m 7s\n",
      "1242:\tlearn: 0.0049463\ttotal: 1m 50s\tremaining: 1m 7s\n",
      "1243:\tlearn: 0.0049433\ttotal: 1m 50s\tremaining: 1m 6s\n",
      "1244:\tlearn: 0.0049318\ttotal: 1m 50s\tremaining: 1m 6s\n",
      "1245:\tlearn: 0.0049296\ttotal: 1m 50s\tremaining: 1m 6s\n",
      "1246:\tlearn: 0.0049262\ttotal: 1m 50s\tremaining: 1m 6s\n",
      "1247:\tlearn: 0.0049219\ttotal: 1m 50s\tremaining: 1m 6s\n",
      "1248:\tlearn: 0.0049210\ttotal: 1m 50s\tremaining: 1m 6s\n",
      "1249:\tlearn: 0.0049204\ttotal: 1m 50s\tremaining: 1m 6s\n",
      "1250:\tlearn: 0.0049185\ttotal: 1m 50s\tremaining: 1m 6s\n",
      "1251:\tlearn: 0.0049144\ttotal: 1m 50s\tremaining: 1m 6s\n",
      "1252:\tlearn: 0.0049103\ttotal: 1m 50s\tremaining: 1m 6s\n",
      "1253:\tlearn: 0.0049099\ttotal: 1m 51s\tremaining: 1m 6s\n",
      "1254:\tlearn: 0.0049084\ttotal: 1m 51s\tremaining: 1m 5s\n",
      "1255:\tlearn: 0.0049048\ttotal: 1m 51s\tremaining: 1m 5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1256:\tlearn: 0.0049025\ttotal: 1m 51s\tremaining: 1m 5s\n",
      "1257:\tlearn: 0.0048938\ttotal: 1m 51s\tremaining: 1m 5s\n",
      "1258:\tlearn: 0.0048924\ttotal: 1m 51s\tremaining: 1m 5s\n",
      "1259:\tlearn: 0.0048923\ttotal: 1m 51s\tremaining: 1m 5s\n",
      "1260:\tlearn: 0.0048902\ttotal: 1m 51s\tremaining: 1m 5s\n",
      "1261:\tlearn: 0.0048845\ttotal: 1m 51s\tremaining: 1m 5s\n",
      "1262:\tlearn: 0.0048818\ttotal: 1m 51s\tremaining: 1m 5s\n",
      "1263:\tlearn: 0.0048773\ttotal: 1m 51s\tremaining: 1m 5s\n",
      "1264:\tlearn: 0.0048765\ttotal: 1m 51s\tremaining: 1m 5s\n",
      "1265:\tlearn: 0.0048758\ttotal: 1m 52s\tremaining: 1m 4s\n",
      "1266:\tlearn: 0.0048699\ttotal: 1m 52s\tremaining: 1m 4s\n",
      "1267:\tlearn: 0.0048691\ttotal: 1m 52s\tremaining: 1m 4s\n",
      "1268:\tlearn: 0.0048680\ttotal: 1m 52s\tremaining: 1m 4s\n",
      "1269:\tlearn: 0.0048670\ttotal: 1m 52s\tremaining: 1m 4s\n",
      "1270:\tlearn: 0.0048665\ttotal: 1m 52s\tremaining: 1m 4s\n",
      "1271:\tlearn: 0.0048658\ttotal: 1m 52s\tremaining: 1m 4s\n",
      "1272:\tlearn: 0.0048570\ttotal: 1m 52s\tremaining: 1m 4s\n",
      "1273:\tlearn: 0.0048556\ttotal: 1m 52s\tremaining: 1m 4s\n",
      "1274:\tlearn: 0.0048534\ttotal: 1m 52s\tremaining: 1m 4s\n",
      "1275:\tlearn: 0.0048485\ttotal: 1m 52s\tremaining: 1m 4s\n",
      "1276:\tlearn: 0.0048473\ttotal: 1m 53s\tremaining: 1m 4s\n",
      "1277:\tlearn: 0.0048460\ttotal: 1m 53s\tremaining: 1m 3s\n",
      "1278:\tlearn: 0.0048454\ttotal: 1m 53s\tremaining: 1m 3s\n",
      "1279:\tlearn: 0.0048336\ttotal: 1m 53s\tremaining: 1m 3s\n",
      "1280:\tlearn: 0.0048327\ttotal: 1m 53s\tremaining: 1m 3s\n",
      "1281:\tlearn: 0.0048295\ttotal: 1m 53s\tremaining: 1m 3s\n",
      "1282:\tlearn: 0.0048230\ttotal: 1m 53s\tremaining: 1m 3s\n",
      "1283:\tlearn: 0.0048220\ttotal: 1m 53s\tremaining: 1m 3s\n",
      "1284:\tlearn: 0.0048192\ttotal: 1m 53s\tremaining: 1m 3s\n",
      "1285:\tlearn: 0.0048178\ttotal: 1m 53s\tremaining: 1m 3s\n",
      "1286:\tlearn: 0.0048093\ttotal: 1m 54s\tremaining: 1m 3s\n",
      "1287:\tlearn: 0.0048075\ttotal: 1m 54s\tremaining: 1m 3s\n",
      "1288:\tlearn: 0.0048062\ttotal: 1m 54s\tremaining: 1m 2s\n",
      "1289:\tlearn: 0.0048025\ttotal: 1m 54s\tremaining: 1m 2s\n",
      "1290:\tlearn: 0.0048020\ttotal: 1m 54s\tremaining: 1m 2s\n",
      "1291:\tlearn: 0.0048016\ttotal: 1m 54s\tremaining: 1m 2s\n",
      "1292:\tlearn: 0.0048014\ttotal: 1m 54s\tremaining: 1m 2s\n",
      "1293:\tlearn: 0.0047932\ttotal: 1m 54s\tremaining: 1m 2s\n",
      "1294:\tlearn: 0.0047899\ttotal: 1m 54s\tremaining: 1m 2s\n",
      "1295:\tlearn: 0.0047878\ttotal: 1m 54s\tremaining: 1m 2s\n",
      "1296:\tlearn: 0.0047860\ttotal: 1m 54s\tremaining: 1m 2s\n",
      "1297:\tlearn: 0.0047815\ttotal: 1m 54s\tremaining: 1m 2s\n",
      "1298:\tlearn: 0.0047805\ttotal: 1m 55s\tremaining: 1m 2s\n",
      "1299:\tlearn: 0.0047793\ttotal: 1m 55s\tremaining: 1m 2s\n",
      "1300:\tlearn: 0.0047754\ttotal: 1m 55s\tremaining: 1m 1s\n",
      "1301:\tlearn: 0.0047752\ttotal: 1m 55s\tremaining: 1m 1s\n",
      "1302:\tlearn: 0.0047742\ttotal: 1m 55s\tremaining: 1m 1s\n",
      "1303:\tlearn: 0.0047737\ttotal: 1m 55s\tremaining: 1m 1s\n",
      "1304:\tlearn: 0.0047733\ttotal: 1m 55s\tremaining: 1m 1s\n",
      "1305:\tlearn: 0.0047709\ttotal: 1m 55s\tremaining: 1m 1s\n",
      "1306:\tlearn: 0.0047694\ttotal: 1m 55s\tremaining: 1m 1s\n",
      "1307:\tlearn: 0.0047678\ttotal: 1m 55s\tremaining: 1m 1s\n",
      "1308:\tlearn: 0.0047659\ttotal: 1m 55s\tremaining: 1m 1s\n",
      "1309:\tlearn: 0.0047584\ttotal: 1m 56s\tremaining: 1m 1s\n",
      "1310:\tlearn: 0.0047536\ttotal: 1m 56s\tremaining: 1m 1s\n",
      "1311:\tlearn: 0.0047508\ttotal: 1m 56s\tremaining: 1m\n",
      "1312:\tlearn: 0.0047504\ttotal: 1m 56s\tremaining: 1m\n",
      "1313:\tlearn: 0.0047486\ttotal: 1m 56s\tremaining: 1m\n",
      "1314:\tlearn: 0.0047477\ttotal: 1m 56s\tremaining: 1m\n",
      "1315:\tlearn: 0.0047433\ttotal: 1m 56s\tremaining: 1m\n",
      "1316:\tlearn: 0.0047416\ttotal: 1m 56s\tremaining: 1m\n",
      "1317:\tlearn: 0.0047396\ttotal: 1m 56s\tremaining: 1m\n",
      "1318:\tlearn: 0.0047335\ttotal: 1m 56s\tremaining: 1m\n",
      "1319:\tlearn: 0.0047305\ttotal: 1m 56s\tremaining: 1m\n",
      "1320:\tlearn: 0.0047299\ttotal: 1m 56s\tremaining: 1m\n",
      "1321:\tlearn: 0.0047203\ttotal: 1m 57s\tremaining: 1m\n",
      "1322:\tlearn: 0.0047198\ttotal: 1m 57s\tremaining: 59.9s\n",
      "1323:\tlearn: 0.0047196\ttotal: 1m 57s\tremaining: 59.8s\n",
      "1324:\tlearn: 0.0047186\ttotal: 1m 57s\tremaining: 59.8s\n",
      "1325:\tlearn: 0.0047182\ttotal: 1m 57s\tremaining: 59.7s\n",
      "1326:\tlearn: 0.0047171\ttotal: 1m 57s\tremaining: 59.6s\n",
      "1327:\tlearn: 0.0047120\ttotal: 1m 57s\tremaining: 59.5s\n",
      "1328:\tlearn: 0.0047113\ttotal: 1m 57s\tremaining: 59.4s\n",
      "1329:\tlearn: 0.0047091\ttotal: 1m 57s\tremaining: 59.3s\n",
      "1330:\tlearn: 0.0047087\ttotal: 1m 57s\tremaining: 59.2s\n",
      "1331:\tlearn: 0.0046997\ttotal: 1m 57s\tremaining: 59.1s\n",
      "1332:\tlearn: 0.0046978\ttotal: 1m 57s\tremaining: 59s\n",
      "1333:\tlearn: 0.0046950\ttotal: 1m 58s\tremaining: 59s\n",
      "1334:\tlearn: 0.0046947\ttotal: 1m 58s\tremaining: 58.9s\n",
      "1335:\tlearn: 0.0046940\ttotal: 1m 58s\tremaining: 58.8s\n",
      "1336:\tlearn: 0.0046915\ttotal: 1m 58s\tremaining: 58.7s\n",
      "1337:\tlearn: 0.0046899\ttotal: 1m 58s\tremaining: 58.6s\n",
      "1338:\tlearn: 0.0046870\ttotal: 1m 58s\tremaining: 58.5s\n",
      "1339:\tlearn: 0.0046853\ttotal: 1m 58s\tremaining: 58.4s\n",
      "1340:\tlearn: 0.0046823\ttotal: 1m 58s\tremaining: 58.3s\n",
      "1341:\tlearn: 0.0046810\ttotal: 1m 58s\tremaining: 58.2s\n",
      "1342:\tlearn: 0.0046799\ttotal: 1m 58s\tremaining: 58.2s\n",
      "1343:\tlearn: 0.0046790\ttotal: 1m 58s\tremaining: 58.1s\n",
      "1344:\tlearn: 0.0046771\ttotal: 1m 59s\tremaining: 58s\n",
      "1345:\tlearn: 0.0046760\ttotal: 1m 59s\tremaining: 57.9s\n",
      "1346:\tlearn: 0.0046717\ttotal: 1m 59s\tremaining: 57.8s\n",
      "1347:\tlearn: 0.0046703\ttotal: 1m 59s\tremaining: 57.7s\n",
      "1348:\tlearn: 0.0046674\ttotal: 1m 59s\tremaining: 57.6s\n",
      "1349:\tlearn: 0.0046669\ttotal: 1m 59s\tremaining: 57.5s\n",
      "1350:\tlearn: 0.0046660\ttotal: 1m 59s\tremaining: 57.4s\n",
      "1351:\tlearn: 0.0046607\ttotal: 1m 59s\tremaining: 57.4s\n",
      "1352:\tlearn: 0.0046584\ttotal: 1m 59s\tremaining: 57.3s\n",
      "1353:\tlearn: 0.0046545\ttotal: 1m 59s\tremaining: 57.2s\n",
      "1354:\tlearn: 0.0046510\ttotal: 1m 59s\tremaining: 57.1s\n",
      "1355:\tlearn: 0.0046404\ttotal: 2m\tremaining: 57s\n",
      "1356:\tlearn: 0.0046316\ttotal: 2m\tremaining: 56.9s\n",
      "1357:\tlearn: 0.0046313\ttotal: 2m\tremaining: 56.8s\n",
      "1358:\tlearn: 0.0046308\ttotal: 2m\tremaining: 56.7s\n",
      "1359:\tlearn: 0.0046298\ttotal: 2m\tremaining: 56.6s\n",
      "1360:\tlearn: 0.0046282\ttotal: 2m\tremaining: 56.6s\n",
      "1361:\tlearn: 0.0046252\ttotal: 2m\tremaining: 56.5s\n",
      "1362:\tlearn: 0.0046239\ttotal: 2m\tremaining: 56.4s\n",
      "1363:\tlearn: 0.0046215\ttotal: 2m\tremaining: 56.3s\n",
      "1364:\tlearn: 0.0046213\ttotal: 2m\tremaining: 56.2s\n",
      "1365:\tlearn: 0.0046208\ttotal: 2m\tremaining: 56.1s\n",
      "1366:\tlearn: 0.0046205\ttotal: 2m\tremaining: 56s\n",
      "1367:\tlearn: 0.0046199\ttotal: 2m 1s\tremaining: 55.9s\n",
      "1368:\tlearn: 0.0046185\ttotal: 2m 1s\tremaining: 55.8s\n",
      "1369:\tlearn: 0.0046175\ttotal: 2m 1s\tremaining: 55.7s\n",
      "1370:\tlearn: 0.0046171\ttotal: 2m 1s\tremaining: 55.7s\n",
      "1371:\tlearn: 0.0046165\ttotal: 2m 1s\tremaining: 55.6s\n",
      "1372:\tlearn: 0.0046154\ttotal: 2m 1s\tremaining: 55.5s\n",
      "1373:\tlearn: 0.0046133\ttotal: 2m 1s\tremaining: 55.4s\n",
      "1374:\tlearn: 0.0046085\ttotal: 2m 1s\tremaining: 55.3s\n",
      "1375:\tlearn: 0.0045905\ttotal: 2m 1s\tremaining: 55.2s\n",
      "1376:\tlearn: 0.0045885\ttotal: 2m 1s\tremaining: 55.1s\n",
      "1377:\tlearn: 0.0045879\ttotal: 2m 1s\tremaining: 55s\n",
      "1378:\tlearn: 0.0045863\ttotal: 2m 1s\tremaining: 54.9s\n",
      "1379:\tlearn: 0.0045853\ttotal: 2m 2s\tremaining: 54.8s\n",
      "1380:\tlearn: 0.0045840\ttotal: 2m 2s\tremaining: 54.8s\n",
      "1381:\tlearn: 0.0045713\ttotal: 2m 2s\tremaining: 54.7s\n",
      "1382:\tlearn: 0.0045702\ttotal: 2m 2s\tremaining: 54.6s\n",
      "1383:\tlearn: 0.0045684\ttotal: 2m 2s\tremaining: 54.5s\n",
      "1384:\tlearn: 0.0045612\ttotal: 2m 2s\tremaining: 54.4s\n",
      "1385:\tlearn: 0.0045603\ttotal: 2m 2s\tremaining: 54.3s\n",
      "1386:\tlearn: 0.0045594\ttotal: 2m 2s\tremaining: 54.2s\n",
      "1387:\tlearn: 0.0045586\ttotal: 2m 2s\tremaining: 54.1s\n",
      "1388:\tlearn: 0.0045579\ttotal: 2m 2s\tremaining: 54.1s\n",
      "1389:\tlearn: 0.0045476\ttotal: 2m 2s\tremaining: 54s\n",
      "1390:\tlearn: 0.0045469\ttotal: 2m 3s\tremaining: 53.9s\n",
      "1391:\tlearn: 0.0045463\ttotal: 2m 3s\tremaining: 53.8s\n",
      "1392:\tlearn: 0.0045436\ttotal: 2m 3s\tremaining: 53.7s\n",
      "1393:\tlearn: 0.0045432\ttotal: 2m 3s\tremaining: 53.6s\n",
      "1394:\tlearn: 0.0045429\ttotal: 2m 3s\tremaining: 53.5s\n",
      "1395:\tlearn: 0.0045426\ttotal: 2m 3s\tremaining: 53.4s\n",
      "1396:\tlearn: 0.0045417\ttotal: 2m 3s\tremaining: 53.4s\n",
      "1397:\tlearn: 0.0045368\ttotal: 2m 3s\tremaining: 53.3s\n",
      "1398:\tlearn: 0.0045360\ttotal: 2m 3s\tremaining: 53.2s\n",
      "1399:\tlearn: 0.0045332\ttotal: 2m 3s\tremaining: 53.1s\n",
      "1400:\tlearn: 0.0045329\ttotal: 2m 3s\tremaining: 53s\n",
      "1401:\tlearn: 0.0045313\ttotal: 2m 4s\tremaining: 52.9s\n",
      "1402:\tlearn: 0.0045293\ttotal: 2m 4s\tremaining: 52.8s\n",
      "1403:\tlearn: 0.0045267\ttotal: 2m 4s\tremaining: 52.7s\n",
      "1404:\tlearn: 0.0045247\ttotal: 2m 4s\tremaining: 52.6s\n",
      "1405:\tlearn: 0.0045244\ttotal: 2m 4s\tremaining: 52.5s\n",
      "1406:\tlearn: 0.0045240\ttotal: 2m 4s\tremaining: 52.5s\n",
      "1407:\tlearn: 0.0045237\ttotal: 2m 4s\tremaining: 52.4s\n",
      "1408:\tlearn: 0.0045228\ttotal: 2m 4s\tremaining: 52.3s\n",
      "1409:\tlearn: 0.0045214\ttotal: 2m 4s\tremaining: 52.2s\n",
      "1410:\tlearn: 0.0045210\ttotal: 2m 4s\tremaining: 52.1s\n",
      "1411:\tlearn: 0.0045195\ttotal: 2m 4s\tremaining: 52s\n",
      "1412:\tlearn: 0.0045190\ttotal: 2m 4s\tremaining: 51.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1413:\tlearn: 0.0045183\ttotal: 2m 5s\tremaining: 51.8s\n",
      "1414:\tlearn: 0.0045174\ttotal: 2m 5s\tremaining: 51.7s\n",
      "1415:\tlearn: 0.0045106\ttotal: 2m 5s\tremaining: 51.6s\n",
      "1416:\tlearn: 0.0045070\ttotal: 2m 5s\tremaining: 51.6s\n",
      "1417:\tlearn: 0.0044942\ttotal: 2m 5s\tremaining: 51.5s\n",
      "1418:\tlearn: 0.0044930\ttotal: 2m 5s\tremaining: 51.4s\n",
      "1419:\tlearn: 0.0044922\ttotal: 2m 5s\tremaining: 51.3s\n",
      "1420:\tlearn: 0.0044907\ttotal: 2m 5s\tremaining: 51.2s\n",
      "1421:\tlearn: 0.0044893\ttotal: 2m 5s\tremaining: 51.1s\n",
      "1422:\tlearn: 0.0044878\ttotal: 2m 5s\tremaining: 51s\n",
      "1423:\tlearn: 0.0044866\ttotal: 2m 5s\tremaining: 50.9s\n",
      "1424:\tlearn: 0.0044858\ttotal: 2m 5s\tremaining: 50.8s\n",
      "1425:\tlearn: 0.0044828\ttotal: 2m 6s\tremaining: 50.8s\n",
      "1426:\tlearn: 0.0044813\ttotal: 2m 6s\tremaining: 50.7s\n",
      "1427:\tlearn: 0.0044784\ttotal: 2m 6s\tremaining: 50.6s\n",
      "1428:\tlearn: 0.0044720\ttotal: 2m 6s\tremaining: 50.5s\n",
      "1429:\tlearn: 0.0044683\ttotal: 2m 6s\tremaining: 50.4s\n",
      "1430:\tlearn: 0.0044564\ttotal: 2m 6s\tremaining: 50.3s\n",
      "1431:\tlearn: 0.0044562\ttotal: 2m 6s\tremaining: 50.2s\n",
      "1432:\tlearn: 0.0044556\ttotal: 2m 6s\tremaining: 50.1s\n",
      "1433:\tlearn: 0.0044528\ttotal: 2m 6s\tremaining: 50s\n",
      "1434:\tlearn: 0.0044490\ttotal: 2m 6s\tremaining: 50s\n",
      "1435:\tlearn: 0.0044462\ttotal: 2m 6s\tremaining: 49.9s\n",
      "1436:\tlearn: 0.0044455\ttotal: 2m 7s\tremaining: 49.8s\n",
      "1437:\tlearn: 0.0044446\ttotal: 2m 7s\tremaining: 49.7s\n",
      "1438:\tlearn: 0.0044437\ttotal: 2m 7s\tremaining: 49.6s\n",
      "1439:\tlearn: 0.0044425\ttotal: 2m 7s\tremaining: 49.5s\n",
      "1440:\tlearn: 0.0044406\ttotal: 2m 7s\tremaining: 49.4s\n",
      "1441:\tlearn: 0.0044345\ttotal: 2m 7s\tremaining: 49.3s\n",
      "1442:\tlearn: 0.0044334\ttotal: 2m 7s\tremaining: 49.2s\n",
      "1443:\tlearn: 0.0044319\ttotal: 2m 7s\tremaining: 49.2s\n",
      "1444:\tlearn: 0.0044311\ttotal: 2m 7s\tremaining: 49.1s\n",
      "1445:\tlearn: 0.0044286\ttotal: 2m 7s\tremaining: 49s\n",
      "1446:\tlearn: 0.0044252\ttotal: 2m 7s\tremaining: 48.9s\n",
      "1447:\tlearn: 0.0044219\ttotal: 2m 7s\tremaining: 48.8s\n",
      "1448:\tlearn: 0.0044213\ttotal: 2m 8s\tremaining: 48.7s\n",
      "1449:\tlearn: 0.0044153\ttotal: 2m 8s\tremaining: 48.6s\n",
      "1450:\tlearn: 0.0044053\ttotal: 2m 8s\tremaining: 48.5s\n",
      "1451:\tlearn: 0.0044015\ttotal: 2m 8s\tremaining: 48.4s\n",
      "1452:\tlearn: 0.0043972\ttotal: 2m 8s\tremaining: 48.4s\n",
      "1453:\tlearn: 0.0043970\ttotal: 2m 8s\tremaining: 48.3s\n",
      "1454:\tlearn: 0.0043949\ttotal: 2m 8s\tremaining: 48.2s\n",
      "1455:\tlearn: 0.0043942\ttotal: 2m 8s\tremaining: 48.1s\n",
      "1456:\tlearn: 0.0043932\ttotal: 2m 8s\tremaining: 48s\n",
      "1457:\tlearn: 0.0043866\ttotal: 2m 8s\tremaining: 47.9s\n",
      "1458:\tlearn: 0.0043844\ttotal: 2m 8s\tremaining: 47.8s\n",
      "1459:\tlearn: 0.0043840\ttotal: 2m 9s\tremaining: 47.7s\n",
      "1460:\tlearn: 0.0043838\ttotal: 2m 9s\tremaining: 47.6s\n",
      "1461:\tlearn: 0.0043802\ttotal: 2m 9s\tremaining: 47.6s\n",
      "1462:\tlearn: 0.0043776\ttotal: 2m 9s\tremaining: 47.5s\n",
      "1463:\tlearn: 0.0043728\ttotal: 2m 9s\tremaining: 47.4s\n",
      "1464:\tlearn: 0.0043709\ttotal: 2m 9s\tremaining: 47.3s\n",
      "1465:\tlearn: 0.0043636\ttotal: 2m 9s\tremaining: 47.2s\n",
      "1466:\tlearn: 0.0043614\ttotal: 2m 9s\tremaining: 47.1s\n",
      "1467:\tlearn: 0.0043604\ttotal: 2m 9s\tremaining: 47s\n",
      "1468:\tlearn: 0.0043525\ttotal: 2m 9s\tremaining: 46.9s\n",
      "1469:\tlearn: 0.0043516\ttotal: 2m 9s\tremaining: 46.8s\n",
      "1470:\tlearn: 0.0043505\ttotal: 2m 9s\tremaining: 46.7s\n",
      "1471:\tlearn: 0.0043453\ttotal: 2m 10s\tremaining: 46.7s\n",
      "1472:\tlearn: 0.0043418\ttotal: 2m 10s\tremaining: 46.6s\n",
      "1473:\tlearn: 0.0043416\ttotal: 2m 10s\tremaining: 46.5s\n",
      "1474:\tlearn: 0.0043248\ttotal: 2m 10s\tremaining: 46.4s\n",
      "1475:\tlearn: 0.0043181\ttotal: 2m 10s\tremaining: 46.3s\n",
      "1476:\tlearn: 0.0043176\ttotal: 2m 10s\tremaining: 46.2s\n",
      "1477:\tlearn: 0.0043148\ttotal: 2m 10s\tremaining: 46.1s\n",
      "1478:\tlearn: 0.0043131\ttotal: 2m 10s\tremaining: 46s\n",
      "1479:\tlearn: 0.0043128\ttotal: 2m 10s\tremaining: 45.9s\n",
      "1480:\tlearn: 0.0043118\ttotal: 2m 10s\tremaining: 45.9s\n",
      "1481:\tlearn: 0.0043085\ttotal: 2m 10s\tremaining: 45.8s\n",
      "1482:\tlearn: 0.0043082\ttotal: 2m 11s\tremaining: 45.7s\n",
      "1483:\tlearn: 0.0043031\ttotal: 2m 11s\tremaining: 45.6s\n",
      "1484:\tlearn: 0.0043021\ttotal: 2m 11s\tremaining: 45.5s\n",
      "1485:\tlearn: 0.0042989\ttotal: 2m 11s\tremaining: 45.4s\n",
      "1486:\tlearn: 0.0042969\ttotal: 2m 11s\tremaining: 45.3s\n",
      "1487:\tlearn: 0.0042964\ttotal: 2m 11s\tremaining: 45.2s\n",
      "1488:\tlearn: 0.0042959\ttotal: 2m 11s\tremaining: 45.1s\n",
      "1489:\tlearn: 0.0042944\ttotal: 2m 11s\tremaining: 45.1s\n",
      "1490:\tlearn: 0.0042938\ttotal: 2m 11s\tremaining: 45s\n",
      "1491:\tlearn: 0.0042869\ttotal: 2m 11s\tremaining: 44.9s\n",
      "1492:\tlearn: 0.0042856\ttotal: 2m 11s\tremaining: 44.8s\n",
      "1493:\tlearn: 0.0042773\ttotal: 2m 11s\tremaining: 44.7s\n",
      "1494:\tlearn: 0.0042749\ttotal: 2m 12s\tremaining: 44.6s\n",
      "1495:\tlearn: 0.0042715\ttotal: 2m 12s\tremaining: 44.5s\n",
      "1496:\tlearn: 0.0042697\ttotal: 2m 12s\tremaining: 44.4s\n",
      "1497:\tlearn: 0.0042685\ttotal: 2m 12s\tremaining: 44.3s\n",
      "1498:\tlearn: 0.0042651\ttotal: 2m 12s\tremaining: 44.3s\n",
      "1499:\tlearn: 0.0042638\ttotal: 2m 12s\tremaining: 44.2s\n",
      "1500:\tlearn: 0.0042598\ttotal: 2m 12s\tremaining: 44.1s\n",
      "1501:\tlearn: 0.0042589\ttotal: 2m 12s\tremaining: 44s\n",
      "1502:\tlearn: 0.0042588\ttotal: 2m 12s\tremaining: 43.9s\n",
      "1503:\tlearn: 0.0042587\ttotal: 2m 12s\tremaining: 43.8s\n",
      "1504:\tlearn: 0.0042552\ttotal: 2m 12s\tremaining: 43.7s\n",
      "1505:\tlearn: 0.0042543\ttotal: 2m 13s\tremaining: 43.6s\n",
      "1506:\tlearn: 0.0042536\ttotal: 2m 13s\tremaining: 43.5s\n",
      "1507:\tlearn: 0.0042449\ttotal: 2m 13s\tremaining: 43.5s\n",
      "1508:\tlearn: 0.0042447\ttotal: 2m 13s\tremaining: 43.4s\n",
      "1509:\tlearn: 0.0042438\ttotal: 2m 13s\tremaining: 43.3s\n",
      "1510:\tlearn: 0.0042437\ttotal: 2m 13s\tremaining: 43.2s\n",
      "1511:\tlearn: 0.0042425\ttotal: 2m 13s\tremaining: 43.1s\n",
      "1512:\tlearn: 0.0042417\ttotal: 2m 13s\tremaining: 43s\n",
      "1513:\tlearn: 0.0042398\ttotal: 2m 13s\tremaining: 42.9s\n",
      "1514:\tlearn: 0.0042389\ttotal: 2m 13s\tremaining: 42.8s\n",
      "1515:\tlearn: 0.0042384\ttotal: 2m 13s\tremaining: 42.7s\n",
      "1516:\tlearn: 0.0042379\ttotal: 2m 14s\tremaining: 42.7s\n",
      "1517:\tlearn: 0.0042235\ttotal: 2m 14s\tremaining: 42.6s\n",
      "1518:\tlearn: 0.0042222\ttotal: 2m 14s\tremaining: 42.5s\n",
      "1519:\tlearn: 0.0042216\ttotal: 2m 14s\tremaining: 42.4s\n",
      "1520:\tlearn: 0.0042172\ttotal: 2m 14s\tremaining: 42.3s\n",
      "1521:\tlearn: 0.0042150\ttotal: 2m 14s\tremaining: 42.2s\n",
      "1522:\tlearn: 0.0042142\ttotal: 2m 14s\tremaining: 42.1s\n",
      "1523:\tlearn: 0.0042120\ttotal: 2m 14s\tremaining: 42.1s\n",
      "1524:\tlearn: 0.0042116\ttotal: 2m 14s\tremaining: 42s\n",
      "1525:\tlearn: 0.0042097\ttotal: 2m 15s\tremaining: 41.9s\n",
      "1526:\tlearn: 0.0042093\ttotal: 2m 15s\tremaining: 41.9s\n",
      "1527:\tlearn: 0.0042051\ttotal: 2m 15s\tremaining: 41.8s\n",
      "1528:\tlearn: 0.0042042\ttotal: 2m 15s\tremaining: 41.7s\n",
      "1529:\tlearn: 0.0042040\ttotal: 2m 15s\tremaining: 41.6s\n",
      "1530:\tlearn: 0.0042025\ttotal: 2m 15s\tremaining: 41.6s\n",
      "1531:\tlearn: 0.0042003\ttotal: 2m 15s\tremaining: 41.5s\n",
      "1532:\tlearn: 0.0041961\ttotal: 2m 15s\tremaining: 41.4s\n",
      "1533:\tlearn: 0.0041917\ttotal: 2m 15s\tremaining: 41.3s\n",
      "1534:\tlearn: 0.0041908\ttotal: 2m 16s\tremaining: 41.2s\n",
      "1535:\tlearn: 0.0041892\ttotal: 2m 16s\tremaining: 41.1s\n",
      "1536:\tlearn: 0.0041880\ttotal: 2m 16s\tremaining: 41s\n",
      "1537:\tlearn: 0.0041862\ttotal: 2m 16s\tremaining: 40.9s\n",
      "1538:\tlearn: 0.0041841\ttotal: 2m 16s\tremaining: 40.9s\n",
      "1539:\tlearn: 0.0041794\ttotal: 2m 16s\tremaining: 40.8s\n",
      "1540:\tlearn: 0.0041715\ttotal: 2m 16s\tremaining: 40.7s\n",
      "1541:\tlearn: 0.0041669\ttotal: 2m 16s\tremaining: 40.6s\n",
      "1542:\tlearn: 0.0041567\ttotal: 2m 16s\tremaining: 40.5s\n",
      "1543:\tlearn: 0.0041557\ttotal: 2m 16s\tremaining: 40.4s\n",
      "1544:\tlearn: 0.0041555\ttotal: 2m 16s\tremaining: 40.3s\n",
      "1545:\tlearn: 0.0041533\ttotal: 2m 17s\tremaining: 40.2s\n",
      "1546:\tlearn: 0.0041523\ttotal: 2m 17s\tremaining: 40.1s\n",
      "1547:\tlearn: 0.0041517\ttotal: 2m 17s\tremaining: 40.1s\n",
      "1548:\tlearn: 0.0041510\ttotal: 2m 17s\tremaining: 40s\n",
      "1549:\tlearn: 0.0041499\ttotal: 2m 17s\tremaining: 39.9s\n",
      "1550:\tlearn: 0.0041474\ttotal: 2m 17s\tremaining: 39.8s\n",
      "1551:\tlearn: 0.0041431\ttotal: 2m 17s\tremaining: 39.7s\n",
      "1552:\tlearn: 0.0041419\ttotal: 2m 17s\tremaining: 39.6s\n",
      "1553:\tlearn: 0.0041402\ttotal: 2m 17s\tremaining: 39.5s\n",
      "1554:\tlearn: 0.0041395\ttotal: 2m 17s\tremaining: 39.4s\n",
      "1555:\tlearn: 0.0041361\ttotal: 2m 17s\tremaining: 39.3s\n",
      "1556:\tlearn: 0.0041360\ttotal: 2m 17s\tremaining: 39.3s\n",
      "1557:\tlearn: 0.0041338\ttotal: 2m 18s\tremaining: 39.2s\n",
      "1558:\tlearn: 0.0041327\ttotal: 2m 18s\tremaining: 39.1s\n",
      "1559:\tlearn: 0.0041324\ttotal: 2m 18s\tremaining: 39s\n",
      "1560:\tlearn: 0.0041311\ttotal: 2m 18s\tremaining: 38.9s\n",
      "1561:\tlearn: 0.0041274\ttotal: 2m 18s\tremaining: 38.8s\n",
      "1562:\tlearn: 0.0041257\ttotal: 2m 18s\tremaining: 38.7s\n",
      "1563:\tlearn: 0.0041255\ttotal: 2m 18s\tremaining: 38.6s\n",
      "1564:\tlearn: 0.0041214\ttotal: 2m 18s\tremaining: 38.5s\n",
      "1565:\tlearn: 0.0041154\ttotal: 2m 18s\tremaining: 38.5s\n",
      "1566:\tlearn: 0.0041141\ttotal: 2m 18s\tremaining: 38.4s\n",
      "1567:\tlearn: 0.0041135\ttotal: 2m 18s\tremaining: 38.3s\n",
      "1568:\tlearn: 0.0041133\ttotal: 2m 19s\tremaining: 38.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1569:\tlearn: 0.0041104\ttotal: 2m 19s\tremaining: 38.1s\n",
      "1570:\tlearn: 0.0041097\ttotal: 2m 19s\tremaining: 38s\n",
      "1571:\tlearn: 0.0041089\ttotal: 2m 19s\tremaining: 37.9s\n",
      "1572:\tlearn: 0.0041078\ttotal: 2m 19s\tremaining: 37.8s\n",
      "1573:\tlearn: 0.0041032\ttotal: 2m 19s\tremaining: 37.7s\n",
      "1574:\tlearn: 0.0040984\ttotal: 2m 19s\tremaining: 37.7s\n",
      "1575:\tlearn: 0.0040982\ttotal: 2m 19s\tremaining: 37.6s\n",
      "1576:\tlearn: 0.0040968\ttotal: 2m 19s\tremaining: 37.5s\n",
      "1577:\tlearn: 0.0040955\ttotal: 2m 19s\tremaining: 37.4s\n",
      "1578:\tlearn: 0.0040879\ttotal: 2m 19s\tremaining: 37.3s\n",
      "1579:\tlearn: 0.0040877\ttotal: 2m 19s\tremaining: 37.2s\n",
      "1580:\tlearn: 0.0040877\ttotal: 2m 20s\tremaining: 37.1s\n",
      "1581:\tlearn: 0.0040873\ttotal: 2m 20s\tremaining: 37s\n",
      "1582:\tlearn: 0.0040830\ttotal: 2m 20s\tremaining: 36.9s\n",
      "1583:\tlearn: 0.0040822\ttotal: 2m 20s\tremaining: 36.8s\n",
      "1584:\tlearn: 0.0040802\ttotal: 2m 20s\tremaining: 36.8s\n",
      "1585:\tlearn: 0.0040772\ttotal: 2m 20s\tremaining: 36.7s\n",
      "1586:\tlearn: 0.0040747\ttotal: 2m 20s\tremaining: 36.6s\n",
      "1587:\tlearn: 0.0040744\ttotal: 2m 20s\tremaining: 36.5s\n",
      "1588:\tlearn: 0.0040687\ttotal: 2m 20s\tremaining: 36.4s\n",
      "1589:\tlearn: 0.0040671\ttotal: 2m 20s\tremaining: 36.3s\n",
      "1590:\tlearn: 0.0040665\ttotal: 2m 20s\tremaining: 36.2s\n",
      "1591:\tlearn: 0.0040651\ttotal: 2m 21s\tremaining: 36.1s\n",
      "1592:\tlearn: 0.0040647\ttotal: 2m 21s\tremaining: 36s\n",
      "1593:\tlearn: 0.0040645\ttotal: 2m 21s\tremaining: 36s\n",
      "1594:\tlearn: 0.0040623\ttotal: 2m 21s\tremaining: 35.9s\n",
      "1595:\tlearn: 0.0040618\ttotal: 2m 21s\tremaining: 35.8s\n",
      "1596:\tlearn: 0.0040614\ttotal: 2m 21s\tremaining: 35.7s\n",
      "1597:\tlearn: 0.0040571\ttotal: 2m 21s\tremaining: 35.6s\n",
      "1598:\tlearn: 0.0040560\ttotal: 2m 21s\tremaining: 35.5s\n",
      "1599:\tlearn: 0.0040518\ttotal: 2m 21s\tremaining: 35.4s\n",
      "1600:\tlearn: 0.0040506\ttotal: 2m 21s\tremaining: 35.3s\n",
      "1601:\tlearn: 0.0040379\ttotal: 2m 21s\tremaining: 35.2s\n",
      "1602:\tlearn: 0.0040368\ttotal: 2m 21s\tremaining: 35.2s\n",
      "1603:\tlearn: 0.0040364\ttotal: 2m 22s\tremaining: 35.1s\n",
      "1604:\tlearn: 0.0040354\ttotal: 2m 22s\tremaining: 35s\n",
      "1605:\tlearn: 0.0040337\ttotal: 2m 22s\tremaining: 34.9s\n",
      "1606:\tlearn: 0.0040327\ttotal: 2m 22s\tremaining: 34.8s\n",
      "1607:\tlearn: 0.0040326\ttotal: 2m 22s\tremaining: 34.7s\n",
      "1608:\tlearn: 0.0040322\ttotal: 2m 22s\tremaining: 34.6s\n",
      "1609:\tlearn: 0.0040321\ttotal: 2m 22s\tremaining: 34.5s\n",
      "1610:\tlearn: 0.0040315\ttotal: 2m 22s\tremaining: 34.4s\n",
      "1611:\tlearn: 0.0040294\ttotal: 2m 22s\tremaining: 34.3s\n",
      "1612:\tlearn: 0.0040236\ttotal: 2m 22s\tremaining: 34.3s\n",
      "1613:\tlearn: 0.0040234\ttotal: 2m 22s\tremaining: 34.2s\n",
      "1614:\tlearn: 0.0040227\ttotal: 2m 22s\tremaining: 34.1s\n",
      "1615:\tlearn: 0.0040224\ttotal: 2m 23s\tremaining: 34s\n",
      "1616:\tlearn: 0.0040203\ttotal: 2m 23s\tremaining: 33.9s\n",
      "1617:\tlearn: 0.0040158\ttotal: 2m 23s\tremaining: 33.8s\n",
      "1618:\tlearn: 0.0040155\ttotal: 2m 23s\tremaining: 33.7s\n",
      "1619:\tlearn: 0.0040147\ttotal: 2m 23s\tremaining: 33.6s\n",
      "1620:\tlearn: 0.0040116\ttotal: 2m 23s\tremaining: 33.5s\n",
      "1621:\tlearn: 0.0040064\ttotal: 2m 23s\tremaining: 33.5s\n",
      "1622:\tlearn: 0.0039984\ttotal: 2m 23s\tremaining: 33.4s\n",
      "1623:\tlearn: 0.0039976\ttotal: 2m 23s\tremaining: 33.3s\n",
      "1624:\tlearn: 0.0039967\ttotal: 2m 23s\tremaining: 33.2s\n",
      "1625:\tlearn: 0.0039961\ttotal: 2m 23s\tremaining: 33.1s\n",
      "1626:\tlearn: 0.0039935\ttotal: 2m 24s\tremaining: 33s\n",
      "1627:\tlearn: 0.0039867\ttotal: 2m 24s\tremaining: 32.9s\n",
      "1628:\tlearn: 0.0039841\ttotal: 2m 24s\tremaining: 32.8s\n",
      "1629:\tlearn: 0.0039814\ttotal: 2m 24s\tremaining: 32.7s\n",
      "1630:\tlearn: 0.0039811\ttotal: 2m 24s\tremaining: 32.7s\n",
      "1631:\tlearn: 0.0039712\ttotal: 2m 24s\tremaining: 32.6s\n",
      "1632:\tlearn: 0.0039698\ttotal: 2m 24s\tremaining: 32.5s\n",
      "1633:\tlearn: 0.0039687\ttotal: 2m 24s\tremaining: 32.4s\n",
      "1634:\tlearn: 0.0039669\ttotal: 2m 24s\tremaining: 32.3s\n",
      "1635:\tlearn: 0.0039665\ttotal: 2m 24s\tremaining: 32.2s\n",
      "1636:\tlearn: 0.0039598\ttotal: 2m 24s\tremaining: 32.1s\n",
      "1637:\tlearn: 0.0039572\ttotal: 2m 24s\tremaining: 32s\n",
      "1638:\tlearn: 0.0039554\ttotal: 2m 25s\tremaining: 32s\n",
      "1639:\tlearn: 0.0039549\ttotal: 2m 25s\tremaining: 31.9s\n",
      "1640:\tlearn: 0.0039530\ttotal: 2m 25s\tremaining: 31.8s\n",
      "1641:\tlearn: 0.0039473\ttotal: 2m 25s\tremaining: 31.7s\n",
      "1642:\tlearn: 0.0039459\ttotal: 2m 25s\tremaining: 31.6s\n",
      "1643:\tlearn: 0.0039454\ttotal: 2m 25s\tremaining: 31.5s\n",
      "1644:\tlearn: 0.0039433\ttotal: 2m 25s\tremaining: 31.4s\n",
      "1645:\tlearn: 0.0039425\ttotal: 2m 25s\tremaining: 31.3s\n",
      "1646:\tlearn: 0.0039415\ttotal: 2m 25s\tremaining: 31.2s\n",
      "1647:\tlearn: 0.0039390\ttotal: 2m 25s\tremaining: 31.2s\n",
      "1648:\tlearn: 0.0039388\ttotal: 2m 25s\tremaining: 31.1s\n",
      "1649:\tlearn: 0.0039373\ttotal: 2m 26s\tremaining: 31s\n",
      "1650:\tlearn: 0.0039369\ttotal: 2m 26s\tremaining: 30.9s\n",
      "1651:\tlearn: 0.0039367\ttotal: 2m 26s\tremaining: 30.8s\n",
      "1652:\tlearn: 0.0039346\ttotal: 2m 26s\tremaining: 30.7s\n",
      "1653:\tlearn: 0.0039323\ttotal: 2m 26s\tremaining: 30.6s\n",
      "1654:\tlearn: 0.0039309\ttotal: 2m 26s\tremaining: 30.5s\n",
      "1655:\tlearn: 0.0039303\ttotal: 2m 26s\tremaining: 30.4s\n",
      "1656:\tlearn: 0.0039278\ttotal: 2m 26s\tremaining: 30.4s\n",
      "1657:\tlearn: 0.0039276\ttotal: 2m 26s\tremaining: 30.3s\n",
      "1658:\tlearn: 0.0039230\ttotal: 2m 26s\tremaining: 30.2s\n",
      "1659:\tlearn: 0.0039190\ttotal: 2m 26s\tremaining: 30.1s\n",
      "1660:\tlearn: 0.0039186\ttotal: 2m 26s\tremaining: 30s\n",
      "1661:\tlearn: 0.0039158\ttotal: 2m 27s\tremaining: 29.9s\n",
      "1662:\tlearn: 0.0039154\ttotal: 2m 27s\tremaining: 29.8s\n",
      "1663:\tlearn: 0.0039152\ttotal: 2m 27s\tremaining: 29.7s\n",
      "1664:\tlearn: 0.0039109\ttotal: 2m 27s\tremaining: 29.6s\n",
      "1665:\tlearn: 0.0039104\ttotal: 2m 27s\tremaining: 29.6s\n",
      "1666:\tlearn: 0.0039094\ttotal: 2m 27s\tremaining: 29.5s\n",
      "1667:\tlearn: 0.0039044\ttotal: 2m 27s\tremaining: 29.4s\n",
      "1668:\tlearn: 0.0039038\ttotal: 2m 27s\tremaining: 29.3s\n",
      "1669:\tlearn: 0.0039036\ttotal: 2m 27s\tremaining: 29.2s\n",
      "1670:\tlearn: 0.0039032\ttotal: 2m 27s\tremaining: 29.1s\n",
      "1671:\tlearn: 0.0039021\ttotal: 2m 27s\tremaining: 29s\n",
      "1672:\tlearn: 0.0039002\ttotal: 2m 28s\tremaining: 28.9s\n",
      "1673:\tlearn: 0.0038986\ttotal: 2m 28s\tremaining: 28.8s\n",
      "1674:\tlearn: 0.0038965\ttotal: 2m 28s\tremaining: 28.8s\n",
      "1675:\tlearn: 0.0038929\ttotal: 2m 28s\tremaining: 28.7s\n",
      "1676:\tlearn: 0.0038864\ttotal: 2m 28s\tremaining: 28.6s\n",
      "1677:\tlearn: 0.0038860\ttotal: 2m 28s\tremaining: 28.5s\n",
      "1678:\tlearn: 0.0038848\ttotal: 2m 28s\tremaining: 28.4s\n",
      "1679:\tlearn: 0.0038841\ttotal: 2m 28s\tremaining: 28.3s\n",
      "1680:\tlearn: 0.0038795\ttotal: 2m 28s\tremaining: 28.2s\n",
      "1681:\tlearn: 0.0038785\ttotal: 2m 28s\tremaining: 28.1s\n",
      "1682:\tlearn: 0.0038775\ttotal: 2m 28s\tremaining: 28s\n",
      "1683:\tlearn: 0.0038751\ttotal: 2m 29s\tremaining: 28s\n",
      "1684:\tlearn: 0.0038657\ttotal: 2m 29s\tremaining: 27.9s\n",
      "1685:\tlearn: 0.0038633\ttotal: 2m 29s\tremaining: 27.8s\n",
      "1686:\tlearn: 0.0038620\ttotal: 2m 29s\tremaining: 27.7s\n",
      "1687:\tlearn: 0.0038608\ttotal: 2m 29s\tremaining: 27.6s\n",
      "1688:\tlearn: 0.0038590\ttotal: 2m 29s\tremaining: 27.5s\n",
      "1689:\tlearn: 0.0038588\ttotal: 2m 29s\tremaining: 27.4s\n",
      "1690:\tlearn: 0.0038586\ttotal: 2m 29s\tremaining: 27.3s\n",
      "1691:\tlearn: 0.0038583\ttotal: 2m 29s\tremaining: 27.2s\n",
      "1692:\tlearn: 0.0038539\ttotal: 2m 29s\tremaining: 27.2s\n",
      "1693:\tlearn: 0.0038538\ttotal: 2m 29s\tremaining: 27.1s\n",
      "1694:\tlearn: 0.0038501\ttotal: 2m 29s\tremaining: 27s\n",
      "1695:\tlearn: 0.0038483\ttotal: 2m 30s\tremaining: 26.9s\n",
      "1696:\tlearn: 0.0038479\ttotal: 2m 30s\tremaining: 26.8s\n",
      "1697:\tlearn: 0.0038430\ttotal: 2m 30s\tremaining: 26.7s\n",
      "1698:\tlearn: 0.0038421\ttotal: 2m 30s\tremaining: 26.6s\n",
      "1699:\tlearn: 0.0038402\ttotal: 2m 30s\tremaining: 26.5s\n",
      "1700:\tlearn: 0.0038382\ttotal: 2m 30s\tremaining: 26.4s\n",
      "1701:\tlearn: 0.0038381\ttotal: 2m 30s\tremaining: 26.4s\n",
      "1702:\tlearn: 0.0038352\ttotal: 2m 30s\tremaining: 26.3s\n",
      "1703:\tlearn: 0.0038331\ttotal: 2m 30s\tremaining: 26.2s\n",
      "1704:\tlearn: 0.0038330\ttotal: 2m 30s\tremaining: 26.1s\n",
      "1705:\tlearn: 0.0038313\ttotal: 2m 30s\tremaining: 26s\n",
      "1706:\tlearn: 0.0038302\ttotal: 2m 30s\tremaining: 25.9s\n",
      "1707:\tlearn: 0.0038288\ttotal: 2m 31s\tremaining: 25.8s\n",
      "1708:\tlearn: 0.0038287\ttotal: 2m 31s\tremaining: 25.7s\n",
      "1709:\tlearn: 0.0038249\ttotal: 2m 31s\tremaining: 25.7s\n",
      "1710:\tlearn: 0.0038237\ttotal: 2m 31s\tremaining: 25.6s\n",
      "1711:\tlearn: 0.0038207\ttotal: 2m 31s\tremaining: 25.5s\n",
      "1712:\tlearn: 0.0038170\ttotal: 2m 31s\tremaining: 25.4s\n",
      "1713:\tlearn: 0.0038166\ttotal: 2m 31s\tremaining: 25.3s\n",
      "1714:\tlearn: 0.0038146\ttotal: 2m 31s\tremaining: 25.2s\n",
      "1715:\tlearn: 0.0038136\ttotal: 2m 31s\tremaining: 25.1s\n",
      "1716:\tlearn: 0.0038130\ttotal: 2m 31s\tremaining: 25s\n",
      "1717:\tlearn: 0.0038126\ttotal: 2m 31s\tremaining: 24.9s\n",
      "1718:\tlearn: 0.0038002\ttotal: 2m 32s\tremaining: 24.9s\n",
      "1719:\tlearn: 0.0037995\ttotal: 2m 32s\tremaining: 24.8s\n",
      "1720:\tlearn: 0.0037991\ttotal: 2m 32s\tremaining: 24.7s\n",
      "1721:\tlearn: 0.0037973\ttotal: 2m 32s\tremaining: 24.6s\n",
      "1722:\tlearn: 0.0037957\ttotal: 2m 32s\tremaining: 24.5s\n",
      "1723:\tlearn: 0.0037948\ttotal: 2m 32s\tremaining: 24.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1724:\tlearn: 0.0037945\ttotal: 2m 32s\tremaining: 24.3s\n",
      "1725:\tlearn: 0.0037927\ttotal: 2m 32s\tremaining: 24.2s\n",
      "1726:\tlearn: 0.0037900\ttotal: 2m 32s\tremaining: 24.1s\n",
      "1727:\tlearn: 0.0037895\ttotal: 2m 32s\tremaining: 24.1s\n",
      "1728:\tlearn: 0.0037894\ttotal: 2m 32s\tremaining: 24s\n",
      "1729:\tlearn: 0.0037860\ttotal: 2m 33s\tremaining: 23.9s\n",
      "1730:\tlearn: 0.0037846\ttotal: 2m 33s\tremaining: 23.8s\n",
      "1731:\tlearn: 0.0037820\ttotal: 2m 33s\tremaining: 23.7s\n",
      "1732:\tlearn: 0.0037815\ttotal: 2m 33s\tremaining: 23.6s\n",
      "1733:\tlearn: 0.0037787\ttotal: 2m 33s\tremaining: 23.5s\n",
      "1734:\tlearn: 0.0037777\ttotal: 2m 33s\tremaining: 23.4s\n",
      "1735:\tlearn: 0.0037775\ttotal: 2m 33s\tremaining: 23.3s\n",
      "1736:\tlearn: 0.0037771\ttotal: 2m 33s\tremaining: 23.3s\n",
      "1737:\tlearn: 0.0037770\ttotal: 2m 33s\tremaining: 23.2s\n",
      "1738:\tlearn: 0.0037763\ttotal: 2m 33s\tremaining: 23.1s\n",
      "1739:\tlearn: 0.0037738\ttotal: 2m 33s\tremaining: 23s\n",
      "1740:\tlearn: 0.0037729\ttotal: 2m 33s\tremaining: 22.9s\n",
      "1741:\tlearn: 0.0037647\ttotal: 2m 34s\tremaining: 22.8s\n",
      "1742:\tlearn: 0.0037645\ttotal: 2m 34s\tremaining: 22.7s\n",
      "1743:\tlearn: 0.0037612\ttotal: 2m 34s\tremaining: 22.6s\n",
      "1744:\tlearn: 0.0037575\ttotal: 2m 34s\tremaining: 22.5s\n",
      "1745:\tlearn: 0.0037536\ttotal: 2m 34s\tremaining: 22.5s\n",
      "1746:\tlearn: 0.0037523\ttotal: 2m 34s\tremaining: 22.4s\n",
      "1747:\tlearn: 0.0037519\ttotal: 2m 34s\tremaining: 22.3s\n",
      "1748:\tlearn: 0.0037491\ttotal: 2m 34s\tremaining: 22.2s\n",
      "1749:\tlearn: 0.0037479\ttotal: 2m 34s\tremaining: 22.1s\n",
      "1750:\tlearn: 0.0037435\ttotal: 2m 34s\tremaining: 22s\n",
      "1751:\tlearn: 0.0037433\ttotal: 2m 34s\tremaining: 21.9s\n",
      "1752:\tlearn: 0.0037379\ttotal: 2m 35s\tremaining: 21.8s\n",
      "1753:\tlearn: 0.0037366\ttotal: 2m 35s\tremaining: 21.8s\n",
      "1754:\tlearn: 0.0037348\ttotal: 2m 35s\tremaining: 21.7s\n",
      "1755:\tlearn: 0.0037344\ttotal: 2m 35s\tremaining: 21.6s\n",
      "1756:\tlearn: 0.0037214\ttotal: 2m 35s\tremaining: 21.5s\n",
      "1757:\tlearn: 0.0037161\ttotal: 2m 35s\tremaining: 21.4s\n",
      "1758:\tlearn: 0.0037150\ttotal: 2m 35s\tremaining: 21.3s\n",
      "1759:\tlearn: 0.0037141\ttotal: 2m 35s\tremaining: 21.2s\n",
      "1760:\tlearn: 0.0037086\ttotal: 2m 35s\tremaining: 21.1s\n",
      "1761:\tlearn: 0.0037078\ttotal: 2m 35s\tremaining: 21s\n",
      "1762:\tlearn: 0.0037061\ttotal: 2m 35s\tremaining: 21s\n",
      "1763:\tlearn: 0.0037048\ttotal: 2m 35s\tremaining: 20.9s\n",
      "1764:\tlearn: 0.0037045\ttotal: 2m 36s\tremaining: 20.8s\n",
      "1765:\tlearn: 0.0036979\ttotal: 2m 36s\tremaining: 20.7s\n",
      "1766:\tlearn: 0.0036925\ttotal: 2m 36s\tremaining: 20.6s\n",
      "1767:\tlearn: 0.0036923\ttotal: 2m 36s\tremaining: 20.5s\n",
      "1768:\tlearn: 0.0036920\ttotal: 2m 36s\tremaining: 20.4s\n",
      "1769:\tlearn: 0.0036917\ttotal: 2m 36s\tremaining: 20.3s\n",
      "1770:\tlearn: 0.0036910\ttotal: 2m 36s\tremaining: 20.2s\n",
      "1771:\tlearn: 0.0036910\ttotal: 2m 36s\tremaining: 20.2s\n",
      "1772:\tlearn: 0.0036884\ttotal: 2m 36s\tremaining: 20.1s\n",
      "1773:\tlearn: 0.0036872\ttotal: 2m 36s\tremaining: 20s\n",
      "1774:\tlearn: 0.0036842\ttotal: 2m 36s\tremaining: 19.9s\n",
      "1775:\tlearn: 0.0036810\ttotal: 2m 37s\tremaining: 19.8s\n",
      "1776:\tlearn: 0.0036797\ttotal: 2m 37s\tremaining: 19.7s\n",
      "1777:\tlearn: 0.0036759\ttotal: 2m 37s\tremaining: 19.6s\n",
      "1778:\tlearn: 0.0036755\ttotal: 2m 37s\tremaining: 19.5s\n",
      "1779:\tlearn: 0.0036754\ttotal: 2m 37s\tremaining: 19.4s\n",
      "1780:\tlearn: 0.0036743\ttotal: 2m 37s\tremaining: 19.4s\n",
      "1781:\tlearn: 0.0036739\ttotal: 2m 37s\tremaining: 19.3s\n",
      "1782:\tlearn: 0.0036733\ttotal: 2m 37s\tremaining: 19.2s\n",
      "1783:\tlearn: 0.0036721\ttotal: 2m 37s\tremaining: 19.1s\n",
      "1784:\tlearn: 0.0036697\ttotal: 2m 37s\tremaining: 19s\n",
      "1785:\tlearn: 0.0036692\ttotal: 2m 37s\tremaining: 18.9s\n",
      "1786:\tlearn: 0.0036660\ttotal: 2m 37s\tremaining: 18.8s\n",
      "1787:\tlearn: 0.0036650\ttotal: 2m 38s\tremaining: 18.7s\n",
      "1788:\tlearn: 0.0036636\ttotal: 2m 38s\tremaining: 18.6s\n",
      "1789:\tlearn: 0.0036603\ttotal: 2m 38s\tremaining: 18.6s\n",
      "1790:\tlearn: 0.0036596\ttotal: 2m 38s\tremaining: 18.5s\n",
      "1791:\tlearn: 0.0036583\ttotal: 2m 38s\tremaining: 18.4s\n",
      "1792:\tlearn: 0.0036569\ttotal: 2m 38s\tremaining: 18.3s\n",
      "1793:\tlearn: 0.0036557\ttotal: 2m 38s\tremaining: 18.2s\n",
      "1794:\tlearn: 0.0036554\ttotal: 2m 38s\tremaining: 18.1s\n",
      "1795:\tlearn: 0.0036544\ttotal: 2m 38s\tremaining: 18s\n",
      "1796:\tlearn: 0.0036543\ttotal: 2m 38s\tremaining: 17.9s\n",
      "1797:\tlearn: 0.0036541\ttotal: 2m 38s\tremaining: 17.9s\n",
      "1798:\tlearn: 0.0036540\ttotal: 2m 38s\tremaining: 17.8s\n",
      "1799:\tlearn: 0.0036512\ttotal: 2m 39s\tremaining: 17.7s\n",
      "1800:\tlearn: 0.0036512\ttotal: 2m 39s\tremaining: 17.6s\n",
      "1801:\tlearn: 0.0036508\ttotal: 2m 39s\tremaining: 17.5s\n",
      "1802:\tlearn: 0.0036503\ttotal: 2m 39s\tremaining: 17.4s\n",
      "1803:\tlearn: 0.0036500\ttotal: 2m 39s\tremaining: 17.3s\n",
      "1804:\tlearn: 0.0036493\ttotal: 2m 39s\tremaining: 17.2s\n",
      "1805:\tlearn: 0.0036492\ttotal: 2m 39s\tremaining: 17.1s\n",
      "1806:\tlearn: 0.0036485\ttotal: 2m 39s\tremaining: 17.1s\n",
      "1807:\tlearn: 0.0036435\ttotal: 2m 39s\tremaining: 17s\n",
      "1808:\tlearn: 0.0036401\ttotal: 2m 39s\tremaining: 16.9s\n",
      "1809:\tlearn: 0.0036390\ttotal: 2m 39s\tremaining: 16.8s\n",
      "1810:\tlearn: 0.0036332\ttotal: 2m 40s\tremaining: 16.7s\n",
      "1811:\tlearn: 0.0036307\ttotal: 2m 40s\tremaining: 16.6s\n",
      "1812:\tlearn: 0.0036289\ttotal: 2m 40s\tremaining: 16.5s\n",
      "1813:\tlearn: 0.0036282\ttotal: 2m 40s\tremaining: 16.4s\n",
      "1814:\tlearn: 0.0036243\ttotal: 2m 40s\tremaining: 16.3s\n",
      "1815:\tlearn: 0.0036242\ttotal: 2m 40s\tremaining: 16.3s\n",
      "1816:\tlearn: 0.0036240\ttotal: 2m 40s\tremaining: 16.2s\n",
      "1817:\tlearn: 0.0036198\ttotal: 2m 40s\tremaining: 16.1s\n",
      "1818:\tlearn: 0.0036186\ttotal: 2m 40s\tremaining: 16s\n",
      "1819:\tlearn: 0.0036143\ttotal: 2m 40s\tremaining: 15.9s\n",
      "1820:\tlearn: 0.0036141\ttotal: 2m 40s\tremaining: 15.8s\n",
      "1821:\tlearn: 0.0036122\ttotal: 2m 40s\tremaining: 15.7s\n",
      "1822:\tlearn: 0.0036111\ttotal: 2m 41s\tremaining: 15.6s\n",
      "1823:\tlearn: 0.0036105\ttotal: 2m 41s\tremaining: 15.5s\n",
      "1824:\tlearn: 0.0036062\ttotal: 2m 41s\tremaining: 15.5s\n",
      "1825:\tlearn: 0.0036023\ttotal: 2m 41s\tremaining: 15.4s\n",
      "1826:\tlearn: 0.0035995\ttotal: 2m 41s\tremaining: 15.3s\n",
      "1827:\tlearn: 0.0035992\ttotal: 2m 41s\tremaining: 15.2s\n",
      "1828:\tlearn: 0.0035991\ttotal: 2m 41s\tremaining: 15.1s\n",
      "1829:\tlearn: 0.0035969\ttotal: 2m 41s\tremaining: 15s\n",
      "1830:\tlearn: 0.0035960\ttotal: 2m 41s\tremaining: 14.9s\n",
      "1831:\tlearn: 0.0035916\ttotal: 2m 41s\tremaining: 14.8s\n",
      "1832:\tlearn: 0.0035908\ttotal: 2m 41s\tremaining: 14.8s\n",
      "1833:\tlearn: 0.0035907\ttotal: 2m 42s\tremaining: 14.7s\n",
      "1834:\tlearn: 0.0035906\ttotal: 2m 42s\tremaining: 14.6s\n",
      "1835:\tlearn: 0.0035889\ttotal: 2m 42s\tremaining: 14.5s\n",
      "1836:\tlearn: 0.0035888\ttotal: 2m 42s\tremaining: 14.4s\n",
      "1837:\tlearn: 0.0035886\ttotal: 2m 42s\tremaining: 14.3s\n",
      "1838:\tlearn: 0.0035884\ttotal: 2m 42s\tremaining: 14.2s\n",
      "1839:\tlearn: 0.0035881\ttotal: 2m 42s\tremaining: 14.1s\n",
      "1840:\tlearn: 0.0035873\ttotal: 2m 42s\tremaining: 14s\n",
      "1841:\tlearn: 0.0035871\ttotal: 2m 42s\tremaining: 14s\n",
      "1842:\tlearn: 0.0035860\ttotal: 2m 42s\tremaining: 13.9s\n",
      "1843:\tlearn: 0.0035841\ttotal: 2m 42s\tremaining: 13.8s\n",
      "1844:\tlearn: 0.0035837\ttotal: 2m 42s\tremaining: 13.7s\n",
      "1845:\tlearn: 0.0035818\ttotal: 2m 43s\tremaining: 13.6s\n",
      "1846:\tlearn: 0.0035799\ttotal: 2m 43s\tremaining: 13.5s\n",
      "1847:\tlearn: 0.0035786\ttotal: 2m 43s\tremaining: 13.4s\n",
      "1848:\tlearn: 0.0035783\ttotal: 2m 43s\tremaining: 13.3s\n",
      "1849:\tlearn: 0.0035782\ttotal: 2m 43s\tremaining: 13.2s\n",
      "1850:\tlearn: 0.0035771\ttotal: 2m 43s\tremaining: 13.2s\n",
      "1851:\tlearn: 0.0035757\ttotal: 2m 43s\tremaining: 13.1s\n",
      "1852:\tlearn: 0.0035756\ttotal: 2m 43s\tremaining: 13s\n",
      "1853:\tlearn: 0.0035734\ttotal: 2m 43s\tremaining: 12.9s\n",
      "1854:\tlearn: 0.0035732\ttotal: 2m 43s\tremaining: 12.8s\n",
      "1855:\tlearn: 0.0035702\ttotal: 2m 43s\tremaining: 12.7s\n",
      "1856:\tlearn: 0.0035686\ttotal: 2m 44s\tremaining: 12.6s\n",
      "1857:\tlearn: 0.0035662\ttotal: 2m 44s\tremaining: 12.5s\n",
      "1858:\tlearn: 0.0035654\ttotal: 2m 44s\tremaining: 12.5s\n",
      "1859:\tlearn: 0.0035630\ttotal: 2m 44s\tremaining: 12.4s\n",
      "1860:\tlearn: 0.0035628\ttotal: 2m 44s\tremaining: 12.3s\n",
      "1861:\tlearn: 0.0035619\ttotal: 2m 44s\tremaining: 12.2s\n",
      "1862:\tlearn: 0.0035616\ttotal: 2m 44s\tremaining: 12.1s\n",
      "1863:\tlearn: 0.0035583\ttotal: 2m 44s\tremaining: 12s\n",
      "1864:\tlearn: 0.0035568\ttotal: 2m 44s\tremaining: 11.9s\n",
      "1865:\tlearn: 0.0035567\ttotal: 2m 44s\tremaining: 11.8s\n",
      "1866:\tlearn: 0.0035550\ttotal: 2m 44s\tremaining: 11.7s\n",
      "1867:\tlearn: 0.0035548\ttotal: 2m 44s\tremaining: 11.7s\n",
      "1868:\tlearn: 0.0035528\ttotal: 2m 45s\tremaining: 11.6s\n",
      "1869:\tlearn: 0.0035525\ttotal: 2m 45s\tremaining: 11.5s\n",
      "1870:\tlearn: 0.0035521\ttotal: 2m 45s\tremaining: 11.4s\n",
      "1871:\tlearn: 0.0035517\ttotal: 2m 45s\tremaining: 11.3s\n",
      "1872:\tlearn: 0.0035516\ttotal: 2m 45s\tremaining: 11.2s\n",
      "1873:\tlearn: 0.0035506\ttotal: 2m 45s\tremaining: 11.1s\n",
      "1874:\tlearn: 0.0035496\ttotal: 2m 45s\tremaining: 11s\n",
      "1875:\tlearn: 0.0035495\ttotal: 2m 45s\tremaining: 10.9s\n",
      "1876:\tlearn: 0.0035494\ttotal: 2m 45s\tremaining: 10.9s\n",
      "1877:\tlearn: 0.0035485\ttotal: 2m 45s\tremaining: 10.8s\n",
      "1878:\tlearn: 0.0035440\ttotal: 2m 45s\tremaining: 10.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1879:\tlearn: 0.0035432\ttotal: 2m 46s\tremaining: 10.6s\n",
      "1880:\tlearn: 0.0035425\ttotal: 2m 46s\tremaining: 10.5s\n",
      "1881:\tlearn: 0.0035416\ttotal: 2m 46s\tremaining: 10.4s\n",
      "1882:\tlearn: 0.0035412\ttotal: 2m 46s\tremaining: 10.3s\n",
      "1883:\tlearn: 0.0035411\ttotal: 2m 46s\tremaining: 10.2s\n",
      "1884:\tlearn: 0.0035395\ttotal: 2m 46s\tremaining: 10.2s\n",
      "1885:\tlearn: 0.0035393\ttotal: 2m 46s\tremaining: 10.1s\n",
      "1886:\tlearn: 0.0035371\ttotal: 2m 46s\tremaining: 9.98s\n",
      "1887:\tlearn: 0.0035368\ttotal: 2m 46s\tremaining: 9.89s\n",
      "1888:\tlearn: 0.0035365\ttotal: 2m 46s\tremaining: 9.8s\n",
      "1889:\tlearn: 0.0035351\ttotal: 2m 46s\tremaining: 9.71s\n",
      "1890:\tlearn: 0.0035348\ttotal: 2m 46s\tremaining: 9.62s\n",
      "1891:\tlearn: 0.0035286\ttotal: 2m 47s\tremaining: 9.54s\n",
      "1892:\tlearn: 0.0035282\ttotal: 2m 47s\tremaining: 9.45s\n",
      "1893:\tlearn: 0.0035281\ttotal: 2m 47s\tremaining: 9.36s\n",
      "1894:\tlearn: 0.0035270\ttotal: 2m 47s\tremaining: 9.27s\n",
      "1895:\tlearn: 0.0035259\ttotal: 2m 47s\tremaining: 9.18s\n",
      "1896:\tlearn: 0.0035254\ttotal: 2m 47s\tremaining: 9.09s\n",
      "1897:\tlearn: 0.0035252\ttotal: 2m 47s\tremaining: 9s\n",
      "1898:\tlearn: 0.0035252\ttotal: 2m 47s\tremaining: 8.91s\n",
      "1899:\tlearn: 0.0035243\ttotal: 2m 47s\tremaining: 8.83s\n",
      "1900:\tlearn: 0.0035241\ttotal: 2m 47s\tremaining: 8.74s\n",
      "1901:\tlearn: 0.0035216\ttotal: 2m 47s\tremaining: 8.65s\n",
      "1902:\tlearn: 0.0035181\ttotal: 2m 47s\tremaining: 8.56s\n",
      "1903:\tlearn: 0.0035160\ttotal: 2m 48s\tremaining: 8.47s\n",
      "1904:\tlearn: 0.0035152\ttotal: 2m 48s\tremaining: 8.38s\n",
      "1905:\tlearn: 0.0035150\ttotal: 2m 48s\tremaining: 8.29s\n",
      "1906:\tlearn: 0.0035142\ttotal: 2m 48s\tremaining: 8.21s\n",
      "1907:\tlearn: 0.0035125\ttotal: 2m 48s\tremaining: 8.12s\n",
      "1908:\tlearn: 0.0035123\ttotal: 2m 48s\tremaining: 8.03s\n",
      "1909:\tlearn: 0.0035122\ttotal: 2m 48s\tremaining: 7.94s\n",
      "1910:\tlearn: 0.0035078\ttotal: 2m 48s\tremaining: 7.85s\n",
      "1911:\tlearn: 0.0035077\ttotal: 2m 48s\tremaining: 7.76s\n",
      "1912:\tlearn: 0.0035059\ttotal: 2m 48s\tremaining: 7.68s\n",
      "1913:\tlearn: 0.0035053\ttotal: 2m 48s\tremaining: 7.59s\n",
      "1914:\tlearn: 0.0035041\ttotal: 2m 48s\tremaining: 7.5s\n",
      "1915:\tlearn: 0.0035033\ttotal: 2m 49s\tremaining: 7.41s\n",
      "1916:\tlearn: 0.0035032\ttotal: 2m 49s\tremaining: 7.32s\n",
      "1917:\tlearn: 0.0035000\ttotal: 2m 49s\tremaining: 7.24s\n",
      "1918:\tlearn: 0.0034990\ttotal: 2m 49s\tremaining: 7.15s\n",
      "1919:\tlearn: 0.0034989\ttotal: 2m 49s\tremaining: 7.06s\n",
      "1920:\tlearn: 0.0034944\ttotal: 2m 49s\tremaining: 6.97s\n",
      "1921:\tlearn: 0.0034941\ttotal: 2m 49s\tremaining: 6.88s\n",
      "1922:\tlearn: 0.0034935\ttotal: 2m 49s\tremaining: 6.79s\n",
      "1923:\tlearn: 0.0034924\ttotal: 2m 49s\tremaining: 6.71s\n",
      "1924:\tlearn: 0.0034915\ttotal: 2m 49s\tremaining: 6.62s\n",
      "1925:\tlearn: 0.0034908\ttotal: 2m 49s\tremaining: 6.53s\n",
      "1926:\tlearn: 0.0034905\ttotal: 2m 50s\tremaining: 6.44s\n",
      "1927:\tlearn: 0.0034898\ttotal: 2m 50s\tremaining: 6.35s\n",
      "1928:\tlearn: 0.0034895\ttotal: 2m 50s\tremaining: 6.26s\n",
      "1929:\tlearn: 0.0034891\ttotal: 2m 50s\tremaining: 6.17s\n",
      "1930:\tlearn: 0.0034886\ttotal: 2m 50s\tremaining: 6.09s\n",
      "1931:\tlearn: 0.0034844\ttotal: 2m 50s\tremaining: 6s\n",
      "1932:\tlearn: 0.0034816\ttotal: 2m 50s\tremaining: 5.91s\n",
      "1933:\tlearn: 0.0034809\ttotal: 2m 50s\tremaining: 5.82s\n",
      "1934:\tlearn: 0.0034756\ttotal: 2m 50s\tremaining: 5.73s\n",
      "1935:\tlearn: 0.0034752\ttotal: 2m 50s\tremaining: 5.64s\n",
      "1936:\tlearn: 0.0034749\ttotal: 2m 50s\tremaining: 5.56s\n",
      "1937:\tlearn: 0.0034746\ttotal: 2m 50s\tremaining: 5.47s\n",
      "1938:\tlearn: 0.0034745\ttotal: 2m 51s\tremaining: 5.38s\n",
      "1939:\tlearn: 0.0034730\ttotal: 2m 51s\tremaining: 5.29s\n",
      "1940:\tlearn: 0.0034675\ttotal: 2m 51s\tremaining: 5.2s\n",
      "1941:\tlearn: 0.0034673\ttotal: 2m 51s\tremaining: 5.12s\n",
      "1942:\tlearn: 0.0034668\ttotal: 2m 51s\tremaining: 5.03s\n",
      "1943:\tlearn: 0.0034667\ttotal: 2m 51s\tremaining: 4.94s\n",
      "1944:\tlearn: 0.0034656\ttotal: 2m 51s\tremaining: 4.85s\n",
      "1945:\tlearn: 0.0034634\ttotal: 2m 51s\tremaining: 4.76s\n",
      "1946:\tlearn: 0.0034628\ttotal: 2m 51s\tremaining: 4.67s\n",
      "1947:\tlearn: 0.0034582\ttotal: 2m 51s\tremaining: 4.58s\n",
      "1948:\tlearn: 0.0034578\ttotal: 2m 51s\tremaining: 4.5s\n",
      "1949:\tlearn: 0.0034575\ttotal: 2m 51s\tremaining: 4.41s\n",
      "1950:\tlearn: 0.0034532\ttotal: 2m 52s\tremaining: 4.32s\n",
      "1951:\tlearn: 0.0034521\ttotal: 2m 52s\tremaining: 4.23s\n",
      "1952:\tlearn: 0.0034514\ttotal: 2m 52s\tremaining: 4.14s\n",
      "1953:\tlearn: 0.0034514\ttotal: 2m 52s\tremaining: 4.06s\n",
      "1954:\tlearn: 0.0034499\ttotal: 2m 52s\tremaining: 3.97s\n",
      "1955:\tlearn: 0.0034484\ttotal: 2m 52s\tremaining: 3.88s\n",
      "1956:\tlearn: 0.0034470\ttotal: 2m 52s\tremaining: 3.79s\n",
      "1957:\tlearn: 0.0034460\ttotal: 2m 52s\tremaining: 3.7s\n",
      "1958:\tlearn: 0.0034380\ttotal: 2m 52s\tremaining: 3.62s\n",
      "1959:\tlearn: 0.0034379\ttotal: 2m 52s\tremaining: 3.53s\n",
      "1960:\tlearn: 0.0034378\ttotal: 2m 52s\tremaining: 3.44s\n",
      "1961:\tlearn: 0.0034373\ttotal: 2m 53s\tremaining: 3.35s\n",
      "1962:\tlearn: 0.0034346\ttotal: 2m 53s\tremaining: 3.26s\n",
      "1963:\tlearn: 0.0034338\ttotal: 2m 53s\tremaining: 3.17s\n",
      "1964:\tlearn: 0.0034337\ttotal: 2m 53s\tremaining: 3.09s\n",
      "1965:\tlearn: 0.0034332\ttotal: 2m 53s\tremaining: 3s\n",
      "1966:\tlearn: 0.0034324\ttotal: 2m 53s\tremaining: 2.91s\n",
      "1967:\tlearn: 0.0034321\ttotal: 2m 53s\tremaining: 2.82s\n",
      "1968:\tlearn: 0.0034310\ttotal: 2m 53s\tremaining: 2.73s\n",
      "1969:\tlearn: 0.0034291\ttotal: 2m 53s\tremaining: 2.65s\n",
      "1970:\tlearn: 0.0034254\ttotal: 2m 53s\tremaining: 2.56s\n",
      "1971:\tlearn: 0.0034239\ttotal: 2m 53s\tremaining: 2.47s\n",
      "1972:\tlearn: 0.0034231\ttotal: 2m 53s\tremaining: 2.38s\n",
      "1973:\tlearn: 0.0034228\ttotal: 2m 54s\tremaining: 2.29s\n",
      "1974:\tlearn: 0.0034221\ttotal: 2m 54s\tremaining: 2.2s\n",
      "1975:\tlearn: 0.0034201\ttotal: 2m 54s\tremaining: 2.12s\n",
      "1976:\tlearn: 0.0034177\ttotal: 2m 54s\tremaining: 2.03s\n",
      "1977:\tlearn: 0.0034173\ttotal: 2m 54s\tremaining: 1.94s\n",
      "1978:\tlearn: 0.0034142\ttotal: 2m 54s\tremaining: 1.85s\n",
      "1979:\tlearn: 0.0034139\ttotal: 2m 54s\tremaining: 1.76s\n",
      "1980:\tlearn: 0.0034100\ttotal: 2m 54s\tremaining: 1.67s\n",
      "1981:\tlearn: 0.0034098\ttotal: 2m 54s\tremaining: 1.59s\n",
      "1982:\tlearn: 0.0034095\ttotal: 2m 54s\tremaining: 1.5s\n",
      "1983:\tlearn: 0.0034090\ttotal: 2m 54s\tremaining: 1.41s\n",
      "1984:\tlearn: 0.0034087\ttotal: 2m 54s\tremaining: 1.32s\n",
      "1985:\tlearn: 0.0034048\ttotal: 2m 55s\tremaining: 1.23s\n",
      "1986:\tlearn: 0.0034039\ttotal: 2m 55s\tremaining: 1.15s\n",
      "1987:\tlearn: 0.0034015\ttotal: 2m 55s\tremaining: 1.06s\n",
      "1988:\tlearn: 0.0034008\ttotal: 2m 55s\tremaining: 969ms\n",
      "1989:\tlearn: 0.0034008\ttotal: 2m 55s\tremaining: 881ms\n",
      "1990:\tlearn: 0.0033998\ttotal: 2m 55s\tremaining: 793ms\n",
      "1991:\tlearn: 0.0033987\ttotal: 2m 55s\tremaining: 705ms\n",
      "1992:\tlearn: 0.0033942\ttotal: 2m 55s\tremaining: 617ms\n",
      "1993:\tlearn: 0.0033932\ttotal: 2m 55s\tremaining: 529ms\n",
      "1994:\tlearn: 0.0033925\ttotal: 2m 55s\tremaining: 441ms\n",
      "1995:\tlearn: 0.0033921\ttotal: 2m 55s\tremaining: 353ms\n",
      "1996:\tlearn: 0.0033897\ttotal: 2m 55s\tremaining: 264ms\n",
      "1997:\tlearn: 0.0033892\ttotal: 2m 56s\tremaining: 176ms\n",
      "1998:\tlearn: 0.0033858\ttotal: 2m 56s\tremaining: 88.1ms\n",
      "1999:\tlearn: 0.0033822\ttotal: 2m 56s\tremaining: 0us\n",
      "Learning rate set to 0.031656\n",
      "0:\tlearn: 0.6107556\ttotal: 131ms\tremaining: 4m 20s\n",
      "1:\tlearn: 0.5450170\ttotal: 231ms\tremaining: 3m 50s\n",
      "2:\tlearn: 0.4703932\ttotal: 331ms\tremaining: 3m 40s\n",
      "3:\tlearn: 0.4177674\ttotal: 438ms\tremaining: 3m 38s\n",
      "4:\tlearn: 0.3779128\ttotal: 539ms\tremaining: 3m 34s\n",
      "5:\tlearn: 0.3328453\ttotal: 652ms\tremaining: 3m 36s\n",
      "6:\tlearn: 0.3067899\ttotal: 794ms\tremaining: 3m 46s\n",
      "7:\tlearn: 0.2834134\ttotal: 904ms\tremaining: 3m 45s\n",
      "8:\tlearn: 0.2620900\ttotal: 1.02s\tremaining: 3m 46s\n",
      "9:\tlearn: 0.2450895\ttotal: 1.13s\tremaining: 3m 44s\n",
      "10:\tlearn: 0.2213902\ttotal: 1.24s\tremaining: 3m 43s\n",
      "11:\tlearn: 0.2072903\ttotal: 1.35s\tremaining: 3m 44s\n",
      "12:\tlearn: 0.1924715\ttotal: 1.47s\tremaining: 3m 44s\n",
      "13:\tlearn: 0.1736495\ttotal: 1.58s\tremaining: 3m 44s\n",
      "14:\tlearn: 0.1651931\ttotal: 1.68s\tremaining: 3m 42s\n",
      "15:\tlearn: 0.1570172\ttotal: 1.79s\tremaining: 3m 42s\n",
      "16:\tlearn: 0.1502749\ttotal: 1.9s\tremaining: 3m 41s\n",
      "17:\tlearn: 0.1431460\ttotal: 2.02s\tremaining: 3m 41s\n",
      "18:\tlearn: 0.1362858\ttotal: 2.13s\tremaining: 3m 41s\n",
      "19:\tlearn: 0.1292166\ttotal: 2.23s\tremaining: 3m 41s\n",
      "20:\tlearn: 0.1237355\ttotal: 2.32s\tremaining: 3m 38s\n",
      "21:\tlearn: 0.1186711\ttotal: 2.43s\tremaining: 3m 38s\n",
      "22:\tlearn: 0.1133164\ttotal: 2.55s\tremaining: 3m 39s\n",
      "23:\tlearn: 0.1080350\ttotal: 2.66s\tremaining: 3m 38s\n",
      "24:\tlearn: 0.1032201\ttotal: 2.75s\tremaining: 3m 37s\n",
      "25:\tlearn: 0.0976709\ttotal: 2.92s\tremaining: 3m 41s\n",
      "26:\tlearn: 0.0951523\ttotal: 3.04s\tremaining: 3m 41s\n",
      "27:\tlearn: 0.0905642\ttotal: 3.15s\tremaining: 3m 41s\n",
      "28:\tlearn: 0.0867694\ttotal: 3.25s\tremaining: 3m 41s\n",
      "29:\tlearn: 0.0847731\ttotal: 3.37s\tremaining: 3m 41s\n",
      "30:\tlearn: 0.0821186\ttotal: 3.49s\tremaining: 3m 41s\n",
      "31:\tlearn: 0.0795952\ttotal: 3.61s\tremaining: 3m 42s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32:\tlearn: 0.0764629\ttotal: 3.72s\tremaining: 3m 41s\n",
      "33:\tlearn: 0.0747598\ttotal: 3.84s\tremaining: 3m 42s\n",
      "34:\tlearn: 0.0723530\ttotal: 3.94s\tremaining: 3m 41s\n",
      "35:\tlearn: 0.0707113\ttotal: 4.05s\tremaining: 3m 41s\n",
      "36:\tlearn: 0.0688064\ttotal: 4.16s\tremaining: 3m 40s\n",
      "37:\tlearn: 0.0667817\ttotal: 4.26s\tremaining: 3m 39s\n",
      "38:\tlearn: 0.0651012\ttotal: 4.36s\tremaining: 3m 39s\n",
      "39:\tlearn: 0.0639295\ttotal: 4.45s\tremaining: 3m 38s\n",
      "40:\tlearn: 0.0625794\ttotal: 4.55s\tremaining: 3m 37s\n",
      "41:\tlearn: 0.0612018\ttotal: 4.65s\tremaining: 3m 36s\n",
      "42:\tlearn: 0.0599264\ttotal: 4.75s\tremaining: 3m 36s\n",
      "43:\tlearn: 0.0588515\ttotal: 4.85s\tremaining: 3m 35s\n",
      "44:\tlearn: 0.0576249\ttotal: 4.96s\tremaining: 3m 35s\n",
      "45:\tlearn: 0.0563313\ttotal: 5.07s\tremaining: 3m 35s\n",
      "46:\tlearn: 0.0553038\ttotal: 5.16s\tremaining: 3m 34s\n",
      "47:\tlearn: 0.0538617\ttotal: 5.26s\tremaining: 3m 34s\n",
      "48:\tlearn: 0.0528743\ttotal: 5.35s\tremaining: 3m 32s\n",
      "49:\tlearn: 0.0516075\ttotal: 5.46s\tremaining: 3m 32s\n",
      "50:\tlearn: 0.0510254\ttotal: 5.54s\tremaining: 3m 31s\n",
      "51:\tlearn: 0.0500353\ttotal: 5.63s\tremaining: 3m 30s\n",
      "52:\tlearn: 0.0492852\ttotal: 5.73s\tremaining: 3m 30s\n",
      "53:\tlearn: 0.0483883\ttotal: 5.82s\tremaining: 3m 29s\n",
      "54:\tlearn: 0.0477177\ttotal: 5.9s\tremaining: 3m 28s\n",
      "55:\tlearn: 0.0471526\ttotal: 6.01s\tremaining: 3m 28s\n",
      "56:\tlearn: 0.0464321\ttotal: 6.1s\tremaining: 3m 27s\n",
      "57:\tlearn: 0.0456586\ttotal: 6.19s\tremaining: 3m 27s\n",
      "58:\tlearn: 0.0447996\ttotal: 6.3s\tremaining: 3m 27s\n",
      "59:\tlearn: 0.0439710\ttotal: 6.39s\tremaining: 3m 26s\n",
      "60:\tlearn: 0.0434693\ttotal: 6.49s\tremaining: 3m 26s\n",
      "61:\tlearn: 0.0431628\ttotal: 6.57s\tremaining: 3m 25s\n",
      "62:\tlearn: 0.0424962\ttotal: 6.67s\tremaining: 3m 24s\n",
      "63:\tlearn: 0.0421510\ttotal: 6.75s\tremaining: 3m 24s\n",
      "64:\tlearn: 0.0415789\ttotal: 6.83s\tremaining: 3m 23s\n",
      "65:\tlearn: 0.0409428\ttotal: 6.93s\tremaining: 3m 23s\n",
      "66:\tlearn: 0.0403926\ttotal: 7.03s\tremaining: 3m 22s\n",
      "67:\tlearn: 0.0398939\ttotal: 7.12s\tremaining: 3m 22s\n",
      "68:\tlearn: 0.0394990\ttotal: 7.23s\tremaining: 3m 22s\n",
      "69:\tlearn: 0.0390692\ttotal: 7.33s\tremaining: 3m 22s\n",
      "70:\tlearn: 0.0386375\ttotal: 7.43s\tremaining: 3m 21s\n",
      "71:\tlearn: 0.0382624\ttotal: 7.52s\tremaining: 3m 21s\n",
      "72:\tlearn: 0.0376606\ttotal: 7.63s\tremaining: 3m 21s\n",
      "73:\tlearn: 0.0371629\ttotal: 7.72s\tremaining: 3m 21s\n",
      "74:\tlearn: 0.0370055\ttotal: 7.81s\tremaining: 3m 20s\n",
      "75:\tlearn: 0.0364329\ttotal: 7.91s\tremaining: 3m 20s\n",
      "76:\tlearn: 0.0360802\ttotal: 8.01s\tremaining: 3m 20s\n",
      "77:\tlearn: 0.0356009\ttotal: 8.11s\tremaining: 3m 19s\n",
      "78:\tlearn: 0.0353335\ttotal: 8.2s\tremaining: 3m 19s\n",
      "79:\tlearn: 0.0350325\ttotal: 8.29s\tremaining: 3m 18s\n",
      "80:\tlearn: 0.0346564\ttotal: 8.38s\tremaining: 3m 18s\n",
      "81:\tlearn: 0.0343426\ttotal: 8.49s\tremaining: 3m 18s\n",
      "82:\tlearn: 0.0341447\ttotal: 8.56s\tremaining: 3m 17s\n",
      "83:\tlearn: 0.0337522\ttotal: 8.67s\tremaining: 3m 17s\n",
      "84:\tlearn: 0.0334595\ttotal: 8.75s\tremaining: 3m 17s\n",
      "85:\tlearn: 0.0331274\ttotal: 8.85s\tremaining: 3m 17s\n",
      "86:\tlearn: 0.0329183\ttotal: 8.95s\tremaining: 3m 16s\n",
      "87:\tlearn: 0.0325680\ttotal: 9.05s\tremaining: 3m 16s\n",
      "88:\tlearn: 0.0323096\ttotal: 9.14s\tremaining: 3m 16s\n",
      "89:\tlearn: 0.0321772\ttotal: 9.22s\tremaining: 3m 15s\n",
      "90:\tlearn: 0.0317351\ttotal: 9.31s\tremaining: 3m 15s\n",
      "91:\tlearn: 0.0314807\ttotal: 9.42s\tremaining: 3m 15s\n",
      "92:\tlearn: 0.0312709\ttotal: 9.52s\tremaining: 3m 15s\n",
      "93:\tlearn: 0.0310521\ttotal: 9.61s\tremaining: 3m 14s\n",
      "94:\tlearn: 0.0308514\ttotal: 9.7s\tremaining: 3m 14s\n",
      "95:\tlearn: 0.0307268\ttotal: 9.77s\tremaining: 3m 13s\n",
      "96:\tlearn: 0.0301998\ttotal: 9.89s\tremaining: 3m 13s\n",
      "97:\tlearn: 0.0297331\ttotal: 9.98s\tremaining: 3m 13s\n",
      "98:\tlearn: 0.0295482\ttotal: 10.1s\tremaining: 3m 13s\n",
      "99:\tlearn: 0.0293143\ttotal: 10.2s\tremaining: 3m 13s\n",
      "100:\tlearn: 0.0291379\ttotal: 10.3s\tremaining: 3m 12s\n",
      "101:\tlearn: 0.0289177\ttotal: 10.3s\tremaining: 3m 12s\n",
      "102:\tlearn: 0.0285202\ttotal: 10.5s\tremaining: 3m 12s\n",
      "103:\tlearn: 0.0283950\ttotal: 10.5s\tremaining: 3m 12s\n",
      "104:\tlearn: 0.0283010\ttotal: 10.6s\tremaining: 3m 11s\n",
      "105:\tlearn: 0.0280901\ttotal: 10.7s\tremaining: 3m 11s\n",
      "106:\tlearn: 0.0279741\ttotal: 10.8s\tremaining: 3m 11s\n",
      "107:\tlearn: 0.0277492\ttotal: 10.9s\tremaining: 3m 10s\n",
      "108:\tlearn: 0.0276512\ttotal: 11s\tremaining: 3m 10s\n",
      "109:\tlearn: 0.0273546\ttotal: 11.1s\tremaining: 3m 10s\n",
      "110:\tlearn: 0.0272067\ttotal: 11.2s\tremaining: 3m 10s\n",
      "111:\tlearn: 0.0269209\ttotal: 11.3s\tremaining: 3m 9s\n",
      "112:\tlearn: 0.0267186\ttotal: 11.3s\tremaining: 3m 9s\n",
      "113:\tlearn: 0.0265684\ttotal: 11.5s\tremaining: 3m 9s\n",
      "114:\tlearn: 0.0264537\ttotal: 11.5s\tremaining: 3m 9s\n",
      "115:\tlearn: 0.0262073\ttotal: 11.6s\tremaining: 3m 8s\n",
      "116:\tlearn: 0.0258677\ttotal: 11.7s\tremaining: 3m 8s\n",
      "117:\tlearn: 0.0257925\ttotal: 11.8s\tremaining: 3m 8s\n",
      "118:\tlearn: 0.0256748\ttotal: 11.9s\tremaining: 3m 8s\n",
      "119:\tlearn: 0.0255818\ttotal: 12s\tremaining: 3m 7s\n",
      "120:\tlearn: 0.0254277\ttotal: 12.1s\tremaining: 3m 7s\n",
      "121:\tlearn: 0.0252807\ttotal: 12.2s\tremaining: 3m 7s\n",
      "122:\tlearn: 0.0250613\ttotal: 12.3s\tremaining: 3m 7s\n",
      "123:\tlearn: 0.0249569\ttotal: 12.3s\tremaining: 3m 6s\n",
      "124:\tlearn: 0.0248409\ttotal: 12.4s\tremaining: 3m 6s\n",
      "125:\tlearn: 0.0246469\ttotal: 12.5s\tremaining: 3m 6s\n",
      "126:\tlearn: 0.0245087\ttotal: 12.6s\tremaining: 3m 6s\n",
      "127:\tlearn: 0.0244158\ttotal: 12.7s\tremaining: 3m 5s\n",
      "128:\tlearn: 0.0242422\ttotal: 12.8s\tremaining: 3m 5s\n",
      "129:\tlearn: 0.0241144\ttotal: 12.9s\tremaining: 3m 5s\n",
      "130:\tlearn: 0.0238562\ttotal: 13s\tremaining: 3m 5s\n",
      "131:\tlearn: 0.0237503\ttotal: 13.1s\tremaining: 3m 5s\n",
      "132:\tlearn: 0.0236773\ttotal: 13.2s\tremaining: 3m 4s\n",
      "133:\tlearn: 0.0234348\ttotal: 13.3s\tremaining: 3m 4s\n",
      "134:\tlearn: 0.0232726\ttotal: 13.4s\tremaining: 3m 4s\n",
      "135:\tlearn: 0.0231632\ttotal: 13.4s\tremaining: 3m 4s\n",
      "136:\tlearn: 0.0230686\ttotal: 13.5s\tremaining: 3m 3s\n",
      "137:\tlearn: 0.0229473\ttotal: 13.6s\tremaining: 3m 3s\n",
      "138:\tlearn: 0.0228822\ttotal: 13.7s\tremaining: 3m 3s\n",
      "139:\tlearn: 0.0228001\ttotal: 13.8s\tremaining: 3m 3s\n",
      "140:\tlearn: 0.0226281\ttotal: 13.9s\tremaining: 3m 3s\n",
      "141:\tlearn: 0.0225770\ttotal: 14s\tremaining: 3m 2s\n",
      "142:\tlearn: 0.0224906\ttotal: 14.1s\tremaining: 3m 2s\n",
      "143:\tlearn: 0.0224111\ttotal: 14.2s\tremaining: 3m 2s\n",
      "144:\tlearn: 0.0223214\ttotal: 14.3s\tremaining: 3m 2s\n",
      "145:\tlearn: 0.0222009\ttotal: 14.4s\tremaining: 3m 2s\n",
      "146:\tlearn: 0.0220503\ttotal: 14.5s\tremaining: 3m 2s\n",
      "147:\tlearn: 0.0219914\ttotal: 14.5s\tremaining: 3m 2s\n",
      "148:\tlearn: 0.0218636\ttotal: 14.6s\tremaining: 3m 1s\n",
      "149:\tlearn: 0.0217057\ttotal: 14.7s\tremaining: 3m 1s\n",
      "150:\tlearn: 0.0216374\ttotal: 14.8s\tremaining: 3m 1s\n",
      "151:\tlearn: 0.0215324\ttotal: 14.9s\tremaining: 3m 1s\n",
      "152:\tlearn: 0.0214701\ttotal: 15s\tremaining: 3m\n",
      "153:\tlearn: 0.0214236\ttotal: 15.1s\tremaining: 3m\n",
      "154:\tlearn: 0.0213440\ttotal: 15.2s\tremaining: 3m\n",
      "155:\tlearn: 0.0212825\ttotal: 15.2s\tremaining: 3m\n",
      "156:\tlearn: 0.0211568\ttotal: 15.3s\tremaining: 3m\n",
      "157:\tlearn: 0.0210146\ttotal: 15.4s\tremaining: 2m 59s\n",
      "158:\tlearn: 0.0209442\ttotal: 15.5s\tremaining: 2m 59s\n",
      "159:\tlearn: 0.0209052\ttotal: 15.6s\tremaining: 2m 59s\n",
      "160:\tlearn: 0.0208752\ttotal: 15.7s\tremaining: 2m 59s\n",
      "161:\tlearn: 0.0206448\ttotal: 15.8s\tremaining: 2m 59s\n",
      "162:\tlearn: 0.0205256\ttotal: 15.9s\tremaining: 2m 58s\n",
      "163:\tlearn: 0.0204464\ttotal: 16s\tremaining: 2m 58s\n",
      "164:\tlearn: 0.0203546\ttotal: 16.1s\tremaining: 2m 58s\n",
      "165:\tlearn: 0.0202770\ttotal: 16.2s\tremaining: 2m 58s\n",
      "166:\tlearn: 0.0201807\ttotal: 16.2s\tremaining: 2m 58s\n",
      "167:\tlearn: 0.0201513\ttotal: 16.3s\tremaining: 2m 58s\n",
      "168:\tlearn: 0.0200684\ttotal: 16.4s\tremaining: 2m 57s\n",
      "169:\tlearn: 0.0199457\ttotal: 16.5s\tremaining: 2m 57s\n",
      "170:\tlearn: 0.0198715\ttotal: 16.6s\tremaining: 2m 57s\n",
      "171:\tlearn: 0.0198041\ttotal: 16.7s\tremaining: 2m 57s\n",
      "172:\tlearn: 0.0197340\ttotal: 16.8s\tremaining: 2m 57s\n",
      "173:\tlearn: 0.0196320\ttotal: 16.9s\tremaining: 2m 57s\n",
      "174:\tlearn: 0.0195784\ttotal: 17s\tremaining: 2m 57s\n",
      "175:\tlearn: 0.0195010\ttotal: 17.1s\tremaining: 2m 56s\n",
      "176:\tlearn: 0.0194206\ttotal: 17.2s\tremaining: 2m 56s\n",
      "177:\tlearn: 0.0193838\ttotal: 17.3s\tremaining: 2m 56s\n",
      "178:\tlearn: 0.0193133\ttotal: 17.3s\tremaining: 2m 56s\n",
      "179:\tlearn: 0.0192741\ttotal: 17.4s\tremaining: 2m 56s\n",
      "180:\tlearn: 0.0192423\ttotal: 17.5s\tremaining: 2m 56s\n",
      "181:\tlearn: 0.0191075\ttotal: 17.6s\tremaining: 2m 56s\n",
      "182:\tlearn: 0.0190728\ttotal: 17.7s\tremaining: 2m 55s\n",
      "183:\tlearn: 0.0190123\ttotal: 17.8s\tremaining: 2m 55s\n",
      "184:\tlearn: 0.0189683\ttotal: 17.9s\tremaining: 2m 55s\n",
      "185:\tlearn: 0.0189436\ttotal: 18s\tremaining: 2m 55s\n",
      "186:\tlearn: 0.0188756\ttotal: 18.1s\tremaining: 2m 55s\n",
      "187:\tlearn: 0.0188436\ttotal: 18.2s\tremaining: 2m 55s\n",
      "188:\tlearn: 0.0188011\ttotal: 18.2s\tremaining: 2m 54s\n",
      "189:\tlearn: 0.0187346\ttotal: 18.3s\tremaining: 2m 54s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190:\tlearn: 0.0186682\ttotal: 18.4s\tremaining: 2m 54s\n",
      "191:\tlearn: 0.0185644\ttotal: 18.5s\tremaining: 2m 54s\n",
      "192:\tlearn: 0.0184502\ttotal: 18.6s\tremaining: 2m 54s\n",
      "193:\tlearn: 0.0184033\ttotal: 18.7s\tremaining: 2m 54s\n",
      "194:\tlearn: 0.0183682\ttotal: 18.8s\tremaining: 2m 54s\n",
      "195:\tlearn: 0.0182940\ttotal: 18.9s\tremaining: 2m 53s\n",
      "196:\tlearn: 0.0182578\ttotal: 19s\tremaining: 2m 53s\n",
      "197:\tlearn: 0.0182178\ttotal: 19.1s\tremaining: 2m 53s\n",
      "198:\tlearn: 0.0181754\ttotal: 19.1s\tremaining: 2m 53s\n",
      "199:\tlearn: 0.0181586\ttotal: 19.2s\tremaining: 2m 53s\n",
      "200:\tlearn: 0.0180051\ttotal: 19.3s\tremaining: 2m 52s\n",
      "201:\tlearn: 0.0179557\ttotal: 19.4s\tremaining: 2m 52s\n",
      "202:\tlearn: 0.0179055\ttotal: 19.5s\tremaining: 2m 52s\n",
      "203:\tlearn: 0.0178559\ttotal: 19.6s\tremaining: 2m 52s\n",
      "204:\tlearn: 0.0178144\ttotal: 19.7s\tremaining: 2m 52s\n",
      "205:\tlearn: 0.0177894\ttotal: 19.8s\tremaining: 2m 52s\n",
      "206:\tlearn: 0.0177461\ttotal: 19.8s\tremaining: 2m 51s\n",
      "207:\tlearn: 0.0177087\ttotal: 19.9s\tremaining: 2m 51s\n",
      "208:\tlearn: 0.0176672\ttotal: 20s\tremaining: 2m 51s\n",
      "209:\tlearn: 0.0176201\ttotal: 20.1s\tremaining: 2m 51s\n",
      "210:\tlearn: 0.0176000\ttotal: 20.2s\tremaining: 2m 51s\n",
      "211:\tlearn: 0.0175593\ttotal: 20.3s\tremaining: 2m 51s\n",
      "212:\tlearn: 0.0174561\ttotal: 20.4s\tremaining: 2m 51s\n",
      "213:\tlearn: 0.0174225\ttotal: 20.5s\tremaining: 2m 50s\n",
      "214:\tlearn: 0.0174159\ttotal: 20.6s\tremaining: 2m 50s\n",
      "215:\tlearn: 0.0174024\ttotal: 20.6s\tremaining: 2m 50s\n",
      "216:\tlearn: 0.0173110\ttotal: 20.7s\tremaining: 2m 50s\n",
      "217:\tlearn: 0.0172415\ttotal: 20.8s\tremaining: 2m 50s\n",
      "218:\tlearn: 0.0172059\ttotal: 20.9s\tremaining: 2m 50s\n",
      "219:\tlearn: 0.0171437\ttotal: 21s\tremaining: 2m 49s\n",
      "220:\tlearn: 0.0171087\ttotal: 21.1s\tremaining: 2m 49s\n",
      "221:\tlearn: 0.0170807\ttotal: 21.2s\tremaining: 2m 49s\n",
      "222:\tlearn: 0.0170053\ttotal: 21.3s\tremaining: 2m 49s\n",
      "223:\tlearn: 0.0169834\ttotal: 21.4s\tremaining: 2m 49s\n",
      "224:\tlearn: 0.0169524\ttotal: 21.5s\tremaining: 2m 49s\n",
      "225:\tlearn: 0.0169236\ttotal: 21.5s\tremaining: 2m 49s\n",
      "226:\tlearn: 0.0168916\ttotal: 21.6s\tremaining: 2m 48s\n",
      "227:\tlearn: 0.0168306\ttotal: 21.7s\tremaining: 2m 48s\n",
      "228:\tlearn: 0.0168130\ttotal: 21.8s\tremaining: 2m 48s\n",
      "229:\tlearn: 0.0167819\ttotal: 21.9s\tremaining: 2m 48s\n",
      "230:\tlearn: 0.0167457\ttotal: 22s\tremaining: 2m 48s\n",
      "231:\tlearn: 0.0167332\ttotal: 22.1s\tremaining: 2m 48s\n",
      "232:\tlearn: 0.0166740\ttotal: 22.2s\tremaining: 2m 48s\n",
      "233:\tlearn: 0.0166559\ttotal: 22.2s\tremaining: 2m 47s\n",
      "234:\tlearn: 0.0166145\ttotal: 22.3s\tremaining: 2m 47s\n",
      "235:\tlearn: 0.0165890\ttotal: 22.4s\tremaining: 2m 47s\n",
      "236:\tlearn: 0.0165208\ttotal: 22.5s\tremaining: 2m 47s\n",
      "237:\tlearn: 0.0164931\ttotal: 22.6s\tremaining: 2m 47s\n",
      "238:\tlearn: 0.0164663\ttotal: 22.7s\tremaining: 2m 47s\n",
      "239:\tlearn: 0.0164351\ttotal: 22.8s\tremaining: 2m 46s\n",
      "240:\tlearn: 0.0164071\ttotal: 22.9s\tremaining: 2m 46s\n",
      "241:\tlearn: 0.0163193\ttotal: 22.9s\tremaining: 2m 46s\n",
      "242:\tlearn: 0.0162478\ttotal: 23s\tremaining: 2m 46s\n",
      "243:\tlearn: 0.0162242\ttotal: 23.1s\tremaining: 2m 46s\n",
      "244:\tlearn: 0.0161954\ttotal: 23.2s\tremaining: 2m 46s\n",
      "245:\tlearn: 0.0161788\ttotal: 23.3s\tremaining: 2m 46s\n",
      "246:\tlearn: 0.0161457\ttotal: 23.4s\tremaining: 2m 46s\n",
      "247:\tlearn: 0.0161012\ttotal: 23.5s\tremaining: 2m 45s\n",
      "248:\tlearn: 0.0160591\ttotal: 23.6s\tremaining: 2m 45s\n",
      "249:\tlearn: 0.0160016\ttotal: 23.7s\tremaining: 2m 45s\n",
      "250:\tlearn: 0.0159567\ttotal: 23.8s\tremaining: 2m 45s\n",
      "251:\tlearn: 0.0158986\ttotal: 23.9s\tremaining: 2m 45s\n",
      "252:\tlearn: 0.0158910\ttotal: 23.9s\tremaining: 2m 45s\n",
      "253:\tlearn: 0.0158572\ttotal: 24s\tremaining: 2m 45s\n",
      "254:\tlearn: 0.0158099\ttotal: 24.1s\tremaining: 2m 45s\n",
      "255:\tlearn: 0.0157756\ttotal: 24.2s\tremaining: 2m 44s\n",
      "256:\tlearn: 0.0157241\ttotal: 24.3s\tremaining: 2m 44s\n",
      "257:\tlearn: 0.0156804\ttotal: 24.4s\tremaining: 2m 44s\n",
      "258:\tlearn: 0.0156008\ttotal: 24.5s\tremaining: 2m 44s\n",
      "259:\tlearn: 0.0155584\ttotal: 24.5s\tremaining: 2m 44s\n",
      "260:\tlearn: 0.0155347\ttotal: 24.6s\tremaining: 2m 44s\n",
      "261:\tlearn: 0.0154524\ttotal: 24.7s\tremaining: 2m 44s\n",
      "262:\tlearn: 0.0154204\ttotal: 24.8s\tremaining: 2m 43s\n",
      "263:\tlearn: 0.0154048\ttotal: 24.9s\tremaining: 2m 43s\n",
      "264:\tlearn: 0.0153326\ttotal: 25s\tremaining: 2m 43s\n",
      "265:\tlearn: 0.0153147\ttotal: 25.1s\tremaining: 2m 43s\n",
      "266:\tlearn: 0.0152947\ttotal: 25.2s\tremaining: 2m 43s\n",
      "267:\tlearn: 0.0152873\ttotal: 25.3s\tremaining: 2m 43s\n",
      "268:\tlearn: 0.0152654\ttotal: 25.4s\tremaining: 2m 43s\n",
      "269:\tlearn: 0.0152277\ttotal: 25.4s\tremaining: 2m 43s\n",
      "270:\tlearn: 0.0152151\ttotal: 25.5s\tremaining: 2m 42s\n",
      "271:\tlearn: 0.0151725\ttotal: 25.6s\tremaining: 2m 42s\n",
      "272:\tlearn: 0.0151443\ttotal: 25.7s\tremaining: 2m 42s\n",
      "273:\tlearn: 0.0151264\ttotal: 25.8s\tremaining: 2m 42s\n",
      "274:\tlearn: 0.0151133\ttotal: 25.9s\tremaining: 2m 42s\n",
      "275:\tlearn: 0.0150938\ttotal: 26s\tremaining: 2m 42s\n",
      "276:\tlearn: 0.0150449\ttotal: 26.1s\tremaining: 2m 42s\n",
      "277:\tlearn: 0.0150350\ttotal: 26.1s\tremaining: 2m 41s\n",
      "278:\tlearn: 0.0150121\ttotal: 26.2s\tremaining: 2m 41s\n",
      "279:\tlearn: 0.0149905\ttotal: 26.3s\tremaining: 2m 41s\n",
      "280:\tlearn: 0.0149817\ttotal: 26.4s\tremaining: 2m 41s\n",
      "281:\tlearn: 0.0149677\ttotal: 26.5s\tremaining: 2m 41s\n",
      "282:\tlearn: 0.0149519\ttotal: 26.6s\tremaining: 2m 41s\n",
      "283:\tlearn: 0.0149271\ttotal: 26.7s\tremaining: 2m 41s\n",
      "284:\tlearn: 0.0149127\ttotal: 26.8s\tremaining: 2m 41s\n",
      "285:\tlearn: 0.0148815\ttotal: 26.9s\tremaining: 2m 40s\n",
      "286:\tlearn: 0.0148530\ttotal: 26.9s\tremaining: 2m 40s\n",
      "287:\tlearn: 0.0147938\ttotal: 27.1s\tremaining: 2m 40s\n",
      "288:\tlearn: 0.0147519\ttotal: 27.1s\tremaining: 2m 40s\n",
      "289:\tlearn: 0.0147385\ttotal: 27.2s\tremaining: 2m 40s\n",
      "290:\tlearn: 0.0147045\ttotal: 27.3s\tremaining: 2m 40s\n",
      "291:\tlearn: 0.0146979\ttotal: 27.4s\tremaining: 2m 40s\n",
      "292:\tlearn: 0.0146460\ttotal: 27.5s\tremaining: 2m 40s\n",
      "293:\tlearn: 0.0145638\ttotal: 27.6s\tremaining: 2m 40s\n",
      "294:\tlearn: 0.0145406\ttotal: 27.7s\tremaining: 2m 39s\n",
      "295:\tlearn: 0.0145230\ttotal: 27.8s\tremaining: 2m 39s\n",
      "296:\tlearn: 0.0145038\ttotal: 27.9s\tremaining: 2m 39s\n",
      "297:\tlearn: 0.0144885\ttotal: 27.9s\tremaining: 2m 39s\n",
      "298:\tlearn: 0.0144532\ttotal: 28s\tremaining: 2m 39s\n",
      "299:\tlearn: 0.0144355\ttotal: 28.1s\tremaining: 2m 39s\n",
      "300:\tlearn: 0.0144197\ttotal: 28.2s\tremaining: 2m 39s\n",
      "301:\tlearn: 0.0143969\ttotal: 28.3s\tremaining: 2m 38s\n",
      "302:\tlearn: 0.0143654\ttotal: 28.4s\tremaining: 2m 38s\n",
      "303:\tlearn: 0.0143357\ttotal: 28.5s\tremaining: 2m 38s\n",
      "304:\tlearn: 0.0143124\ttotal: 28.6s\tremaining: 2m 38s\n",
      "305:\tlearn: 0.0142839\ttotal: 28.6s\tremaining: 2m 38s\n",
      "306:\tlearn: 0.0142507\ttotal: 28.7s\tremaining: 2m 38s\n",
      "307:\tlearn: 0.0142199\ttotal: 28.8s\tremaining: 2m 38s\n",
      "308:\tlearn: 0.0141891\ttotal: 28.9s\tremaining: 2m 38s\n",
      "309:\tlearn: 0.0141635\ttotal: 29s\tremaining: 2m 38s\n",
      "310:\tlearn: 0.0141557\ttotal: 29.1s\tremaining: 2m 37s\n",
      "311:\tlearn: 0.0141367\ttotal: 29.2s\tremaining: 2m 37s\n",
      "312:\tlearn: 0.0141144\ttotal: 29.3s\tremaining: 2m 37s\n",
      "313:\tlearn: 0.0140863\ttotal: 29.4s\tremaining: 2m 37s\n",
      "314:\tlearn: 0.0140737\ttotal: 29.4s\tremaining: 2m 37s\n",
      "315:\tlearn: 0.0140641\ttotal: 29.5s\tremaining: 2m 37s\n",
      "316:\tlearn: 0.0140493\ttotal: 29.6s\tremaining: 2m 37s\n",
      "317:\tlearn: 0.0140110\ttotal: 29.7s\tremaining: 2m 37s\n",
      "318:\tlearn: 0.0139962\ttotal: 29.8s\tremaining: 2m 36s\n",
      "319:\tlearn: 0.0139834\ttotal: 29.9s\tremaining: 2m 36s\n",
      "320:\tlearn: 0.0139183\ttotal: 30s\tremaining: 2m 36s\n",
      "321:\tlearn: 0.0138645\ttotal: 30.1s\tremaining: 2m 36s\n",
      "322:\tlearn: 0.0138437\ttotal: 30.1s\tremaining: 2m 36s\n",
      "323:\tlearn: 0.0138167\ttotal: 30.2s\tremaining: 2m 36s\n",
      "324:\tlearn: 0.0137969\ttotal: 30.3s\tremaining: 2m 36s\n",
      "325:\tlearn: 0.0137789\ttotal: 30.4s\tremaining: 2m 36s\n",
      "326:\tlearn: 0.0137603\ttotal: 30.5s\tremaining: 2m 36s\n",
      "327:\tlearn: 0.0136896\ttotal: 30.6s\tremaining: 2m 35s\n",
      "328:\tlearn: 0.0136751\ttotal: 30.7s\tremaining: 2m 35s\n",
      "329:\tlearn: 0.0136542\ttotal: 30.8s\tremaining: 2m 35s\n",
      "330:\tlearn: 0.0136270\ttotal: 30.9s\tremaining: 2m 35s\n",
      "331:\tlearn: 0.0136127\ttotal: 30.9s\tremaining: 2m 35s\n",
      "332:\tlearn: 0.0135745\ttotal: 31s\tremaining: 2m 35s\n",
      "333:\tlearn: 0.0135673\ttotal: 31.1s\tremaining: 2m 35s\n",
      "334:\tlearn: 0.0135511\ttotal: 31.2s\tremaining: 2m 35s\n",
      "335:\tlearn: 0.0135439\ttotal: 31.3s\tremaining: 2m 34s\n",
      "336:\tlearn: 0.0135212\ttotal: 31.4s\tremaining: 2m 34s\n",
      "337:\tlearn: 0.0134848\ttotal: 31.5s\tremaining: 2m 34s\n",
      "338:\tlearn: 0.0134796\ttotal: 31.5s\tremaining: 2m 34s\n",
      "339:\tlearn: 0.0134601\ttotal: 31.6s\tremaining: 2m 34s\n",
      "340:\tlearn: 0.0134249\ttotal: 31.7s\tremaining: 2m 34s\n",
      "341:\tlearn: 0.0134180\ttotal: 31.8s\tremaining: 2m 34s\n",
      "342:\tlearn: 0.0133769\ttotal: 31.9s\tremaining: 2m 34s\n",
      "343:\tlearn: 0.0133219\ttotal: 32s\tremaining: 2m 34s\n",
      "344:\tlearn: 0.0133135\ttotal: 32.1s\tremaining: 2m 33s\n",
      "345:\tlearn: 0.0133025\ttotal: 32.2s\tremaining: 2m 33s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346:\tlearn: 0.0132544\ttotal: 32.3s\tremaining: 2m 33s\n",
      "347:\tlearn: 0.0132357\ttotal: 32.4s\tremaining: 2m 33s\n",
      "348:\tlearn: 0.0132092\ttotal: 32.5s\tremaining: 2m 33s\n",
      "349:\tlearn: 0.0131758\ttotal: 32.6s\tremaining: 2m 33s\n",
      "350:\tlearn: 0.0131350\ttotal: 32.6s\tremaining: 2m 33s\n",
      "351:\tlearn: 0.0131177\ttotal: 32.7s\tremaining: 2m 33s\n",
      "352:\tlearn: 0.0131066\ttotal: 32.8s\tremaining: 2m 33s\n",
      "353:\tlearn: 0.0130748\ttotal: 32.9s\tremaining: 2m 32s\n",
      "354:\tlearn: 0.0130300\ttotal: 33s\tremaining: 2m 32s\n",
      "355:\tlearn: 0.0130153\ttotal: 33.1s\tremaining: 2m 32s\n",
      "356:\tlearn: 0.0129987\ttotal: 33.2s\tremaining: 2m 32s\n",
      "357:\tlearn: 0.0129738\ttotal: 33.3s\tremaining: 2m 32s\n",
      "358:\tlearn: 0.0129631\ttotal: 33.4s\tremaining: 2m 32s\n",
      "359:\tlearn: 0.0129262\ttotal: 33.5s\tremaining: 2m 32s\n",
      "360:\tlearn: 0.0129087\ttotal: 33.5s\tremaining: 2m 32s\n",
      "361:\tlearn: 0.0128704\ttotal: 33.6s\tremaining: 2m 32s\n",
      "362:\tlearn: 0.0128363\ttotal: 33.7s\tremaining: 2m 32s\n",
      "363:\tlearn: 0.0127951\ttotal: 33.8s\tremaining: 2m 31s\n",
      "364:\tlearn: 0.0127774\ttotal: 33.9s\tremaining: 2m 31s\n",
      "365:\tlearn: 0.0127647\ttotal: 34s\tremaining: 2m 31s\n",
      "366:\tlearn: 0.0127255\ttotal: 34.1s\tremaining: 2m 31s\n",
      "367:\tlearn: 0.0126785\ttotal: 34.2s\tremaining: 2m 31s\n",
      "368:\tlearn: 0.0126678\ttotal: 34.3s\tremaining: 2m 31s\n",
      "369:\tlearn: 0.0126642\ttotal: 34.3s\tremaining: 2m 31s\n",
      "370:\tlearn: 0.0126538\ttotal: 34.4s\tremaining: 2m 31s\n",
      "371:\tlearn: 0.0126397\ttotal: 34.5s\tremaining: 2m 31s\n",
      "372:\tlearn: 0.0126266\ttotal: 34.6s\tremaining: 2m 30s\n",
      "373:\tlearn: 0.0126204\ttotal: 34.7s\tremaining: 2m 30s\n",
      "374:\tlearn: 0.0126120\ttotal: 34.8s\tremaining: 2m 30s\n",
      "375:\tlearn: 0.0125896\ttotal: 34.9s\tremaining: 2m 30s\n",
      "376:\tlearn: 0.0125776\ttotal: 35s\tremaining: 2m 30s\n",
      "377:\tlearn: 0.0125713\ttotal: 35.1s\tremaining: 2m 30s\n",
      "378:\tlearn: 0.0125684\ttotal: 35.1s\tremaining: 2m 30s\n",
      "379:\tlearn: 0.0125436\ttotal: 35.2s\tremaining: 2m 30s\n",
      "380:\tlearn: 0.0124711\ttotal: 35.3s\tremaining: 2m 30s\n",
      "381:\tlearn: 0.0124402\ttotal: 35.4s\tremaining: 2m 29s\n",
      "382:\tlearn: 0.0124225\ttotal: 35.5s\tremaining: 2m 29s\n",
      "383:\tlearn: 0.0124176\ttotal: 35.6s\tremaining: 2m 29s\n",
      "384:\tlearn: 0.0123588\ttotal: 35.7s\tremaining: 2m 29s\n",
      "385:\tlearn: 0.0123396\ttotal: 35.8s\tremaining: 2m 29s\n",
      "386:\tlearn: 0.0123155\ttotal: 35.8s\tremaining: 2m 29s\n",
      "387:\tlearn: 0.0123091\ttotal: 35.9s\tremaining: 2m 29s\n",
      "388:\tlearn: 0.0122668\ttotal: 36s\tremaining: 2m 29s\n",
      "389:\tlearn: 0.0122552\ttotal: 36.1s\tremaining: 2m 29s\n",
      "390:\tlearn: 0.0122445\ttotal: 36.2s\tremaining: 2m 28s\n",
      "391:\tlearn: 0.0122368\ttotal: 36.3s\tremaining: 2m 28s\n",
      "392:\tlearn: 0.0121929\ttotal: 36.4s\tremaining: 2m 28s\n",
      "393:\tlearn: 0.0121321\ttotal: 36.5s\tremaining: 2m 28s\n",
      "394:\tlearn: 0.0121221\ttotal: 36.6s\tremaining: 2m 28s\n",
      "395:\tlearn: 0.0121161\ttotal: 36.6s\tremaining: 2m 28s\n",
      "396:\tlearn: 0.0120864\ttotal: 36.7s\tremaining: 2m 28s\n",
      "397:\tlearn: 0.0120632\ttotal: 36.8s\tremaining: 2m 28s\n",
      "398:\tlearn: 0.0120440\ttotal: 36.9s\tremaining: 2m 28s\n",
      "399:\tlearn: 0.0120108\ttotal: 37s\tremaining: 2m 28s\n",
      "400:\tlearn: 0.0119773\ttotal: 37.1s\tremaining: 2m 27s\n",
      "401:\tlearn: 0.0119737\ttotal: 37.2s\tremaining: 2m 27s\n",
      "402:\tlearn: 0.0119634\ttotal: 37.3s\tremaining: 2m 27s\n",
      "403:\tlearn: 0.0119245\ttotal: 37.4s\tremaining: 2m 27s\n",
      "404:\tlearn: 0.0119228\ttotal: 37.5s\tremaining: 2m 27s\n",
      "405:\tlearn: 0.0119093\ttotal: 37.5s\tremaining: 2m 27s\n",
      "406:\tlearn: 0.0118784\ttotal: 37.6s\tremaining: 2m 27s\n",
      "407:\tlearn: 0.0118486\ttotal: 37.7s\tremaining: 2m 27s\n",
      "408:\tlearn: 0.0118117\ttotal: 37.8s\tremaining: 2m 27s\n",
      "409:\tlearn: 0.0118000\ttotal: 37.9s\tremaining: 2m 27s\n",
      "410:\tlearn: 0.0117960\ttotal: 38s\tremaining: 2m 26s\n",
      "411:\tlearn: 0.0117804\ttotal: 38.1s\tremaining: 2m 26s\n",
      "412:\tlearn: 0.0117205\ttotal: 38.2s\tremaining: 2m 26s\n",
      "413:\tlearn: 0.0117013\ttotal: 38.3s\tremaining: 2m 26s\n",
      "414:\tlearn: 0.0116882\ttotal: 38.4s\tremaining: 2m 26s\n",
      "415:\tlearn: 0.0116702\ttotal: 38.5s\tremaining: 2m 26s\n",
      "416:\tlearn: 0.0116598\ttotal: 38.6s\tremaining: 2m 26s\n",
      "417:\tlearn: 0.0116455\ttotal: 38.7s\tremaining: 2m 26s\n",
      "418:\tlearn: 0.0116336\ttotal: 38.7s\tremaining: 2m 26s\n",
      "419:\tlearn: 0.0116208\ttotal: 38.8s\tremaining: 2m 26s\n",
      "420:\tlearn: 0.0116144\ttotal: 38.9s\tremaining: 2m 25s\n",
      "421:\tlearn: 0.0116024\ttotal: 39s\tremaining: 2m 25s\n",
      "422:\tlearn: 0.0115710\ttotal: 39.1s\tremaining: 2m 25s\n",
      "423:\tlearn: 0.0115354\ttotal: 39.2s\tremaining: 2m 25s\n",
      "424:\tlearn: 0.0115186\ttotal: 39.3s\tremaining: 2m 25s\n",
      "425:\tlearn: 0.0114937\ttotal: 39.4s\tremaining: 2m 25s\n",
      "426:\tlearn: 0.0114714\ttotal: 39.5s\tremaining: 2m 25s\n",
      "427:\tlearn: 0.0114519\ttotal: 39.5s\tremaining: 2m 25s\n",
      "428:\tlearn: 0.0114149\ttotal: 39.6s\tremaining: 2m 25s\n",
      "429:\tlearn: 0.0114075\ttotal: 39.7s\tremaining: 2m 25s\n",
      "430:\tlearn: 0.0113910\ttotal: 39.8s\tremaining: 2m 24s\n",
      "431:\tlearn: 0.0113694\ttotal: 40s\tremaining: 2m 25s\n",
      "432:\tlearn: 0.0113504\ttotal: 40.1s\tremaining: 2m 24s\n",
      "433:\tlearn: 0.0113312\ttotal: 40.2s\tremaining: 2m 24s\n",
      "434:\tlearn: 0.0113117\ttotal: 40.3s\tremaining: 2m 24s\n",
      "435:\tlearn: 0.0113013\ttotal: 40.4s\tremaining: 2m 24s\n",
      "436:\tlearn: 0.0112977\ttotal: 40.5s\tremaining: 2m 24s\n",
      "437:\tlearn: 0.0112828\ttotal: 40.5s\tremaining: 2m 24s\n",
      "438:\tlearn: 0.0112709\ttotal: 40.6s\tremaining: 2m 24s\n",
      "439:\tlearn: 0.0112571\ttotal: 40.7s\tremaining: 2m 24s\n",
      "440:\tlearn: 0.0112281\ttotal: 40.8s\tremaining: 2m 24s\n",
      "441:\tlearn: 0.0111995\ttotal: 41s\tremaining: 2m 24s\n",
      "442:\tlearn: 0.0111909\ttotal: 41.1s\tremaining: 2m 24s\n",
      "443:\tlearn: 0.0111605\ttotal: 41.2s\tremaining: 2m 24s\n",
      "444:\tlearn: 0.0111495\ttotal: 41.3s\tremaining: 2m 24s\n",
      "445:\tlearn: 0.0111206\ttotal: 41.4s\tremaining: 2m 24s\n",
      "446:\tlearn: 0.0110945\ttotal: 41.4s\tremaining: 2m 24s\n",
      "447:\tlearn: 0.0110868\ttotal: 41.5s\tremaining: 2m 23s\n",
      "448:\tlearn: 0.0110813\ttotal: 41.6s\tremaining: 2m 23s\n",
      "449:\tlearn: 0.0110543\ttotal: 41.7s\tremaining: 2m 23s\n",
      "450:\tlearn: 0.0110186\ttotal: 41.8s\tremaining: 2m 23s\n",
      "451:\tlearn: 0.0110117\ttotal: 41.9s\tremaining: 2m 23s\n",
      "452:\tlearn: 0.0109955\ttotal: 42s\tremaining: 2m 23s\n",
      "453:\tlearn: 0.0109483\ttotal: 42.1s\tremaining: 2m 23s\n",
      "454:\tlearn: 0.0109434\ttotal: 42.2s\tremaining: 2m 23s\n",
      "455:\tlearn: 0.0109364\ttotal: 42.3s\tremaining: 2m 23s\n",
      "456:\tlearn: 0.0109274\ttotal: 42.4s\tremaining: 2m 23s\n",
      "457:\tlearn: 0.0109164\ttotal: 42.5s\tremaining: 2m 22s\n",
      "458:\tlearn: 0.0108932\ttotal: 42.6s\tremaining: 2m 22s\n",
      "459:\tlearn: 0.0108832\ttotal: 42.6s\tremaining: 2m 22s\n",
      "460:\tlearn: 0.0108784\ttotal: 42.7s\tremaining: 2m 22s\n",
      "461:\tlearn: 0.0108553\ttotal: 42.8s\tremaining: 2m 22s\n",
      "462:\tlearn: 0.0108426\ttotal: 42.9s\tremaining: 2m 22s\n",
      "463:\tlearn: 0.0108160\ttotal: 43.1s\tremaining: 2m 22s\n",
      "464:\tlearn: 0.0108021\ttotal: 43.2s\tremaining: 2m 22s\n",
      "465:\tlearn: 0.0107609\ttotal: 43.2s\tremaining: 2m 22s\n",
      "466:\tlearn: 0.0107366\ttotal: 43.3s\tremaining: 2m 22s\n",
      "467:\tlearn: 0.0107216\ttotal: 43.4s\tremaining: 2m 22s\n",
      "468:\tlearn: 0.0106710\ttotal: 43.5s\tremaining: 2m 22s\n",
      "469:\tlearn: 0.0106579\ttotal: 43.6s\tremaining: 2m 21s\n",
      "470:\tlearn: 0.0106371\ttotal: 43.7s\tremaining: 2m 21s\n",
      "471:\tlearn: 0.0106316\ttotal: 43.8s\tremaining: 2m 21s\n",
      "472:\tlearn: 0.0106150\ttotal: 43.9s\tremaining: 2m 21s\n",
      "473:\tlearn: 0.0105768\ttotal: 44s\tremaining: 2m 21s\n",
      "474:\tlearn: 0.0105543\ttotal: 44.1s\tremaining: 2m 21s\n",
      "475:\tlearn: 0.0105437\ttotal: 44.2s\tremaining: 2m 21s\n",
      "476:\tlearn: 0.0105237\ttotal: 44.3s\tremaining: 2m 21s\n",
      "477:\tlearn: 0.0105142\ttotal: 44.4s\tremaining: 2m 21s\n",
      "478:\tlearn: 0.0105090\ttotal: 44.4s\tremaining: 2m 21s\n",
      "479:\tlearn: 0.0105002\ttotal: 44.5s\tremaining: 2m 21s\n",
      "480:\tlearn: 0.0104950\ttotal: 44.6s\tremaining: 2m 20s\n",
      "481:\tlearn: 0.0104797\ttotal: 44.7s\tremaining: 2m 20s\n",
      "482:\tlearn: 0.0104534\ttotal: 44.8s\tremaining: 2m 20s\n",
      "483:\tlearn: 0.0104277\ttotal: 44.9s\tremaining: 2m 20s\n",
      "484:\tlearn: 0.0104247\ttotal: 45s\tremaining: 2m 20s\n",
      "485:\tlearn: 0.0104093\ttotal: 45.1s\tremaining: 2m 20s\n",
      "486:\tlearn: 0.0103932\ttotal: 45.2s\tremaining: 2m 20s\n",
      "487:\tlearn: 0.0103880\ttotal: 45.2s\tremaining: 2m 20s\n",
      "488:\tlearn: 0.0103724\ttotal: 45.3s\tremaining: 2m 20s\n",
      "489:\tlearn: 0.0103629\ttotal: 45.4s\tremaining: 2m 19s\n",
      "490:\tlearn: 0.0103576\ttotal: 45.5s\tremaining: 2m 19s\n",
      "491:\tlearn: 0.0103493\ttotal: 45.6s\tremaining: 2m 19s\n",
      "492:\tlearn: 0.0103464\ttotal: 45.7s\tremaining: 2m 19s\n",
      "493:\tlearn: 0.0103330\ttotal: 45.8s\tremaining: 2m 19s\n",
      "494:\tlearn: 0.0103311\ttotal: 45.8s\tremaining: 2m 19s\n",
      "495:\tlearn: 0.0103261\ttotal: 45.9s\tremaining: 2m 19s\n",
      "496:\tlearn: 0.0103188\ttotal: 46s\tremaining: 2m 19s\n",
      "497:\tlearn: 0.0103116\ttotal: 46.1s\tremaining: 2m 19s\n",
      "498:\tlearn: 0.0103008\ttotal: 46.2s\tremaining: 2m 18s\n",
      "499:\tlearn: 0.0102902\ttotal: 46.3s\tremaining: 2m 18s\n",
      "500:\tlearn: 0.0102762\ttotal: 46.4s\tremaining: 2m 18s\n",
      "501:\tlearn: 0.0102575\ttotal: 46.5s\tremaining: 2m 18s\n",
      "502:\tlearn: 0.0102515\ttotal: 46.5s\tremaining: 2m 18s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503:\tlearn: 0.0102285\ttotal: 46.6s\tremaining: 2m 18s\n",
      "504:\tlearn: 0.0102205\ttotal: 46.7s\tremaining: 2m 18s\n",
      "505:\tlearn: 0.0102008\ttotal: 46.8s\tremaining: 2m 18s\n",
      "506:\tlearn: 0.0101744\ttotal: 46.9s\tremaining: 2m 18s\n",
      "507:\tlearn: 0.0101375\ttotal: 47s\tremaining: 2m 18s\n",
      "508:\tlearn: 0.0101337\ttotal: 47.1s\tremaining: 2m 17s\n",
      "509:\tlearn: 0.0101178\ttotal: 47.2s\tremaining: 2m 17s\n",
      "510:\tlearn: 0.0101138\ttotal: 47.3s\tremaining: 2m 17s\n",
      "511:\tlearn: 0.0101051\ttotal: 47.4s\tremaining: 2m 17s\n",
      "512:\tlearn: 0.0101000\ttotal: 47.4s\tremaining: 2m 17s\n",
      "513:\tlearn: 0.0100805\ttotal: 47.6s\tremaining: 2m 17s\n",
      "514:\tlearn: 0.0100666\ttotal: 47.6s\tremaining: 2m 17s\n",
      "515:\tlearn: 0.0100344\ttotal: 47.7s\tremaining: 2m 17s\n",
      "516:\tlearn: 0.0100262\ttotal: 47.8s\tremaining: 2m 17s\n",
      "517:\tlearn: 0.0100120\ttotal: 47.9s\tremaining: 2m 17s\n",
      "518:\tlearn: 0.0100036\ttotal: 48s\tremaining: 2m 16s\n",
      "519:\tlearn: 0.0100022\ttotal: 48.1s\tremaining: 2m 16s\n",
      "520:\tlearn: 0.0099960\ttotal: 48.2s\tremaining: 2m 16s\n",
      "521:\tlearn: 0.0099804\ttotal: 48.2s\tremaining: 2m 16s\n",
      "522:\tlearn: 0.0099567\ttotal: 48.3s\tremaining: 2m 16s\n",
      "523:\tlearn: 0.0099420\ttotal: 48.4s\tremaining: 2m 16s\n",
      "524:\tlearn: 0.0099011\ttotal: 48.5s\tremaining: 2m 16s\n",
      "525:\tlearn: 0.0098821\ttotal: 48.6s\tremaining: 2m 16s\n",
      "526:\tlearn: 0.0098697\ttotal: 48.7s\tremaining: 2m 16s\n",
      "527:\tlearn: 0.0098576\ttotal: 48.8s\tremaining: 2m 15s\n",
      "528:\tlearn: 0.0098542\ttotal: 48.9s\tremaining: 2m 15s\n",
      "529:\tlearn: 0.0098489\ttotal: 48.9s\tremaining: 2m 15s\n",
      "530:\tlearn: 0.0098410\ttotal: 49s\tremaining: 2m 15s\n",
      "531:\tlearn: 0.0098301\ttotal: 49.1s\tremaining: 2m 15s\n",
      "532:\tlearn: 0.0098247\ttotal: 49.2s\tremaining: 2m 15s\n",
      "533:\tlearn: 0.0098104\ttotal: 49.3s\tremaining: 2m 15s\n",
      "534:\tlearn: 0.0097922\ttotal: 49.4s\tremaining: 2m 15s\n",
      "535:\tlearn: 0.0097828\ttotal: 49.5s\tremaining: 2m 15s\n",
      "536:\tlearn: 0.0097802\ttotal: 49.6s\tremaining: 2m 15s\n",
      "537:\tlearn: 0.0097652\ttotal: 49.6s\tremaining: 2m 14s\n",
      "538:\tlearn: 0.0097203\ttotal: 49.7s\tremaining: 2m 14s\n",
      "539:\tlearn: 0.0097039\ttotal: 49.8s\tremaining: 2m 14s\n",
      "540:\tlearn: 0.0096925\ttotal: 49.9s\tremaining: 2m 14s\n",
      "541:\tlearn: 0.0096842\ttotal: 50s\tremaining: 2m 14s\n",
      "542:\tlearn: 0.0096762\ttotal: 50.1s\tremaining: 2m 14s\n",
      "543:\tlearn: 0.0096649\ttotal: 50.2s\tremaining: 2m 14s\n",
      "544:\tlearn: 0.0096525\ttotal: 50.3s\tremaining: 2m 14s\n",
      "545:\tlearn: 0.0096437\ttotal: 50.4s\tremaining: 2m 14s\n",
      "546:\tlearn: 0.0096388\ttotal: 50.5s\tremaining: 2m 14s\n",
      "547:\tlearn: 0.0096327\ttotal: 50.6s\tremaining: 2m 14s\n",
      "548:\tlearn: 0.0095899\ttotal: 50.7s\tremaining: 2m 13s\n",
      "549:\tlearn: 0.0095844\ttotal: 50.8s\tremaining: 2m 13s\n",
      "550:\tlearn: 0.0095798\ttotal: 50.8s\tremaining: 2m 13s\n",
      "551:\tlearn: 0.0095751\ttotal: 50.9s\tremaining: 2m 13s\n",
      "552:\tlearn: 0.0095728\ttotal: 51s\tremaining: 2m 13s\n",
      "553:\tlearn: 0.0095659\ttotal: 51.1s\tremaining: 2m 13s\n",
      "554:\tlearn: 0.0095291\ttotal: 51.2s\tremaining: 2m 13s\n",
      "555:\tlearn: 0.0095220\ttotal: 51.3s\tremaining: 2m 13s\n",
      "556:\tlearn: 0.0095173\ttotal: 51.4s\tremaining: 2m 13s\n",
      "557:\tlearn: 0.0095076\ttotal: 51.5s\tremaining: 2m 13s\n",
      "558:\tlearn: 0.0094886\ttotal: 51.6s\tremaining: 2m 12s\n",
      "559:\tlearn: 0.0094843\ttotal: 51.6s\tremaining: 2m 12s\n",
      "560:\tlearn: 0.0094823\ttotal: 51.7s\tremaining: 2m 12s\n",
      "561:\tlearn: 0.0094773\ttotal: 51.8s\tremaining: 2m 12s\n",
      "562:\tlearn: 0.0094542\ttotal: 51.9s\tremaining: 2m 12s\n",
      "563:\tlearn: 0.0094456\ttotal: 52s\tremaining: 2m 12s\n",
      "564:\tlearn: 0.0094137\ttotal: 52.1s\tremaining: 2m 12s\n",
      "565:\tlearn: 0.0094050\ttotal: 52.2s\tremaining: 2m 12s\n",
      "566:\tlearn: 0.0093952\ttotal: 52.3s\tremaining: 2m 12s\n",
      "567:\tlearn: 0.0093750\ttotal: 52.4s\tremaining: 2m 11s\n",
      "568:\tlearn: 0.0093695\ttotal: 52.4s\tremaining: 2m 11s\n",
      "569:\tlearn: 0.0093463\ttotal: 52.5s\tremaining: 2m 11s\n",
      "570:\tlearn: 0.0093304\ttotal: 52.6s\tremaining: 2m 11s\n",
      "571:\tlearn: 0.0093277\ttotal: 52.7s\tremaining: 2m 11s\n",
      "572:\tlearn: 0.0093224\ttotal: 52.8s\tremaining: 2m 11s\n",
      "573:\tlearn: 0.0093049\ttotal: 52.9s\tremaining: 2m 11s\n",
      "574:\tlearn: 0.0092926\ttotal: 53s\tremaining: 2m 11s\n",
      "575:\tlearn: 0.0092799\ttotal: 53.1s\tremaining: 2m 11s\n",
      "576:\tlearn: 0.0092607\ttotal: 53.1s\tremaining: 2m 11s\n",
      "577:\tlearn: 0.0092587\ttotal: 53.2s\tremaining: 2m 10s\n",
      "578:\tlearn: 0.0092325\ttotal: 53.3s\tremaining: 2m 10s\n",
      "579:\tlearn: 0.0092141\ttotal: 53.4s\tremaining: 2m 10s\n",
      "580:\tlearn: 0.0092084\ttotal: 53.5s\tremaining: 2m 10s\n",
      "581:\tlearn: 0.0092026\ttotal: 53.6s\tremaining: 2m 10s\n",
      "582:\tlearn: 0.0091987\ttotal: 53.7s\tremaining: 2m 10s\n",
      "583:\tlearn: 0.0091879\ttotal: 53.8s\tremaining: 2m 10s\n",
      "584:\tlearn: 0.0091757\ttotal: 53.9s\tremaining: 2m 10s\n",
      "585:\tlearn: 0.0091707\ttotal: 53.9s\tremaining: 2m 10s\n",
      "586:\tlearn: 0.0091508\ttotal: 54s\tremaining: 2m 10s\n",
      "587:\tlearn: 0.0091409\ttotal: 54.1s\tremaining: 2m 9s\n",
      "588:\tlearn: 0.0091385\ttotal: 54.2s\tremaining: 2m 9s\n",
      "589:\tlearn: 0.0091323\ttotal: 54.3s\tremaining: 2m 9s\n",
      "590:\tlearn: 0.0091245\ttotal: 54.4s\tremaining: 2m 9s\n",
      "591:\tlearn: 0.0091184\ttotal: 54.5s\tremaining: 2m 9s\n",
      "592:\tlearn: 0.0091065\ttotal: 54.6s\tremaining: 2m 9s\n",
      "593:\tlearn: 0.0091012\ttotal: 54.6s\tremaining: 2m 9s\n",
      "594:\tlearn: 0.0090875\ttotal: 54.7s\tremaining: 2m 9s\n",
      "595:\tlearn: 0.0090852\ttotal: 54.8s\tremaining: 2m 9s\n",
      "596:\tlearn: 0.0090770\ttotal: 54.9s\tremaining: 2m 9s\n",
      "597:\tlearn: 0.0090672\ttotal: 55s\tremaining: 2m 8s\n",
      "598:\tlearn: 0.0090572\ttotal: 55.1s\tremaining: 2m 8s\n",
      "599:\tlearn: 0.0090445\ttotal: 55.2s\tremaining: 2m 8s\n",
      "600:\tlearn: 0.0090383\ttotal: 55.3s\tremaining: 2m 8s\n",
      "601:\tlearn: 0.0090158\ttotal: 55.4s\tremaining: 2m 8s\n",
      "602:\tlearn: 0.0090075\ttotal: 55.4s\tremaining: 2m 8s\n",
      "603:\tlearn: 0.0089997\ttotal: 55.5s\tremaining: 2m 8s\n",
      "604:\tlearn: 0.0089916\ttotal: 55.6s\tremaining: 2m 8s\n",
      "605:\tlearn: 0.0089833\ttotal: 55.7s\tremaining: 2m 8s\n",
      "606:\tlearn: 0.0089744\ttotal: 55.8s\tremaining: 2m 8s\n",
      "607:\tlearn: 0.0089674\ttotal: 55.9s\tremaining: 2m 7s\n",
      "608:\tlearn: 0.0089555\ttotal: 56s\tremaining: 2m 7s\n",
      "609:\tlearn: 0.0089431\ttotal: 56.1s\tremaining: 2m 7s\n",
      "610:\tlearn: 0.0089297\ttotal: 56.2s\tremaining: 2m 7s\n",
      "611:\tlearn: 0.0089274\ttotal: 56.2s\tremaining: 2m 7s\n",
      "612:\tlearn: 0.0089137\ttotal: 56.3s\tremaining: 2m 7s\n",
      "613:\tlearn: 0.0089072\ttotal: 56.4s\tremaining: 2m 7s\n",
      "614:\tlearn: 0.0088991\ttotal: 56.5s\tremaining: 2m 7s\n",
      "615:\tlearn: 0.0088888\ttotal: 56.6s\tremaining: 2m 7s\n",
      "616:\tlearn: 0.0088785\ttotal: 56.7s\tremaining: 2m 7s\n",
      "617:\tlearn: 0.0088662\ttotal: 56.8s\tremaining: 2m 6s\n",
      "618:\tlearn: 0.0088530\ttotal: 56.9s\tremaining: 2m 6s\n",
      "619:\tlearn: 0.0088363\ttotal: 57s\tremaining: 2m 6s\n",
      "620:\tlearn: 0.0088298\ttotal: 57.1s\tremaining: 2m 6s\n",
      "621:\tlearn: 0.0088258\ttotal: 57.1s\tremaining: 2m 6s\n",
      "622:\tlearn: 0.0088143\ttotal: 57.2s\tremaining: 2m 6s\n",
      "623:\tlearn: 0.0088038\ttotal: 57.3s\tremaining: 2m 6s\n",
      "624:\tlearn: 0.0087978\ttotal: 57.4s\tremaining: 2m 6s\n",
      "625:\tlearn: 0.0087811\ttotal: 57.5s\tremaining: 2m 6s\n",
      "626:\tlearn: 0.0087690\ttotal: 57.6s\tremaining: 2m 6s\n",
      "627:\tlearn: 0.0087636\ttotal: 57.7s\tremaining: 2m 6s\n",
      "628:\tlearn: 0.0087473\ttotal: 57.8s\tremaining: 2m 5s\n",
      "629:\tlearn: 0.0087421\ttotal: 57.9s\tremaining: 2m 5s\n",
      "630:\tlearn: 0.0087339\ttotal: 57.9s\tremaining: 2m 5s\n",
      "631:\tlearn: 0.0087171\ttotal: 58.1s\tremaining: 2m 5s\n",
      "632:\tlearn: 0.0087136\ttotal: 58.1s\tremaining: 2m 5s\n",
      "633:\tlearn: 0.0086981\ttotal: 58.2s\tremaining: 2m 5s\n",
      "634:\tlearn: 0.0086835\ttotal: 58.3s\tremaining: 2m 5s\n",
      "635:\tlearn: 0.0086826\ttotal: 58.4s\tremaining: 2m 5s\n",
      "636:\tlearn: 0.0086753\ttotal: 58.5s\tremaining: 2m 5s\n",
      "637:\tlearn: 0.0086672\ttotal: 58.6s\tremaining: 2m 5s\n",
      "638:\tlearn: 0.0086637\ttotal: 58.7s\tremaining: 2m 4s\n",
      "639:\tlearn: 0.0086430\ttotal: 58.8s\tremaining: 2m 4s\n",
      "640:\tlearn: 0.0086343\ttotal: 58.9s\tremaining: 2m 4s\n",
      "641:\tlearn: 0.0086214\ttotal: 58.9s\tremaining: 2m 4s\n",
      "642:\tlearn: 0.0086105\ttotal: 59s\tremaining: 2m 4s\n",
      "643:\tlearn: 0.0086072\ttotal: 59.1s\tremaining: 2m 4s\n",
      "644:\tlearn: 0.0086040\ttotal: 59.2s\tremaining: 2m 4s\n",
      "645:\tlearn: 0.0085958\ttotal: 59.3s\tremaining: 2m 4s\n",
      "646:\tlearn: 0.0085890\ttotal: 59.4s\tremaining: 2m 4s\n",
      "647:\tlearn: 0.0085669\ttotal: 59.5s\tremaining: 2m 4s\n",
      "648:\tlearn: 0.0085555\ttotal: 59.6s\tremaining: 2m 4s\n",
      "649:\tlearn: 0.0085477\ttotal: 59.7s\tremaining: 2m 3s\n",
      "650:\tlearn: 0.0085438\ttotal: 59.8s\tremaining: 2m 3s\n",
      "651:\tlearn: 0.0085413\ttotal: 59.9s\tremaining: 2m 3s\n",
      "652:\tlearn: 0.0085360\ttotal: 59.9s\tremaining: 2m 3s\n",
      "653:\tlearn: 0.0085324\ttotal: 1m\tremaining: 2m 3s\n",
      "654:\tlearn: 0.0085173\ttotal: 1m\tremaining: 2m 3s\n",
      "655:\tlearn: 0.0085012\ttotal: 1m\tremaining: 2m 3s\n",
      "656:\tlearn: 0.0084924\ttotal: 1m\tremaining: 2m 3s\n",
      "657:\tlearn: 0.0084826\ttotal: 1m\tremaining: 2m 3s\n",
      "658:\tlearn: 0.0084570\ttotal: 1m\tremaining: 2m 3s\n",
      "659:\tlearn: 0.0084360\ttotal: 1m\tremaining: 2m 3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660:\tlearn: 0.0084329\ttotal: 1m\tremaining: 2m 2s\n",
      "661:\tlearn: 0.0084296\ttotal: 1m\tremaining: 2m 2s\n",
      "662:\tlearn: 0.0084281\ttotal: 1m\tremaining: 2m 2s\n",
      "663:\tlearn: 0.0084210\ttotal: 1m\tremaining: 2m 2s\n",
      "664:\tlearn: 0.0084084\ttotal: 1m 1s\tremaining: 2m 2s\n",
      "665:\tlearn: 0.0084014\ttotal: 1m 1s\tremaining: 2m 2s\n",
      "666:\tlearn: 0.0083746\ttotal: 1m 1s\tremaining: 2m 2s\n",
      "667:\tlearn: 0.0083668\ttotal: 1m 1s\tremaining: 2m 2s\n",
      "668:\tlearn: 0.0083606\ttotal: 1m 1s\tremaining: 2m 2s\n",
      "669:\tlearn: 0.0083515\ttotal: 1m 1s\tremaining: 2m 2s\n",
      "670:\tlearn: 0.0083481\ttotal: 1m 1s\tremaining: 2m 2s\n",
      "671:\tlearn: 0.0083367\ttotal: 1m 1s\tremaining: 2m 1s\n",
      "672:\tlearn: 0.0083122\ttotal: 1m 1s\tremaining: 2m 1s\n",
      "673:\tlearn: 0.0083035\ttotal: 1m 1s\tremaining: 2m 1s\n",
      "674:\tlearn: 0.0082896\ttotal: 1m 1s\tremaining: 2m 1s\n",
      "675:\tlearn: 0.0082881\ttotal: 1m 2s\tremaining: 2m 1s\n",
      "676:\tlearn: 0.0082798\ttotal: 1m 2s\tremaining: 2m 1s\n",
      "677:\tlearn: 0.0082744\ttotal: 1m 2s\tremaining: 2m 1s\n",
      "678:\tlearn: 0.0082588\ttotal: 1m 2s\tremaining: 2m 1s\n",
      "679:\tlearn: 0.0082571\ttotal: 1m 2s\tremaining: 2m 1s\n",
      "680:\tlearn: 0.0082334\ttotal: 1m 2s\tremaining: 2m 1s\n",
      "681:\tlearn: 0.0082184\ttotal: 1m 2s\tremaining: 2m 1s\n",
      "682:\tlearn: 0.0081867\ttotal: 1m 2s\tremaining: 2m 1s\n",
      "683:\tlearn: 0.0081861\ttotal: 1m 2s\tremaining: 2m\n",
      "684:\tlearn: 0.0081823\ttotal: 1m 2s\tremaining: 2m\n",
      "685:\tlearn: 0.0081783\ttotal: 1m 3s\tremaining: 2m\n",
      "686:\tlearn: 0.0081698\ttotal: 1m 3s\tremaining: 2m\n",
      "687:\tlearn: 0.0081672\ttotal: 1m 3s\tremaining: 2m\n",
      "688:\tlearn: 0.0081546\ttotal: 1m 3s\tremaining: 2m\n",
      "689:\tlearn: 0.0081473\ttotal: 1m 3s\tremaining: 2m\n",
      "690:\tlearn: 0.0081398\ttotal: 1m 3s\tremaining: 2m\n",
      "691:\tlearn: 0.0081376\ttotal: 1m 3s\tremaining: 2m\n",
      "692:\tlearn: 0.0081297\ttotal: 1m 3s\tremaining: 2m\n",
      "693:\tlearn: 0.0081263\ttotal: 1m 3s\tremaining: 1m 59s\n",
      "694:\tlearn: 0.0081187\ttotal: 1m 3s\tremaining: 1m 59s\n",
      "695:\tlearn: 0.0081144\ttotal: 1m 3s\tremaining: 1m 59s\n",
      "696:\tlearn: 0.0081083\ttotal: 1m 4s\tremaining: 1m 59s\n",
      "697:\tlearn: 0.0081008\ttotal: 1m 4s\tremaining: 1m 59s\n",
      "698:\tlearn: 0.0080977\ttotal: 1m 4s\tremaining: 1m 59s\n",
      "699:\tlearn: 0.0080893\ttotal: 1m 4s\tremaining: 1m 59s\n",
      "700:\tlearn: 0.0080802\ttotal: 1m 4s\tremaining: 1m 59s\n",
      "701:\tlearn: 0.0080778\ttotal: 1m 4s\tremaining: 1m 59s\n",
      "702:\tlearn: 0.0080630\ttotal: 1m 4s\tremaining: 1m 59s\n",
      "703:\tlearn: 0.0080475\ttotal: 1m 4s\tremaining: 1m 59s\n",
      "704:\tlearn: 0.0080126\ttotal: 1m 4s\tremaining: 1m 58s\n",
      "705:\tlearn: 0.0080026\ttotal: 1m 4s\tremaining: 1m 58s\n",
      "706:\tlearn: 0.0079826\ttotal: 1m 4s\tremaining: 1m 58s\n",
      "707:\tlearn: 0.0079791\ttotal: 1m 5s\tremaining: 1m 58s\n",
      "708:\tlearn: 0.0079712\ttotal: 1m 5s\tremaining: 1m 58s\n",
      "709:\tlearn: 0.0079600\ttotal: 1m 5s\tremaining: 1m 58s\n",
      "710:\tlearn: 0.0079525\ttotal: 1m 5s\tremaining: 1m 58s\n",
      "711:\tlearn: 0.0079435\ttotal: 1m 5s\tremaining: 1m 58s\n",
      "712:\tlearn: 0.0079332\ttotal: 1m 5s\tremaining: 1m 58s\n",
      "713:\tlearn: 0.0079289\ttotal: 1m 5s\tremaining: 1m 58s\n",
      "714:\tlearn: 0.0079257\ttotal: 1m 5s\tremaining: 1m 57s\n",
      "715:\tlearn: 0.0079104\ttotal: 1m 5s\tremaining: 1m 57s\n",
      "716:\tlearn: 0.0079022\ttotal: 1m 5s\tremaining: 1m 57s\n",
      "717:\tlearn: 0.0078955\ttotal: 1m 5s\tremaining: 1m 57s\n",
      "718:\tlearn: 0.0078909\ttotal: 1m 5s\tremaining: 1m 57s\n",
      "719:\tlearn: 0.0078840\ttotal: 1m 6s\tremaining: 1m 57s\n",
      "720:\tlearn: 0.0078758\ttotal: 1m 6s\tremaining: 1m 57s\n",
      "721:\tlearn: 0.0078640\ttotal: 1m 6s\tremaining: 1m 57s\n",
      "722:\tlearn: 0.0078605\ttotal: 1m 6s\tremaining: 1m 57s\n",
      "723:\tlearn: 0.0078550\ttotal: 1m 6s\tremaining: 1m 57s\n",
      "724:\tlearn: 0.0078447\ttotal: 1m 6s\tremaining: 1m 57s\n",
      "725:\tlearn: 0.0078429\ttotal: 1m 6s\tremaining: 1m 56s\n",
      "726:\tlearn: 0.0078157\ttotal: 1m 6s\tremaining: 1m 56s\n",
      "727:\tlearn: 0.0078032\ttotal: 1m 6s\tremaining: 1m 56s\n",
      "728:\tlearn: 0.0077963\ttotal: 1m 6s\tremaining: 1m 56s\n",
      "729:\tlearn: 0.0077862\ttotal: 1m 6s\tremaining: 1m 56s\n",
      "730:\tlearn: 0.0077726\ttotal: 1m 7s\tremaining: 1m 56s\n",
      "731:\tlearn: 0.0077696\ttotal: 1m 7s\tremaining: 1m 56s\n",
      "732:\tlearn: 0.0077646\ttotal: 1m 7s\tremaining: 1m 56s\n",
      "733:\tlearn: 0.0077604\ttotal: 1m 7s\tremaining: 1m 56s\n",
      "734:\tlearn: 0.0077389\ttotal: 1m 7s\tremaining: 1m 56s\n",
      "735:\tlearn: 0.0077223\ttotal: 1m 7s\tremaining: 1m 55s\n",
      "736:\tlearn: 0.0077169\ttotal: 1m 7s\tremaining: 1m 55s\n",
      "737:\tlearn: 0.0077106\ttotal: 1m 7s\tremaining: 1m 55s\n",
      "738:\tlearn: 0.0077029\ttotal: 1m 7s\tremaining: 1m 55s\n",
      "739:\tlearn: 0.0076940\ttotal: 1m 7s\tremaining: 1m 55s\n",
      "740:\tlearn: 0.0076864\ttotal: 1m 7s\tremaining: 1m 55s\n",
      "741:\tlearn: 0.0076762\ttotal: 1m 8s\tremaining: 1m 55s\n",
      "742:\tlearn: 0.0076691\ttotal: 1m 8s\tremaining: 1m 55s\n",
      "743:\tlearn: 0.0076648\ttotal: 1m 8s\tremaining: 1m 55s\n",
      "744:\tlearn: 0.0076577\ttotal: 1m 8s\tremaining: 1m 55s\n",
      "745:\tlearn: 0.0076406\ttotal: 1m 8s\tremaining: 1m 55s\n",
      "746:\tlearn: 0.0076369\ttotal: 1m 8s\tremaining: 1m 54s\n",
      "747:\tlearn: 0.0076329\ttotal: 1m 8s\tremaining: 1m 54s\n",
      "748:\tlearn: 0.0076256\ttotal: 1m 8s\tremaining: 1m 54s\n",
      "749:\tlearn: 0.0076198\ttotal: 1m 8s\tremaining: 1m 54s\n",
      "750:\tlearn: 0.0076147\ttotal: 1m 8s\tremaining: 1m 54s\n",
      "751:\tlearn: 0.0076116\ttotal: 1m 8s\tremaining: 1m 54s\n",
      "752:\tlearn: 0.0075989\ttotal: 1m 9s\tremaining: 1m 54s\n",
      "753:\tlearn: 0.0075905\ttotal: 1m 9s\tremaining: 1m 54s\n",
      "754:\tlearn: 0.0075836\ttotal: 1m 9s\tremaining: 1m 54s\n",
      "755:\tlearn: 0.0075792\ttotal: 1m 9s\tremaining: 1m 54s\n",
      "756:\tlearn: 0.0075681\ttotal: 1m 9s\tremaining: 1m 54s\n",
      "757:\tlearn: 0.0075588\ttotal: 1m 9s\tremaining: 1m 53s\n",
      "758:\tlearn: 0.0075557\ttotal: 1m 9s\tremaining: 1m 53s\n",
      "759:\tlearn: 0.0075510\ttotal: 1m 9s\tremaining: 1m 53s\n",
      "760:\tlearn: 0.0075474\ttotal: 1m 9s\tremaining: 1m 53s\n",
      "761:\tlearn: 0.0075448\ttotal: 1m 9s\tremaining: 1m 53s\n",
      "762:\tlearn: 0.0075398\ttotal: 1m 9s\tremaining: 1m 53s\n",
      "763:\tlearn: 0.0075301\ttotal: 1m 10s\tremaining: 1m 53s\n",
      "764:\tlearn: 0.0075287\ttotal: 1m 10s\tremaining: 1m 53s\n",
      "765:\tlearn: 0.0075252\ttotal: 1m 10s\tremaining: 1m 53s\n",
      "766:\tlearn: 0.0075219\ttotal: 1m 10s\tremaining: 1m 53s\n",
      "767:\tlearn: 0.0075138\ttotal: 1m 10s\tremaining: 1m 52s\n",
      "768:\tlearn: 0.0075129\ttotal: 1m 10s\tremaining: 1m 52s\n",
      "769:\tlearn: 0.0075103\ttotal: 1m 10s\tremaining: 1m 52s\n",
      "770:\tlearn: 0.0075070\ttotal: 1m 10s\tremaining: 1m 52s\n",
      "771:\tlearn: 0.0075022\ttotal: 1m 10s\tremaining: 1m 52s\n",
      "772:\tlearn: 0.0074993\ttotal: 1m 10s\tremaining: 1m 52s\n",
      "773:\tlearn: 0.0074960\ttotal: 1m 10s\tremaining: 1m 52s\n",
      "774:\tlearn: 0.0074883\ttotal: 1m 11s\tremaining: 1m 52s\n",
      "775:\tlearn: 0.0074829\ttotal: 1m 11s\tremaining: 1m 52s\n",
      "776:\tlearn: 0.0074786\ttotal: 1m 11s\tremaining: 1m 52s\n",
      "777:\tlearn: 0.0074684\ttotal: 1m 11s\tremaining: 1m 51s\n",
      "778:\tlearn: 0.0074670\ttotal: 1m 11s\tremaining: 1m 51s\n",
      "779:\tlearn: 0.0074640\ttotal: 1m 11s\tremaining: 1m 51s\n",
      "780:\tlearn: 0.0074636\ttotal: 1m 11s\tremaining: 1m 51s\n",
      "781:\tlearn: 0.0074540\ttotal: 1m 11s\tremaining: 1m 51s\n",
      "782:\tlearn: 0.0074429\ttotal: 1m 11s\tremaining: 1m 51s\n",
      "783:\tlearn: 0.0074195\ttotal: 1m 11s\tremaining: 1m 51s\n",
      "784:\tlearn: 0.0074181\ttotal: 1m 11s\tremaining: 1m 51s\n",
      "785:\tlearn: 0.0074083\ttotal: 1m 11s\tremaining: 1m 51s\n",
      "786:\tlearn: 0.0074029\ttotal: 1m 12s\tremaining: 1m 51s\n",
      "787:\tlearn: 0.0074010\ttotal: 1m 12s\tremaining: 1m 50s\n",
      "788:\tlearn: 0.0073825\ttotal: 1m 12s\tremaining: 1m 50s\n",
      "789:\tlearn: 0.0073743\ttotal: 1m 12s\tremaining: 1m 50s\n",
      "790:\tlearn: 0.0073678\ttotal: 1m 12s\tremaining: 1m 50s\n",
      "791:\tlearn: 0.0073618\ttotal: 1m 12s\tremaining: 1m 50s\n",
      "792:\tlearn: 0.0073606\ttotal: 1m 12s\tremaining: 1m 50s\n",
      "793:\tlearn: 0.0073478\ttotal: 1m 12s\tremaining: 1m 50s\n",
      "794:\tlearn: 0.0073393\ttotal: 1m 12s\tremaining: 1m 50s\n",
      "795:\tlearn: 0.0073354\ttotal: 1m 12s\tremaining: 1m 50s\n",
      "796:\tlearn: 0.0073308\ttotal: 1m 12s\tremaining: 1m 50s\n",
      "797:\tlearn: 0.0073299\ttotal: 1m 13s\tremaining: 1m 50s\n",
      "798:\tlearn: 0.0073274\ttotal: 1m 13s\tremaining: 1m 49s\n",
      "799:\tlearn: 0.0073236\ttotal: 1m 13s\tremaining: 1m 49s\n",
      "800:\tlearn: 0.0073213\ttotal: 1m 13s\tremaining: 1m 49s\n",
      "801:\tlearn: 0.0073143\ttotal: 1m 13s\tremaining: 1m 49s\n",
      "802:\tlearn: 0.0073090\ttotal: 1m 13s\tremaining: 1m 49s\n",
      "803:\tlearn: 0.0072977\ttotal: 1m 13s\tremaining: 1m 49s\n",
      "804:\tlearn: 0.0072928\ttotal: 1m 13s\tremaining: 1m 49s\n",
      "805:\tlearn: 0.0072867\ttotal: 1m 13s\tremaining: 1m 49s\n",
      "806:\tlearn: 0.0072815\ttotal: 1m 13s\tremaining: 1m 49s\n",
      "807:\tlearn: 0.0072762\ttotal: 1m 13s\tremaining: 1m 49s\n",
      "808:\tlearn: 0.0072670\ttotal: 1m 14s\tremaining: 1m 49s\n",
      "809:\tlearn: 0.0072550\ttotal: 1m 14s\tremaining: 1m 49s\n",
      "810:\tlearn: 0.0072376\ttotal: 1m 14s\tremaining: 1m 48s\n",
      "811:\tlearn: 0.0072327\ttotal: 1m 14s\tremaining: 1m 48s\n",
      "812:\tlearn: 0.0072245\ttotal: 1m 14s\tremaining: 1m 48s\n",
      "813:\tlearn: 0.0072234\ttotal: 1m 14s\tremaining: 1m 48s\n",
      "814:\tlearn: 0.0072208\ttotal: 1m 14s\tremaining: 1m 48s\n",
      "815:\tlearn: 0.0072170\ttotal: 1m 14s\tremaining: 1m 48s\n",
      "816:\tlearn: 0.0072068\ttotal: 1m 14s\tremaining: 1m 48s\n",
      "817:\tlearn: 0.0072027\ttotal: 1m 14s\tremaining: 1m 48s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "818:\tlearn: 0.0071970\ttotal: 1m 15s\tremaining: 1m 48s\n",
      "819:\tlearn: 0.0071930\ttotal: 1m 15s\tremaining: 1m 48s\n",
      "820:\tlearn: 0.0071895\ttotal: 1m 15s\tremaining: 1m 47s\n",
      "821:\tlearn: 0.0071873\ttotal: 1m 15s\tremaining: 1m 47s\n",
      "822:\tlearn: 0.0071859\ttotal: 1m 15s\tremaining: 1m 47s\n",
      "823:\tlearn: 0.0071805\ttotal: 1m 15s\tremaining: 1m 47s\n",
      "824:\tlearn: 0.0071761\ttotal: 1m 15s\tremaining: 1m 47s\n",
      "825:\tlearn: 0.0071730\ttotal: 1m 15s\tremaining: 1m 47s\n",
      "826:\tlearn: 0.0071648\ttotal: 1m 15s\tremaining: 1m 47s\n",
      "827:\tlearn: 0.0071553\ttotal: 1m 15s\tremaining: 1m 47s\n",
      "828:\tlearn: 0.0071534\ttotal: 1m 15s\tremaining: 1m 47s\n",
      "829:\tlearn: 0.0071510\ttotal: 1m 16s\tremaining: 1m 47s\n",
      "830:\tlearn: 0.0071445\ttotal: 1m 16s\tremaining: 1m 47s\n",
      "831:\tlearn: 0.0071401\ttotal: 1m 16s\tremaining: 1m 46s\n",
      "832:\tlearn: 0.0071321\ttotal: 1m 16s\tremaining: 1m 46s\n",
      "833:\tlearn: 0.0071181\ttotal: 1m 16s\tremaining: 1m 46s\n",
      "834:\tlearn: 0.0071128\ttotal: 1m 16s\tremaining: 1m 46s\n",
      "835:\tlearn: 0.0071104\ttotal: 1m 16s\tremaining: 1m 46s\n",
      "836:\tlearn: 0.0070946\ttotal: 1m 16s\tremaining: 1m 46s\n",
      "837:\tlearn: 0.0070857\ttotal: 1m 16s\tremaining: 1m 46s\n",
      "838:\tlearn: 0.0070813\ttotal: 1m 16s\tremaining: 1m 46s\n",
      "839:\tlearn: 0.0070762\ttotal: 1m 16s\tremaining: 1m 46s\n",
      "840:\tlearn: 0.0070701\ttotal: 1m 16s\tremaining: 1m 46s\n",
      "841:\tlearn: 0.0070662\ttotal: 1m 17s\tremaining: 1m 45s\n",
      "842:\tlearn: 0.0070496\ttotal: 1m 17s\tremaining: 1m 45s\n",
      "843:\tlearn: 0.0070359\ttotal: 1m 17s\tremaining: 1m 45s\n",
      "844:\tlearn: 0.0070326\ttotal: 1m 17s\tremaining: 1m 45s\n",
      "845:\tlearn: 0.0070280\ttotal: 1m 17s\tremaining: 1m 45s\n",
      "846:\tlearn: 0.0070208\ttotal: 1m 17s\tremaining: 1m 45s\n",
      "847:\tlearn: 0.0070192\ttotal: 1m 17s\tremaining: 1m 45s\n",
      "848:\tlearn: 0.0070123\ttotal: 1m 17s\tremaining: 1m 45s\n",
      "849:\tlearn: 0.0070062\ttotal: 1m 17s\tremaining: 1m 45s\n",
      "850:\tlearn: 0.0069784\ttotal: 1m 17s\tremaining: 1m 45s\n",
      "851:\tlearn: 0.0069738\ttotal: 1m 17s\tremaining: 1m 45s\n",
      "852:\tlearn: 0.0069691\ttotal: 1m 18s\tremaining: 1m 44s\n",
      "853:\tlearn: 0.0069580\ttotal: 1m 18s\tremaining: 1m 44s\n",
      "854:\tlearn: 0.0069460\ttotal: 1m 18s\tremaining: 1m 44s\n",
      "855:\tlearn: 0.0069407\ttotal: 1m 18s\tremaining: 1m 44s\n",
      "856:\tlearn: 0.0069389\ttotal: 1m 18s\tremaining: 1m 44s\n",
      "857:\tlearn: 0.0069351\ttotal: 1m 18s\tremaining: 1m 44s\n",
      "858:\tlearn: 0.0069268\ttotal: 1m 18s\tremaining: 1m 44s\n",
      "859:\tlearn: 0.0069244\ttotal: 1m 18s\tremaining: 1m 44s\n",
      "860:\tlearn: 0.0069229\ttotal: 1m 18s\tremaining: 1m 44s\n",
      "861:\tlearn: 0.0069212\ttotal: 1m 18s\tremaining: 1m 44s\n",
      "862:\tlearn: 0.0069064\ttotal: 1m 18s\tremaining: 1m 43s\n",
      "863:\tlearn: 0.0069063\ttotal: 1m 18s\tremaining: 1m 43s\n",
      "864:\tlearn: 0.0068892\ttotal: 1m 19s\tremaining: 1m 43s\n",
      "865:\tlearn: 0.0068784\ttotal: 1m 19s\tremaining: 1m 43s\n",
      "866:\tlearn: 0.0068638\ttotal: 1m 19s\tremaining: 1m 43s\n",
      "867:\tlearn: 0.0068576\ttotal: 1m 19s\tremaining: 1m 43s\n",
      "868:\tlearn: 0.0068419\ttotal: 1m 19s\tremaining: 1m 43s\n",
      "869:\tlearn: 0.0068332\ttotal: 1m 19s\tremaining: 1m 43s\n",
      "870:\tlearn: 0.0068284\ttotal: 1m 19s\tremaining: 1m 43s\n",
      "871:\tlearn: 0.0068268\ttotal: 1m 19s\tremaining: 1m 43s\n",
      "872:\tlearn: 0.0068250\ttotal: 1m 19s\tremaining: 1m 42s\n",
      "873:\tlearn: 0.0068206\ttotal: 1m 19s\tremaining: 1m 42s\n",
      "874:\tlearn: 0.0068147\ttotal: 1m 19s\tremaining: 1m 42s\n",
      "875:\tlearn: 0.0067995\ttotal: 1m 20s\tremaining: 1m 42s\n",
      "876:\tlearn: 0.0067982\ttotal: 1m 20s\tremaining: 1m 42s\n",
      "877:\tlearn: 0.0067918\ttotal: 1m 20s\tremaining: 1m 42s\n",
      "878:\tlearn: 0.0067878\ttotal: 1m 20s\tremaining: 1m 42s\n",
      "879:\tlearn: 0.0067855\ttotal: 1m 20s\tremaining: 1m 42s\n",
      "880:\tlearn: 0.0067806\ttotal: 1m 20s\tremaining: 1m 42s\n",
      "881:\tlearn: 0.0067688\ttotal: 1m 20s\tremaining: 1m 42s\n",
      "882:\tlearn: 0.0067661\ttotal: 1m 20s\tremaining: 1m 42s\n",
      "883:\tlearn: 0.0067645\ttotal: 1m 20s\tremaining: 1m 41s\n",
      "884:\tlearn: 0.0067607\ttotal: 1m 20s\tremaining: 1m 41s\n",
      "885:\tlearn: 0.0067577\ttotal: 1m 20s\tremaining: 1m 41s\n",
      "886:\tlearn: 0.0067527\ttotal: 1m 21s\tremaining: 1m 41s\n",
      "887:\tlearn: 0.0067492\ttotal: 1m 21s\tremaining: 1m 41s\n",
      "888:\tlearn: 0.0067416\ttotal: 1m 21s\tremaining: 1m 41s\n",
      "889:\tlearn: 0.0067386\ttotal: 1m 21s\tremaining: 1m 41s\n",
      "890:\tlearn: 0.0067304\ttotal: 1m 21s\tremaining: 1m 41s\n",
      "891:\tlearn: 0.0067264\ttotal: 1m 21s\tremaining: 1m 41s\n",
      "892:\tlearn: 0.0067199\ttotal: 1m 21s\tremaining: 1m 41s\n",
      "893:\tlearn: 0.0067147\ttotal: 1m 21s\tremaining: 1m 41s\n",
      "894:\tlearn: 0.0067084\ttotal: 1m 21s\tremaining: 1m 41s\n",
      "895:\tlearn: 0.0067042\ttotal: 1m 21s\tremaining: 1m 40s\n",
      "896:\tlearn: 0.0066991\ttotal: 1m 22s\tremaining: 1m 40s\n",
      "897:\tlearn: 0.0066941\ttotal: 1m 22s\tremaining: 1m 40s\n",
      "898:\tlearn: 0.0066874\ttotal: 1m 22s\tremaining: 1m 40s\n",
      "899:\tlearn: 0.0066824\ttotal: 1m 22s\tremaining: 1m 40s\n",
      "900:\tlearn: 0.0066756\ttotal: 1m 22s\tremaining: 1m 40s\n",
      "901:\tlearn: 0.0066734\ttotal: 1m 22s\tremaining: 1m 40s\n",
      "902:\tlearn: 0.0066652\ttotal: 1m 22s\tremaining: 1m 40s\n",
      "903:\tlearn: 0.0066511\ttotal: 1m 22s\tremaining: 1m 40s\n",
      "904:\tlearn: 0.0066498\ttotal: 1m 22s\tremaining: 1m 40s\n",
      "905:\tlearn: 0.0066476\ttotal: 1m 22s\tremaining: 1m 40s\n",
      "906:\tlearn: 0.0066419\ttotal: 1m 22s\tremaining: 1m 39s\n",
      "907:\tlearn: 0.0066403\ttotal: 1m 23s\tremaining: 1m 39s\n",
      "908:\tlearn: 0.0066288\ttotal: 1m 23s\tremaining: 1m 39s\n",
      "909:\tlearn: 0.0066141\ttotal: 1m 23s\tremaining: 1m 39s\n",
      "910:\tlearn: 0.0066052\ttotal: 1m 23s\tremaining: 1m 39s\n",
      "911:\tlearn: 0.0066035\ttotal: 1m 23s\tremaining: 1m 39s\n",
      "912:\tlearn: 0.0066001\ttotal: 1m 23s\tremaining: 1m 39s\n",
      "913:\tlearn: 0.0065980\ttotal: 1m 23s\tremaining: 1m 39s\n",
      "914:\tlearn: 0.0065966\ttotal: 1m 23s\tremaining: 1m 39s\n",
      "915:\tlearn: 0.0065901\ttotal: 1m 23s\tremaining: 1m 39s\n",
      "916:\tlearn: 0.0065871\ttotal: 1m 23s\tremaining: 1m 39s\n",
      "917:\tlearn: 0.0065789\ttotal: 1m 23s\tremaining: 1m 38s\n",
      "918:\tlearn: 0.0065629\ttotal: 1m 24s\tremaining: 1m 38s\n",
      "919:\tlearn: 0.0065607\ttotal: 1m 24s\tremaining: 1m 38s\n",
      "920:\tlearn: 0.0065562\ttotal: 1m 24s\tremaining: 1m 38s\n",
      "921:\tlearn: 0.0065448\ttotal: 1m 24s\tremaining: 1m 38s\n",
      "922:\tlearn: 0.0065424\ttotal: 1m 24s\tremaining: 1m 38s\n",
      "923:\tlearn: 0.0065412\ttotal: 1m 24s\tremaining: 1m 38s\n",
      "924:\tlearn: 0.0065404\ttotal: 1m 24s\tremaining: 1m 38s\n",
      "925:\tlearn: 0.0065359\ttotal: 1m 24s\tremaining: 1m 38s\n",
      "926:\tlearn: 0.0065289\ttotal: 1m 24s\tremaining: 1m 38s\n",
      "927:\tlearn: 0.0065248\ttotal: 1m 24s\tremaining: 1m 37s\n",
      "928:\tlearn: 0.0065202\ttotal: 1m 24s\tremaining: 1m 37s\n",
      "929:\tlearn: 0.0065044\ttotal: 1m 24s\tremaining: 1m 37s\n",
      "930:\tlearn: 0.0065025\ttotal: 1m 25s\tremaining: 1m 37s\n",
      "931:\tlearn: 0.0064978\ttotal: 1m 25s\tremaining: 1m 37s\n",
      "932:\tlearn: 0.0064903\ttotal: 1m 25s\tremaining: 1m 37s\n",
      "933:\tlearn: 0.0064785\ttotal: 1m 25s\tremaining: 1m 37s\n",
      "934:\tlearn: 0.0064745\ttotal: 1m 25s\tremaining: 1m 37s\n",
      "935:\tlearn: 0.0064651\ttotal: 1m 25s\tremaining: 1m 37s\n",
      "936:\tlearn: 0.0064543\ttotal: 1m 25s\tremaining: 1m 37s\n",
      "937:\tlearn: 0.0064493\ttotal: 1m 25s\tremaining: 1m 37s\n",
      "938:\tlearn: 0.0064303\ttotal: 1m 25s\tremaining: 1m 36s\n",
      "939:\tlearn: 0.0064259\ttotal: 1m 25s\tremaining: 1m 36s\n",
      "940:\tlearn: 0.0064249\ttotal: 1m 26s\tremaining: 1m 36s\n",
      "941:\tlearn: 0.0064177\ttotal: 1m 26s\tremaining: 1m 36s\n",
      "942:\tlearn: 0.0064114\ttotal: 1m 26s\tremaining: 1m 36s\n",
      "943:\tlearn: 0.0064063\ttotal: 1m 26s\tremaining: 1m 36s\n",
      "944:\tlearn: 0.0064057\ttotal: 1m 26s\tremaining: 1m 36s\n",
      "945:\tlearn: 0.0064027\ttotal: 1m 26s\tremaining: 1m 36s\n",
      "946:\tlearn: 0.0064008\ttotal: 1m 26s\tremaining: 1m 36s\n",
      "947:\tlearn: 0.0063977\ttotal: 1m 26s\tremaining: 1m 36s\n",
      "948:\tlearn: 0.0063934\ttotal: 1m 26s\tremaining: 1m 36s\n",
      "949:\tlearn: 0.0063912\ttotal: 1m 26s\tremaining: 1m 35s\n",
      "950:\tlearn: 0.0063875\ttotal: 1m 26s\tremaining: 1m 35s\n",
      "951:\tlearn: 0.0063842\ttotal: 1m 27s\tremaining: 1m 35s\n",
      "952:\tlearn: 0.0063780\ttotal: 1m 27s\tremaining: 1m 35s\n",
      "953:\tlearn: 0.0063654\ttotal: 1m 27s\tremaining: 1m 35s\n",
      "954:\tlearn: 0.0063616\ttotal: 1m 27s\tremaining: 1m 35s\n",
      "955:\tlearn: 0.0063574\ttotal: 1m 27s\tremaining: 1m 35s\n",
      "956:\tlearn: 0.0063557\ttotal: 1m 27s\tremaining: 1m 35s\n",
      "957:\tlearn: 0.0063523\ttotal: 1m 27s\tremaining: 1m 35s\n",
      "958:\tlearn: 0.0063508\ttotal: 1m 27s\tremaining: 1m 35s\n",
      "959:\tlearn: 0.0063483\ttotal: 1m 27s\tremaining: 1m 35s\n",
      "960:\tlearn: 0.0063465\ttotal: 1m 27s\tremaining: 1m 34s\n",
      "961:\tlearn: 0.0063436\ttotal: 1m 27s\tremaining: 1m 34s\n",
      "962:\tlearn: 0.0063401\ttotal: 1m 28s\tremaining: 1m 34s\n",
      "963:\tlearn: 0.0063347\ttotal: 1m 28s\tremaining: 1m 34s\n",
      "964:\tlearn: 0.0063284\ttotal: 1m 28s\tremaining: 1m 34s\n",
      "965:\tlearn: 0.0063272\ttotal: 1m 28s\tremaining: 1m 34s\n",
      "966:\tlearn: 0.0063231\ttotal: 1m 28s\tremaining: 1m 34s\n",
      "967:\tlearn: 0.0063183\ttotal: 1m 28s\tremaining: 1m 34s\n",
      "968:\tlearn: 0.0063116\ttotal: 1m 28s\tremaining: 1m 34s\n",
      "969:\tlearn: 0.0063101\ttotal: 1m 28s\tremaining: 1m 34s\n",
      "970:\tlearn: 0.0063031\ttotal: 1m 28s\tremaining: 1m 34s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "971:\tlearn: 0.0063011\ttotal: 1m 28s\tremaining: 1m 33s\n",
      "972:\tlearn: 0.0062954\ttotal: 1m 28s\tremaining: 1m 33s\n",
      "973:\tlearn: 0.0062905\ttotal: 1m 29s\tremaining: 1m 33s\n",
      "974:\tlearn: 0.0062861\ttotal: 1m 29s\tremaining: 1m 33s\n",
      "975:\tlearn: 0.0062828\ttotal: 1m 29s\tremaining: 1m 33s\n",
      "976:\tlearn: 0.0062712\ttotal: 1m 29s\tremaining: 1m 33s\n",
      "977:\tlearn: 0.0062562\ttotal: 1m 29s\tremaining: 1m 33s\n",
      "978:\tlearn: 0.0062539\ttotal: 1m 29s\tremaining: 1m 33s\n",
      "979:\tlearn: 0.0062436\ttotal: 1m 29s\tremaining: 1m 33s\n",
      "980:\tlearn: 0.0062409\ttotal: 1m 29s\tremaining: 1m 33s\n",
      "981:\tlearn: 0.0062300\ttotal: 1m 29s\tremaining: 1m 33s\n",
      "982:\tlearn: 0.0062222\ttotal: 1m 29s\tremaining: 1m 32s\n",
      "983:\tlearn: 0.0062191\ttotal: 1m 29s\tremaining: 1m 32s\n",
      "984:\tlearn: 0.0062152\ttotal: 1m 29s\tremaining: 1m 32s\n",
      "985:\tlearn: 0.0062073\ttotal: 1m 30s\tremaining: 1m 32s\n",
      "986:\tlearn: 0.0062068\ttotal: 1m 30s\tremaining: 1m 32s\n",
      "987:\tlearn: 0.0061884\ttotal: 1m 30s\tremaining: 1m 32s\n",
      "988:\tlearn: 0.0061868\ttotal: 1m 30s\tremaining: 1m 32s\n",
      "989:\tlearn: 0.0061734\ttotal: 1m 30s\tremaining: 1m 32s\n",
      "990:\tlearn: 0.0061617\ttotal: 1m 30s\tremaining: 1m 32s\n",
      "991:\tlearn: 0.0061579\ttotal: 1m 30s\tremaining: 1m 32s\n",
      "992:\tlearn: 0.0061500\ttotal: 1m 30s\tremaining: 1m 31s\n",
      "993:\tlearn: 0.0061468\ttotal: 1m 30s\tremaining: 1m 31s\n",
      "994:\tlearn: 0.0061444\ttotal: 1m 30s\tremaining: 1m 31s\n",
      "995:\tlearn: 0.0061389\ttotal: 1m 30s\tremaining: 1m 31s\n",
      "996:\tlearn: 0.0061262\ttotal: 1m 31s\tremaining: 1m 31s\n",
      "997:\tlearn: 0.0061241\ttotal: 1m 31s\tremaining: 1m 31s\n",
      "998:\tlearn: 0.0061065\ttotal: 1m 31s\tremaining: 1m 31s\n",
      "999:\tlearn: 0.0061012\ttotal: 1m 31s\tremaining: 1m 31s\n",
      "1000:\tlearn: 0.0060998\ttotal: 1m 31s\tremaining: 1m 31s\n",
      "1001:\tlearn: 0.0060923\ttotal: 1m 31s\tremaining: 1m 31s\n",
      "1002:\tlearn: 0.0060910\ttotal: 1m 31s\tremaining: 1m 31s\n",
      "1003:\tlearn: 0.0060866\ttotal: 1m 31s\tremaining: 1m 30s\n",
      "1004:\tlearn: 0.0060837\ttotal: 1m 31s\tremaining: 1m 30s\n",
      "1005:\tlearn: 0.0060786\ttotal: 1m 31s\tremaining: 1m 30s\n",
      "1006:\tlearn: 0.0060693\ttotal: 1m 31s\tremaining: 1m 30s\n",
      "1007:\tlearn: 0.0060635\ttotal: 1m 32s\tremaining: 1m 30s\n",
      "1008:\tlearn: 0.0060607\ttotal: 1m 32s\tremaining: 1m 30s\n",
      "1009:\tlearn: 0.0060560\ttotal: 1m 32s\tremaining: 1m 30s\n",
      "1010:\tlearn: 0.0060436\ttotal: 1m 32s\tremaining: 1m 30s\n",
      "1011:\tlearn: 0.0060423\ttotal: 1m 32s\tremaining: 1m 30s\n",
      "1012:\tlearn: 0.0060415\ttotal: 1m 32s\tremaining: 1m 30s\n",
      "1013:\tlearn: 0.0060399\ttotal: 1m 32s\tremaining: 1m 30s\n",
      "1014:\tlearn: 0.0060395\ttotal: 1m 32s\tremaining: 1m 29s\n",
      "1015:\tlearn: 0.0060374\ttotal: 1m 32s\tremaining: 1m 29s\n",
      "1016:\tlearn: 0.0060329\ttotal: 1m 32s\tremaining: 1m 29s\n",
      "1017:\tlearn: 0.0060276\ttotal: 1m 32s\tremaining: 1m 29s\n",
      "1018:\tlearn: 0.0060258\ttotal: 1m 33s\tremaining: 1m 29s\n",
      "1019:\tlearn: 0.0060205\ttotal: 1m 33s\tremaining: 1m 29s\n",
      "1020:\tlearn: 0.0060089\ttotal: 1m 33s\tremaining: 1m 29s\n",
      "1021:\tlearn: 0.0060075\ttotal: 1m 33s\tremaining: 1m 29s\n",
      "1022:\tlearn: 0.0060056\ttotal: 1m 33s\tremaining: 1m 29s\n",
      "1023:\tlearn: 0.0060015\ttotal: 1m 33s\tremaining: 1m 29s\n",
      "1024:\tlearn: 0.0059923\ttotal: 1m 33s\tremaining: 1m 29s\n",
      "1025:\tlearn: 0.0059902\ttotal: 1m 33s\tremaining: 1m 28s\n",
      "1026:\tlearn: 0.0059870\ttotal: 1m 33s\tremaining: 1m 28s\n",
      "1027:\tlearn: 0.0059839\ttotal: 1m 33s\tremaining: 1m 28s\n",
      "1028:\tlearn: 0.0059823\ttotal: 1m 33s\tremaining: 1m 28s\n",
      "1029:\tlearn: 0.0059799\ttotal: 1m 34s\tremaining: 1m 28s\n",
      "1030:\tlearn: 0.0059782\ttotal: 1m 34s\tremaining: 1m 28s\n",
      "1031:\tlearn: 0.0059760\ttotal: 1m 34s\tremaining: 1m 28s\n",
      "1032:\tlearn: 0.0059714\ttotal: 1m 34s\tremaining: 1m 28s\n",
      "1033:\tlearn: 0.0059632\ttotal: 1m 34s\tremaining: 1m 28s\n",
      "1034:\tlearn: 0.0059620\ttotal: 1m 34s\tremaining: 1m 28s\n",
      "1035:\tlearn: 0.0059370\ttotal: 1m 34s\tremaining: 1m 28s\n",
      "1036:\tlearn: 0.0059345\ttotal: 1m 34s\tremaining: 1m 27s\n",
      "1037:\tlearn: 0.0059341\ttotal: 1m 34s\tremaining: 1m 27s\n",
      "1038:\tlearn: 0.0059310\ttotal: 1m 34s\tremaining: 1m 27s\n",
      "1039:\tlearn: 0.0059257\ttotal: 1m 34s\tremaining: 1m 27s\n",
      "1040:\tlearn: 0.0059172\ttotal: 1m 35s\tremaining: 1m 27s\n",
      "1041:\tlearn: 0.0059156\ttotal: 1m 35s\tremaining: 1m 27s\n",
      "1042:\tlearn: 0.0059091\ttotal: 1m 35s\tremaining: 1m 27s\n",
      "1043:\tlearn: 0.0059028\ttotal: 1m 35s\tremaining: 1m 27s\n",
      "1044:\tlearn: 0.0058997\ttotal: 1m 35s\tremaining: 1m 27s\n",
      "1045:\tlearn: 0.0058966\ttotal: 1m 35s\tremaining: 1m 27s\n",
      "1046:\tlearn: 0.0058951\ttotal: 1m 35s\tremaining: 1m 27s\n",
      "1047:\tlearn: 0.0058885\ttotal: 1m 35s\tremaining: 1m 26s\n",
      "1048:\tlearn: 0.0058794\ttotal: 1m 35s\tremaining: 1m 26s\n",
      "1049:\tlearn: 0.0058736\ttotal: 1m 35s\tremaining: 1m 26s\n",
      "1050:\tlearn: 0.0058718\ttotal: 1m 35s\tremaining: 1m 26s\n",
      "1051:\tlearn: 0.0058707\ttotal: 1m 36s\tremaining: 1m 26s\n",
      "1052:\tlearn: 0.0058669\ttotal: 1m 36s\tremaining: 1m 26s\n",
      "1053:\tlearn: 0.0058655\ttotal: 1m 36s\tremaining: 1m 26s\n",
      "1054:\tlearn: 0.0058578\ttotal: 1m 36s\tremaining: 1m 26s\n",
      "1055:\tlearn: 0.0058510\ttotal: 1m 36s\tremaining: 1m 26s\n",
      "1056:\tlearn: 0.0058486\ttotal: 1m 36s\tremaining: 1m 26s\n",
      "1057:\tlearn: 0.0058441\ttotal: 1m 36s\tremaining: 1m 26s\n",
      "1058:\tlearn: 0.0058396\ttotal: 1m 36s\tremaining: 1m 25s\n",
      "1059:\tlearn: 0.0058285\ttotal: 1m 36s\tremaining: 1m 25s\n",
      "1060:\tlearn: 0.0058168\ttotal: 1m 36s\tremaining: 1m 25s\n",
      "1061:\tlearn: 0.0058152\ttotal: 1m 36s\tremaining: 1m 25s\n",
      "1062:\tlearn: 0.0058121\ttotal: 1m 37s\tremaining: 1m 25s\n",
      "1063:\tlearn: 0.0058096\ttotal: 1m 37s\tremaining: 1m 25s\n",
      "1064:\tlearn: 0.0058053\ttotal: 1m 37s\tremaining: 1m 25s\n",
      "1065:\tlearn: 0.0058040\ttotal: 1m 37s\tremaining: 1m 25s\n",
      "1066:\tlearn: 0.0058023\ttotal: 1m 37s\tremaining: 1m 25s\n",
      "1067:\tlearn: 0.0057996\ttotal: 1m 37s\tremaining: 1m 25s\n",
      "1068:\tlearn: 0.0057970\ttotal: 1m 37s\tremaining: 1m 24s\n",
      "1069:\tlearn: 0.0057957\ttotal: 1m 37s\tremaining: 1m 24s\n",
      "1070:\tlearn: 0.0057940\ttotal: 1m 37s\tremaining: 1m 24s\n",
      "1071:\tlearn: 0.0057902\ttotal: 1m 37s\tremaining: 1m 24s\n",
      "1072:\tlearn: 0.0057822\ttotal: 1m 37s\tremaining: 1m 24s\n",
      "1073:\tlearn: 0.0057808\ttotal: 1m 38s\tremaining: 1m 24s\n",
      "1074:\tlearn: 0.0057756\ttotal: 1m 38s\tremaining: 1m 24s\n",
      "1075:\tlearn: 0.0057690\ttotal: 1m 38s\tremaining: 1m 24s\n",
      "1076:\tlearn: 0.0057540\ttotal: 1m 38s\tremaining: 1m 24s\n",
      "1077:\tlearn: 0.0057510\ttotal: 1m 38s\tremaining: 1m 24s\n",
      "1078:\tlearn: 0.0057456\ttotal: 1m 38s\tremaining: 1m 24s\n",
      "1079:\tlearn: 0.0057446\ttotal: 1m 38s\tremaining: 1m 23s\n",
      "1080:\tlearn: 0.0057427\ttotal: 1m 38s\tremaining: 1m 23s\n",
      "1081:\tlearn: 0.0057392\ttotal: 1m 38s\tremaining: 1m 23s\n",
      "1082:\tlearn: 0.0057337\ttotal: 1m 38s\tremaining: 1m 23s\n",
      "1083:\tlearn: 0.0057322\ttotal: 1m 38s\tremaining: 1m 23s\n",
      "1084:\tlearn: 0.0057296\ttotal: 1m 39s\tremaining: 1m 23s\n",
      "1085:\tlearn: 0.0057245\ttotal: 1m 39s\tremaining: 1m 23s\n",
      "1086:\tlearn: 0.0057086\ttotal: 1m 39s\tremaining: 1m 23s\n",
      "1087:\tlearn: 0.0057050\ttotal: 1m 39s\tremaining: 1m 23s\n",
      "1088:\tlearn: 0.0056996\ttotal: 1m 39s\tremaining: 1m 23s\n",
      "1089:\tlearn: 0.0056969\ttotal: 1m 39s\tremaining: 1m 23s\n",
      "1090:\tlearn: 0.0056965\ttotal: 1m 39s\tremaining: 1m 22s\n",
      "1091:\tlearn: 0.0056919\ttotal: 1m 39s\tremaining: 1m 22s\n",
      "1092:\tlearn: 0.0056904\ttotal: 1m 39s\tremaining: 1m 22s\n",
      "1093:\tlearn: 0.0056888\ttotal: 1m 39s\tremaining: 1m 22s\n",
      "1094:\tlearn: 0.0056875\ttotal: 1m 39s\tremaining: 1m 22s\n",
      "1095:\tlearn: 0.0056819\ttotal: 1m 40s\tremaining: 1m 22s\n",
      "1096:\tlearn: 0.0056687\ttotal: 1m 40s\tremaining: 1m 22s\n",
      "1097:\tlearn: 0.0056677\ttotal: 1m 40s\tremaining: 1m 22s\n",
      "1098:\tlearn: 0.0056664\ttotal: 1m 40s\tremaining: 1m 22s\n",
      "1099:\tlearn: 0.0056598\ttotal: 1m 40s\tremaining: 1m 22s\n",
      "1100:\tlearn: 0.0056533\ttotal: 1m 40s\tremaining: 1m 22s\n",
      "1101:\tlearn: 0.0056513\ttotal: 1m 40s\tremaining: 1m 21s\n",
      "1102:\tlearn: 0.0056488\ttotal: 1m 40s\tremaining: 1m 21s\n",
      "1103:\tlearn: 0.0056445\ttotal: 1m 40s\tremaining: 1m 21s\n",
      "1104:\tlearn: 0.0056370\ttotal: 1m 40s\tremaining: 1m 21s\n",
      "1105:\tlearn: 0.0056358\ttotal: 1m 40s\tremaining: 1m 21s\n",
      "1106:\tlearn: 0.0056315\ttotal: 1m 41s\tremaining: 1m 21s\n",
      "1107:\tlearn: 0.0056306\ttotal: 1m 41s\tremaining: 1m 21s\n",
      "1108:\tlearn: 0.0056294\ttotal: 1m 41s\tremaining: 1m 21s\n",
      "1109:\tlearn: 0.0056179\ttotal: 1m 41s\tremaining: 1m 21s\n",
      "1110:\tlearn: 0.0056099\ttotal: 1m 41s\tremaining: 1m 21s\n",
      "1111:\tlearn: 0.0056071\ttotal: 1m 41s\tremaining: 1m 21s\n",
      "1112:\tlearn: 0.0056058\ttotal: 1m 41s\tremaining: 1m 20s\n",
      "1113:\tlearn: 0.0056020\ttotal: 1m 41s\tremaining: 1m 20s\n",
      "1114:\tlearn: 0.0056013\ttotal: 1m 41s\tremaining: 1m 20s\n",
      "1115:\tlearn: 0.0055998\ttotal: 1m 41s\tremaining: 1m 20s\n",
      "1116:\tlearn: 0.0055886\ttotal: 1m 41s\tremaining: 1m 20s\n",
      "1117:\tlearn: 0.0055867\ttotal: 1m 41s\tremaining: 1m 20s\n",
      "1118:\tlearn: 0.0055837\ttotal: 1m 42s\tremaining: 1m 20s\n",
      "1119:\tlearn: 0.0055833\ttotal: 1m 42s\tremaining: 1m 20s\n",
      "1120:\tlearn: 0.0055810\ttotal: 1m 42s\tremaining: 1m 20s\n",
      "1121:\tlearn: 0.0055579\ttotal: 1m 42s\tremaining: 1m 20s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1122:\tlearn: 0.0055505\ttotal: 1m 42s\tremaining: 1m 20s\n",
      "1123:\tlearn: 0.0055467\ttotal: 1m 42s\tremaining: 1m 19s\n",
      "1124:\tlearn: 0.0055459\ttotal: 1m 42s\tremaining: 1m 19s\n",
      "1125:\tlearn: 0.0055447\ttotal: 1m 42s\tremaining: 1m 19s\n",
      "1126:\tlearn: 0.0055391\ttotal: 1m 42s\tremaining: 1m 19s\n",
      "1127:\tlearn: 0.0055376\ttotal: 1m 42s\tremaining: 1m 19s\n",
      "1128:\tlearn: 0.0055340\ttotal: 1m 42s\tremaining: 1m 19s\n",
      "1129:\tlearn: 0.0055330\ttotal: 1m 43s\tremaining: 1m 19s\n",
      "1130:\tlearn: 0.0055325\ttotal: 1m 43s\tremaining: 1m 19s\n",
      "1131:\tlearn: 0.0055301\ttotal: 1m 43s\tremaining: 1m 19s\n",
      "1132:\tlearn: 0.0055247\ttotal: 1m 43s\tremaining: 1m 19s\n",
      "1133:\tlearn: 0.0055243\ttotal: 1m 43s\tremaining: 1m 18s\n",
      "1134:\tlearn: 0.0055234\ttotal: 1m 43s\tremaining: 1m 18s\n",
      "1135:\tlearn: 0.0055220\ttotal: 1m 43s\tremaining: 1m 18s\n",
      "1136:\tlearn: 0.0055211\ttotal: 1m 43s\tremaining: 1m 18s\n",
      "1137:\tlearn: 0.0055203\ttotal: 1m 43s\tremaining: 1m 18s\n",
      "1138:\tlearn: 0.0055192\ttotal: 1m 43s\tremaining: 1m 18s\n",
      "1139:\tlearn: 0.0055159\ttotal: 1m 43s\tremaining: 1m 18s\n",
      "1140:\tlearn: 0.0055150\ttotal: 1m 44s\tremaining: 1m 18s\n",
      "1141:\tlearn: 0.0055135\ttotal: 1m 44s\tremaining: 1m 18s\n",
      "1142:\tlearn: 0.0055128\ttotal: 1m 44s\tremaining: 1m 18s\n",
      "1143:\tlearn: 0.0055117\ttotal: 1m 44s\tremaining: 1m 18s\n",
      "1144:\tlearn: 0.0055063\ttotal: 1m 44s\tremaining: 1m 17s\n",
      "1145:\tlearn: 0.0055016\ttotal: 1m 44s\tremaining: 1m 17s\n",
      "1146:\tlearn: 0.0054992\ttotal: 1m 44s\tremaining: 1m 17s\n",
      "1147:\tlearn: 0.0054959\ttotal: 1m 44s\tremaining: 1m 17s\n",
      "1148:\tlearn: 0.0054948\ttotal: 1m 44s\tremaining: 1m 17s\n",
      "1149:\tlearn: 0.0054930\ttotal: 1m 44s\tremaining: 1m 17s\n",
      "1150:\tlearn: 0.0054820\ttotal: 1m 44s\tremaining: 1m 17s\n",
      "1151:\tlearn: 0.0054817\ttotal: 1m 44s\tremaining: 1m 17s\n",
      "1152:\tlearn: 0.0054795\ttotal: 1m 45s\tremaining: 1m 17s\n",
      "1153:\tlearn: 0.0054787\ttotal: 1m 45s\tremaining: 1m 17s\n",
      "1154:\tlearn: 0.0054746\ttotal: 1m 45s\tremaining: 1m 16s\n",
      "1155:\tlearn: 0.0054728\ttotal: 1m 45s\tremaining: 1m 16s\n",
      "1156:\tlearn: 0.0054629\ttotal: 1m 45s\tremaining: 1m 16s\n",
      "1157:\tlearn: 0.0054614\ttotal: 1m 45s\tremaining: 1m 16s\n",
      "1158:\tlearn: 0.0054595\ttotal: 1m 45s\tremaining: 1m 16s\n",
      "1159:\tlearn: 0.0054529\ttotal: 1m 45s\tremaining: 1m 16s\n",
      "1160:\tlearn: 0.0054450\ttotal: 1m 45s\tremaining: 1m 16s\n",
      "1161:\tlearn: 0.0054374\ttotal: 1m 45s\tremaining: 1m 16s\n",
      "1162:\tlearn: 0.0054361\ttotal: 1m 45s\tremaining: 1m 16s\n",
      "1163:\tlearn: 0.0054338\ttotal: 1m 46s\tremaining: 1m 16s\n",
      "1164:\tlearn: 0.0054285\ttotal: 1m 46s\tremaining: 1m 16s\n",
      "1165:\tlearn: 0.0054239\ttotal: 1m 46s\tremaining: 1m 15s\n",
      "1166:\tlearn: 0.0054204\ttotal: 1m 46s\tremaining: 1m 15s\n",
      "1167:\tlearn: 0.0054193\ttotal: 1m 46s\tremaining: 1m 15s\n",
      "1168:\tlearn: 0.0054185\ttotal: 1m 46s\tremaining: 1m 15s\n",
      "1169:\tlearn: 0.0054183\ttotal: 1m 46s\tremaining: 1m 15s\n",
      "1170:\tlearn: 0.0054171\ttotal: 1m 46s\tremaining: 1m 15s\n",
      "1171:\tlearn: 0.0054163\ttotal: 1m 46s\tremaining: 1m 15s\n",
      "1172:\tlearn: 0.0054114\ttotal: 1m 46s\tremaining: 1m 15s\n",
      "1173:\tlearn: 0.0054103\ttotal: 1m 46s\tremaining: 1m 15s\n",
      "1174:\tlearn: 0.0054085\ttotal: 1m 46s\tremaining: 1m 15s\n",
      "1175:\tlearn: 0.0053980\ttotal: 1m 47s\tremaining: 1m 15s\n",
      "1176:\tlearn: 0.0053949\ttotal: 1m 47s\tremaining: 1m 14s\n",
      "1177:\tlearn: 0.0053935\ttotal: 1m 47s\tremaining: 1m 14s\n",
      "1178:\tlearn: 0.0053931\ttotal: 1m 47s\tremaining: 1m 14s\n",
      "1179:\tlearn: 0.0053880\ttotal: 1m 47s\tremaining: 1m 14s\n",
      "1180:\tlearn: 0.0053821\ttotal: 1m 47s\tremaining: 1m 14s\n",
      "1181:\tlearn: 0.0053751\ttotal: 1m 47s\tremaining: 1m 14s\n",
      "1182:\tlearn: 0.0053699\ttotal: 1m 47s\tremaining: 1m 14s\n",
      "1183:\tlearn: 0.0053665\ttotal: 1m 47s\tremaining: 1m 14s\n",
      "1184:\tlearn: 0.0053653\ttotal: 1m 47s\tremaining: 1m 14s\n",
      "1185:\tlearn: 0.0053633\ttotal: 1m 47s\tremaining: 1m 14s\n",
      "1186:\tlearn: 0.0053604\ttotal: 1m 48s\tremaining: 1m 14s\n",
      "1187:\tlearn: 0.0053580\ttotal: 1m 48s\tremaining: 1m 13s\n",
      "1188:\tlearn: 0.0053540\ttotal: 1m 48s\tremaining: 1m 13s\n",
      "1189:\tlearn: 0.0053538\ttotal: 1m 48s\tremaining: 1m 13s\n",
      "1190:\tlearn: 0.0053509\ttotal: 1m 48s\tremaining: 1m 13s\n",
      "1191:\tlearn: 0.0053501\ttotal: 1m 48s\tremaining: 1m 13s\n",
      "1192:\tlearn: 0.0053490\ttotal: 1m 48s\tremaining: 1m 13s\n",
      "1193:\tlearn: 0.0053483\ttotal: 1m 48s\tremaining: 1m 13s\n",
      "1194:\tlearn: 0.0053454\ttotal: 1m 48s\tremaining: 1m 13s\n",
      "1195:\tlearn: 0.0053417\ttotal: 1m 48s\tremaining: 1m 13s\n",
      "1196:\tlearn: 0.0053372\ttotal: 1m 48s\tremaining: 1m 13s\n",
      "1197:\tlearn: 0.0053359\ttotal: 1m 49s\tremaining: 1m 12s\n",
      "1198:\tlearn: 0.0053351\ttotal: 1m 49s\tremaining: 1m 12s\n",
      "1199:\tlearn: 0.0053318\ttotal: 1m 49s\tremaining: 1m 12s\n",
      "1200:\tlearn: 0.0053308\ttotal: 1m 49s\tremaining: 1m 12s\n",
      "1201:\tlearn: 0.0053294\ttotal: 1m 49s\tremaining: 1m 12s\n",
      "1202:\tlearn: 0.0053270\ttotal: 1m 49s\tremaining: 1m 12s\n",
      "1203:\tlearn: 0.0053203\ttotal: 1m 49s\tremaining: 1m 12s\n",
      "1204:\tlearn: 0.0053193\ttotal: 1m 49s\tremaining: 1m 12s\n",
      "1205:\tlearn: 0.0053181\ttotal: 1m 49s\tremaining: 1m 12s\n",
      "1206:\tlearn: 0.0053171\ttotal: 1m 49s\tremaining: 1m 12s\n",
      "1207:\tlearn: 0.0053140\ttotal: 1m 49s\tremaining: 1m 12s\n",
      "1208:\tlearn: 0.0053128\ttotal: 1m 49s\tremaining: 1m 11s\n",
      "1209:\tlearn: 0.0053100\ttotal: 1m 50s\tremaining: 1m 11s\n",
      "1210:\tlearn: 0.0053076\ttotal: 1m 50s\tremaining: 1m 11s\n",
      "1211:\tlearn: 0.0053026\ttotal: 1m 50s\tremaining: 1m 11s\n",
      "1212:\tlearn: 0.0053014\ttotal: 1m 50s\tremaining: 1m 11s\n",
      "1213:\tlearn: 0.0052998\ttotal: 1m 50s\tremaining: 1m 11s\n",
      "1214:\tlearn: 0.0052946\ttotal: 1m 50s\tremaining: 1m 11s\n",
      "1215:\tlearn: 0.0052922\ttotal: 1m 50s\tremaining: 1m 11s\n",
      "1216:\tlearn: 0.0052882\ttotal: 1m 50s\tremaining: 1m 11s\n",
      "1217:\tlearn: 0.0052821\ttotal: 1m 50s\tremaining: 1m 11s\n",
      "1218:\tlearn: 0.0052800\ttotal: 1m 50s\tremaining: 1m 11s\n",
      "1219:\tlearn: 0.0052778\ttotal: 1m 50s\tremaining: 1m 10s\n",
      "1220:\tlearn: 0.0052668\ttotal: 1m 51s\tremaining: 1m 10s\n",
      "1221:\tlearn: 0.0052654\ttotal: 1m 51s\tremaining: 1m 10s\n",
      "1222:\tlearn: 0.0052518\ttotal: 1m 51s\tremaining: 1m 10s\n",
      "1223:\tlearn: 0.0052425\ttotal: 1m 51s\tremaining: 1m 10s\n",
      "1224:\tlearn: 0.0052389\ttotal: 1m 51s\tremaining: 1m 10s\n",
      "1225:\tlearn: 0.0052359\ttotal: 1m 51s\tremaining: 1m 10s\n",
      "1226:\tlearn: 0.0052335\ttotal: 1m 51s\tremaining: 1m 10s\n",
      "1227:\tlearn: 0.0052302\ttotal: 1m 51s\tremaining: 1m 10s\n",
      "1228:\tlearn: 0.0052297\ttotal: 1m 51s\tremaining: 1m 10s\n",
      "1229:\tlearn: 0.0052264\ttotal: 1m 51s\tremaining: 1m 10s\n",
      "1230:\tlearn: 0.0052240\ttotal: 1m 51s\tremaining: 1m 9s\n",
      "1231:\tlearn: 0.0052193\ttotal: 1m 52s\tremaining: 1m 9s\n",
      "1232:\tlearn: 0.0052184\ttotal: 1m 52s\tremaining: 1m 9s\n",
      "1233:\tlearn: 0.0052151\ttotal: 1m 52s\tremaining: 1m 9s\n",
      "1234:\tlearn: 0.0052124\ttotal: 1m 52s\tremaining: 1m 9s\n",
      "1235:\tlearn: 0.0052097\ttotal: 1m 52s\tremaining: 1m 9s\n",
      "1236:\tlearn: 0.0052076\ttotal: 1m 52s\tremaining: 1m 9s\n",
      "1237:\tlearn: 0.0052034\ttotal: 1m 52s\tremaining: 1m 9s\n",
      "1238:\tlearn: 0.0052021\ttotal: 1m 52s\tremaining: 1m 9s\n",
      "1239:\tlearn: 0.0051988\ttotal: 1m 52s\tremaining: 1m 9s\n",
      "1240:\tlearn: 0.0051982\ttotal: 1m 52s\tremaining: 1m 9s\n",
      "1241:\tlearn: 0.0051951\ttotal: 1m 52s\tremaining: 1m 8s\n",
      "1242:\tlearn: 0.0051936\ttotal: 1m 53s\tremaining: 1m 8s\n",
      "1243:\tlearn: 0.0051917\ttotal: 1m 53s\tremaining: 1m 8s\n",
      "1244:\tlearn: 0.0051899\ttotal: 1m 53s\tremaining: 1m 8s\n",
      "1245:\tlearn: 0.0051856\ttotal: 1m 53s\tremaining: 1m 8s\n",
      "1246:\tlearn: 0.0051819\ttotal: 1m 53s\tremaining: 1m 8s\n",
      "1247:\tlearn: 0.0051816\ttotal: 1m 53s\tremaining: 1m 8s\n",
      "1248:\tlearn: 0.0051794\ttotal: 1m 53s\tremaining: 1m 8s\n",
      "1249:\tlearn: 0.0051729\ttotal: 1m 53s\tremaining: 1m 8s\n",
      "1250:\tlearn: 0.0051719\ttotal: 1m 53s\tremaining: 1m 8s\n",
      "1251:\tlearn: 0.0051704\ttotal: 1m 53s\tremaining: 1m 7s\n",
      "1252:\tlearn: 0.0051682\ttotal: 1m 53s\tremaining: 1m 7s\n",
      "1253:\tlearn: 0.0051673\ttotal: 1m 53s\tremaining: 1m 7s\n",
      "1254:\tlearn: 0.0051646\ttotal: 1m 54s\tremaining: 1m 7s\n",
      "1255:\tlearn: 0.0051630\ttotal: 1m 54s\tremaining: 1m 7s\n",
      "1256:\tlearn: 0.0051598\ttotal: 1m 54s\tremaining: 1m 7s\n",
      "1257:\tlearn: 0.0051574\ttotal: 1m 54s\tremaining: 1m 7s\n",
      "1258:\tlearn: 0.0051540\ttotal: 1m 54s\tremaining: 1m 7s\n",
      "1259:\tlearn: 0.0051522\ttotal: 1m 54s\tremaining: 1m 7s\n",
      "1260:\tlearn: 0.0051431\ttotal: 1m 54s\tremaining: 1m 7s\n",
      "1261:\tlearn: 0.0051393\ttotal: 1m 54s\tremaining: 1m 7s\n",
      "1262:\tlearn: 0.0051382\ttotal: 1m 54s\tremaining: 1m 6s\n",
      "1263:\tlearn: 0.0051297\ttotal: 1m 54s\tremaining: 1m 6s\n",
      "1264:\tlearn: 0.0051282\ttotal: 1m 55s\tremaining: 1m 6s\n",
      "1265:\tlearn: 0.0051279\ttotal: 1m 55s\tremaining: 1m 6s\n",
      "1266:\tlearn: 0.0051268\ttotal: 1m 55s\tremaining: 1m 6s\n",
      "1267:\tlearn: 0.0051163\ttotal: 1m 55s\tremaining: 1m 6s\n",
      "1268:\tlearn: 0.0051155\ttotal: 1m 55s\tremaining: 1m 6s\n",
      "1269:\tlearn: 0.0051134\ttotal: 1m 55s\tremaining: 1m 6s\n",
      "1270:\tlearn: 0.0051089\ttotal: 1m 55s\tremaining: 1m 6s\n",
      "1271:\tlearn: 0.0051057\ttotal: 1m 55s\tremaining: 1m 6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1272:\tlearn: 0.0050961\ttotal: 1m 55s\tremaining: 1m 6s\n",
      "1273:\tlearn: 0.0050953\ttotal: 1m 55s\tremaining: 1m 5s\n",
      "1274:\tlearn: 0.0050936\ttotal: 1m 55s\tremaining: 1m 5s\n",
      "1275:\tlearn: 0.0050931\ttotal: 1m 55s\tremaining: 1m 5s\n",
      "1276:\tlearn: 0.0050925\ttotal: 1m 56s\tremaining: 1m 5s\n",
      "1277:\tlearn: 0.0050919\ttotal: 1m 56s\tremaining: 1m 5s\n",
      "1278:\tlearn: 0.0050899\ttotal: 1m 56s\tremaining: 1m 5s\n",
      "1279:\tlearn: 0.0050867\ttotal: 1m 56s\tremaining: 1m 5s\n",
      "1280:\tlearn: 0.0050855\ttotal: 1m 56s\tremaining: 1m 5s\n",
      "1281:\tlearn: 0.0050801\ttotal: 1m 56s\tremaining: 1m 5s\n",
      "1282:\tlearn: 0.0050791\ttotal: 1m 56s\tremaining: 1m 5s\n",
      "1283:\tlearn: 0.0050734\ttotal: 1m 56s\tremaining: 1m 5s\n",
      "1284:\tlearn: 0.0050712\ttotal: 1m 56s\tremaining: 1m 4s\n",
      "1285:\tlearn: 0.0050694\ttotal: 1m 56s\tremaining: 1m 4s\n",
      "1286:\tlearn: 0.0050674\ttotal: 1m 56s\tremaining: 1m 4s\n",
      "1287:\tlearn: 0.0050571\ttotal: 1m 57s\tremaining: 1m 4s\n",
      "1288:\tlearn: 0.0050557\ttotal: 1m 57s\tremaining: 1m 4s\n",
      "1289:\tlearn: 0.0050548\ttotal: 1m 57s\tremaining: 1m 4s\n",
      "1290:\tlearn: 0.0050544\ttotal: 1m 57s\tremaining: 1m 4s\n",
      "1291:\tlearn: 0.0050529\ttotal: 1m 57s\tremaining: 1m 4s\n",
      "1292:\tlearn: 0.0050459\ttotal: 1m 57s\tremaining: 1m 4s\n",
      "1293:\tlearn: 0.0050423\ttotal: 1m 57s\tremaining: 1m 4s\n",
      "1294:\tlearn: 0.0050391\ttotal: 1m 57s\tremaining: 1m 4s\n",
      "1295:\tlearn: 0.0050371\ttotal: 1m 57s\tremaining: 1m 3s\n",
      "1296:\tlearn: 0.0050295\ttotal: 1m 57s\tremaining: 1m 3s\n",
      "1297:\tlearn: 0.0050283\ttotal: 1m 57s\tremaining: 1m 3s\n",
      "1298:\tlearn: 0.0050281\ttotal: 1m 57s\tremaining: 1m 3s\n",
      "1299:\tlearn: 0.0050254\ttotal: 1m 58s\tremaining: 1m 3s\n",
      "1300:\tlearn: 0.0050244\ttotal: 1m 58s\tremaining: 1m 3s\n",
      "1301:\tlearn: 0.0050240\ttotal: 1m 58s\tremaining: 1m 3s\n",
      "1302:\tlearn: 0.0050219\ttotal: 1m 58s\tremaining: 1m 3s\n",
      "1303:\tlearn: 0.0050215\ttotal: 1m 58s\tremaining: 1m 3s\n",
      "1304:\tlearn: 0.0050195\ttotal: 1m 58s\tremaining: 1m 3s\n",
      "1305:\tlearn: 0.0050176\ttotal: 1m 58s\tremaining: 1m 2s\n",
      "1306:\tlearn: 0.0050152\ttotal: 1m 58s\tremaining: 1m 2s\n",
      "1307:\tlearn: 0.0050116\ttotal: 1m 58s\tremaining: 1m 2s\n",
      "1308:\tlearn: 0.0050091\ttotal: 1m 58s\tremaining: 1m 2s\n",
      "1309:\tlearn: 0.0050085\ttotal: 1m 58s\tremaining: 1m 2s\n",
      "1310:\tlearn: 0.0050079\ttotal: 1m 58s\tremaining: 1m 2s\n",
      "1311:\tlearn: 0.0050060\ttotal: 1m 59s\tremaining: 1m 2s\n",
      "1312:\tlearn: 0.0050027\ttotal: 1m 59s\tremaining: 1m 2s\n",
      "1313:\tlearn: 0.0050018\ttotal: 1m 59s\tremaining: 1m 2s\n",
      "1314:\tlearn: 0.0050005\ttotal: 1m 59s\tremaining: 1m 2s\n",
      "1315:\tlearn: 0.0049956\ttotal: 1m 59s\tremaining: 1m 2s\n",
      "1316:\tlearn: 0.0049951\ttotal: 1m 59s\tremaining: 1m 1s\n",
      "1317:\tlearn: 0.0049928\ttotal: 1m 59s\tremaining: 1m 1s\n",
      "1318:\tlearn: 0.0049873\ttotal: 1m 59s\tremaining: 1m 1s\n",
      "1319:\tlearn: 0.0049836\ttotal: 1m 59s\tremaining: 1m 1s\n",
      "1320:\tlearn: 0.0049794\ttotal: 1m 59s\tremaining: 1m 1s\n",
      "1321:\tlearn: 0.0049788\ttotal: 1m 59s\tremaining: 1m 1s\n",
      "1322:\tlearn: 0.0049785\ttotal: 2m\tremaining: 1m 1s\n",
      "1323:\tlearn: 0.0049768\ttotal: 2m\tremaining: 1m 1s\n",
      "1324:\tlearn: 0.0049761\ttotal: 2m\tremaining: 1m 1s\n",
      "1325:\tlearn: 0.0049683\ttotal: 2m\tremaining: 1m 1s\n",
      "1326:\tlearn: 0.0049641\ttotal: 2m\tremaining: 1m 1s\n",
      "1327:\tlearn: 0.0049557\ttotal: 2m\tremaining: 1m\n",
      "1328:\tlearn: 0.0049520\ttotal: 2m\tremaining: 1m\n",
      "1329:\tlearn: 0.0049511\ttotal: 2m\tremaining: 1m\n",
      "1330:\tlearn: 0.0049486\ttotal: 2m\tremaining: 1m\n",
      "1331:\tlearn: 0.0049469\ttotal: 2m\tremaining: 1m\n",
      "1332:\tlearn: 0.0049460\ttotal: 2m\tremaining: 1m\n",
      "1333:\tlearn: 0.0049411\ttotal: 2m 1s\tremaining: 1m\n",
      "1334:\tlearn: 0.0049400\ttotal: 2m 1s\tremaining: 1m\n",
      "1335:\tlearn: 0.0049393\ttotal: 2m 1s\tremaining: 1m\n",
      "1336:\tlearn: 0.0049382\ttotal: 2m 1s\tremaining: 1m\n",
      "1337:\tlearn: 0.0049367\ttotal: 2m 1s\tremaining: 1m\n",
      "1338:\tlearn: 0.0049356\ttotal: 2m 1s\tremaining: 59.9s\n",
      "1339:\tlearn: 0.0049260\ttotal: 2m 1s\tremaining: 59.9s\n",
      "1340:\tlearn: 0.0049245\ttotal: 2m 1s\tremaining: 59.8s\n",
      "1341:\tlearn: 0.0049237\ttotal: 2m 1s\tremaining: 59.7s\n",
      "1342:\tlearn: 0.0049207\ttotal: 2m 1s\tremaining: 59.6s\n",
      "1343:\tlearn: 0.0049204\ttotal: 2m 1s\tremaining: 59.5s\n",
      "1344:\tlearn: 0.0049195\ttotal: 2m 1s\tremaining: 59.4s\n",
      "1345:\tlearn: 0.0049177\ttotal: 2m 2s\tremaining: 59.3s\n",
      "1346:\tlearn: 0.0049170\ttotal: 2m 2s\tremaining: 59.2s\n",
      "1347:\tlearn: 0.0049146\ttotal: 2m 2s\tremaining: 59.1s\n",
      "1348:\tlearn: 0.0049122\ttotal: 2m 2s\tremaining: 59s\n",
      "1349:\tlearn: 0.0049111\ttotal: 2m 2s\tremaining: 58.9s\n",
      "1350:\tlearn: 0.0049094\ttotal: 2m 2s\tremaining: 58.8s\n",
      "1351:\tlearn: 0.0049036\ttotal: 2m 2s\tremaining: 58.8s\n",
      "1352:\tlearn: 0.0049004\ttotal: 2m 2s\tremaining: 58.7s\n",
      "1353:\tlearn: 0.0048999\ttotal: 2m 2s\tremaining: 58.6s\n",
      "1354:\tlearn: 0.0048981\ttotal: 2m 2s\tremaining: 58.5s\n",
      "1355:\tlearn: 0.0048970\ttotal: 2m 2s\tremaining: 58.4s\n",
      "1356:\tlearn: 0.0048911\ttotal: 2m 2s\tremaining: 58.3s\n",
      "1357:\tlearn: 0.0048891\ttotal: 2m 3s\tremaining: 58.2s\n",
      "1358:\tlearn: 0.0048880\ttotal: 2m 3s\tremaining: 58.1s\n",
      "1359:\tlearn: 0.0048813\ttotal: 2m 3s\tremaining: 58s\n",
      "1360:\tlearn: 0.0048800\ttotal: 2m 3s\tremaining: 57.9s\n",
      "1361:\tlearn: 0.0048760\ttotal: 2m 3s\tremaining: 57.8s\n",
      "1362:\tlearn: 0.0048759\ttotal: 2m 3s\tremaining: 57.7s\n",
      "1363:\tlearn: 0.0048722\ttotal: 2m 3s\tremaining: 57.6s\n",
      "1364:\tlearn: 0.0048669\ttotal: 2m 3s\tremaining: 57.5s\n",
      "1365:\tlearn: 0.0048653\ttotal: 2m 3s\tremaining: 57.5s\n",
      "1366:\tlearn: 0.0048638\ttotal: 2m 3s\tremaining: 57.4s\n",
      "1367:\tlearn: 0.0048637\ttotal: 2m 3s\tremaining: 57.3s\n",
      "1368:\tlearn: 0.0048629\ttotal: 2m 4s\tremaining: 57.2s\n",
      "1369:\tlearn: 0.0048621\ttotal: 2m 4s\tremaining: 57.1s\n",
      "1370:\tlearn: 0.0048578\ttotal: 2m 4s\tremaining: 57s\n",
      "1371:\tlearn: 0.0048552\ttotal: 2m 4s\tremaining: 56.9s\n",
      "1372:\tlearn: 0.0048543\ttotal: 2m 4s\tremaining: 56.8s\n",
      "1373:\tlearn: 0.0048504\ttotal: 2m 4s\tremaining: 56.7s\n",
      "1374:\tlearn: 0.0048490\ttotal: 2m 4s\tremaining: 56.6s\n",
      "1375:\tlearn: 0.0048443\ttotal: 2m 4s\tremaining: 56.5s\n",
      "1376:\tlearn: 0.0048427\ttotal: 2m 4s\tremaining: 56.4s\n",
      "1377:\tlearn: 0.0048388\ttotal: 2m 4s\tremaining: 56.3s\n",
      "1378:\tlearn: 0.0048372\ttotal: 2m 4s\tremaining: 56.2s\n",
      "1379:\tlearn: 0.0048369\ttotal: 2m 4s\tremaining: 56.2s\n",
      "1380:\tlearn: 0.0048342\ttotal: 2m 5s\tremaining: 56.1s\n",
      "1381:\tlearn: 0.0048320\ttotal: 2m 5s\tremaining: 56s\n",
      "1382:\tlearn: 0.0048220\ttotal: 2m 5s\tremaining: 55.9s\n",
      "1383:\tlearn: 0.0048184\ttotal: 2m 5s\tremaining: 55.8s\n",
      "1384:\tlearn: 0.0048165\ttotal: 2m 5s\tremaining: 55.7s\n",
      "1385:\tlearn: 0.0048160\ttotal: 2m 5s\tremaining: 55.6s\n",
      "1386:\tlearn: 0.0048150\ttotal: 2m 5s\tremaining: 55.5s\n",
      "1387:\tlearn: 0.0048127\ttotal: 2m 5s\tremaining: 55.4s\n",
      "1388:\tlearn: 0.0048053\ttotal: 2m 5s\tremaining: 55.3s\n",
      "1389:\tlearn: 0.0048032\ttotal: 2m 5s\tremaining: 55.3s\n",
      "1390:\tlearn: 0.0048006\ttotal: 2m 6s\tremaining: 55.2s\n",
      "1391:\tlearn: 0.0047969\ttotal: 2m 6s\tremaining: 55.1s\n",
      "1392:\tlearn: 0.0047962\ttotal: 2m 6s\tremaining: 55s\n",
      "1393:\tlearn: 0.0047934\ttotal: 2m 6s\tremaining: 54.9s\n",
      "1394:\tlearn: 0.0047901\ttotal: 2m 6s\tremaining: 54.8s\n",
      "1395:\tlearn: 0.0047898\ttotal: 2m 6s\tremaining: 54.7s\n",
      "1396:\tlearn: 0.0047870\ttotal: 2m 6s\tremaining: 54.6s\n",
      "1397:\tlearn: 0.0047821\ttotal: 2m 6s\tremaining: 54.5s\n",
      "1398:\tlearn: 0.0047800\ttotal: 2m 6s\tremaining: 54.4s\n",
      "1399:\tlearn: 0.0047690\ttotal: 2m 6s\tremaining: 54.4s\n",
      "1400:\tlearn: 0.0047637\ttotal: 2m 6s\tremaining: 54.3s\n",
      "1401:\tlearn: 0.0047629\ttotal: 2m 7s\tremaining: 54.2s\n",
      "1402:\tlearn: 0.0047614\ttotal: 2m 7s\tremaining: 54.1s\n",
      "1403:\tlearn: 0.0047521\ttotal: 2m 7s\tremaining: 54s\n",
      "1404:\tlearn: 0.0047515\ttotal: 2m 7s\tremaining: 53.9s\n",
      "1405:\tlearn: 0.0047482\ttotal: 2m 7s\tremaining: 53.8s\n",
      "1406:\tlearn: 0.0047473\ttotal: 2m 7s\tremaining: 53.7s\n",
      "1407:\tlearn: 0.0047442\ttotal: 2m 7s\tremaining: 53.6s\n",
      "1408:\tlearn: 0.0047434\ttotal: 2m 7s\tremaining: 53.5s\n",
      "1409:\tlearn: 0.0047416\ttotal: 2m 7s\tremaining: 53.4s\n",
      "1410:\tlearn: 0.0047397\ttotal: 2m 7s\tremaining: 53.3s\n",
      "1411:\tlearn: 0.0047384\ttotal: 2m 7s\tremaining: 53.3s\n",
      "1412:\tlearn: 0.0047360\ttotal: 2m 7s\tremaining: 53.2s\n",
      "1413:\tlearn: 0.0047348\ttotal: 2m 8s\tremaining: 53.1s\n",
      "1414:\tlearn: 0.0047235\ttotal: 2m 8s\tremaining: 53s\n",
      "1415:\tlearn: 0.0047206\ttotal: 2m 8s\tremaining: 52.9s\n",
      "1416:\tlearn: 0.0047202\ttotal: 2m 8s\tremaining: 52.8s\n",
      "1417:\tlearn: 0.0047188\ttotal: 2m 8s\tremaining: 52.7s\n",
      "1418:\tlearn: 0.0047158\ttotal: 2m 8s\tremaining: 52.6s\n",
      "1419:\tlearn: 0.0047153\ttotal: 2m 8s\tremaining: 52.5s\n",
      "1420:\tlearn: 0.0047151\ttotal: 2m 8s\tremaining: 52.4s\n",
      "1421:\tlearn: 0.0047041\ttotal: 2m 8s\tremaining: 52.3s\n",
      "1422:\tlearn: 0.0047028\ttotal: 2m 8s\tremaining: 52.3s\n",
      "1423:\tlearn: 0.0047024\ttotal: 2m 8s\tremaining: 52.2s\n",
      "1424:\tlearn: 0.0047020\ttotal: 2m 9s\tremaining: 52.1s\n",
      "1425:\tlearn: 0.0046975\ttotal: 2m 9s\tremaining: 52s\n",
      "1426:\tlearn: 0.0046962\ttotal: 2m 9s\tremaining: 51.9s\n",
      "1427:\tlearn: 0.0046907\ttotal: 2m 9s\tremaining: 51.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1428:\tlearn: 0.0046889\ttotal: 2m 9s\tremaining: 51.7s\n",
      "1429:\tlearn: 0.0046857\ttotal: 2m 9s\tremaining: 51.6s\n",
      "1430:\tlearn: 0.0046839\ttotal: 2m 9s\tremaining: 51.5s\n",
      "1431:\tlearn: 0.0046732\ttotal: 2m 9s\tremaining: 51.4s\n",
      "1432:\tlearn: 0.0046725\ttotal: 2m 9s\tremaining: 51.3s\n",
      "1433:\tlearn: 0.0046701\ttotal: 2m 9s\tremaining: 51.2s\n",
      "1434:\tlearn: 0.0046658\ttotal: 2m 9s\tremaining: 51.2s\n",
      "1435:\tlearn: 0.0046608\ttotal: 2m 10s\tremaining: 51.1s\n",
      "1436:\tlearn: 0.0046575\ttotal: 2m 10s\tremaining: 51s\n",
      "1437:\tlearn: 0.0046570\ttotal: 2m 10s\tremaining: 50.9s\n",
      "1438:\tlearn: 0.0046533\ttotal: 2m 10s\tremaining: 50.8s\n",
      "1439:\tlearn: 0.0046517\ttotal: 2m 10s\tremaining: 50.7s\n",
      "1440:\tlearn: 0.0046476\ttotal: 2m 10s\tremaining: 50.6s\n",
      "1441:\tlearn: 0.0046466\ttotal: 2m 10s\tremaining: 50.5s\n",
      "1442:\tlearn: 0.0046406\ttotal: 2m 10s\tremaining: 50.4s\n",
      "1443:\tlearn: 0.0046390\ttotal: 2m 10s\tremaining: 50.3s\n",
      "1444:\tlearn: 0.0046380\ttotal: 2m 10s\tremaining: 50.3s\n",
      "1445:\tlearn: 0.0046365\ttotal: 2m 10s\tremaining: 50.2s\n",
      "1446:\tlearn: 0.0046356\ttotal: 2m 11s\tremaining: 50.1s\n",
      "1447:\tlearn: 0.0046336\ttotal: 2m 11s\tremaining: 50s\n",
      "1448:\tlearn: 0.0046329\ttotal: 2m 11s\tremaining: 49.9s\n",
      "1449:\tlearn: 0.0046324\ttotal: 2m 11s\tremaining: 49.8s\n",
      "1450:\tlearn: 0.0046320\ttotal: 2m 11s\tremaining: 49.7s\n",
      "1451:\tlearn: 0.0046257\ttotal: 2m 11s\tremaining: 49.6s\n",
      "1452:\tlearn: 0.0046246\ttotal: 2m 11s\tremaining: 49.5s\n",
      "1453:\tlearn: 0.0046240\ttotal: 2m 11s\tremaining: 49.4s\n",
      "1454:\tlearn: 0.0046222\ttotal: 2m 11s\tremaining: 49.3s\n",
      "1455:\tlearn: 0.0046193\ttotal: 2m 11s\tremaining: 49.2s\n",
      "1456:\tlearn: 0.0046177\ttotal: 2m 11s\tremaining: 49.1s\n",
      "1457:\tlearn: 0.0046119\ttotal: 2m 11s\tremaining: 49.1s\n",
      "1458:\tlearn: 0.0046098\ttotal: 2m 12s\tremaining: 49s\n",
      "1459:\tlearn: 0.0046092\ttotal: 2m 12s\tremaining: 48.9s\n",
      "1460:\tlearn: 0.0046066\ttotal: 2m 12s\tremaining: 48.8s\n",
      "1461:\tlearn: 0.0046062\ttotal: 2m 12s\tremaining: 48.7s\n",
      "1462:\tlearn: 0.0046053\ttotal: 2m 12s\tremaining: 48.6s\n",
      "1463:\tlearn: 0.0046001\ttotal: 2m 12s\tremaining: 48.5s\n",
      "1464:\tlearn: 0.0045995\ttotal: 2m 12s\tremaining: 48.4s\n",
      "1465:\tlearn: 0.0045991\ttotal: 2m 12s\tremaining: 48.3s\n",
      "1466:\tlearn: 0.0045982\ttotal: 2m 12s\tremaining: 48.2s\n",
      "1467:\tlearn: 0.0045967\ttotal: 2m 12s\tremaining: 48.1s\n",
      "1468:\tlearn: 0.0045943\ttotal: 2m 12s\tremaining: 48s\n",
      "1469:\tlearn: 0.0045925\ttotal: 2m 12s\tremaining: 47.9s\n",
      "1470:\tlearn: 0.0045910\ttotal: 2m 13s\tremaining: 47.9s\n",
      "1471:\tlearn: 0.0045906\ttotal: 2m 13s\tremaining: 47.8s\n",
      "1472:\tlearn: 0.0045900\ttotal: 2m 13s\tremaining: 47.7s\n",
      "1473:\tlearn: 0.0045891\ttotal: 2m 13s\tremaining: 47.6s\n",
      "1474:\tlearn: 0.0045874\ttotal: 2m 13s\tremaining: 47.5s\n",
      "1475:\tlearn: 0.0045863\ttotal: 2m 13s\tremaining: 47.4s\n",
      "1476:\tlearn: 0.0045799\ttotal: 2m 13s\tremaining: 47.3s\n",
      "1477:\tlearn: 0.0045788\ttotal: 2m 13s\tremaining: 47.2s\n",
      "1478:\tlearn: 0.0045764\ttotal: 2m 13s\tremaining: 47.1s\n",
      "1479:\tlearn: 0.0045722\ttotal: 2m 13s\tremaining: 47s\n",
      "1480:\tlearn: 0.0045695\ttotal: 2m 13s\tremaining: 46.9s\n",
      "1481:\tlearn: 0.0045666\ttotal: 2m 14s\tremaining: 46.9s\n",
      "1482:\tlearn: 0.0045618\ttotal: 2m 14s\tremaining: 46.8s\n",
      "1483:\tlearn: 0.0045590\ttotal: 2m 14s\tremaining: 46.7s\n",
      "1484:\tlearn: 0.0045579\ttotal: 2m 14s\tremaining: 46.6s\n",
      "1485:\tlearn: 0.0045549\ttotal: 2m 14s\tremaining: 46.5s\n",
      "1486:\tlearn: 0.0045543\ttotal: 2m 14s\tremaining: 46.4s\n",
      "1487:\tlearn: 0.0045533\ttotal: 2m 14s\tremaining: 46.3s\n",
      "1488:\tlearn: 0.0045518\ttotal: 2m 14s\tremaining: 46.2s\n",
      "1489:\tlearn: 0.0045443\ttotal: 2m 14s\tremaining: 46.1s\n",
      "1490:\tlearn: 0.0045439\ttotal: 2m 14s\tremaining: 46s\n",
      "1491:\tlearn: 0.0045433\ttotal: 2m 14s\tremaining: 45.9s\n",
      "1492:\tlearn: 0.0045413\ttotal: 2m 15s\tremaining: 45.9s\n",
      "1493:\tlearn: 0.0045359\ttotal: 2m 15s\tremaining: 45.8s\n",
      "1494:\tlearn: 0.0045337\ttotal: 2m 15s\tremaining: 45.7s\n",
      "1495:\tlearn: 0.0045330\ttotal: 2m 15s\tremaining: 45.6s\n",
      "1496:\tlearn: 0.0045329\ttotal: 2m 15s\tremaining: 45.5s\n",
      "1497:\tlearn: 0.0045320\ttotal: 2m 15s\tremaining: 45.4s\n",
      "1498:\tlearn: 0.0045251\ttotal: 2m 15s\tremaining: 45.3s\n",
      "1499:\tlearn: 0.0045234\ttotal: 2m 15s\tremaining: 45.2s\n",
      "1500:\tlearn: 0.0045225\ttotal: 2m 15s\tremaining: 45.1s\n",
      "1501:\tlearn: 0.0045186\ttotal: 2m 15s\tremaining: 45s\n",
      "1502:\tlearn: 0.0045181\ttotal: 2m 15s\tremaining: 44.9s\n",
      "1503:\tlearn: 0.0045158\ttotal: 2m 16s\tremaining: 44.9s\n",
      "1504:\tlearn: 0.0045150\ttotal: 2m 16s\tremaining: 44.8s\n",
      "1505:\tlearn: 0.0045142\ttotal: 2m 16s\tremaining: 44.7s\n",
      "1506:\tlearn: 0.0045139\ttotal: 2m 16s\tremaining: 44.6s\n",
      "1507:\tlearn: 0.0045117\ttotal: 2m 16s\tremaining: 44.5s\n",
      "1508:\tlearn: 0.0045111\ttotal: 2m 16s\tremaining: 44.4s\n",
      "1509:\tlearn: 0.0045081\ttotal: 2m 16s\tremaining: 44.3s\n",
      "1510:\tlearn: 0.0045064\ttotal: 2m 16s\tremaining: 44.2s\n",
      "1511:\tlearn: 0.0045058\ttotal: 2m 16s\tremaining: 44.1s\n",
      "1512:\tlearn: 0.0045053\ttotal: 2m 16s\tremaining: 44s\n",
      "1513:\tlearn: 0.0045025\ttotal: 2m 16s\tremaining: 43.9s\n",
      "1514:\tlearn: 0.0045020\ttotal: 2m 16s\tremaining: 43.8s\n",
      "1515:\tlearn: 0.0045013\ttotal: 2m 17s\tremaining: 43.8s\n",
      "1516:\tlearn: 0.0044983\ttotal: 2m 17s\tremaining: 43.7s\n",
      "1517:\tlearn: 0.0044977\ttotal: 2m 17s\tremaining: 43.6s\n",
      "1518:\tlearn: 0.0044932\ttotal: 2m 17s\tremaining: 43.5s\n",
      "1519:\tlearn: 0.0044883\ttotal: 2m 17s\tremaining: 43.4s\n",
      "1520:\tlearn: 0.0044815\ttotal: 2m 17s\tremaining: 43.3s\n",
      "1521:\tlearn: 0.0044784\ttotal: 2m 17s\tremaining: 43.2s\n",
      "1522:\tlearn: 0.0044764\ttotal: 2m 17s\tremaining: 43.1s\n",
      "1523:\tlearn: 0.0044755\ttotal: 2m 17s\tremaining: 43s\n",
      "1524:\tlearn: 0.0044750\ttotal: 2m 17s\tremaining: 42.9s\n",
      "1525:\tlearn: 0.0044706\ttotal: 2m 17s\tremaining: 42.9s\n",
      "1526:\tlearn: 0.0044636\ttotal: 2m 18s\tremaining: 42.8s\n",
      "1527:\tlearn: 0.0044630\ttotal: 2m 18s\tremaining: 42.7s\n",
      "1528:\tlearn: 0.0044597\ttotal: 2m 18s\tremaining: 42.6s\n",
      "1529:\tlearn: 0.0044578\ttotal: 2m 18s\tremaining: 42.5s\n",
      "1530:\tlearn: 0.0044569\ttotal: 2m 18s\tremaining: 42.4s\n",
      "1531:\tlearn: 0.0044564\ttotal: 2m 18s\tremaining: 42.3s\n",
      "1532:\tlearn: 0.0044558\ttotal: 2m 18s\tremaining: 42.2s\n",
      "1533:\tlearn: 0.0044547\ttotal: 2m 18s\tremaining: 42.1s\n",
      "1534:\tlearn: 0.0044529\ttotal: 2m 18s\tremaining: 42s\n",
      "1535:\tlearn: 0.0044527\ttotal: 2m 18s\tremaining: 41.9s\n",
      "1536:\tlearn: 0.0044505\ttotal: 2m 18s\tremaining: 41.8s\n",
      "1537:\tlearn: 0.0044499\ttotal: 2m 18s\tremaining: 41.7s\n",
      "1538:\tlearn: 0.0044494\ttotal: 2m 19s\tremaining: 41.7s\n",
      "1539:\tlearn: 0.0044437\ttotal: 2m 19s\tremaining: 41.6s\n",
      "1540:\tlearn: 0.0044382\ttotal: 2m 19s\tremaining: 41.5s\n",
      "1541:\tlearn: 0.0044378\ttotal: 2m 19s\tremaining: 41.4s\n",
      "1542:\tlearn: 0.0044359\ttotal: 2m 19s\tremaining: 41.3s\n",
      "1543:\tlearn: 0.0044343\ttotal: 2m 19s\tremaining: 41.2s\n",
      "1544:\tlearn: 0.0044322\ttotal: 2m 19s\tremaining: 41.1s\n",
      "1545:\tlearn: 0.0044308\ttotal: 2m 19s\tremaining: 41s\n",
      "1546:\tlearn: 0.0044284\ttotal: 2m 19s\tremaining: 40.9s\n",
      "1547:\tlearn: 0.0044252\ttotal: 2m 19s\tremaining: 40.8s\n",
      "1548:\tlearn: 0.0044242\ttotal: 2m 19s\tremaining: 40.7s\n",
      "1549:\tlearn: 0.0044220\ttotal: 2m 20s\tremaining: 40.7s\n",
      "1550:\tlearn: 0.0044191\ttotal: 2m 20s\tremaining: 40.6s\n",
      "1551:\tlearn: 0.0044189\ttotal: 2m 20s\tremaining: 40.5s\n",
      "1552:\tlearn: 0.0044162\ttotal: 2m 20s\tremaining: 40.4s\n",
      "1553:\tlearn: 0.0044149\ttotal: 2m 20s\tremaining: 40.3s\n",
      "1554:\tlearn: 0.0044144\ttotal: 2m 20s\tremaining: 40.2s\n",
      "1555:\tlearn: 0.0044103\ttotal: 2m 20s\tremaining: 40.1s\n",
      "1556:\tlearn: 0.0044087\ttotal: 2m 20s\tremaining: 40s\n",
      "1557:\tlearn: 0.0044076\ttotal: 2m 20s\tremaining: 39.9s\n",
      "1558:\tlearn: 0.0044067\ttotal: 2m 20s\tremaining: 39.8s\n",
      "1559:\tlearn: 0.0044008\ttotal: 2m 20s\tremaining: 39.7s\n",
      "1560:\tlearn: 0.0043968\ttotal: 2m 20s\tremaining: 39.6s\n",
      "1561:\tlearn: 0.0043952\ttotal: 2m 21s\tremaining: 39.6s\n",
      "1562:\tlearn: 0.0043910\ttotal: 2m 21s\tremaining: 39.5s\n",
      "1563:\tlearn: 0.0043862\ttotal: 2m 21s\tremaining: 39.4s\n",
      "1564:\tlearn: 0.0043857\ttotal: 2m 21s\tremaining: 39.3s\n",
      "1565:\tlearn: 0.0043849\ttotal: 2m 21s\tremaining: 39.2s\n",
      "1566:\tlearn: 0.0043821\ttotal: 2m 21s\tremaining: 39.1s\n",
      "1567:\tlearn: 0.0043796\ttotal: 2m 21s\tremaining: 39s\n",
      "1568:\tlearn: 0.0043788\ttotal: 2m 21s\tremaining: 38.9s\n",
      "1569:\tlearn: 0.0043783\ttotal: 2m 21s\tremaining: 38.8s\n",
      "1570:\tlearn: 0.0043747\ttotal: 2m 21s\tremaining: 38.7s\n",
      "1571:\tlearn: 0.0043739\ttotal: 2m 21s\tremaining: 38.7s\n",
      "1572:\tlearn: 0.0043728\ttotal: 2m 22s\tremaining: 38.6s\n",
      "1573:\tlearn: 0.0043685\ttotal: 2m 22s\tremaining: 38.5s\n",
      "1574:\tlearn: 0.0043651\ttotal: 2m 22s\tremaining: 38.4s\n",
      "1575:\tlearn: 0.0043628\ttotal: 2m 22s\tremaining: 38.3s\n",
      "1576:\tlearn: 0.0043620\ttotal: 2m 22s\tremaining: 38.2s\n",
      "1577:\tlearn: 0.0043558\ttotal: 2m 22s\tremaining: 38.1s\n",
      "1578:\tlearn: 0.0043540\ttotal: 2m 22s\tremaining: 38s\n",
      "1579:\tlearn: 0.0043525\ttotal: 2m 22s\tremaining: 37.9s\n",
      "1580:\tlearn: 0.0043524\ttotal: 2m 22s\tremaining: 37.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1581:\tlearn: 0.0043506\ttotal: 2m 22s\tremaining: 37.7s\n",
      "1582:\tlearn: 0.0043500\ttotal: 2m 22s\tremaining: 37.7s\n",
      "1583:\tlearn: 0.0043489\ttotal: 2m 23s\tremaining: 37.6s\n",
      "1584:\tlearn: 0.0043486\ttotal: 2m 23s\tremaining: 37.5s\n",
      "1585:\tlearn: 0.0043481\ttotal: 2m 23s\tremaining: 37.4s\n",
      "1586:\tlearn: 0.0043471\ttotal: 2m 23s\tremaining: 37.3s\n",
      "1587:\tlearn: 0.0043463\ttotal: 2m 23s\tremaining: 37.2s\n",
      "1588:\tlearn: 0.0043320\ttotal: 2m 23s\tremaining: 37.1s\n",
      "1589:\tlearn: 0.0043313\ttotal: 2m 23s\tremaining: 37s\n",
      "1590:\tlearn: 0.0043286\ttotal: 2m 23s\tremaining: 36.9s\n",
      "1591:\tlearn: 0.0043217\ttotal: 2m 23s\tremaining: 36.8s\n",
      "1592:\tlearn: 0.0043212\ttotal: 2m 23s\tremaining: 36.7s\n",
      "1593:\tlearn: 0.0043155\ttotal: 2m 23s\tremaining: 36.7s\n",
      "1594:\tlearn: 0.0043134\ttotal: 2m 23s\tremaining: 36.6s\n",
      "1595:\tlearn: 0.0043099\ttotal: 2m 24s\tremaining: 36.5s\n",
      "1596:\tlearn: 0.0043092\ttotal: 2m 24s\tremaining: 36.4s\n",
      "1597:\tlearn: 0.0043081\ttotal: 2m 24s\tremaining: 36.3s\n",
      "1598:\tlearn: 0.0043073\ttotal: 2m 24s\tremaining: 36.2s\n",
      "1599:\tlearn: 0.0043021\ttotal: 2m 24s\tremaining: 36.1s\n",
      "1600:\tlearn: 0.0043018\ttotal: 2m 24s\tremaining: 36s\n",
      "1601:\tlearn: 0.0042955\ttotal: 2m 24s\tremaining: 35.9s\n",
      "1602:\tlearn: 0.0042947\ttotal: 2m 24s\tremaining: 35.8s\n",
      "1603:\tlearn: 0.0042943\ttotal: 2m 24s\tremaining: 35.7s\n",
      "1604:\tlearn: 0.0042936\ttotal: 2m 24s\tremaining: 35.7s\n",
      "1605:\tlearn: 0.0042930\ttotal: 2m 24s\tremaining: 35.6s\n",
      "1606:\tlearn: 0.0042877\ttotal: 2m 25s\tremaining: 35.5s\n",
      "1607:\tlearn: 0.0042871\ttotal: 2m 25s\tremaining: 35.4s\n",
      "1608:\tlearn: 0.0042857\ttotal: 2m 25s\tremaining: 35.3s\n",
      "1609:\tlearn: 0.0042855\ttotal: 2m 25s\tremaining: 35.2s\n",
      "1610:\tlearn: 0.0042809\ttotal: 2m 25s\tremaining: 35.1s\n",
      "1611:\tlearn: 0.0042792\ttotal: 2m 25s\tremaining: 35s\n",
      "1612:\tlearn: 0.0042775\ttotal: 2m 25s\tremaining: 34.9s\n",
      "1613:\tlearn: 0.0042744\ttotal: 2m 25s\tremaining: 34.8s\n",
      "1614:\tlearn: 0.0042702\ttotal: 2m 25s\tremaining: 34.7s\n",
      "1615:\tlearn: 0.0042697\ttotal: 2m 25s\tremaining: 34.7s\n",
      "1616:\tlearn: 0.0042685\ttotal: 2m 25s\tremaining: 34.6s\n",
      "1617:\tlearn: 0.0042679\ttotal: 2m 26s\tremaining: 34.5s\n",
      "1618:\tlearn: 0.0042659\ttotal: 2m 26s\tremaining: 34.4s\n",
      "1619:\tlearn: 0.0042619\ttotal: 2m 26s\tremaining: 34.3s\n",
      "1620:\tlearn: 0.0042609\ttotal: 2m 26s\tremaining: 34.2s\n",
      "1621:\tlearn: 0.0042582\ttotal: 2m 26s\tremaining: 34.1s\n",
      "1622:\tlearn: 0.0042558\ttotal: 2m 26s\tremaining: 34s\n",
      "1623:\tlearn: 0.0042498\ttotal: 2m 26s\tremaining: 33.9s\n",
      "1624:\tlearn: 0.0042476\ttotal: 2m 26s\tremaining: 33.8s\n",
      "1625:\tlearn: 0.0042470\ttotal: 2m 26s\tremaining: 33.8s\n",
      "1626:\tlearn: 0.0042469\ttotal: 2m 26s\tremaining: 33.7s\n",
      "1627:\tlearn: 0.0042461\ttotal: 2m 26s\tremaining: 33.6s\n",
      "1628:\tlearn: 0.0042453\ttotal: 2m 26s\tremaining: 33.5s\n",
      "1629:\tlearn: 0.0042451\ttotal: 2m 27s\tremaining: 33.4s\n",
      "1630:\tlearn: 0.0042445\ttotal: 2m 27s\tremaining: 33.3s\n",
      "1631:\tlearn: 0.0042444\ttotal: 2m 27s\tremaining: 33.2s\n",
      "1632:\tlearn: 0.0042420\ttotal: 2m 27s\tremaining: 33.1s\n",
      "1633:\tlearn: 0.0042408\ttotal: 2m 27s\tremaining: 33s\n",
      "1634:\tlearn: 0.0042302\ttotal: 2m 27s\tremaining: 32.9s\n",
      "1635:\tlearn: 0.0042299\ttotal: 2m 27s\tremaining: 32.8s\n",
      "1636:\tlearn: 0.0042288\ttotal: 2m 27s\tremaining: 32.8s\n",
      "1637:\tlearn: 0.0042250\ttotal: 2m 27s\tremaining: 32.7s\n",
      "1638:\tlearn: 0.0042246\ttotal: 2m 27s\tremaining: 32.6s\n",
      "1639:\tlearn: 0.0042231\ttotal: 2m 27s\tremaining: 32.5s\n",
      "1640:\tlearn: 0.0042226\ttotal: 2m 28s\tremaining: 32.4s\n",
      "1641:\tlearn: 0.0042201\ttotal: 2m 28s\tremaining: 32.3s\n",
      "1642:\tlearn: 0.0042166\ttotal: 2m 28s\tremaining: 32.2s\n",
      "1643:\tlearn: 0.0042165\ttotal: 2m 28s\tremaining: 32.1s\n",
      "1644:\tlearn: 0.0042154\ttotal: 2m 28s\tremaining: 32s\n",
      "1645:\tlearn: 0.0042131\ttotal: 2m 28s\tremaining: 31.9s\n",
      "1646:\tlearn: 0.0042125\ttotal: 2m 28s\tremaining: 31.8s\n",
      "1647:\tlearn: 0.0042102\ttotal: 2m 28s\tremaining: 31.7s\n",
      "1648:\tlearn: 0.0042100\ttotal: 2m 28s\tremaining: 31.7s\n",
      "1649:\tlearn: 0.0042065\ttotal: 2m 28s\tremaining: 31.6s\n",
      "1650:\tlearn: 0.0041990\ttotal: 2m 28s\tremaining: 31.5s\n",
      "1651:\tlearn: 0.0041968\ttotal: 2m 28s\tremaining: 31.4s\n",
      "1652:\tlearn: 0.0041954\ttotal: 2m 29s\tremaining: 31.3s\n",
      "1653:\tlearn: 0.0041950\ttotal: 2m 29s\tremaining: 31.2s\n",
      "1654:\tlearn: 0.0041949\ttotal: 2m 29s\tremaining: 31.1s\n",
      "1655:\tlearn: 0.0041940\ttotal: 2m 29s\tremaining: 31s\n",
      "1656:\tlearn: 0.0041918\ttotal: 2m 29s\tremaining: 30.9s\n",
      "1657:\tlearn: 0.0041850\ttotal: 2m 29s\tremaining: 30.8s\n",
      "1658:\tlearn: 0.0041849\ttotal: 2m 29s\tremaining: 30.7s\n",
      "1659:\tlearn: 0.0041841\ttotal: 2m 29s\tremaining: 30.7s\n",
      "1660:\tlearn: 0.0041826\ttotal: 2m 29s\tremaining: 30.6s\n",
      "1661:\tlearn: 0.0041811\ttotal: 2m 29s\tremaining: 30.5s\n",
      "1662:\tlearn: 0.0041806\ttotal: 2m 29s\tremaining: 30.4s\n",
      "1663:\tlearn: 0.0041783\ttotal: 2m 30s\tremaining: 30.3s\n",
      "1664:\tlearn: 0.0041775\ttotal: 2m 30s\tremaining: 30.2s\n",
      "1665:\tlearn: 0.0041764\ttotal: 2m 30s\tremaining: 30.1s\n",
      "1666:\tlearn: 0.0041739\ttotal: 2m 30s\tremaining: 30s\n",
      "1667:\tlearn: 0.0041676\ttotal: 2m 30s\tremaining: 29.9s\n",
      "1668:\tlearn: 0.0041662\ttotal: 2m 30s\tremaining: 29.8s\n",
      "1669:\tlearn: 0.0041651\ttotal: 2m 30s\tremaining: 29.7s\n",
      "1670:\tlearn: 0.0041569\ttotal: 2m 30s\tremaining: 29.7s\n",
      "1671:\tlearn: 0.0041562\ttotal: 2m 30s\tremaining: 29.6s\n",
      "1672:\tlearn: 0.0041552\ttotal: 2m 30s\tremaining: 29.5s\n",
      "1673:\tlearn: 0.0041546\ttotal: 2m 30s\tremaining: 29.4s\n",
      "1674:\tlearn: 0.0041494\ttotal: 2m 30s\tremaining: 29.3s\n",
      "1675:\tlearn: 0.0041451\ttotal: 2m 31s\tremaining: 29.2s\n",
      "1676:\tlearn: 0.0041443\ttotal: 2m 31s\tremaining: 29.1s\n",
      "1677:\tlearn: 0.0041424\ttotal: 2m 31s\tremaining: 29s\n",
      "1678:\tlearn: 0.0041409\ttotal: 2m 31s\tremaining: 28.9s\n",
      "1679:\tlearn: 0.0041407\ttotal: 2m 31s\tremaining: 28.8s\n",
      "1680:\tlearn: 0.0041400\ttotal: 2m 31s\tremaining: 28.8s\n",
      "1681:\tlearn: 0.0041392\ttotal: 2m 31s\tremaining: 28.7s\n",
      "1682:\tlearn: 0.0041368\ttotal: 2m 31s\tremaining: 28.6s\n",
      "1683:\tlearn: 0.0041339\ttotal: 2m 31s\tremaining: 28.5s\n",
      "1684:\tlearn: 0.0041336\ttotal: 2m 31s\tremaining: 28.4s\n",
      "1685:\tlearn: 0.0041330\ttotal: 2m 31s\tremaining: 28.3s\n",
      "1686:\tlearn: 0.0041319\ttotal: 2m 32s\tremaining: 28.2s\n",
      "1687:\tlearn: 0.0041275\ttotal: 2m 32s\tremaining: 28.1s\n",
      "1688:\tlearn: 0.0041255\ttotal: 2m 32s\tremaining: 28s\n",
      "1689:\tlearn: 0.0041234\ttotal: 2m 32s\tremaining: 27.9s\n",
      "1690:\tlearn: 0.0041223\ttotal: 2m 32s\tremaining: 27.8s\n",
      "1691:\tlearn: 0.0041222\ttotal: 2m 32s\tremaining: 27.8s\n",
      "1692:\tlearn: 0.0041217\ttotal: 2m 32s\tremaining: 27.7s\n",
      "1693:\tlearn: 0.0041211\ttotal: 2m 32s\tremaining: 27.6s\n",
      "1694:\tlearn: 0.0041206\ttotal: 2m 32s\tremaining: 27.5s\n",
      "1695:\tlearn: 0.0041197\ttotal: 2m 32s\tremaining: 27.4s\n",
      "1696:\tlearn: 0.0041185\ttotal: 2m 32s\tremaining: 27.3s\n",
      "1697:\tlearn: 0.0041168\ttotal: 2m 32s\tremaining: 27.2s\n",
      "1698:\tlearn: 0.0041161\ttotal: 2m 33s\tremaining: 27.1s\n",
      "1699:\tlearn: 0.0041144\ttotal: 2m 33s\tremaining: 27s\n",
      "1700:\tlearn: 0.0041070\ttotal: 2m 33s\tremaining: 26.9s\n",
      "1701:\tlearn: 0.0041050\ttotal: 2m 33s\tremaining: 26.8s\n",
      "1702:\tlearn: 0.0041038\ttotal: 2m 33s\tremaining: 26.8s\n",
      "1703:\tlearn: 0.0040996\ttotal: 2m 33s\tremaining: 26.7s\n",
      "1704:\tlearn: 0.0040983\ttotal: 2m 33s\tremaining: 26.6s\n",
      "1705:\tlearn: 0.0040954\ttotal: 2m 33s\tremaining: 26.5s\n",
      "1706:\tlearn: 0.0040940\ttotal: 2m 33s\tremaining: 26.4s\n",
      "1707:\tlearn: 0.0040937\ttotal: 2m 33s\tremaining: 26.3s\n",
      "1708:\tlearn: 0.0040932\ttotal: 2m 33s\tremaining: 26.2s\n",
      "1709:\tlearn: 0.0040914\ttotal: 2m 34s\tremaining: 26.1s\n",
      "1710:\tlearn: 0.0040902\ttotal: 2m 34s\tremaining: 26s\n",
      "1711:\tlearn: 0.0040896\ttotal: 2m 34s\tremaining: 25.9s\n",
      "1712:\tlearn: 0.0040874\ttotal: 2m 34s\tremaining: 25.9s\n",
      "1713:\tlearn: 0.0040873\ttotal: 2m 34s\tremaining: 25.8s\n",
      "1714:\tlearn: 0.0040872\ttotal: 2m 34s\tremaining: 25.7s\n",
      "1715:\tlearn: 0.0040865\ttotal: 2m 34s\tremaining: 25.6s\n",
      "1716:\tlearn: 0.0040862\ttotal: 2m 34s\tremaining: 25.5s\n",
      "1717:\tlearn: 0.0040850\ttotal: 2m 34s\tremaining: 25.4s\n",
      "1718:\tlearn: 0.0040829\ttotal: 2m 34s\tremaining: 25.3s\n",
      "1719:\tlearn: 0.0040819\ttotal: 2m 34s\tremaining: 25.2s\n",
      "1720:\tlearn: 0.0040777\ttotal: 2m 34s\tremaining: 25.1s\n",
      "1721:\tlearn: 0.0040769\ttotal: 2m 35s\tremaining: 25s\n",
      "1722:\tlearn: 0.0040766\ttotal: 2m 35s\tremaining: 24.9s\n",
      "1723:\tlearn: 0.0040745\ttotal: 2m 35s\tremaining: 24.9s\n",
      "1724:\tlearn: 0.0040728\ttotal: 2m 35s\tremaining: 24.8s\n",
      "1725:\tlearn: 0.0040728\ttotal: 2m 35s\tremaining: 24.7s\n",
      "1726:\tlearn: 0.0040705\ttotal: 2m 35s\tremaining: 24.6s\n",
      "1727:\tlearn: 0.0040693\ttotal: 2m 35s\tremaining: 24.5s\n",
      "1728:\tlearn: 0.0040608\ttotal: 2m 35s\tremaining: 24.4s\n",
      "1729:\tlearn: 0.0040585\ttotal: 2m 35s\tremaining: 24.3s\n",
      "1730:\tlearn: 0.0040573\ttotal: 2m 35s\tremaining: 24.2s\n",
      "1731:\tlearn: 0.0040569\ttotal: 2m 35s\tremaining: 24.1s\n",
      "1732:\tlearn: 0.0040565\ttotal: 2m 36s\tremaining: 24s\n",
      "1733:\tlearn: 0.0040535\ttotal: 2m 36s\tremaining: 23.9s\n",
      "1734:\tlearn: 0.0040528\ttotal: 2m 36s\tremaining: 23.9s\n",
      "1735:\tlearn: 0.0040473\ttotal: 2m 36s\tremaining: 23.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1736:\tlearn: 0.0040468\ttotal: 2m 36s\tremaining: 23.7s\n",
      "1737:\tlearn: 0.0040427\ttotal: 2m 36s\tremaining: 23.6s\n",
      "1738:\tlearn: 0.0040415\ttotal: 2m 36s\tremaining: 23.5s\n",
      "1739:\tlearn: 0.0040398\ttotal: 2m 36s\tremaining: 23.4s\n",
      "1740:\tlearn: 0.0040387\ttotal: 2m 36s\tremaining: 23.3s\n",
      "1741:\tlearn: 0.0040364\ttotal: 2m 36s\tremaining: 23.2s\n",
      "1742:\tlearn: 0.0040302\ttotal: 2m 36s\tremaining: 23.1s\n",
      "1743:\tlearn: 0.0040302\ttotal: 2m 36s\tremaining: 23s\n",
      "1744:\tlearn: 0.0040300\ttotal: 2m 37s\tremaining: 22.9s\n",
      "1745:\tlearn: 0.0040295\ttotal: 2m 37s\tremaining: 22.9s\n",
      "1746:\tlearn: 0.0040292\ttotal: 2m 37s\tremaining: 22.8s\n",
      "1747:\tlearn: 0.0040258\ttotal: 2m 37s\tremaining: 22.7s\n",
      "1748:\tlearn: 0.0040244\ttotal: 2m 37s\tremaining: 22.6s\n",
      "1749:\tlearn: 0.0040243\ttotal: 2m 37s\tremaining: 22.5s\n",
      "1750:\tlearn: 0.0040229\ttotal: 2m 37s\tremaining: 22.4s\n",
      "1751:\tlearn: 0.0040205\ttotal: 2m 37s\tremaining: 22.3s\n",
      "1752:\tlearn: 0.0040203\ttotal: 2m 37s\tremaining: 22.2s\n",
      "1753:\tlearn: 0.0040192\ttotal: 2m 37s\tremaining: 22.1s\n",
      "1754:\tlearn: 0.0040165\ttotal: 2m 37s\tremaining: 22s\n",
      "1755:\tlearn: 0.0040139\ttotal: 2m 37s\tremaining: 22s\n",
      "1756:\tlearn: 0.0040120\ttotal: 2m 38s\tremaining: 21.9s\n",
      "1757:\tlearn: 0.0040097\ttotal: 2m 38s\tremaining: 21.8s\n",
      "1758:\tlearn: 0.0040085\ttotal: 2m 38s\tremaining: 21.7s\n",
      "1759:\tlearn: 0.0040078\ttotal: 2m 38s\tremaining: 21.6s\n",
      "1760:\tlearn: 0.0040052\ttotal: 2m 38s\tremaining: 21.5s\n",
      "1761:\tlearn: 0.0040038\ttotal: 2m 38s\tremaining: 21.4s\n",
      "1762:\tlearn: 0.0040037\ttotal: 2m 38s\tremaining: 21.3s\n",
      "1763:\tlearn: 0.0040034\ttotal: 2m 38s\tremaining: 21.2s\n",
      "1764:\tlearn: 0.0040019\ttotal: 2m 38s\tremaining: 21.1s\n",
      "1765:\tlearn: 0.0040005\ttotal: 2m 38s\tremaining: 21.1s\n",
      "1766:\tlearn: 0.0039995\ttotal: 2m 38s\tremaining: 21s\n",
      "1767:\tlearn: 0.0039993\ttotal: 2m 39s\tremaining: 20.9s\n",
      "1768:\tlearn: 0.0039983\ttotal: 2m 39s\tremaining: 20.8s\n",
      "1769:\tlearn: 0.0039961\ttotal: 2m 39s\tremaining: 20.7s\n",
      "1770:\tlearn: 0.0039952\ttotal: 2m 39s\tremaining: 20.6s\n",
      "1771:\tlearn: 0.0039931\ttotal: 2m 39s\tremaining: 20.5s\n",
      "1772:\tlearn: 0.0039871\ttotal: 2m 39s\tremaining: 20.4s\n",
      "1773:\tlearn: 0.0039868\ttotal: 2m 39s\tremaining: 20.3s\n",
      "1774:\tlearn: 0.0039867\ttotal: 2m 39s\tremaining: 20.2s\n",
      "1775:\tlearn: 0.0039849\ttotal: 2m 39s\tremaining: 20.2s\n",
      "1776:\tlearn: 0.0039846\ttotal: 2m 39s\tremaining: 20.1s\n",
      "1777:\tlearn: 0.0039823\ttotal: 2m 40s\tremaining: 20s\n",
      "1778:\tlearn: 0.0039801\ttotal: 2m 40s\tremaining: 19.9s\n",
      "1779:\tlearn: 0.0039747\ttotal: 2m 40s\tremaining: 19.8s\n",
      "1780:\tlearn: 0.0039740\ttotal: 2m 40s\tremaining: 19.7s\n",
      "1781:\tlearn: 0.0039685\ttotal: 2m 40s\tremaining: 19.6s\n",
      "1782:\tlearn: 0.0039677\ttotal: 2m 40s\tremaining: 19.5s\n",
      "1783:\tlearn: 0.0039676\ttotal: 2m 40s\tremaining: 19.4s\n",
      "1784:\tlearn: 0.0039669\ttotal: 2m 40s\tremaining: 19.3s\n",
      "1785:\tlearn: 0.0039662\ttotal: 2m 40s\tremaining: 19.3s\n",
      "1786:\tlearn: 0.0039616\ttotal: 2m 40s\tremaining: 19.2s\n",
      "1787:\tlearn: 0.0039591\ttotal: 2m 40s\tremaining: 19.1s\n",
      "1788:\tlearn: 0.0039582\ttotal: 2m 40s\tremaining: 19s\n",
      "1789:\tlearn: 0.0039495\ttotal: 2m 41s\tremaining: 18.9s\n",
      "1790:\tlearn: 0.0039490\ttotal: 2m 41s\tremaining: 18.8s\n",
      "1791:\tlearn: 0.0039445\ttotal: 2m 41s\tremaining: 18.7s\n",
      "1792:\tlearn: 0.0039430\ttotal: 2m 41s\tremaining: 18.6s\n",
      "1793:\tlearn: 0.0039407\ttotal: 2m 41s\tremaining: 18.5s\n",
      "1794:\tlearn: 0.0039403\ttotal: 2m 41s\tremaining: 18.4s\n",
      "1795:\tlearn: 0.0039386\ttotal: 2m 41s\tremaining: 18.4s\n",
      "1796:\tlearn: 0.0039382\ttotal: 2m 41s\tremaining: 18.3s\n",
      "1797:\tlearn: 0.0039345\ttotal: 2m 41s\tremaining: 18.2s\n",
      "1798:\tlearn: 0.0039330\ttotal: 2m 41s\tremaining: 18.1s\n",
      "1799:\tlearn: 0.0039238\ttotal: 2m 42s\tremaining: 18s\n",
      "1800:\tlearn: 0.0039225\ttotal: 2m 42s\tremaining: 17.9s\n",
      "1801:\tlearn: 0.0039213\ttotal: 2m 42s\tremaining: 17.8s\n",
      "1802:\tlearn: 0.0039203\ttotal: 2m 42s\tremaining: 17.7s\n",
      "1803:\tlearn: 0.0039149\ttotal: 2m 42s\tremaining: 17.6s\n",
      "1804:\tlearn: 0.0039140\ttotal: 2m 42s\tremaining: 17.5s\n",
      "1805:\tlearn: 0.0039116\ttotal: 2m 42s\tremaining: 17.5s\n",
      "1806:\tlearn: 0.0039099\ttotal: 2m 42s\tremaining: 17.4s\n",
      "1807:\tlearn: 0.0039092\ttotal: 2m 42s\tremaining: 17.3s\n",
      "1808:\tlearn: 0.0039078\ttotal: 2m 42s\tremaining: 17.2s\n",
      "1809:\tlearn: 0.0039057\ttotal: 2m 42s\tremaining: 17.1s\n",
      "1810:\tlearn: 0.0039043\ttotal: 2m 42s\tremaining: 17s\n",
      "1811:\tlearn: 0.0039040\ttotal: 2m 43s\tremaining: 16.9s\n",
      "1812:\tlearn: 0.0039039\ttotal: 2m 43s\tremaining: 16.8s\n",
      "1813:\tlearn: 0.0039017\ttotal: 2m 43s\tremaining: 16.7s\n",
      "1814:\tlearn: 0.0038996\ttotal: 2m 43s\tremaining: 16.6s\n",
      "1815:\tlearn: 0.0038988\ttotal: 2m 43s\tremaining: 16.6s\n",
      "1816:\tlearn: 0.0038984\ttotal: 2m 43s\tremaining: 16.5s\n",
      "1817:\tlearn: 0.0038983\ttotal: 2m 43s\tremaining: 16.4s\n",
      "1818:\tlearn: 0.0038977\ttotal: 2m 43s\tremaining: 16.3s\n",
      "1819:\tlearn: 0.0038973\ttotal: 2m 43s\tremaining: 16.2s\n",
      "1820:\tlearn: 0.0038962\ttotal: 2m 43s\tremaining: 16.1s\n",
      "1821:\tlearn: 0.0038959\ttotal: 2m 43s\tremaining: 16s\n",
      "1822:\tlearn: 0.0038954\ttotal: 2m 44s\tremaining: 15.9s\n",
      "1823:\tlearn: 0.0038941\ttotal: 2m 44s\tremaining: 15.8s\n",
      "1824:\tlearn: 0.0038936\ttotal: 2m 44s\tremaining: 15.7s\n",
      "1825:\tlearn: 0.0038904\ttotal: 2m 44s\tremaining: 15.7s\n",
      "1826:\tlearn: 0.0038890\ttotal: 2m 44s\tremaining: 15.6s\n",
      "1827:\tlearn: 0.0038861\ttotal: 2m 44s\tremaining: 15.5s\n",
      "1828:\tlearn: 0.0038783\ttotal: 2m 44s\tremaining: 15.4s\n",
      "1829:\tlearn: 0.0038763\ttotal: 2m 44s\tremaining: 15.3s\n",
      "1830:\tlearn: 0.0038703\ttotal: 2m 44s\tremaining: 15.2s\n",
      "1831:\tlearn: 0.0038700\ttotal: 2m 44s\tremaining: 15.1s\n",
      "1832:\tlearn: 0.0038677\ttotal: 2m 44s\tremaining: 15s\n",
      "1833:\tlearn: 0.0038665\ttotal: 2m 45s\tremaining: 14.9s\n",
      "1834:\tlearn: 0.0038657\ttotal: 2m 45s\tremaining: 14.8s\n",
      "1835:\tlearn: 0.0038620\ttotal: 2m 45s\tremaining: 14.8s\n",
      "1836:\tlearn: 0.0038617\ttotal: 2m 45s\tremaining: 14.7s\n",
      "1837:\tlearn: 0.0038611\ttotal: 2m 45s\tremaining: 14.6s\n",
      "1838:\tlearn: 0.0038551\ttotal: 2m 45s\tremaining: 14.5s\n",
      "1839:\tlearn: 0.0038538\ttotal: 2m 45s\tremaining: 14.4s\n",
      "1840:\tlearn: 0.0038524\ttotal: 2m 45s\tremaining: 14.3s\n",
      "1841:\tlearn: 0.0038523\ttotal: 2m 45s\tremaining: 14.2s\n",
      "1842:\tlearn: 0.0038522\ttotal: 2m 45s\tremaining: 14.1s\n",
      "1843:\tlearn: 0.0038521\ttotal: 2m 45s\tremaining: 14s\n",
      "1844:\tlearn: 0.0038508\ttotal: 2m 45s\tremaining: 13.9s\n",
      "1845:\tlearn: 0.0038493\ttotal: 2m 46s\tremaining: 13.9s\n",
      "1846:\tlearn: 0.0038484\ttotal: 2m 46s\tremaining: 13.8s\n",
      "1847:\tlearn: 0.0038429\ttotal: 2m 46s\tremaining: 13.7s\n",
      "1848:\tlearn: 0.0038424\ttotal: 2m 46s\tremaining: 13.6s\n",
      "1849:\tlearn: 0.0038416\ttotal: 2m 46s\tremaining: 13.5s\n",
      "1850:\tlearn: 0.0038415\ttotal: 2m 46s\tremaining: 13.4s\n",
      "1851:\tlearn: 0.0038402\ttotal: 2m 46s\tremaining: 13.3s\n",
      "1852:\tlearn: 0.0038399\ttotal: 2m 46s\tremaining: 13.2s\n",
      "1853:\tlearn: 0.0038348\ttotal: 2m 46s\tremaining: 13.1s\n",
      "1854:\tlearn: 0.0038347\ttotal: 2m 46s\tremaining: 13s\n",
      "1855:\tlearn: 0.0038343\ttotal: 2m 46s\tremaining: 12.9s\n",
      "1856:\tlearn: 0.0038316\ttotal: 2m 46s\tremaining: 12.9s\n",
      "1857:\tlearn: 0.0038312\ttotal: 2m 47s\tremaining: 12.8s\n",
      "1858:\tlearn: 0.0038310\ttotal: 2m 47s\tremaining: 12.7s\n",
      "1859:\tlearn: 0.0038306\ttotal: 2m 47s\tremaining: 12.6s\n",
      "1860:\tlearn: 0.0038233\ttotal: 2m 47s\tremaining: 12.5s\n",
      "1861:\tlearn: 0.0038227\ttotal: 2m 47s\tremaining: 12.4s\n",
      "1862:\tlearn: 0.0038220\ttotal: 2m 47s\tremaining: 12.3s\n",
      "1863:\tlearn: 0.0038212\ttotal: 2m 47s\tremaining: 12.2s\n",
      "1864:\tlearn: 0.0038208\ttotal: 2m 47s\tremaining: 12.1s\n",
      "1865:\tlearn: 0.0038175\ttotal: 2m 47s\tremaining: 12s\n",
      "1866:\tlearn: 0.0038168\ttotal: 2m 47s\tremaining: 12s\n",
      "1867:\tlearn: 0.0038165\ttotal: 2m 47s\tremaining: 11.9s\n",
      "1868:\tlearn: 0.0038085\ttotal: 2m 48s\tremaining: 11.8s\n",
      "1869:\tlearn: 0.0038083\ttotal: 2m 48s\tremaining: 11.7s\n",
      "1870:\tlearn: 0.0038068\ttotal: 2m 48s\tremaining: 11.6s\n",
      "1871:\tlearn: 0.0038042\ttotal: 2m 48s\tremaining: 11.5s\n",
      "1872:\tlearn: 0.0038031\ttotal: 2m 48s\tremaining: 11.4s\n",
      "1873:\tlearn: 0.0037939\ttotal: 2m 48s\tremaining: 11.3s\n",
      "1874:\tlearn: 0.0037919\ttotal: 2m 48s\tremaining: 11.2s\n",
      "1875:\tlearn: 0.0037918\ttotal: 2m 48s\tremaining: 11.1s\n",
      "1876:\tlearn: 0.0037910\ttotal: 2m 48s\tremaining: 11.1s\n",
      "1877:\tlearn: 0.0037906\ttotal: 2m 48s\tremaining: 11s\n",
      "1878:\tlearn: 0.0037904\ttotal: 2m 48s\tremaining: 10.9s\n",
      "1879:\tlearn: 0.0037857\ttotal: 2m 48s\tremaining: 10.8s\n",
      "1880:\tlearn: 0.0037855\ttotal: 2m 49s\tremaining: 10.7s\n",
      "1881:\tlearn: 0.0037791\ttotal: 2m 49s\tremaining: 10.6s\n",
      "1882:\tlearn: 0.0037789\ttotal: 2m 49s\tremaining: 10.5s\n",
      "1883:\tlearn: 0.0037756\ttotal: 2m 49s\tremaining: 10.4s\n",
      "1884:\tlearn: 0.0037755\ttotal: 2m 49s\tremaining: 10.3s\n",
      "1885:\tlearn: 0.0037744\ttotal: 2m 49s\tremaining: 10.2s\n",
      "1886:\tlearn: 0.0037663\ttotal: 2m 49s\tremaining: 10.2s\n",
      "1887:\tlearn: 0.0037640\ttotal: 2m 49s\tremaining: 10.1s\n",
      "1888:\tlearn: 0.0037639\ttotal: 2m 49s\tremaining: 9.97s\n",
      "1889:\tlearn: 0.0037638\ttotal: 2m 49s\tremaining: 9.88s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1890:\tlearn: 0.0037633\ttotal: 2m 49s\tremaining: 9.79s\n",
      "1891:\tlearn: 0.0037630\ttotal: 2m 50s\tremaining: 9.7s\n",
      "1892:\tlearn: 0.0037612\ttotal: 2m 50s\tremaining: 9.61s\n",
      "1893:\tlearn: 0.0037605\ttotal: 2m 50s\tremaining: 9.52s\n",
      "1894:\tlearn: 0.0037599\ttotal: 2m 50s\tremaining: 9.43s\n",
      "1895:\tlearn: 0.0037582\ttotal: 2m 50s\tremaining: 9.34s\n",
      "1896:\tlearn: 0.0037581\ttotal: 2m 50s\tremaining: 9.25s\n",
      "1897:\tlearn: 0.0037564\ttotal: 2m 50s\tremaining: 9.16s\n",
      "1898:\tlearn: 0.0037549\ttotal: 2m 50s\tremaining: 9.07s\n",
      "1899:\tlearn: 0.0037532\ttotal: 2m 50s\tremaining: 8.98s\n",
      "1900:\tlearn: 0.0037478\ttotal: 2m 50s\tremaining: 8.89s\n",
      "1901:\tlearn: 0.0037454\ttotal: 2m 50s\tremaining: 8.8s\n",
      "1902:\tlearn: 0.0037440\ttotal: 2m 50s\tremaining: 8.71s\n",
      "1903:\tlearn: 0.0037437\ttotal: 2m 51s\tremaining: 8.62s\n",
      "1904:\tlearn: 0.0037423\ttotal: 2m 51s\tremaining: 8.53s\n",
      "1905:\tlearn: 0.0037419\ttotal: 2m 51s\tremaining: 8.44s\n",
      "1906:\tlearn: 0.0037415\ttotal: 2m 51s\tremaining: 8.35s\n",
      "1907:\tlearn: 0.0037414\ttotal: 2m 51s\tremaining: 8.26s\n",
      "1908:\tlearn: 0.0037375\ttotal: 2m 51s\tremaining: 8.17s\n",
      "1909:\tlearn: 0.0037370\ttotal: 2m 51s\tremaining: 8.08s\n",
      "1910:\tlearn: 0.0037345\ttotal: 2m 51s\tremaining: 7.99s\n",
      "1911:\tlearn: 0.0037311\ttotal: 2m 51s\tremaining: 7.9s\n",
      "1912:\tlearn: 0.0037293\ttotal: 2m 51s\tremaining: 7.81s\n",
      "1913:\tlearn: 0.0037280\ttotal: 2m 51s\tremaining: 7.72s\n",
      "1914:\tlearn: 0.0037278\ttotal: 2m 51s\tremaining: 7.63s\n",
      "1915:\tlearn: 0.0037266\ttotal: 2m 52s\tremaining: 7.54s\n",
      "1916:\tlearn: 0.0037255\ttotal: 2m 52s\tremaining: 7.45s\n",
      "1917:\tlearn: 0.0037247\ttotal: 2m 52s\tremaining: 7.36s\n",
      "1918:\tlearn: 0.0037210\ttotal: 2m 52s\tremaining: 7.28s\n",
      "1919:\tlearn: 0.0037195\ttotal: 2m 52s\tremaining: 7.18s\n",
      "1920:\tlearn: 0.0037164\ttotal: 2m 52s\tremaining: 7.09s\n",
      "1921:\tlearn: 0.0037160\ttotal: 2m 52s\tremaining: 7s\n",
      "1922:\tlearn: 0.0037154\ttotal: 2m 52s\tremaining: 6.92s\n",
      "1923:\tlearn: 0.0037151\ttotal: 2m 52s\tremaining: 6.82s\n",
      "1924:\tlearn: 0.0037147\ttotal: 2m 52s\tremaining: 6.73s\n",
      "1925:\tlearn: 0.0037145\ttotal: 2m 52s\tremaining: 6.64s\n",
      "1926:\tlearn: 0.0037133\ttotal: 2m 53s\tremaining: 6.55s\n",
      "1927:\tlearn: 0.0037129\ttotal: 2m 53s\tremaining: 6.46s\n",
      "1928:\tlearn: 0.0037128\ttotal: 2m 53s\tremaining: 6.37s\n",
      "1929:\tlearn: 0.0037112\ttotal: 2m 53s\tremaining: 6.28s\n",
      "1930:\tlearn: 0.0037088\ttotal: 2m 53s\tremaining: 6.19s\n",
      "1931:\tlearn: 0.0037075\ttotal: 2m 53s\tremaining: 6.1s\n",
      "1932:\tlearn: 0.0037069\ttotal: 2m 53s\tremaining: 6.01s\n",
      "1933:\tlearn: 0.0037046\ttotal: 2m 53s\tremaining: 5.92s\n",
      "1934:\tlearn: 0.0037031\ttotal: 2m 53s\tremaining: 5.83s\n",
      "1935:\tlearn: 0.0036991\ttotal: 2m 53s\tremaining: 5.75s\n",
      "1936:\tlearn: 0.0036948\ttotal: 2m 53s\tremaining: 5.66s\n",
      "1937:\tlearn: 0.0036935\ttotal: 2m 53s\tremaining: 5.57s\n",
      "1938:\tlearn: 0.0036929\ttotal: 2m 54s\tremaining: 5.48s\n",
      "1939:\tlearn: 0.0036901\ttotal: 2m 54s\tremaining: 5.39s\n",
      "1940:\tlearn: 0.0036883\ttotal: 2m 54s\tremaining: 5.3s\n",
      "1941:\tlearn: 0.0036847\ttotal: 2m 54s\tremaining: 5.21s\n",
      "1942:\tlearn: 0.0036821\ttotal: 2m 54s\tremaining: 5.12s\n",
      "1943:\tlearn: 0.0036820\ttotal: 2m 54s\tremaining: 5.03s\n",
      "1944:\tlearn: 0.0036803\ttotal: 2m 54s\tremaining: 4.94s\n",
      "1945:\tlearn: 0.0036732\ttotal: 2m 54s\tremaining: 4.85s\n",
      "1946:\tlearn: 0.0036728\ttotal: 2m 54s\tremaining: 4.76s\n",
      "1947:\tlearn: 0.0036722\ttotal: 2m 54s\tremaining: 4.67s\n",
      "1948:\tlearn: 0.0036708\ttotal: 2m 54s\tremaining: 4.58s\n",
      "1949:\tlearn: 0.0036683\ttotal: 2m 55s\tremaining: 4.49s\n",
      "1950:\tlearn: 0.0036677\ttotal: 2m 55s\tremaining: 4.4s\n",
      "1951:\tlearn: 0.0036652\ttotal: 2m 55s\tremaining: 4.31s\n",
      "1952:\tlearn: 0.0036641\ttotal: 2m 55s\tremaining: 4.22s\n",
      "1953:\tlearn: 0.0036615\ttotal: 2m 55s\tremaining: 4.13s\n",
      "1954:\tlearn: 0.0036592\ttotal: 2m 55s\tremaining: 4.04s\n",
      "1955:\tlearn: 0.0036581\ttotal: 2m 55s\tremaining: 3.95s\n",
      "1956:\tlearn: 0.0036524\ttotal: 2m 55s\tremaining: 3.86s\n",
      "1957:\tlearn: 0.0036466\ttotal: 2m 55s\tremaining: 3.77s\n",
      "1958:\tlearn: 0.0036425\ttotal: 2m 55s\tremaining: 3.68s\n",
      "1959:\tlearn: 0.0036397\ttotal: 2m 55s\tremaining: 3.59s\n",
      "1960:\tlearn: 0.0036392\ttotal: 2m 56s\tremaining: 3.5s\n",
      "1961:\tlearn: 0.0036384\ttotal: 2m 56s\tremaining: 3.41s\n",
      "1962:\tlearn: 0.0036374\ttotal: 2m 56s\tremaining: 3.32s\n",
      "1963:\tlearn: 0.0036323\ttotal: 2m 56s\tremaining: 3.23s\n",
      "1964:\tlearn: 0.0036321\ttotal: 2m 56s\tremaining: 3.14s\n",
      "1965:\tlearn: 0.0036315\ttotal: 2m 56s\tremaining: 3.05s\n",
      "1966:\tlearn: 0.0036314\ttotal: 2m 56s\tremaining: 2.96s\n",
      "1967:\tlearn: 0.0036307\ttotal: 2m 56s\tremaining: 2.87s\n",
      "1968:\tlearn: 0.0036307\ttotal: 2m 56s\tremaining: 2.78s\n",
      "1969:\tlearn: 0.0036267\ttotal: 2m 56s\tremaining: 2.69s\n",
      "1970:\tlearn: 0.0036258\ttotal: 2m 56s\tremaining: 2.6s\n",
      "1971:\tlearn: 0.0036247\ttotal: 2m 56s\tremaining: 2.51s\n",
      "1972:\tlearn: 0.0036171\ttotal: 2m 57s\tremaining: 2.42s\n",
      "1973:\tlearn: 0.0036161\ttotal: 2m 57s\tremaining: 2.33s\n",
      "1974:\tlearn: 0.0036161\ttotal: 2m 57s\tremaining: 2.24s\n",
      "1975:\tlearn: 0.0036149\ttotal: 2m 57s\tremaining: 2.15s\n",
      "1976:\tlearn: 0.0036093\ttotal: 2m 57s\tremaining: 2.06s\n",
      "1977:\tlearn: 0.0036070\ttotal: 2m 57s\tremaining: 1.97s\n",
      "1978:\tlearn: 0.0036052\ttotal: 2m 57s\tremaining: 1.88s\n",
      "1979:\tlearn: 0.0036039\ttotal: 2m 57s\tremaining: 1.79s\n",
      "1980:\tlearn: 0.0035994\ttotal: 2m 57s\tremaining: 1.71s\n",
      "1981:\tlearn: 0.0035969\ttotal: 2m 57s\tremaining: 1.61s\n",
      "1982:\tlearn: 0.0035962\ttotal: 2m 57s\tremaining: 1.52s\n",
      "1983:\tlearn: 0.0035912\ttotal: 2m 58s\tremaining: 1.44s\n",
      "1984:\tlearn: 0.0035891\ttotal: 2m 58s\tremaining: 1.35s\n",
      "1985:\tlearn: 0.0035853\ttotal: 2m 58s\tremaining: 1.26s\n",
      "1986:\tlearn: 0.0035843\ttotal: 2m 58s\tremaining: 1.17s\n",
      "1987:\tlearn: 0.0035802\ttotal: 2m 58s\tremaining: 1.08s\n",
      "1988:\tlearn: 0.0035785\ttotal: 2m 58s\tremaining: 987ms\n",
      "1989:\tlearn: 0.0035776\ttotal: 2m 58s\tremaining: 897ms\n",
      "1990:\tlearn: 0.0035773\ttotal: 2m 58s\tremaining: 808ms\n",
      "1991:\tlearn: 0.0035762\ttotal: 2m 58s\tremaining: 718ms\n",
      "1992:\tlearn: 0.0035760\ttotal: 2m 58s\tremaining: 628ms\n",
      "1993:\tlearn: 0.0035757\ttotal: 2m 58s\tremaining: 538ms\n",
      "1994:\tlearn: 0.0035750\ttotal: 2m 58s\tremaining: 449ms\n",
      "1995:\tlearn: 0.0035750\ttotal: 2m 59s\tremaining: 359ms\n",
      "1996:\tlearn: 0.0035714\ttotal: 2m 59s\tremaining: 269ms\n",
      "1997:\tlearn: 0.0035713\ttotal: 2m 59s\tremaining: 179ms\n",
      "1998:\tlearn: 0.0035706\ttotal: 2m 59s\tremaining: 89.7ms\n",
      "1999:\tlearn: 0.0035698\ttotal: 2m 59s\tremaining: 0us\n",
      "Learning rate set to 0.035505\n",
      "0:\tlearn: 0.6000868\ttotal: 145ms\tremaining: 4m 49s\n",
      "1:\tlearn: 0.5241477\ttotal: 283ms\tremaining: 4m 42s\n",
      "2:\tlearn: 0.4681056\ttotal: 438ms\tremaining: 4m 51s\n",
      "3:\tlearn: 0.4213016\ttotal: 581ms\tremaining: 4m 50s\n",
      "4:\tlearn: 0.3806713\ttotal: 761ms\tremaining: 5m 3s\n",
      "5:\tlearn: 0.3301165\ttotal: 904ms\tremaining: 5m\n",
      "6:\tlearn: 0.2961750\ttotal: 1.07s\tremaining: 5m 5s\n",
      "7:\tlearn: 0.2718820\ttotal: 1.22s\tremaining: 5m 3s\n",
      "8:\tlearn: 0.2514403\ttotal: 1.37s\tremaining: 5m 2s\n",
      "9:\tlearn: 0.2269247\ttotal: 1.51s\tremaining: 5m\n",
      "10:\tlearn: 0.2097735\ttotal: 1.67s\tremaining: 5m 1s\n",
      "11:\tlearn: 0.1895383\ttotal: 1.79s\tremaining: 4m 57s\n",
      "12:\tlearn: 0.1750784\ttotal: 1.94s\tremaining: 4m 56s\n",
      "13:\tlearn: 0.1634179\ttotal: 2.07s\tremaining: 4m 54s\n",
      "14:\tlearn: 0.1510148\ttotal: 2.23s\tremaining: 4m 54s\n",
      "15:\tlearn: 0.1450186\ttotal: 2.34s\tremaining: 4m 50s\n",
      "16:\tlearn: 0.1364872\ttotal: 2.47s\tremaining: 4m 48s\n",
      "17:\tlearn: 0.1260796\ttotal: 2.62s\tremaining: 4m 48s\n",
      "18:\tlearn: 0.1179746\ttotal: 2.77s\tremaining: 4m 49s\n",
      "19:\tlearn: 0.1115301\ttotal: 2.91s\tremaining: 4m 48s\n",
      "20:\tlearn: 0.1077420\ttotal: 3.06s\tremaining: 4m 47s\n",
      "21:\tlearn: 0.1036824\ttotal: 3.18s\tremaining: 4m 46s\n",
      "22:\tlearn: 0.0983184\ttotal: 3.33s\tremaining: 4m 46s\n",
      "23:\tlearn: 0.0947371\ttotal: 3.45s\tremaining: 4m 43s\n",
      "24:\tlearn: 0.0919134\ttotal: 3.58s\tremaining: 4m 42s\n",
      "25:\tlearn: 0.0893179\ttotal: 3.7s\tremaining: 4m 41s\n",
      "26:\tlearn: 0.0847720\ttotal: 3.85s\tremaining: 4m 41s\n",
      "27:\tlearn: 0.0823513\ttotal: 3.97s\tremaining: 4m 39s\n",
      "28:\tlearn: 0.0796534\ttotal: 4.1s\tremaining: 4m 38s\n",
      "29:\tlearn: 0.0772917\ttotal: 4.23s\tremaining: 4m 37s\n",
      "30:\tlearn: 0.0756741\ttotal: 4.37s\tremaining: 4m 37s\n",
      "31:\tlearn: 0.0730358\ttotal: 4.49s\tremaining: 4m 35s\n",
      "32:\tlearn: 0.0711110\ttotal: 4.63s\tremaining: 4m 36s\n",
      "33:\tlearn: 0.0685594\ttotal: 4.77s\tremaining: 4m 35s\n",
      "34:\tlearn: 0.0660024\ttotal: 4.92s\tremaining: 4m 36s\n",
      "35:\tlearn: 0.0643181\ttotal: 5.04s\tremaining: 4m 35s\n",
      "36:\tlearn: 0.0624541\ttotal: 5.21s\tremaining: 4m 36s\n",
      "37:\tlearn: 0.0606016\ttotal: 5.33s\tremaining: 4m 35s\n",
      "38:\tlearn: 0.0592423\ttotal: 5.48s\tremaining: 4m 35s\n",
      "39:\tlearn: 0.0579157\ttotal: 5.61s\tremaining: 4m 35s\n",
      "40:\tlearn: 0.0564172\ttotal: 5.75s\tremaining: 4m 34s\n",
      "41:\tlearn: 0.0550127\ttotal: 5.87s\tremaining: 4m 33s\n",
      "42:\tlearn: 0.0526402\ttotal: 6.03s\tremaining: 4m 34s\n",
      "43:\tlearn: 0.0515724\ttotal: 6.15s\tremaining: 4m 33s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44:\tlearn: 0.0506941\ttotal: 6.28s\tremaining: 4m 32s\n",
      "45:\tlearn: 0.0499656\ttotal: 6.4s\tremaining: 4m 31s\n",
      "46:\tlearn: 0.0490102\ttotal: 6.53s\tremaining: 4m 31s\n",
      "47:\tlearn: 0.0480195\ttotal: 6.66s\tremaining: 4m 30s\n",
      "48:\tlearn: 0.0472531\ttotal: 6.8s\tremaining: 4m 30s\n",
      "49:\tlearn: 0.0462291\ttotal: 6.93s\tremaining: 4m 30s\n",
      "50:\tlearn: 0.0454507\ttotal: 7.08s\tremaining: 4m 30s\n",
      "51:\tlearn: 0.0443907\ttotal: 7.2s\tremaining: 4m 29s\n",
      "52:\tlearn: 0.0438523\ttotal: 7.33s\tremaining: 4m 29s\n",
      "53:\tlearn: 0.0432902\ttotal: 7.44s\tremaining: 4m 28s\n",
      "54:\tlearn: 0.0428167\ttotal: 7.56s\tremaining: 4m 27s\n",
      "55:\tlearn: 0.0421118\ttotal: 7.69s\tremaining: 4m 26s\n",
      "56:\tlearn: 0.0417062\ttotal: 7.81s\tremaining: 4m 26s\n",
      "57:\tlearn: 0.0408454\ttotal: 7.95s\tremaining: 4m 26s\n",
      "58:\tlearn: 0.0401554\ttotal: 8.09s\tremaining: 4m 26s\n",
      "59:\tlearn: 0.0397413\ttotal: 8.21s\tremaining: 4m 25s\n",
      "60:\tlearn: 0.0392018\ttotal: 8.34s\tremaining: 4m 25s\n",
      "61:\tlearn: 0.0386707\ttotal: 8.48s\tremaining: 4m 25s\n",
      "62:\tlearn: 0.0382902\ttotal: 8.6s\tremaining: 4m 24s\n",
      "63:\tlearn: 0.0377235\ttotal: 8.72s\tremaining: 4m 23s\n",
      "64:\tlearn: 0.0370887\ttotal: 8.86s\tremaining: 4m 23s\n",
      "65:\tlearn: 0.0364842\ttotal: 8.97s\tremaining: 4m 22s\n",
      "66:\tlearn: 0.0362563\ttotal: 9.09s\tremaining: 4m 22s\n",
      "67:\tlearn: 0.0358470\ttotal: 9.21s\tremaining: 4m 21s\n",
      "68:\tlearn: 0.0353673\ttotal: 9.36s\tremaining: 4m 21s\n",
      "69:\tlearn: 0.0351327\ttotal: 9.49s\tremaining: 4m 21s\n",
      "70:\tlearn: 0.0346154\ttotal: 9.62s\tremaining: 4m 21s\n",
      "71:\tlearn: 0.0341679\ttotal: 9.75s\tremaining: 4m 21s\n",
      "72:\tlearn: 0.0337668\ttotal: 9.9s\tremaining: 4m 21s\n",
      "73:\tlearn: 0.0334407\ttotal: 10s\tremaining: 4m 20s\n",
      "74:\tlearn: 0.0328219\ttotal: 10.1s\tremaining: 4m 20s\n",
      "75:\tlearn: 0.0325725\ttotal: 10.3s\tremaining: 4m 19s\n",
      "76:\tlearn: 0.0321652\ttotal: 10.4s\tremaining: 4m 19s\n",
      "77:\tlearn: 0.0318494\ttotal: 10.5s\tremaining: 4m 18s\n",
      "78:\tlearn: 0.0316371\ttotal: 10.6s\tremaining: 4m 18s\n",
      "79:\tlearn: 0.0314469\ttotal: 10.8s\tremaining: 4m 18s\n",
      "80:\tlearn: 0.0312446\ttotal: 10.9s\tremaining: 4m 17s\n",
      "81:\tlearn: 0.0309086\ttotal: 11s\tremaining: 4m 17s\n",
      "82:\tlearn: 0.0306341\ttotal: 11.1s\tremaining: 4m 17s\n",
      "83:\tlearn: 0.0300744\ttotal: 11.3s\tremaining: 4m 17s\n",
      "84:\tlearn: 0.0299223\ttotal: 11.4s\tremaining: 4m 16s\n",
      "85:\tlearn: 0.0295667\ttotal: 11.5s\tremaining: 4m 16s\n",
      "86:\tlearn: 0.0293424\ttotal: 11.6s\tremaining: 4m 16s\n",
      "87:\tlearn: 0.0288696\ttotal: 11.8s\tremaining: 4m 16s\n",
      "88:\tlearn: 0.0283256\ttotal: 11.9s\tremaining: 4m 15s\n",
      "89:\tlearn: 0.0280180\ttotal: 12s\tremaining: 4m 15s\n",
      "90:\tlearn: 0.0277532\ttotal: 12.2s\tremaining: 4m 15s\n",
      "91:\tlearn: 0.0274559\ttotal: 12.3s\tremaining: 4m 14s\n",
      "92:\tlearn: 0.0273480\ttotal: 12.4s\tremaining: 4m 14s\n",
      "93:\tlearn: 0.0272208\ttotal: 12.5s\tremaining: 4m 13s\n",
      "94:\tlearn: 0.0271216\ttotal: 12.6s\tremaining: 4m 13s\n",
      "95:\tlearn: 0.0270528\ttotal: 12.7s\tremaining: 4m 12s\n",
      "96:\tlearn: 0.0268891\ttotal: 12.8s\tremaining: 4m 12s\n",
      "97:\tlearn: 0.0265408\ttotal: 13s\tremaining: 4m 11s\n",
      "98:\tlearn: 0.0263956\ttotal: 13.1s\tremaining: 4m 11s\n",
      "99:\tlearn: 0.0261806\ttotal: 13.2s\tremaining: 4m 11s\n",
      "100:\tlearn: 0.0260883\ttotal: 13.3s\tremaining: 4m 10s\n",
      "101:\tlearn: 0.0260214\ttotal: 13.4s\tremaining: 4m 10s\n",
      "102:\tlearn: 0.0257520\ttotal: 13.6s\tremaining: 4m 10s\n",
      "103:\tlearn: 0.0255180\ttotal: 13.7s\tremaining: 4m 10s\n",
      "104:\tlearn: 0.0254308\ttotal: 13.8s\tremaining: 4m 9s\n",
      "105:\tlearn: 0.0251769\ttotal: 14s\tremaining: 4m 10s\n",
      "106:\tlearn: 0.0250369\ttotal: 14.1s\tremaining: 4m 9s\n",
      "107:\tlearn: 0.0248874\ttotal: 14.2s\tremaining: 4m 9s\n",
      "108:\tlearn: 0.0246365\ttotal: 14.4s\tremaining: 4m 9s\n",
      "109:\tlearn: 0.0243760\ttotal: 14.5s\tremaining: 4m 9s\n",
      "110:\tlearn: 0.0240544\ttotal: 14.6s\tremaining: 4m 9s\n",
      "111:\tlearn: 0.0239316\ttotal: 14.7s\tremaining: 4m 8s\n",
      "112:\tlearn: 0.0237699\ttotal: 14.9s\tremaining: 4m 8s\n",
      "113:\tlearn: 0.0237016\ttotal: 15s\tremaining: 4m 7s\n",
      "114:\tlearn: 0.0235006\ttotal: 15.1s\tremaining: 4m 7s\n",
      "115:\tlearn: 0.0233992\ttotal: 15.2s\tremaining: 4m 7s\n",
      "116:\tlearn: 0.0232766\ttotal: 15.4s\tremaining: 4m 7s\n",
      "117:\tlearn: 0.0231673\ttotal: 15.5s\tremaining: 4m 6s\n",
      "118:\tlearn: 0.0230993\ttotal: 15.6s\tremaining: 4m 6s\n",
      "119:\tlearn: 0.0229127\ttotal: 15.7s\tremaining: 4m 5s\n",
      "120:\tlearn: 0.0228041\ttotal: 15.8s\tremaining: 4m 5s\n",
      "121:\tlearn: 0.0227000\ttotal: 15.9s\tremaining: 4m 5s\n",
      "122:\tlearn: 0.0225640\ttotal: 16s\tremaining: 4m 4s\n",
      "123:\tlearn: 0.0224992\ttotal: 16.1s\tremaining: 4m 4s\n",
      "124:\tlearn: 0.0223470\ttotal: 16.3s\tremaining: 4m 4s\n",
      "125:\tlearn: 0.0222220\ttotal: 16.4s\tremaining: 4m 3s\n",
      "126:\tlearn: 0.0221608\ttotal: 16.5s\tremaining: 4m 3s\n",
      "127:\tlearn: 0.0220966\ttotal: 16.6s\tremaining: 4m 2s\n",
      "128:\tlearn: 0.0218717\ttotal: 16.7s\tremaining: 4m 2s\n",
      "129:\tlearn: 0.0217847\ttotal: 16.8s\tremaining: 4m 2s\n",
      "130:\tlearn: 0.0216404\ttotal: 17s\tremaining: 4m 2s\n",
      "131:\tlearn: 0.0215916\ttotal: 17.1s\tremaining: 4m 1s\n",
      "132:\tlearn: 0.0215088\ttotal: 17.2s\tremaining: 4m 1s\n",
      "133:\tlearn: 0.0213973\ttotal: 17.3s\tremaining: 4m\n",
      "134:\tlearn: 0.0213242\ttotal: 17.4s\tremaining: 4m\n",
      "135:\tlearn: 0.0211895\ttotal: 17.5s\tremaining: 4m\n",
      "136:\tlearn: 0.0211285\ttotal: 17.6s\tremaining: 3m 59s\n",
      "137:\tlearn: 0.0210652\ttotal: 17.7s\tremaining: 3m 59s\n",
      "138:\tlearn: 0.0209425\ttotal: 17.9s\tremaining: 3m 59s\n",
      "139:\tlearn: 0.0207935\ttotal: 18s\tremaining: 3m 59s\n",
      "140:\tlearn: 0.0206106\ttotal: 18.1s\tremaining: 3m 59s\n",
      "141:\tlearn: 0.0205208\ttotal: 18.3s\tremaining: 3m 58s\n",
      "142:\tlearn: 0.0203549\ttotal: 18.4s\tremaining: 3m 58s\n",
      "143:\tlearn: 0.0203141\ttotal: 18.5s\tremaining: 3m 58s\n",
      "144:\tlearn: 0.0202673\ttotal: 18.6s\tremaining: 3m 58s\n",
      "145:\tlearn: 0.0201476\ttotal: 18.8s\tremaining: 3m 58s\n",
      "146:\tlearn: 0.0201215\ttotal: 18.9s\tremaining: 3m 57s\n",
      "147:\tlearn: 0.0200539\ttotal: 19s\tremaining: 3m 57s\n",
      "148:\tlearn: 0.0200033\ttotal: 19.1s\tremaining: 3m 57s\n",
      "149:\tlearn: 0.0199609\ttotal: 19.2s\tremaining: 3m 56s\n",
      "150:\tlearn: 0.0199195\ttotal: 19.3s\tremaining: 3m 56s\n",
      "151:\tlearn: 0.0198701\ttotal: 19.4s\tremaining: 3m 56s\n",
      "152:\tlearn: 0.0196887\ttotal: 19.6s\tremaining: 3m 56s\n",
      "153:\tlearn: 0.0196144\ttotal: 19.7s\tremaining: 3m 56s\n",
      "154:\tlearn: 0.0195580\ttotal: 19.8s\tremaining: 3m 55s\n",
      "155:\tlearn: 0.0194685\ttotal: 19.9s\tremaining: 3m 55s\n",
      "156:\tlearn: 0.0194384\ttotal: 20s\tremaining: 3m 55s\n",
      "157:\tlearn: 0.0193475\ttotal: 20.1s\tremaining: 3m 54s\n",
      "158:\tlearn: 0.0192904\ttotal: 20.2s\tremaining: 3m 54s\n",
      "159:\tlearn: 0.0192171\ttotal: 20.4s\tremaining: 3m 54s\n",
      "160:\tlearn: 0.0191134\ttotal: 20.5s\tremaining: 3m 53s\n",
      "161:\tlearn: 0.0190492\ttotal: 20.6s\tremaining: 3m 53s\n",
      "162:\tlearn: 0.0189522\ttotal: 20.7s\tremaining: 3m 53s\n",
      "163:\tlearn: 0.0188838\ttotal: 20.8s\tremaining: 3m 53s\n",
      "164:\tlearn: 0.0188392\ttotal: 20.9s\tremaining: 3m 52s\n",
      "165:\tlearn: 0.0187652\ttotal: 21s\tremaining: 3m 52s\n",
      "166:\tlearn: 0.0186690\ttotal: 21.2s\tremaining: 3m 52s\n",
      "167:\tlearn: 0.0186268\ttotal: 21.3s\tremaining: 3m 52s\n",
      "168:\tlearn: 0.0185946\ttotal: 21.4s\tremaining: 3m 51s\n",
      "169:\tlearn: 0.0185695\ttotal: 21.5s\tremaining: 3m 51s\n",
      "170:\tlearn: 0.0184939\ttotal: 21.6s\tremaining: 3m 51s\n",
      "171:\tlearn: 0.0184340\ttotal: 21.7s\tremaining: 3m 50s\n",
      "172:\tlearn: 0.0184060\ttotal: 21.8s\tremaining: 3m 50s\n",
      "173:\tlearn: 0.0183631\ttotal: 21.9s\tremaining: 3m 50s\n",
      "174:\tlearn: 0.0182929\ttotal: 22.1s\tremaining: 3m 50s\n",
      "175:\tlearn: 0.0181987\ttotal: 22.2s\tremaining: 3m 50s\n",
      "176:\tlearn: 0.0181304\ttotal: 22.3s\tremaining: 3m 49s\n",
      "177:\tlearn: 0.0180294\ttotal: 22.4s\tremaining: 3m 49s\n",
      "178:\tlearn: 0.0179305\ttotal: 22.6s\tremaining: 3m 49s\n",
      "179:\tlearn: 0.0179031\ttotal: 22.7s\tremaining: 3m 49s\n",
      "180:\tlearn: 0.0178586\ttotal: 22.8s\tremaining: 3m 49s\n",
      "181:\tlearn: 0.0178063\ttotal: 22.9s\tremaining: 3m 48s\n",
      "182:\tlearn: 0.0176957\ttotal: 23s\tremaining: 3m 48s\n",
      "183:\tlearn: 0.0176290\ttotal: 23.2s\tremaining: 3m 48s\n",
      "184:\tlearn: 0.0175951\ttotal: 23.3s\tremaining: 3m 48s\n",
      "185:\tlearn: 0.0175390\ttotal: 23.4s\tremaining: 3m 48s\n",
      "186:\tlearn: 0.0175165\ttotal: 23.5s\tremaining: 3m 47s\n",
      "187:\tlearn: 0.0174632\ttotal: 23.6s\tremaining: 3m 47s\n",
      "188:\tlearn: 0.0173485\ttotal: 23.8s\tremaining: 3m 47s\n",
      "189:\tlearn: 0.0173205\ttotal: 23.9s\tremaining: 3m 47s\n",
      "190:\tlearn: 0.0173047\ttotal: 24s\tremaining: 3m 47s\n",
      "191:\tlearn: 0.0172825\ttotal: 24.1s\tremaining: 3m 46s\n",
      "192:\tlearn: 0.0171956\ttotal: 24.2s\tremaining: 3m 46s\n",
      "193:\tlearn: 0.0170995\ttotal: 24.3s\tremaining: 3m 46s\n",
      "194:\tlearn: 0.0170782\ttotal: 24.5s\tremaining: 3m 46s\n",
      "195:\tlearn: 0.0170245\ttotal: 24.6s\tremaining: 3m 46s\n",
      "196:\tlearn: 0.0169738\ttotal: 24.7s\tremaining: 3m 45s\n",
      "197:\tlearn: 0.0168588\ttotal: 24.8s\tremaining: 3m 45s\n",
      "198:\tlearn: 0.0168321\ttotal: 24.9s\tremaining: 3m 45s\n",
      "199:\tlearn: 0.0168252\ttotal: 25s\tremaining: 3m 45s\n",
      "200:\tlearn: 0.0167697\ttotal: 25.1s\tremaining: 3m 44s\n",
      "201:\tlearn: 0.0166816\ttotal: 25.2s\tremaining: 3m 44s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202:\tlearn: 0.0166282\ttotal: 25.4s\tremaining: 3m 44s\n",
      "203:\tlearn: 0.0165799\ttotal: 25.5s\tremaining: 3m 44s\n",
      "204:\tlearn: 0.0164514\ttotal: 25.6s\tremaining: 3m 44s\n",
      "205:\tlearn: 0.0164237\ttotal: 25.7s\tremaining: 3m 43s\n",
      "206:\tlearn: 0.0163488\ttotal: 25.8s\tremaining: 3m 43s\n",
      "207:\tlearn: 0.0163280\ttotal: 25.9s\tremaining: 3m 43s\n",
      "208:\tlearn: 0.0163127\ttotal: 26s\tremaining: 3m 43s\n",
      "209:\tlearn: 0.0162474\ttotal: 26.2s\tremaining: 3m 42s\n",
      "210:\tlearn: 0.0161780\ttotal: 26.3s\tremaining: 3m 42s\n",
      "211:\tlearn: 0.0161583\ttotal: 26.4s\tremaining: 3m 42s\n",
      "212:\tlearn: 0.0161327\ttotal: 26.5s\tremaining: 3m 42s\n",
      "213:\tlearn: 0.0160248\ttotal: 26.6s\tremaining: 3m 42s\n",
      "214:\tlearn: 0.0160144\ttotal: 26.7s\tremaining: 3m 41s\n",
      "215:\tlearn: 0.0159457\ttotal: 26.8s\tremaining: 3m 41s\n",
      "216:\tlearn: 0.0159139\ttotal: 26.9s\tremaining: 3m 41s\n",
      "217:\tlearn: 0.0158856\ttotal: 27s\tremaining: 3m 40s\n",
      "218:\tlearn: 0.0158514\ttotal: 27.1s\tremaining: 3m 40s\n",
      "219:\tlearn: 0.0157802\ttotal: 27.3s\tremaining: 3m 40s\n",
      "220:\tlearn: 0.0157602\ttotal: 27.4s\tremaining: 3m 40s\n",
      "221:\tlearn: 0.0157123\ttotal: 27.5s\tremaining: 3m 40s\n",
      "222:\tlearn: 0.0156622\ttotal: 27.6s\tremaining: 3m 39s\n",
      "223:\tlearn: 0.0155451\ttotal: 27.7s\tremaining: 3m 39s\n",
      "224:\tlearn: 0.0155011\ttotal: 27.9s\tremaining: 3m 39s\n",
      "225:\tlearn: 0.0154697\ttotal: 28s\tremaining: 3m 39s\n",
      "226:\tlearn: 0.0154626\ttotal: 28.1s\tremaining: 3m 39s\n",
      "227:\tlearn: 0.0154494\ttotal: 28.2s\tremaining: 3m 38s\n",
      "228:\tlearn: 0.0154334\ttotal: 28.3s\tremaining: 3m 38s\n",
      "229:\tlearn: 0.0153979\ttotal: 28.4s\tremaining: 3m 38s\n",
      "230:\tlearn: 0.0153841\ttotal: 28.5s\tremaining: 3m 38s\n",
      "231:\tlearn: 0.0153599\ttotal: 28.6s\tremaining: 3m 38s\n",
      "232:\tlearn: 0.0153233\ttotal: 28.7s\tremaining: 3m 37s\n",
      "233:\tlearn: 0.0153096\ttotal: 28.9s\tremaining: 3m 37s\n",
      "234:\tlearn: 0.0152354\ttotal: 29s\tremaining: 3m 38s\n",
      "235:\tlearn: 0.0151845\ttotal: 29.2s\tremaining: 3m 38s\n",
      "236:\tlearn: 0.0151345\ttotal: 29.3s\tremaining: 3m 37s\n",
      "237:\tlearn: 0.0150967\ttotal: 29.5s\tremaining: 3m 38s\n",
      "238:\tlearn: 0.0150462\ttotal: 29.6s\tremaining: 3m 37s\n",
      "239:\tlearn: 0.0150141\ttotal: 29.7s\tremaining: 3m 37s\n",
      "240:\tlearn: 0.0149717\ttotal: 29.8s\tremaining: 3m 37s\n",
      "241:\tlearn: 0.0149054\ttotal: 29.9s\tremaining: 3m 37s\n",
      "242:\tlearn: 0.0148763\ttotal: 30.1s\tremaining: 3m 37s\n",
      "243:\tlearn: 0.0148563\ttotal: 30.2s\tremaining: 3m 37s\n",
      "244:\tlearn: 0.0148502\ttotal: 30.3s\tremaining: 3m 36s\n",
      "245:\tlearn: 0.0148111\ttotal: 30.4s\tremaining: 3m 36s\n",
      "246:\tlearn: 0.0147759\ttotal: 30.5s\tremaining: 3m 36s\n",
      "247:\tlearn: 0.0147338\ttotal: 30.6s\tremaining: 3m 36s\n",
      "248:\tlearn: 0.0146923\ttotal: 30.7s\tremaining: 3m 36s\n",
      "249:\tlearn: 0.0146662\ttotal: 30.8s\tremaining: 3m 35s\n",
      "250:\tlearn: 0.0146411\ttotal: 31s\tremaining: 3m 35s\n",
      "251:\tlearn: 0.0146150\ttotal: 31.1s\tremaining: 3m 35s\n",
      "252:\tlearn: 0.0145487\ttotal: 31.2s\tremaining: 3m 35s\n",
      "253:\tlearn: 0.0144665\ttotal: 31.4s\tremaining: 3m 35s\n",
      "254:\tlearn: 0.0144534\ttotal: 31.5s\tremaining: 3m 35s\n",
      "255:\tlearn: 0.0144250\ttotal: 31.6s\tremaining: 3m 34s\n",
      "256:\tlearn: 0.0143914\ttotal: 31.7s\tremaining: 3m 34s\n",
      "257:\tlearn: 0.0143563\ttotal: 31.8s\tremaining: 3m 34s\n",
      "258:\tlearn: 0.0143271\ttotal: 31.9s\tremaining: 3m 34s\n",
      "259:\tlearn: 0.0143097\ttotal: 32s\tremaining: 3m 34s\n",
      "260:\tlearn: 0.0142679\ttotal: 32.2s\tremaining: 3m 34s\n",
      "261:\tlearn: 0.0142551\ttotal: 32.3s\tremaining: 3m 33s\n",
      "262:\tlearn: 0.0142127\ttotal: 32.4s\tremaining: 3m 33s\n",
      "263:\tlearn: 0.0141672\ttotal: 32.5s\tremaining: 3m 33s\n",
      "264:\tlearn: 0.0141221\ttotal: 32.6s\tremaining: 3m 33s\n",
      "265:\tlearn: 0.0140123\ttotal: 32.8s\tremaining: 3m 33s\n",
      "266:\tlearn: 0.0139735\ttotal: 32.9s\tremaining: 3m 33s\n",
      "267:\tlearn: 0.0139587\ttotal: 33s\tremaining: 3m 33s\n",
      "268:\tlearn: 0.0139115\ttotal: 33.1s\tremaining: 3m 33s\n",
      "269:\tlearn: 0.0138906\ttotal: 33.2s\tremaining: 3m 32s\n",
      "270:\tlearn: 0.0138604\ttotal: 33.3s\tremaining: 3m 32s\n",
      "271:\tlearn: 0.0138472\ttotal: 33.5s\tremaining: 3m 32s\n",
      "272:\tlearn: 0.0138345\ttotal: 33.6s\tremaining: 3m 32s\n",
      "273:\tlearn: 0.0137999\ttotal: 33.7s\tremaining: 3m 32s\n",
      "274:\tlearn: 0.0137556\ttotal: 33.8s\tremaining: 3m 32s\n",
      "275:\tlearn: 0.0137463\ttotal: 33.9s\tremaining: 3m 31s\n",
      "276:\tlearn: 0.0137015\ttotal: 34.1s\tremaining: 3m 31s\n",
      "277:\tlearn: 0.0136777\ttotal: 34.2s\tremaining: 3m 31s\n",
      "278:\tlearn: 0.0136113\ttotal: 34.3s\tremaining: 3m 31s\n",
      "279:\tlearn: 0.0135796\ttotal: 34.4s\tremaining: 3m 31s\n",
      "280:\tlearn: 0.0135747\ttotal: 34.5s\tremaining: 3m 31s\n",
      "281:\tlearn: 0.0135480\ttotal: 34.6s\tremaining: 3m 31s\n",
      "282:\tlearn: 0.0134831\ttotal: 34.8s\tremaining: 3m 30s\n",
      "283:\tlearn: 0.0134433\ttotal: 34.9s\tremaining: 3m 30s\n",
      "284:\tlearn: 0.0134099\ttotal: 35s\tremaining: 3m 30s\n",
      "285:\tlearn: 0.0133728\ttotal: 35.1s\tremaining: 3m 30s\n",
      "286:\tlearn: 0.0133448\ttotal: 35.2s\tremaining: 3m 30s\n",
      "287:\tlearn: 0.0133358\ttotal: 35.3s\tremaining: 3m 30s\n",
      "288:\tlearn: 0.0133024\ttotal: 35.5s\tremaining: 3m 29s\n",
      "289:\tlearn: 0.0132276\ttotal: 35.6s\tremaining: 3m 29s\n",
      "290:\tlearn: 0.0131711\ttotal: 35.7s\tremaining: 3m 29s\n",
      "291:\tlearn: 0.0131037\ttotal: 35.8s\tremaining: 3m 29s\n",
      "292:\tlearn: 0.0130838\ttotal: 36s\tremaining: 3m 29s\n",
      "293:\tlearn: 0.0130378\ttotal: 36.1s\tremaining: 3m 29s\n",
      "294:\tlearn: 0.0130218\ttotal: 36.2s\tremaining: 3m 29s\n",
      "295:\tlearn: 0.0129819\ttotal: 36.3s\tremaining: 3m 29s\n",
      "296:\tlearn: 0.0129734\ttotal: 36.4s\tremaining: 3m 28s\n",
      "297:\tlearn: 0.0129473\ttotal: 36.5s\tremaining: 3m 28s\n",
      "298:\tlearn: 0.0129358\ttotal: 36.6s\tremaining: 3m 28s\n",
      "299:\tlearn: 0.0129228\ttotal: 36.7s\tremaining: 3m 28s\n",
      "300:\tlearn: 0.0128890\ttotal: 36.9s\tremaining: 3m 28s\n",
      "301:\tlearn: 0.0128690\ttotal: 37s\tremaining: 3m 27s\n",
      "302:\tlearn: 0.0128569\ttotal: 37.1s\tremaining: 3m 27s\n",
      "303:\tlearn: 0.0128258\ttotal: 37.2s\tremaining: 3m 27s\n",
      "304:\tlearn: 0.0128145\ttotal: 37.3s\tremaining: 3m 27s\n",
      "305:\tlearn: 0.0128031\ttotal: 37.4s\tremaining: 3m 27s\n",
      "306:\tlearn: 0.0127819\ttotal: 37.5s\tremaining: 3m 27s\n",
      "307:\tlearn: 0.0127222\ttotal: 37.6s\tremaining: 3m 26s\n",
      "308:\tlearn: 0.0127115\ttotal: 37.7s\tremaining: 3m 26s\n",
      "309:\tlearn: 0.0126739\ttotal: 37.9s\tremaining: 3m 26s\n",
      "310:\tlearn: 0.0126583\ttotal: 38s\tremaining: 3m 26s\n",
      "311:\tlearn: 0.0126491\ttotal: 38.1s\tremaining: 3m 26s\n",
      "312:\tlearn: 0.0126412\ttotal: 38.2s\tremaining: 3m 25s\n",
      "313:\tlearn: 0.0126237\ttotal: 38.3s\tremaining: 3m 25s\n",
      "314:\tlearn: 0.0125928\ttotal: 38.4s\tremaining: 3m 25s\n",
      "315:\tlearn: 0.0125843\ttotal: 38.5s\tremaining: 3m 25s\n",
      "316:\tlearn: 0.0125678\ttotal: 38.6s\tremaining: 3m 25s\n",
      "317:\tlearn: 0.0125506\ttotal: 38.8s\tremaining: 3m 25s\n",
      "318:\tlearn: 0.0125209\ttotal: 38.9s\tremaining: 3m 24s\n",
      "319:\tlearn: 0.0125021\ttotal: 39s\tremaining: 3m 24s\n",
      "320:\tlearn: 0.0124703\ttotal: 39.1s\tremaining: 3m 24s\n",
      "321:\tlearn: 0.0124599\ttotal: 39.2s\tremaining: 3m 24s\n",
      "322:\tlearn: 0.0124452\ttotal: 39.3s\tremaining: 3m 24s\n",
      "323:\tlearn: 0.0124317\ttotal: 39.4s\tremaining: 3m 23s\n",
      "324:\tlearn: 0.0124264\ttotal: 39.5s\tremaining: 3m 23s\n",
      "325:\tlearn: 0.0124235\ttotal: 39.6s\tremaining: 3m 23s\n",
      "326:\tlearn: 0.0124148\ttotal: 39.8s\tremaining: 3m 23s\n",
      "327:\tlearn: 0.0123946\ttotal: 39.9s\tremaining: 3m 23s\n",
      "328:\tlearn: 0.0123652\ttotal: 40s\tremaining: 3m 23s\n",
      "329:\tlearn: 0.0123468\ttotal: 40.1s\tremaining: 3m 23s\n",
      "330:\tlearn: 0.0123283\ttotal: 40.2s\tremaining: 3m 22s\n",
      "331:\tlearn: 0.0123125\ttotal: 40.4s\tremaining: 3m 22s\n",
      "332:\tlearn: 0.0123009\ttotal: 40.5s\tremaining: 3m 22s\n",
      "333:\tlearn: 0.0122877\ttotal: 40.6s\tremaining: 3m 22s\n",
      "334:\tlearn: 0.0122772\ttotal: 40.7s\tremaining: 3m 22s\n",
      "335:\tlearn: 0.0122696\ttotal: 40.8s\tremaining: 3m 22s\n",
      "336:\tlearn: 0.0122462\ttotal: 40.9s\tremaining: 3m 22s\n",
      "337:\tlearn: 0.0122217\ttotal: 41.1s\tremaining: 3m 21s\n",
      "338:\tlearn: 0.0122076\ttotal: 41.2s\tremaining: 3m 21s\n",
      "339:\tlearn: 0.0121769\ttotal: 41.3s\tremaining: 3m 21s\n",
      "340:\tlearn: 0.0121524\ttotal: 41.4s\tremaining: 3m 21s\n",
      "341:\tlearn: 0.0121328\ttotal: 41.5s\tremaining: 3m 21s\n",
      "342:\tlearn: 0.0121123\ttotal: 41.7s\tremaining: 3m 21s\n",
      "343:\tlearn: 0.0121089\ttotal: 41.8s\tremaining: 3m 20s\n",
      "344:\tlearn: 0.0120944\ttotal: 41.9s\tremaining: 3m 20s\n",
      "345:\tlearn: 0.0120852\ttotal: 42s\tremaining: 3m 20s\n",
      "346:\tlearn: 0.0120753\ttotal: 42.1s\tremaining: 3m 20s\n",
      "347:\tlearn: 0.0120448\ttotal: 42.2s\tremaining: 3m 20s\n",
      "348:\tlearn: 0.0120013\ttotal: 42.3s\tremaining: 3m 20s\n",
      "349:\tlearn: 0.0119886\ttotal: 42.4s\tremaining: 3m 20s\n",
      "350:\tlearn: 0.0119732\ttotal: 42.6s\tremaining: 3m 20s\n",
      "351:\tlearn: 0.0119699\ttotal: 42.7s\tremaining: 3m 19s\n",
      "352:\tlearn: 0.0119543\ttotal: 42.8s\tremaining: 3m 19s\n",
      "353:\tlearn: 0.0119411\ttotal: 42.9s\tremaining: 3m 19s\n",
      "354:\tlearn: 0.0119250\ttotal: 43s\tremaining: 3m 19s\n",
      "355:\tlearn: 0.0118826\ttotal: 43.2s\tremaining: 3m 19s\n",
      "356:\tlearn: 0.0118709\ttotal: 43.3s\tremaining: 3m 19s\n",
      "357:\tlearn: 0.0118471\ttotal: 43.4s\tremaining: 3m 18s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358:\tlearn: 0.0118424\ttotal: 43.5s\tremaining: 3m 18s\n",
      "359:\tlearn: 0.0118395\ttotal: 43.6s\tremaining: 3m 18s\n",
      "360:\tlearn: 0.0118189\ttotal: 43.7s\tremaining: 3m 18s\n",
      "361:\tlearn: 0.0118064\ttotal: 43.8s\tremaining: 3m 18s\n",
      "362:\tlearn: 0.0118012\ttotal: 43.9s\tremaining: 3m 18s\n",
      "363:\tlearn: 0.0117936\ttotal: 44.1s\tremaining: 3m 17s\n",
      "364:\tlearn: 0.0117655\ttotal: 44.2s\tremaining: 3m 17s\n",
      "365:\tlearn: 0.0117585\ttotal: 44.3s\tremaining: 3m 17s\n",
      "366:\tlearn: 0.0117326\ttotal: 44.4s\tremaining: 3m 17s\n",
      "367:\tlearn: 0.0116876\ttotal: 44.5s\tremaining: 3m 17s\n",
      "368:\tlearn: 0.0116648\ttotal: 44.6s\tremaining: 3m 17s\n",
      "369:\tlearn: 0.0116382\ttotal: 44.8s\tremaining: 3m 17s\n",
      "370:\tlearn: 0.0116300\ttotal: 44.9s\tremaining: 3m 17s\n",
      "371:\tlearn: 0.0116258\ttotal: 45s\tremaining: 3m 16s\n",
      "372:\tlearn: 0.0115957\ttotal: 45.1s\tremaining: 3m 16s\n",
      "373:\tlearn: 0.0115702\ttotal: 45.2s\tremaining: 3m 16s\n",
      "374:\tlearn: 0.0115575\ttotal: 45.3s\tremaining: 3m 16s\n",
      "375:\tlearn: 0.0115375\ttotal: 45.4s\tremaining: 3m 16s\n",
      "376:\tlearn: 0.0115176\ttotal: 45.5s\tremaining: 3m 16s\n",
      "377:\tlearn: 0.0114904\ttotal: 45.7s\tremaining: 3m 15s\n",
      "378:\tlearn: 0.0114898\ttotal: 45.8s\tremaining: 3m 15s\n",
      "379:\tlearn: 0.0114769\ttotal: 45.9s\tremaining: 3m 15s\n",
      "380:\tlearn: 0.0114556\ttotal: 46s\tremaining: 3m 15s\n",
      "381:\tlearn: 0.0114466\ttotal: 46.1s\tremaining: 3m 15s\n",
      "382:\tlearn: 0.0114358\ttotal: 46.2s\tremaining: 3m 15s\n",
      "383:\tlearn: 0.0114268\ttotal: 46.3s\tremaining: 3m 14s\n",
      "384:\tlearn: 0.0114145\ttotal: 46.4s\tremaining: 3m 14s\n",
      "385:\tlearn: 0.0114053\ttotal: 46.5s\tremaining: 3m 14s\n",
      "386:\tlearn: 0.0113910\ttotal: 46.6s\tremaining: 3m 14s\n",
      "387:\tlearn: 0.0113825\ttotal: 46.7s\tremaining: 3m 14s\n",
      "388:\tlearn: 0.0113514\ttotal: 46.9s\tremaining: 3m 14s\n",
      "389:\tlearn: 0.0113312\ttotal: 47s\tremaining: 3m 13s\n",
      "390:\tlearn: 0.0113255\ttotal: 47.1s\tremaining: 3m 13s\n",
      "391:\tlearn: 0.0113131\ttotal: 47.2s\tremaining: 3m 13s\n",
      "392:\tlearn: 0.0112801\ttotal: 47.3s\tremaining: 3m 13s\n",
      "393:\tlearn: 0.0112392\ttotal: 47.5s\tremaining: 3m 13s\n",
      "394:\tlearn: 0.0112129\ttotal: 47.6s\tremaining: 3m 13s\n",
      "395:\tlearn: 0.0111943\ttotal: 47.7s\tremaining: 3m 13s\n",
      "396:\tlearn: 0.0111910\ttotal: 47.8s\tremaining: 3m 13s\n",
      "397:\tlearn: 0.0111475\ttotal: 47.9s\tremaining: 3m 12s\n",
      "398:\tlearn: 0.0111141\ttotal: 48.1s\tremaining: 3m 12s\n",
      "399:\tlearn: 0.0110763\ttotal: 48.2s\tremaining: 3m 12s\n",
      "400:\tlearn: 0.0110570\ttotal: 48.3s\tremaining: 3m 12s\n",
      "401:\tlearn: 0.0110345\ttotal: 48.4s\tremaining: 3m 12s\n",
      "402:\tlearn: 0.0110007\ttotal: 48.6s\tremaining: 3m 12s\n",
      "403:\tlearn: 0.0109954\ttotal: 48.7s\tremaining: 3m 12s\n",
      "404:\tlearn: 0.0109886\ttotal: 48.8s\tremaining: 3m 12s\n",
      "405:\tlearn: 0.0109765\ttotal: 48.9s\tremaining: 3m 11s\n",
      "406:\tlearn: 0.0109542\ttotal: 49s\tremaining: 3m 11s\n",
      "407:\tlearn: 0.0109525\ttotal: 49.1s\tremaining: 3m 11s\n",
      "408:\tlearn: 0.0109334\ttotal: 49.2s\tremaining: 3m 11s\n",
      "409:\tlearn: 0.0109260\ttotal: 49.3s\tremaining: 3m 11s\n",
      "410:\tlearn: 0.0109175\ttotal: 49.4s\tremaining: 3m 11s\n",
      "411:\tlearn: 0.0108864\ttotal: 49.5s\tremaining: 3m 10s\n",
      "412:\tlearn: 0.0108595\ttotal: 49.7s\tremaining: 3m 10s\n",
      "413:\tlearn: 0.0108325\ttotal: 49.8s\tremaining: 3m 10s\n",
      "414:\tlearn: 0.0108252\ttotal: 49.9s\tremaining: 3m 10s\n",
      "415:\tlearn: 0.0108117\ttotal: 50s\tremaining: 3m 10s\n",
      "416:\tlearn: 0.0107960\ttotal: 50.1s\tremaining: 3m 10s\n",
      "417:\tlearn: 0.0107765\ttotal: 50.2s\tremaining: 3m 10s\n",
      "418:\tlearn: 0.0107737\ttotal: 50.3s\tremaining: 3m 9s\n",
      "419:\tlearn: 0.0107548\ttotal: 50.5s\tremaining: 3m 9s\n",
      "420:\tlearn: 0.0107125\ttotal: 50.6s\tremaining: 3m 9s\n",
      "421:\tlearn: 0.0106587\ttotal: 50.7s\tremaining: 3m 9s\n",
      "422:\tlearn: 0.0106309\ttotal: 50.8s\tremaining: 3m 9s\n",
      "423:\tlearn: 0.0106283\ttotal: 50.9s\tremaining: 3m 9s\n",
      "424:\tlearn: 0.0106126\ttotal: 51.1s\tremaining: 3m 9s\n",
      "425:\tlearn: 0.0106051\ttotal: 51.2s\tremaining: 3m 9s\n",
      "426:\tlearn: 0.0105669\ttotal: 51.3s\tremaining: 3m 8s\n",
      "427:\tlearn: 0.0105518\ttotal: 51.4s\tremaining: 3m 8s\n",
      "428:\tlearn: 0.0105407\ttotal: 51.5s\tremaining: 3m 8s\n",
      "429:\tlearn: 0.0105210\ttotal: 51.6s\tremaining: 3m 8s\n",
      "430:\tlearn: 0.0104847\ttotal: 51.8s\tremaining: 3m 8s\n",
      "431:\tlearn: 0.0104551\ttotal: 51.9s\tremaining: 3m 8s\n",
      "432:\tlearn: 0.0104352\ttotal: 52s\tremaining: 3m 8s\n",
      "433:\tlearn: 0.0104239\ttotal: 52.1s\tremaining: 3m 8s\n",
      "434:\tlearn: 0.0104158\ttotal: 52.2s\tremaining: 3m 7s\n",
      "435:\tlearn: 0.0103986\ttotal: 52.4s\tremaining: 3m 7s\n",
      "436:\tlearn: 0.0103909\ttotal: 52.5s\tremaining: 3m 7s\n",
      "437:\tlearn: 0.0103852\ttotal: 52.6s\tremaining: 3m 7s\n",
      "438:\tlearn: 0.0103632\ttotal: 52.7s\tremaining: 3m 7s\n",
      "439:\tlearn: 0.0103593\ttotal: 52.8s\tremaining: 3m 7s\n",
      "440:\tlearn: 0.0103509\ttotal: 52.9s\tremaining: 3m 7s\n",
      "441:\tlearn: 0.0103333\ttotal: 53s\tremaining: 3m 6s\n",
      "442:\tlearn: 0.0103166\ttotal: 53.2s\tremaining: 3m 6s\n",
      "443:\tlearn: 0.0103074\ttotal: 53.3s\tremaining: 3m 6s\n",
      "444:\tlearn: 0.0103017\ttotal: 53.4s\tremaining: 3m 6s\n",
      "445:\tlearn: 0.0102928\ttotal: 53.6s\tremaining: 3m 6s\n",
      "446:\tlearn: 0.0102718\ttotal: 53.7s\tremaining: 3m 6s\n",
      "447:\tlearn: 0.0102561\ttotal: 53.8s\tremaining: 3m 6s\n",
      "448:\tlearn: 0.0102428\ttotal: 53.9s\tremaining: 3m 6s\n",
      "449:\tlearn: 0.0102234\ttotal: 54s\tremaining: 3m 6s\n",
      "450:\tlearn: 0.0101940\ttotal: 54.2s\tremaining: 3m 6s\n",
      "451:\tlearn: 0.0101824\ttotal: 54.3s\tremaining: 3m 5s\n",
      "452:\tlearn: 0.0101623\ttotal: 54.4s\tremaining: 3m 5s\n",
      "453:\tlearn: 0.0101585\ttotal: 54.5s\tremaining: 3m 5s\n",
      "454:\tlearn: 0.0101423\ttotal: 54.6s\tremaining: 3m 5s\n",
      "455:\tlearn: 0.0101225\ttotal: 54.7s\tremaining: 3m 5s\n",
      "456:\tlearn: 0.0101099\ttotal: 54.9s\tremaining: 3m 5s\n",
      "457:\tlearn: 0.0100946\ttotal: 55s\tremaining: 3m 5s\n",
      "458:\tlearn: 0.0100867\ttotal: 55.1s\tremaining: 3m 4s\n",
      "459:\tlearn: 0.0100821\ttotal: 55.2s\tremaining: 3m 4s\n",
      "460:\tlearn: 0.0100762\ttotal: 55.3s\tremaining: 3m 4s\n",
      "461:\tlearn: 0.0100642\ttotal: 55.4s\tremaining: 3m 4s\n",
      "462:\tlearn: 0.0100550\ttotal: 55.5s\tremaining: 3m 4s\n",
      "463:\tlearn: 0.0100372\ttotal: 55.7s\tremaining: 3m 4s\n",
      "464:\tlearn: 0.0100267\ttotal: 55.8s\tremaining: 3m 4s\n",
      "465:\tlearn: 0.0100206\ttotal: 55.9s\tremaining: 3m 3s\n",
      "466:\tlearn: 0.0100139\ttotal: 56s\tremaining: 3m 3s\n",
      "467:\tlearn: 0.0100064\ttotal: 56.1s\tremaining: 3m 3s\n",
      "468:\tlearn: 0.0099857\ttotal: 56.2s\tremaining: 3m 3s\n",
      "469:\tlearn: 0.0099783\ttotal: 56.3s\tremaining: 3m 3s\n",
      "470:\tlearn: 0.0099514\ttotal: 56.4s\tremaining: 3m 3s\n",
      "471:\tlearn: 0.0099135\ttotal: 56.6s\tremaining: 3m 3s\n",
      "472:\tlearn: 0.0099009\ttotal: 56.7s\tremaining: 3m 2s\n",
      "473:\tlearn: 0.0098939\ttotal: 56.8s\tremaining: 3m 2s\n",
      "474:\tlearn: 0.0098845\ttotal: 56.9s\tremaining: 3m 2s\n",
      "475:\tlearn: 0.0098689\ttotal: 57s\tremaining: 3m 2s\n",
      "476:\tlearn: 0.0098569\ttotal: 57.1s\tremaining: 3m 2s\n",
      "477:\tlearn: 0.0098075\ttotal: 57.3s\tremaining: 3m 2s\n",
      "478:\tlearn: 0.0097893\ttotal: 57.4s\tremaining: 3m 2s\n",
      "479:\tlearn: 0.0097798\ttotal: 57.5s\tremaining: 3m 2s\n",
      "480:\tlearn: 0.0097537\ttotal: 57.6s\tremaining: 3m 1s\n",
      "481:\tlearn: 0.0097433\ttotal: 57.7s\tremaining: 3m 1s\n",
      "482:\tlearn: 0.0097329\ttotal: 57.8s\tremaining: 3m 1s\n",
      "483:\tlearn: 0.0097165\ttotal: 57.9s\tremaining: 3m 1s\n",
      "484:\tlearn: 0.0097134\ttotal: 58s\tremaining: 3m 1s\n",
      "485:\tlearn: 0.0096978\ttotal: 58.2s\tremaining: 3m 1s\n",
      "486:\tlearn: 0.0096916\ttotal: 58.3s\tremaining: 3m 1s\n",
      "487:\tlearn: 0.0096738\ttotal: 58.4s\tremaining: 3m\n",
      "488:\tlearn: 0.0096626\ttotal: 58.5s\tremaining: 3m\n",
      "489:\tlearn: 0.0096376\ttotal: 58.6s\tremaining: 3m\n",
      "490:\tlearn: 0.0096322\ttotal: 58.7s\tremaining: 3m\n",
      "491:\tlearn: 0.0096233\ttotal: 58.9s\tremaining: 3m\n",
      "492:\tlearn: 0.0096112\ttotal: 59s\tremaining: 3m\n",
      "493:\tlearn: 0.0095672\ttotal: 59.1s\tremaining: 3m\n",
      "494:\tlearn: 0.0095440\ttotal: 59.3s\tremaining: 3m\n",
      "495:\tlearn: 0.0094889\ttotal: 59.4s\tremaining: 3m\n",
      "496:\tlearn: 0.0094768\ttotal: 59.5s\tremaining: 2m 59s\n",
      "497:\tlearn: 0.0094572\ttotal: 59.6s\tremaining: 2m 59s\n",
      "498:\tlearn: 0.0094389\ttotal: 59.7s\tremaining: 2m 59s\n",
      "499:\tlearn: 0.0094149\ttotal: 59.9s\tremaining: 2m 59s\n",
      "500:\tlearn: 0.0094023\ttotal: 60s\tremaining: 2m 59s\n",
      "501:\tlearn: 0.0093805\ttotal: 1m\tremaining: 2m 59s\n",
      "502:\tlearn: 0.0093588\ttotal: 1m\tremaining: 2m 59s\n",
      "503:\tlearn: 0.0093486\ttotal: 1m\tremaining: 2m 59s\n",
      "504:\tlearn: 0.0093386\ttotal: 1m\tremaining: 2m 58s\n",
      "505:\tlearn: 0.0093355\ttotal: 1m\tremaining: 2m 58s\n",
      "506:\tlearn: 0.0093308\ttotal: 1m\tremaining: 2m 58s\n",
      "507:\tlearn: 0.0093182\ttotal: 1m\tremaining: 2m 58s\n",
      "508:\tlearn: 0.0093084\ttotal: 1m\tremaining: 2m 58s\n",
      "509:\tlearn: 0.0092975\ttotal: 1m 1s\tremaining: 2m 58s\n",
      "510:\tlearn: 0.0092873\ttotal: 1m 1s\tremaining: 2m 58s\n",
      "511:\tlearn: 0.0092808\ttotal: 1m 1s\tremaining: 2m 58s\n",
      "512:\tlearn: 0.0092661\ttotal: 1m 1s\tremaining: 2m 58s\n",
      "513:\tlearn: 0.0092609\ttotal: 1m 1s\tremaining: 2m 58s\n",
      "514:\tlearn: 0.0092484\ttotal: 1m 1s\tremaining: 2m 58s\n",
      "515:\tlearn: 0.0092244\ttotal: 1m 2s\tremaining: 2m 58s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516:\tlearn: 0.0092173\ttotal: 1m 2s\tremaining: 2m 58s\n",
      "517:\tlearn: 0.0092051\ttotal: 1m 2s\tremaining: 2m 58s\n",
      "518:\tlearn: 0.0091729\ttotal: 1m 2s\tremaining: 2m 58s\n",
      "519:\tlearn: 0.0091672\ttotal: 1m 2s\tremaining: 2m 58s\n",
      "520:\tlearn: 0.0091557\ttotal: 1m 2s\tremaining: 2m 58s\n",
      "521:\tlearn: 0.0091490\ttotal: 1m 3s\tremaining: 2m 58s\n",
      "522:\tlearn: 0.0091423\ttotal: 1m 3s\tremaining: 2m 58s\n",
      "523:\tlearn: 0.0091364\ttotal: 1m 3s\tremaining: 2m 58s\n",
      "524:\tlearn: 0.0091318\ttotal: 1m 3s\tremaining: 2m 58s\n",
      "525:\tlearn: 0.0091242\ttotal: 1m 3s\tremaining: 2m 57s\n",
      "526:\tlearn: 0.0091056\ttotal: 1m 3s\tremaining: 2m 57s\n",
      "527:\tlearn: 0.0090998\ttotal: 1m 3s\tremaining: 2m 57s\n",
      "528:\tlearn: 0.0090641\ttotal: 1m 3s\tremaining: 2m 57s\n",
      "529:\tlearn: 0.0090609\ttotal: 1m 3s\tremaining: 2m 57s\n",
      "530:\tlearn: 0.0090405\ttotal: 1m 4s\tremaining: 2m 57s\n",
      "531:\tlearn: 0.0090376\ttotal: 1m 4s\tremaining: 2m 57s\n",
      "532:\tlearn: 0.0090263\ttotal: 1m 4s\tremaining: 2m 57s\n",
      "533:\tlearn: 0.0089981\ttotal: 1m 4s\tremaining: 2m 56s\n",
      "534:\tlearn: 0.0089855\ttotal: 1m 4s\tremaining: 2m 56s\n",
      "535:\tlearn: 0.0089707\ttotal: 1m 4s\tremaining: 2m 56s\n",
      "536:\tlearn: 0.0089596\ttotal: 1m 4s\tremaining: 2m 56s\n",
      "537:\tlearn: 0.0089492\ttotal: 1m 4s\tremaining: 2m 56s\n",
      "538:\tlearn: 0.0089216\ttotal: 1m 5s\tremaining: 2m 56s\n",
      "539:\tlearn: 0.0089074\ttotal: 1m 5s\tremaining: 2m 56s\n",
      "540:\tlearn: 0.0088933\ttotal: 1m 5s\tremaining: 2m 56s\n",
      "541:\tlearn: 0.0088889\ttotal: 1m 5s\tremaining: 2m 55s\n",
      "542:\tlearn: 0.0088742\ttotal: 1m 5s\tremaining: 2m 55s\n",
      "543:\tlearn: 0.0088619\ttotal: 1m 5s\tremaining: 2m 55s\n",
      "544:\tlearn: 0.0088572\ttotal: 1m 5s\tremaining: 2m 55s\n",
      "545:\tlearn: 0.0088457\ttotal: 1m 5s\tremaining: 2m 55s\n",
      "546:\tlearn: 0.0088323\ttotal: 1m 6s\tremaining: 2m 55s\n",
      "547:\tlearn: 0.0088229\ttotal: 1m 6s\tremaining: 2m 55s\n",
      "548:\tlearn: 0.0088171\ttotal: 1m 6s\tremaining: 2m 55s\n",
      "549:\tlearn: 0.0088095\ttotal: 1m 6s\tremaining: 2m 54s\n",
      "550:\tlearn: 0.0088060\ttotal: 1m 6s\tremaining: 2m 54s\n",
      "551:\tlearn: 0.0087984\ttotal: 1m 6s\tremaining: 2m 54s\n",
      "552:\tlearn: 0.0087840\ttotal: 1m 6s\tremaining: 2m 54s\n",
      "553:\tlearn: 0.0087656\ttotal: 1m 6s\tremaining: 2m 54s\n",
      "554:\tlearn: 0.0087568\ttotal: 1m 6s\tremaining: 2m 54s\n",
      "555:\tlearn: 0.0087467\ttotal: 1m 7s\tremaining: 2m 54s\n",
      "556:\tlearn: 0.0087359\ttotal: 1m 7s\tremaining: 2m 54s\n",
      "557:\tlearn: 0.0087224\ttotal: 1m 7s\tremaining: 2m 53s\n",
      "558:\tlearn: 0.0087194\ttotal: 1m 7s\tremaining: 2m 53s\n",
      "559:\tlearn: 0.0087124\ttotal: 1m 7s\tremaining: 2m 53s\n",
      "560:\tlearn: 0.0087082\ttotal: 1m 7s\tremaining: 2m 53s\n",
      "561:\tlearn: 0.0086892\ttotal: 1m 7s\tremaining: 2m 53s\n",
      "562:\tlearn: 0.0086792\ttotal: 1m 7s\tremaining: 2m 53s\n",
      "563:\tlearn: 0.0086757\ttotal: 1m 8s\tremaining: 2m 53s\n",
      "564:\tlearn: 0.0086444\ttotal: 1m 8s\tremaining: 2m 53s\n",
      "565:\tlearn: 0.0086286\ttotal: 1m 8s\tremaining: 2m 52s\n",
      "566:\tlearn: 0.0086215\ttotal: 1m 8s\tremaining: 2m 52s\n",
      "567:\tlearn: 0.0086091\ttotal: 1m 8s\tremaining: 2m 52s\n",
      "568:\tlearn: 0.0086010\ttotal: 1m 8s\tremaining: 2m 52s\n",
      "569:\tlearn: 0.0085884\ttotal: 1m 8s\tremaining: 2m 52s\n",
      "570:\tlearn: 0.0085700\ttotal: 1m 8s\tremaining: 2m 52s\n",
      "571:\tlearn: 0.0085471\ttotal: 1m 8s\tremaining: 2m 52s\n",
      "572:\tlearn: 0.0085447\ttotal: 1m 9s\tremaining: 2m 51s\n",
      "573:\tlearn: 0.0085382\ttotal: 1m 9s\tremaining: 2m 51s\n",
      "574:\tlearn: 0.0085343\ttotal: 1m 9s\tremaining: 2m 51s\n",
      "575:\tlearn: 0.0085242\ttotal: 1m 9s\tremaining: 2m 51s\n",
      "576:\tlearn: 0.0085183\ttotal: 1m 9s\tremaining: 2m 51s\n",
      "577:\tlearn: 0.0084894\ttotal: 1m 9s\tremaining: 2m 51s\n",
      "578:\tlearn: 0.0084881\ttotal: 1m 9s\tremaining: 2m 51s\n",
      "579:\tlearn: 0.0084710\ttotal: 1m 9s\tremaining: 2m 51s\n",
      "580:\tlearn: 0.0084529\ttotal: 1m 9s\tremaining: 2m 50s\n",
      "581:\tlearn: 0.0084434\ttotal: 1m 10s\tremaining: 2m 50s\n",
      "582:\tlearn: 0.0084208\ttotal: 1m 10s\tremaining: 2m 50s\n",
      "583:\tlearn: 0.0084158\ttotal: 1m 10s\tremaining: 2m 50s\n",
      "584:\tlearn: 0.0084065\ttotal: 1m 10s\tremaining: 2m 50s\n",
      "585:\tlearn: 0.0084011\ttotal: 1m 10s\tremaining: 2m 50s\n",
      "586:\tlearn: 0.0083924\ttotal: 1m 10s\tremaining: 2m 50s\n",
      "587:\tlearn: 0.0083819\ttotal: 1m 10s\tremaining: 2m 49s\n",
      "588:\tlearn: 0.0083605\ttotal: 1m 10s\tremaining: 2m 49s\n",
      "589:\tlearn: 0.0083522\ttotal: 1m 11s\tremaining: 2m 49s\n",
      "590:\tlearn: 0.0083417\ttotal: 1m 11s\tremaining: 2m 49s\n",
      "591:\tlearn: 0.0083305\ttotal: 1m 11s\tremaining: 2m 49s\n",
      "592:\tlearn: 0.0083194\ttotal: 1m 11s\tremaining: 2m 49s\n",
      "593:\tlearn: 0.0083154\ttotal: 1m 11s\tremaining: 2m 49s\n",
      "594:\tlearn: 0.0083097\ttotal: 1m 11s\tremaining: 2m 49s\n",
      "595:\tlearn: 0.0082976\ttotal: 1m 11s\tremaining: 2m 48s\n",
      "596:\tlearn: 0.0082932\ttotal: 1m 11s\tremaining: 2m 48s\n",
      "597:\tlearn: 0.0082767\ttotal: 1m 11s\tremaining: 2m 48s\n",
      "598:\tlearn: 0.0082729\ttotal: 1m 12s\tremaining: 2m 48s\n",
      "599:\tlearn: 0.0082626\ttotal: 1m 12s\tremaining: 2m 48s\n",
      "600:\tlearn: 0.0082517\ttotal: 1m 12s\tremaining: 2m 48s\n",
      "601:\tlearn: 0.0082383\ttotal: 1m 12s\tremaining: 2m 48s\n",
      "602:\tlearn: 0.0082356\ttotal: 1m 12s\tremaining: 2m 48s\n",
      "603:\tlearn: 0.0082156\ttotal: 1m 12s\tremaining: 2m 48s\n",
      "604:\tlearn: 0.0082104\ttotal: 1m 12s\tremaining: 2m 47s\n",
      "605:\tlearn: 0.0082008\ttotal: 1m 12s\tremaining: 2m 47s\n",
      "606:\tlearn: 0.0081788\ttotal: 1m 13s\tremaining: 2m 47s\n",
      "607:\tlearn: 0.0081763\ttotal: 1m 13s\tremaining: 2m 47s\n",
      "608:\tlearn: 0.0081463\ttotal: 1m 13s\tremaining: 2m 47s\n",
      "609:\tlearn: 0.0081305\ttotal: 1m 13s\tremaining: 2m 47s\n",
      "610:\tlearn: 0.0081271\ttotal: 1m 13s\tremaining: 2m 47s\n",
      "611:\tlearn: 0.0081187\ttotal: 1m 13s\tremaining: 2m 47s\n",
      "612:\tlearn: 0.0081128\ttotal: 1m 13s\tremaining: 2m 46s\n",
      "613:\tlearn: 0.0081014\ttotal: 1m 13s\tremaining: 2m 46s\n",
      "614:\tlearn: 0.0080853\ttotal: 1m 14s\tremaining: 2m 46s\n",
      "615:\tlearn: 0.0080809\ttotal: 1m 14s\tremaining: 2m 46s\n",
      "616:\tlearn: 0.0080775\ttotal: 1m 14s\tremaining: 2m 46s\n",
      "617:\tlearn: 0.0080762\ttotal: 1m 14s\tremaining: 2m 46s\n",
      "618:\tlearn: 0.0080743\ttotal: 1m 14s\tremaining: 2m 46s\n",
      "619:\tlearn: 0.0080603\ttotal: 1m 14s\tremaining: 2m 46s\n",
      "620:\tlearn: 0.0080554\ttotal: 1m 14s\tremaining: 2m 46s\n",
      "621:\tlearn: 0.0080539\ttotal: 1m 14s\tremaining: 2m 45s\n",
      "622:\tlearn: 0.0080489\ttotal: 1m 14s\tremaining: 2m 45s\n",
      "623:\tlearn: 0.0080128\ttotal: 1m 15s\tremaining: 2m 45s\n",
      "624:\tlearn: 0.0080063\ttotal: 1m 15s\tremaining: 2m 45s\n",
      "625:\tlearn: 0.0080025\ttotal: 1m 15s\tremaining: 2m 45s\n",
      "626:\tlearn: 0.0079905\ttotal: 1m 15s\tremaining: 2m 45s\n",
      "627:\tlearn: 0.0079837\ttotal: 1m 15s\tremaining: 2m 45s\n",
      "628:\tlearn: 0.0079550\ttotal: 1m 15s\tremaining: 2m 44s\n",
      "629:\tlearn: 0.0079464\ttotal: 1m 15s\tremaining: 2m 44s\n",
      "630:\tlearn: 0.0079400\ttotal: 1m 15s\tremaining: 2m 44s\n",
      "631:\tlearn: 0.0079385\ttotal: 1m 16s\tremaining: 2m 44s\n",
      "632:\tlearn: 0.0079301\ttotal: 1m 16s\tremaining: 2m 44s\n",
      "633:\tlearn: 0.0079288\ttotal: 1m 16s\tremaining: 2m 44s\n",
      "634:\tlearn: 0.0079235\ttotal: 1m 16s\tremaining: 2m 44s\n",
      "635:\tlearn: 0.0079198\ttotal: 1m 16s\tremaining: 2m 44s\n",
      "636:\tlearn: 0.0079143\ttotal: 1m 16s\tremaining: 2m 43s\n",
      "637:\tlearn: 0.0079059\ttotal: 1m 16s\tremaining: 2m 43s\n",
      "638:\tlearn: 0.0078952\ttotal: 1m 16s\tremaining: 2m 43s\n",
      "639:\tlearn: 0.0078818\ttotal: 1m 16s\tremaining: 2m 43s\n",
      "640:\tlearn: 0.0078750\ttotal: 1m 17s\tremaining: 2m 43s\n",
      "641:\tlearn: 0.0078640\ttotal: 1m 17s\tremaining: 2m 43s\n",
      "642:\tlearn: 0.0078540\ttotal: 1m 17s\tremaining: 2m 43s\n",
      "643:\tlearn: 0.0078425\ttotal: 1m 17s\tremaining: 2m 43s\n",
      "644:\tlearn: 0.0078396\ttotal: 1m 17s\tremaining: 2m 42s\n",
      "645:\tlearn: 0.0078352\ttotal: 1m 17s\tremaining: 2m 42s\n",
      "646:\tlearn: 0.0078328\ttotal: 1m 17s\tremaining: 2m 42s\n",
      "647:\tlearn: 0.0078240\ttotal: 1m 17s\tremaining: 2m 42s\n",
      "648:\tlearn: 0.0078154\ttotal: 1m 17s\tremaining: 2m 42s\n",
      "649:\tlearn: 0.0078050\ttotal: 1m 18s\tremaining: 2m 42s\n",
      "650:\tlearn: 0.0077987\ttotal: 1m 18s\tremaining: 2m 42s\n",
      "651:\tlearn: 0.0077873\ttotal: 1m 18s\tremaining: 2m 42s\n",
      "652:\tlearn: 0.0077807\ttotal: 1m 18s\tremaining: 2m 41s\n",
      "653:\tlearn: 0.0077743\ttotal: 1m 18s\tremaining: 2m 41s\n",
      "654:\tlearn: 0.0077620\ttotal: 1m 18s\tremaining: 2m 41s\n",
      "655:\tlearn: 0.0077536\ttotal: 1m 18s\tremaining: 2m 41s\n",
      "656:\tlearn: 0.0077464\ttotal: 1m 19s\tremaining: 2m 41s\n",
      "657:\tlearn: 0.0077424\ttotal: 1m 19s\tremaining: 2m 41s\n",
      "658:\tlearn: 0.0077255\ttotal: 1m 19s\tremaining: 2m 41s\n",
      "659:\tlearn: 0.0077228\ttotal: 1m 19s\tremaining: 2m 41s\n",
      "660:\tlearn: 0.0077126\ttotal: 1m 19s\tremaining: 2m 40s\n",
      "661:\tlearn: 0.0077084\ttotal: 1m 19s\tremaining: 2m 40s\n",
      "662:\tlearn: 0.0076958\ttotal: 1m 19s\tremaining: 2m 40s\n",
      "663:\tlearn: 0.0076921\ttotal: 1m 19s\tremaining: 2m 40s\n",
      "664:\tlearn: 0.0076898\ttotal: 1m 19s\tremaining: 2m 40s\n",
      "665:\tlearn: 0.0076813\ttotal: 1m 20s\tremaining: 2m 40s\n",
      "666:\tlearn: 0.0076667\ttotal: 1m 20s\tremaining: 2m 40s\n",
      "667:\tlearn: 0.0076618\ttotal: 1m 20s\tremaining: 2m 40s\n",
      "668:\tlearn: 0.0076587\ttotal: 1m 20s\tremaining: 2m 39s\n",
      "669:\tlearn: 0.0076530\ttotal: 1m 20s\tremaining: 2m 39s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670:\tlearn: 0.0076504\ttotal: 1m 20s\tremaining: 2m 39s\n",
      "671:\tlearn: 0.0076421\ttotal: 1m 20s\tremaining: 2m 39s\n",
      "672:\tlearn: 0.0076328\ttotal: 1m 20s\tremaining: 2m 39s\n",
      "673:\tlearn: 0.0076264\ttotal: 1m 20s\tremaining: 2m 39s\n",
      "674:\tlearn: 0.0076243\ttotal: 1m 21s\tremaining: 2m 39s\n",
      "675:\tlearn: 0.0076007\ttotal: 1m 21s\tremaining: 2m 38s\n",
      "676:\tlearn: 0.0075955\ttotal: 1m 21s\tremaining: 2m 38s\n",
      "677:\tlearn: 0.0075945\ttotal: 1m 21s\tremaining: 2m 38s\n",
      "678:\tlearn: 0.0075898\ttotal: 1m 21s\tremaining: 2m 38s\n",
      "679:\tlearn: 0.0075785\ttotal: 1m 21s\tremaining: 2m 38s\n",
      "680:\tlearn: 0.0075734\ttotal: 1m 21s\tremaining: 2m 38s\n",
      "681:\tlearn: 0.0075563\ttotal: 1m 21s\tremaining: 2m 38s\n",
      "682:\tlearn: 0.0075461\ttotal: 1m 22s\tremaining: 2m 38s\n",
      "683:\tlearn: 0.0075395\ttotal: 1m 22s\tremaining: 2m 38s\n",
      "684:\tlearn: 0.0075270\ttotal: 1m 22s\tremaining: 2m 37s\n",
      "685:\tlearn: 0.0075191\ttotal: 1m 22s\tremaining: 2m 37s\n",
      "686:\tlearn: 0.0075070\ttotal: 1m 22s\tremaining: 2m 37s\n",
      "687:\tlearn: 0.0074878\ttotal: 1m 22s\tremaining: 2m 37s\n",
      "688:\tlearn: 0.0074834\ttotal: 1m 22s\tremaining: 2m 37s\n",
      "689:\tlearn: 0.0074708\ttotal: 1m 22s\tremaining: 2m 37s\n",
      "690:\tlearn: 0.0074682\ttotal: 1m 22s\tremaining: 2m 37s\n",
      "691:\tlearn: 0.0074616\ttotal: 1m 23s\tremaining: 2m 37s\n",
      "692:\tlearn: 0.0074401\ttotal: 1m 23s\tremaining: 2m 36s\n",
      "693:\tlearn: 0.0074351\ttotal: 1m 23s\tremaining: 2m 36s\n",
      "694:\tlearn: 0.0074326\ttotal: 1m 23s\tremaining: 2m 36s\n",
      "695:\tlearn: 0.0074299\ttotal: 1m 23s\tremaining: 2m 36s\n",
      "696:\tlearn: 0.0074271\ttotal: 1m 23s\tremaining: 2m 36s\n",
      "697:\tlearn: 0.0074213\ttotal: 1m 23s\tremaining: 2m 36s\n",
      "698:\tlearn: 0.0074099\ttotal: 1m 23s\tremaining: 2m 36s\n",
      "699:\tlearn: 0.0073993\ttotal: 1m 24s\tremaining: 2m 36s\n",
      "700:\tlearn: 0.0073982\ttotal: 1m 24s\tremaining: 2m 35s\n",
      "701:\tlearn: 0.0073867\ttotal: 1m 24s\tremaining: 2m 35s\n",
      "702:\tlearn: 0.0073787\ttotal: 1m 24s\tremaining: 2m 35s\n",
      "703:\tlearn: 0.0073759\ttotal: 1m 24s\tremaining: 2m 35s\n",
      "704:\tlearn: 0.0073705\ttotal: 1m 24s\tremaining: 2m 35s\n",
      "705:\tlearn: 0.0073610\ttotal: 1m 24s\tremaining: 2m 35s\n",
      "706:\tlearn: 0.0073543\ttotal: 1m 24s\tremaining: 2m 35s\n",
      "707:\tlearn: 0.0073513\ttotal: 1m 24s\tremaining: 2m 34s\n",
      "708:\tlearn: 0.0073486\ttotal: 1m 25s\tremaining: 2m 34s\n",
      "709:\tlearn: 0.0073451\ttotal: 1m 25s\tremaining: 2m 34s\n",
      "710:\tlearn: 0.0073429\ttotal: 1m 25s\tremaining: 2m 34s\n",
      "711:\tlearn: 0.0073183\ttotal: 1m 25s\tremaining: 2m 34s\n",
      "712:\tlearn: 0.0072940\ttotal: 1m 25s\tremaining: 2m 34s\n",
      "713:\tlearn: 0.0072897\ttotal: 1m 25s\tremaining: 2m 34s\n",
      "714:\tlearn: 0.0072854\ttotal: 1m 25s\tremaining: 2m 34s\n",
      "715:\tlearn: 0.0072762\ttotal: 1m 25s\tremaining: 2m 34s\n",
      "716:\tlearn: 0.0072642\ttotal: 1m 26s\tremaining: 2m 33s\n",
      "717:\tlearn: 0.0072568\ttotal: 1m 26s\tremaining: 2m 33s\n",
      "718:\tlearn: 0.0072485\ttotal: 1m 26s\tremaining: 2m 33s\n",
      "719:\tlearn: 0.0072179\ttotal: 1m 26s\tremaining: 2m 33s\n",
      "720:\tlearn: 0.0072108\ttotal: 1m 26s\tremaining: 2m 33s\n",
      "721:\tlearn: 0.0072052\ttotal: 1m 26s\tremaining: 2m 33s\n",
      "722:\tlearn: 0.0072002\ttotal: 1m 26s\tremaining: 2m 33s\n",
      "723:\tlearn: 0.0071828\ttotal: 1m 26s\tremaining: 2m 33s\n",
      "724:\tlearn: 0.0071784\ttotal: 1m 27s\tremaining: 2m 33s\n",
      "725:\tlearn: 0.0071556\ttotal: 1m 27s\tremaining: 2m 32s\n",
      "726:\tlearn: 0.0071519\ttotal: 1m 27s\tremaining: 2m 32s\n",
      "727:\tlearn: 0.0071468\ttotal: 1m 27s\tremaining: 2m 32s\n",
      "728:\tlearn: 0.0071363\ttotal: 1m 27s\tremaining: 2m 32s\n",
      "729:\tlearn: 0.0071333\ttotal: 1m 27s\tremaining: 2m 32s\n",
      "730:\tlearn: 0.0071309\ttotal: 1m 27s\tremaining: 2m 32s\n",
      "731:\tlearn: 0.0071194\ttotal: 1m 27s\tremaining: 2m 32s\n",
      "732:\tlearn: 0.0071138\ttotal: 1m 27s\tremaining: 2m 32s\n",
      "733:\tlearn: 0.0071032\ttotal: 1m 28s\tremaining: 2m 31s\n",
      "734:\tlearn: 0.0071020\ttotal: 1m 28s\tremaining: 2m 31s\n",
      "735:\tlearn: 0.0070916\ttotal: 1m 28s\tremaining: 2m 31s\n",
      "736:\tlearn: 0.0070860\ttotal: 1m 28s\tremaining: 2m 31s\n",
      "737:\tlearn: 0.0070783\ttotal: 1m 28s\tremaining: 2m 31s\n",
      "738:\tlearn: 0.0070613\ttotal: 1m 28s\tremaining: 2m 31s\n",
      "739:\tlearn: 0.0070582\ttotal: 1m 28s\tremaining: 2m 31s\n",
      "740:\tlearn: 0.0070328\ttotal: 1m 28s\tremaining: 2m 31s\n",
      "741:\tlearn: 0.0070293\ttotal: 1m 29s\tremaining: 2m 31s\n",
      "742:\tlearn: 0.0070249\ttotal: 1m 29s\tremaining: 2m 30s\n",
      "743:\tlearn: 0.0070227\ttotal: 1m 29s\tremaining: 2m 30s\n",
      "744:\tlearn: 0.0070212\ttotal: 1m 29s\tremaining: 2m 30s\n",
      "745:\tlearn: 0.0070143\ttotal: 1m 29s\tremaining: 2m 30s\n",
      "746:\tlearn: 0.0070100\ttotal: 1m 29s\tremaining: 2m 30s\n",
      "747:\tlearn: 0.0069997\ttotal: 1m 29s\tremaining: 2m 30s\n",
      "748:\tlearn: 0.0069937\ttotal: 1m 29s\tremaining: 2m 30s\n",
      "749:\tlearn: 0.0069868\ttotal: 1m 30s\tremaining: 2m 30s\n",
      "750:\tlearn: 0.0069850\ttotal: 1m 30s\tremaining: 2m 29s\n",
      "751:\tlearn: 0.0069759\ttotal: 1m 30s\tremaining: 2m 29s\n",
      "752:\tlearn: 0.0069732\ttotal: 1m 30s\tremaining: 2m 29s\n",
      "753:\tlearn: 0.0069686\ttotal: 1m 30s\tremaining: 2m 29s\n",
      "754:\tlearn: 0.0069679\ttotal: 1m 30s\tremaining: 2m 29s\n",
      "755:\tlearn: 0.0069601\ttotal: 1m 30s\tremaining: 2m 29s\n",
      "756:\tlearn: 0.0069517\ttotal: 1m 30s\tremaining: 2m 29s\n",
      "757:\tlearn: 0.0069464\ttotal: 1m 31s\tremaining: 2m 29s\n",
      "758:\tlearn: 0.0069444\ttotal: 1m 31s\tremaining: 2m 29s\n",
      "759:\tlearn: 0.0069110\ttotal: 1m 31s\tremaining: 2m 29s\n",
      "760:\tlearn: 0.0069017\ttotal: 1m 31s\tremaining: 2m 28s\n",
      "761:\tlearn: 0.0068989\ttotal: 1m 31s\tremaining: 2m 28s\n",
      "762:\tlearn: 0.0068949\ttotal: 1m 31s\tremaining: 2m 28s\n",
      "763:\tlearn: 0.0068925\ttotal: 1m 31s\tremaining: 2m 28s\n",
      "764:\tlearn: 0.0068832\ttotal: 1m 32s\tremaining: 2m 28s\n",
      "765:\tlearn: 0.0068758\ttotal: 1m 32s\tremaining: 2m 28s\n",
      "766:\tlearn: 0.0068715\ttotal: 1m 32s\tremaining: 2m 28s\n",
      "767:\tlearn: 0.0068526\ttotal: 1m 32s\tremaining: 2m 28s\n",
      "768:\tlearn: 0.0068506\ttotal: 1m 32s\tremaining: 2m 28s\n",
      "769:\tlearn: 0.0068403\ttotal: 1m 32s\tremaining: 2m 27s\n",
      "770:\tlearn: 0.0068371\ttotal: 1m 32s\tremaining: 2m 27s\n",
      "771:\tlearn: 0.0068356\ttotal: 1m 32s\tremaining: 2m 27s\n",
      "772:\tlearn: 0.0068266\ttotal: 1m 32s\tremaining: 2m 27s\n",
      "773:\tlearn: 0.0068204\ttotal: 1m 33s\tremaining: 2m 27s\n",
      "774:\tlearn: 0.0068136\ttotal: 1m 33s\tremaining: 2m 27s\n",
      "775:\tlearn: 0.0068086\ttotal: 1m 33s\tremaining: 2m 27s\n",
      "776:\tlearn: 0.0068003\ttotal: 1m 33s\tremaining: 2m 27s\n",
      "777:\tlearn: 0.0067879\ttotal: 1m 33s\tremaining: 2m 27s\n",
      "778:\tlearn: 0.0067830\ttotal: 1m 33s\tremaining: 2m 26s\n",
      "779:\tlearn: 0.0067797\ttotal: 1m 33s\tremaining: 2m 26s\n",
      "780:\tlearn: 0.0067747\ttotal: 1m 33s\tremaining: 2m 26s\n",
      "781:\tlearn: 0.0067712\ttotal: 1m 34s\tremaining: 2m 26s\n",
      "782:\tlearn: 0.0067570\ttotal: 1m 34s\tremaining: 2m 26s\n",
      "783:\tlearn: 0.0067543\ttotal: 1m 34s\tremaining: 2m 26s\n",
      "784:\tlearn: 0.0067512\ttotal: 1m 34s\tremaining: 2m 26s\n",
      "785:\tlearn: 0.0067437\ttotal: 1m 34s\tremaining: 2m 25s\n",
      "786:\tlearn: 0.0067367\ttotal: 1m 34s\tremaining: 2m 25s\n",
      "787:\tlearn: 0.0067357\ttotal: 1m 34s\tremaining: 2m 25s\n",
      "788:\tlearn: 0.0067122\ttotal: 1m 34s\tremaining: 2m 25s\n",
      "789:\tlearn: 0.0067082\ttotal: 1m 35s\tremaining: 2m 25s\n",
      "790:\tlearn: 0.0067036\ttotal: 1m 35s\tremaining: 2m 25s\n",
      "791:\tlearn: 0.0067009\ttotal: 1m 35s\tremaining: 2m 25s\n",
      "792:\tlearn: 0.0066962\ttotal: 1m 35s\tremaining: 2m 25s\n",
      "793:\tlearn: 0.0066831\ttotal: 1m 35s\tremaining: 2m 25s\n",
      "794:\tlearn: 0.0066816\ttotal: 1m 35s\tremaining: 2m 24s\n",
      "795:\tlearn: 0.0066692\ttotal: 1m 35s\tremaining: 2m 24s\n",
      "796:\tlearn: 0.0066546\ttotal: 1m 35s\tremaining: 2m 24s\n",
      "797:\tlearn: 0.0066510\ttotal: 1m 35s\tremaining: 2m 24s\n",
      "798:\tlearn: 0.0066493\ttotal: 1m 36s\tremaining: 2m 24s\n",
      "799:\tlearn: 0.0066459\ttotal: 1m 36s\tremaining: 2m 24s\n",
      "800:\tlearn: 0.0066245\ttotal: 1m 36s\tremaining: 2m 24s\n",
      "801:\tlearn: 0.0066208\ttotal: 1m 36s\tremaining: 2m 24s\n",
      "802:\tlearn: 0.0066205\ttotal: 1m 36s\tremaining: 2m 23s\n",
      "803:\tlearn: 0.0066119\ttotal: 1m 36s\tremaining: 2m 23s\n",
      "804:\tlearn: 0.0066097\ttotal: 1m 36s\tremaining: 2m 23s\n",
      "805:\tlearn: 0.0065956\ttotal: 1m 36s\tremaining: 2m 23s\n",
      "806:\tlearn: 0.0065842\ttotal: 1m 37s\tremaining: 2m 23s\n",
      "807:\tlearn: 0.0065801\ttotal: 1m 37s\tremaining: 2m 23s\n",
      "808:\tlearn: 0.0065763\ttotal: 1m 37s\tremaining: 2m 23s\n",
      "809:\tlearn: 0.0065746\ttotal: 1m 37s\tremaining: 2m 23s\n",
      "810:\tlearn: 0.0065510\ttotal: 1m 37s\tremaining: 2m 22s\n",
      "811:\tlearn: 0.0065489\ttotal: 1m 37s\tremaining: 2m 22s\n",
      "812:\tlearn: 0.0065440\ttotal: 1m 37s\tremaining: 2m 22s\n",
      "813:\tlearn: 0.0065422\ttotal: 1m 37s\tremaining: 2m 22s\n",
      "814:\tlearn: 0.0065390\ttotal: 1m 38s\tremaining: 2m 22s\n",
      "815:\tlearn: 0.0065326\ttotal: 1m 38s\tremaining: 2m 22s\n",
      "816:\tlearn: 0.0065299\ttotal: 1m 38s\tremaining: 2m 22s\n",
      "817:\tlearn: 0.0065180\ttotal: 1m 38s\tremaining: 2m 22s\n",
      "818:\tlearn: 0.0065125\ttotal: 1m 38s\tremaining: 2m 22s\n",
      "819:\tlearn: 0.0065051\ttotal: 1m 38s\tremaining: 2m 21s\n",
      "820:\tlearn: 0.0064980\ttotal: 1m 38s\tremaining: 2m 21s\n",
      "821:\tlearn: 0.0064891\ttotal: 1m 38s\tremaining: 2m 21s\n",
      "822:\tlearn: 0.0064868\ttotal: 1m 38s\tremaining: 2m 21s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "823:\tlearn: 0.0064820\ttotal: 1m 39s\tremaining: 2m 21s\n",
      "824:\tlearn: 0.0064765\ttotal: 1m 39s\tremaining: 2m 21s\n",
      "825:\tlearn: 0.0064724\ttotal: 1m 39s\tremaining: 2m 21s\n",
      "826:\tlearn: 0.0064617\ttotal: 1m 39s\tremaining: 2m 21s\n",
      "827:\tlearn: 0.0064594\ttotal: 1m 39s\tremaining: 2m 20s\n",
      "828:\tlearn: 0.0064546\ttotal: 1m 39s\tremaining: 2m 20s\n",
      "829:\tlearn: 0.0064512\ttotal: 1m 39s\tremaining: 2m 20s\n",
      "830:\tlearn: 0.0064492\ttotal: 1m 39s\tremaining: 2m 20s\n",
      "831:\tlearn: 0.0064407\ttotal: 1m 40s\tremaining: 2m 20s\n",
      "832:\tlearn: 0.0064336\ttotal: 1m 40s\tremaining: 2m 20s\n",
      "833:\tlearn: 0.0064307\ttotal: 1m 40s\tremaining: 2m 20s\n",
      "834:\tlearn: 0.0064279\ttotal: 1m 40s\tremaining: 2m 20s\n",
      "835:\tlearn: 0.0064242\ttotal: 1m 40s\tremaining: 2m 19s\n",
      "836:\tlearn: 0.0064199\ttotal: 1m 40s\tremaining: 2m 19s\n",
      "837:\tlearn: 0.0064142\ttotal: 1m 40s\tremaining: 2m 19s\n",
      "838:\tlearn: 0.0064102\ttotal: 1m 40s\tremaining: 2m 19s\n",
      "839:\tlearn: 0.0064002\ttotal: 1m 40s\tremaining: 2m 19s\n",
      "840:\tlearn: 0.0063920\ttotal: 1m 41s\tremaining: 2m 19s\n",
      "841:\tlearn: 0.0063786\ttotal: 1m 41s\tremaining: 2m 19s\n",
      "842:\tlearn: 0.0063772\ttotal: 1m 41s\tremaining: 2m 19s\n",
      "843:\tlearn: 0.0063729\ttotal: 1m 41s\tremaining: 2m 18s\n",
      "844:\tlearn: 0.0063619\ttotal: 1m 41s\tremaining: 2m 18s\n",
      "845:\tlearn: 0.0063591\ttotal: 1m 41s\tremaining: 2m 18s\n",
      "846:\tlearn: 0.0063557\ttotal: 1m 41s\tremaining: 2m 18s\n",
      "847:\tlearn: 0.0063552\ttotal: 1m 41s\tremaining: 2m 18s\n",
      "848:\tlearn: 0.0063519\ttotal: 1m 41s\tremaining: 2m 18s\n",
      "849:\tlearn: 0.0063373\ttotal: 1m 42s\tremaining: 2m 18s\n",
      "850:\tlearn: 0.0063363\ttotal: 1m 42s\tremaining: 2m 18s\n",
      "851:\tlearn: 0.0063325\ttotal: 1m 42s\tremaining: 2m 17s\n",
      "852:\tlearn: 0.0063210\ttotal: 1m 42s\tremaining: 2m 17s\n",
      "853:\tlearn: 0.0063197\ttotal: 1m 42s\tremaining: 2m 17s\n",
      "854:\tlearn: 0.0063115\ttotal: 1m 42s\tremaining: 2m 17s\n",
      "855:\tlearn: 0.0063061\ttotal: 1m 42s\tremaining: 2m 17s\n",
      "856:\tlearn: 0.0063030\ttotal: 1m 42s\tremaining: 2m 17s\n",
      "857:\tlearn: 0.0063004\ttotal: 1m 43s\tremaining: 2m 17s\n",
      "858:\tlearn: 0.0062907\ttotal: 1m 43s\tremaining: 2m 17s\n",
      "859:\tlearn: 0.0062677\ttotal: 1m 43s\tremaining: 2m 16s\n",
      "860:\tlearn: 0.0062579\ttotal: 1m 43s\tremaining: 2m 16s\n",
      "861:\tlearn: 0.0062527\ttotal: 1m 43s\tremaining: 2m 16s\n",
      "862:\tlearn: 0.0062500\ttotal: 1m 43s\tremaining: 2m 16s\n",
      "863:\tlearn: 0.0062280\ttotal: 1m 43s\tremaining: 2m 16s\n",
      "864:\tlearn: 0.0062265\ttotal: 1m 43s\tremaining: 2m 16s\n",
      "865:\tlearn: 0.0062225\ttotal: 1m 43s\tremaining: 2m 16s\n",
      "866:\tlearn: 0.0062190\ttotal: 1m 44s\tremaining: 2m 16s\n",
      "867:\tlearn: 0.0062161\ttotal: 1m 44s\tremaining: 2m 15s\n",
      "868:\tlearn: 0.0062109\ttotal: 1m 44s\tremaining: 2m 15s\n",
      "869:\tlearn: 0.0062102\ttotal: 1m 44s\tremaining: 2m 15s\n",
      "870:\tlearn: 0.0061989\ttotal: 1m 44s\tremaining: 2m 15s\n",
      "871:\tlearn: 0.0061919\ttotal: 1m 44s\tremaining: 2m 15s\n",
      "872:\tlearn: 0.0061898\ttotal: 1m 44s\tremaining: 2m 15s\n",
      "873:\tlearn: 0.0061785\ttotal: 1m 44s\tremaining: 2m 15s\n",
      "874:\tlearn: 0.0061762\ttotal: 1m 45s\tremaining: 2m 15s\n",
      "875:\tlearn: 0.0061746\ttotal: 1m 45s\tremaining: 2m 14s\n",
      "876:\tlearn: 0.0061721\ttotal: 1m 45s\tremaining: 2m 14s\n",
      "877:\tlearn: 0.0061666\ttotal: 1m 45s\tremaining: 2m 14s\n",
      "878:\tlearn: 0.0061634\ttotal: 1m 45s\tremaining: 2m 14s\n",
      "879:\tlearn: 0.0061611\ttotal: 1m 45s\tremaining: 2m 14s\n",
      "880:\tlearn: 0.0061603\ttotal: 1m 45s\tremaining: 2m 14s\n",
      "881:\tlearn: 0.0061586\ttotal: 1m 45s\tremaining: 2m 14s\n",
      "882:\tlearn: 0.0061577\ttotal: 1m 45s\tremaining: 2m 14s\n",
      "883:\tlearn: 0.0061553\ttotal: 1m 46s\tremaining: 2m 13s\n",
      "884:\tlearn: 0.0061528\ttotal: 1m 46s\tremaining: 2m 13s\n",
      "885:\tlearn: 0.0061463\ttotal: 1m 46s\tremaining: 2m 13s\n",
      "886:\tlearn: 0.0061346\ttotal: 1m 46s\tremaining: 2m 13s\n",
      "887:\tlearn: 0.0061327\ttotal: 1m 46s\tremaining: 2m 13s\n",
      "888:\tlearn: 0.0061096\ttotal: 1m 46s\tremaining: 2m 13s\n",
      "889:\tlearn: 0.0061020\ttotal: 1m 46s\tremaining: 2m 13s\n",
      "890:\tlearn: 0.0060918\ttotal: 1m 46s\tremaining: 2m 13s\n",
      "891:\tlearn: 0.0060830\ttotal: 1m 47s\tremaining: 2m 12s\n",
      "892:\tlearn: 0.0060795\ttotal: 1m 47s\tremaining: 2m 12s\n",
      "893:\tlearn: 0.0060659\ttotal: 1m 47s\tremaining: 2m 12s\n",
      "894:\tlearn: 0.0060587\ttotal: 1m 47s\tremaining: 2m 12s\n",
      "895:\tlearn: 0.0060395\ttotal: 1m 47s\tremaining: 2m 12s\n",
      "896:\tlearn: 0.0060371\ttotal: 1m 47s\tremaining: 2m 12s\n",
      "897:\tlearn: 0.0060325\ttotal: 1m 47s\tremaining: 2m 12s\n",
      "898:\tlearn: 0.0060284\ttotal: 1m 47s\tremaining: 2m 12s\n",
      "899:\tlearn: 0.0060262\ttotal: 1m 47s\tremaining: 2m 11s\n",
      "900:\tlearn: 0.0060120\ttotal: 1m 48s\tremaining: 2m 11s\n",
      "901:\tlearn: 0.0060087\ttotal: 1m 48s\tremaining: 2m 11s\n",
      "902:\tlearn: 0.0060028\ttotal: 1m 48s\tremaining: 2m 11s\n",
      "903:\tlearn: 0.0060001\ttotal: 1m 48s\tremaining: 2m 11s\n",
      "904:\tlearn: 0.0059991\ttotal: 1m 48s\tremaining: 2m 11s\n",
      "905:\tlearn: 0.0059964\ttotal: 1m 48s\tremaining: 2m 11s\n",
      "906:\tlearn: 0.0059904\ttotal: 1m 48s\tremaining: 2m 11s\n",
      "907:\tlearn: 0.0059737\ttotal: 1m 48s\tremaining: 2m 11s\n",
      "908:\tlearn: 0.0059705\ttotal: 1m 49s\tremaining: 2m 10s\n",
      "909:\tlearn: 0.0059668\ttotal: 1m 49s\tremaining: 2m 10s\n",
      "910:\tlearn: 0.0059594\ttotal: 1m 49s\tremaining: 2m 10s\n",
      "911:\tlearn: 0.0059585\ttotal: 1m 49s\tremaining: 2m 10s\n",
      "912:\tlearn: 0.0059492\ttotal: 1m 49s\tremaining: 2m 10s\n",
      "913:\tlearn: 0.0059485\ttotal: 1m 49s\tremaining: 2m 10s\n",
      "914:\tlearn: 0.0059421\ttotal: 1m 49s\tremaining: 2m 10s\n",
      "915:\tlearn: 0.0059413\ttotal: 1m 49s\tremaining: 2m 10s\n",
      "916:\tlearn: 0.0059387\ttotal: 1m 49s\tremaining: 2m 9s\n",
      "917:\tlearn: 0.0059330\ttotal: 1m 50s\tremaining: 2m 9s\n",
      "918:\tlearn: 0.0059270\ttotal: 1m 50s\tremaining: 2m 9s\n",
      "919:\tlearn: 0.0059249\ttotal: 1m 50s\tremaining: 2m 9s\n",
      "920:\tlearn: 0.0059176\ttotal: 1m 50s\tremaining: 2m 9s\n",
      "921:\tlearn: 0.0059023\ttotal: 1m 50s\tremaining: 2m 9s\n",
      "922:\tlearn: 0.0059012\ttotal: 1m 50s\tremaining: 2m 9s\n",
      "923:\tlearn: 0.0058984\ttotal: 1m 50s\tremaining: 2m 9s\n",
      "924:\tlearn: 0.0058970\ttotal: 1m 50s\tremaining: 2m 8s\n",
      "925:\tlearn: 0.0058947\ttotal: 1m 51s\tremaining: 2m 8s\n",
      "926:\tlearn: 0.0058908\ttotal: 1m 51s\tremaining: 2m 8s\n",
      "927:\tlearn: 0.0058811\ttotal: 1m 51s\tremaining: 2m 8s\n",
      "928:\tlearn: 0.0058800\ttotal: 1m 51s\tremaining: 2m 8s\n",
      "929:\tlearn: 0.0058787\ttotal: 1m 51s\tremaining: 2m 8s\n",
      "930:\tlearn: 0.0058711\ttotal: 1m 51s\tremaining: 2m 8s\n",
      "931:\tlearn: 0.0058700\ttotal: 1m 51s\tremaining: 2m 8s\n",
      "932:\tlearn: 0.0058664\ttotal: 1m 51s\tremaining: 2m 7s\n",
      "933:\tlearn: 0.0058649\ttotal: 1m 52s\tremaining: 2m 7s\n",
      "934:\tlearn: 0.0058616\ttotal: 1m 52s\tremaining: 2m 7s\n",
      "935:\tlearn: 0.0058564\ttotal: 1m 52s\tremaining: 2m 7s\n",
      "936:\tlearn: 0.0058552\ttotal: 1m 52s\tremaining: 2m 7s\n",
      "937:\tlearn: 0.0058455\ttotal: 1m 52s\tremaining: 2m 7s\n",
      "938:\tlearn: 0.0058379\ttotal: 1m 52s\tremaining: 2m 7s\n",
      "939:\tlearn: 0.0058346\ttotal: 1m 52s\tremaining: 2m 7s\n",
      "940:\tlearn: 0.0058223\ttotal: 1m 52s\tremaining: 2m 7s\n",
      "941:\tlearn: 0.0057985\ttotal: 1m 53s\tremaining: 2m 6s\n",
      "942:\tlearn: 0.0057952\ttotal: 1m 53s\tremaining: 2m 6s\n",
      "943:\tlearn: 0.0057947\ttotal: 1m 53s\tremaining: 2m 6s\n",
      "944:\tlearn: 0.0057885\ttotal: 1m 53s\tremaining: 2m 6s\n",
      "945:\tlearn: 0.0057846\ttotal: 1m 53s\tremaining: 2m 6s\n",
      "946:\tlearn: 0.0057819\ttotal: 1m 53s\tremaining: 2m 6s\n",
      "947:\tlearn: 0.0057792\ttotal: 1m 53s\tremaining: 2m 6s\n",
      "948:\tlearn: 0.0057762\ttotal: 1m 53s\tremaining: 2m 6s\n",
      "949:\tlearn: 0.0057739\ttotal: 1m 53s\tremaining: 2m 5s\n",
      "950:\tlearn: 0.0057731\ttotal: 1m 54s\tremaining: 2m 5s\n",
      "951:\tlearn: 0.0057713\ttotal: 1m 54s\tremaining: 2m 5s\n",
      "952:\tlearn: 0.0057702\ttotal: 1m 54s\tremaining: 2m 5s\n",
      "953:\tlearn: 0.0057666\ttotal: 1m 54s\tremaining: 2m 5s\n",
      "954:\tlearn: 0.0057617\ttotal: 1m 54s\tremaining: 2m 5s\n",
      "955:\tlearn: 0.0057495\ttotal: 1m 54s\tremaining: 2m 5s\n",
      "956:\tlearn: 0.0057436\ttotal: 1m 54s\tremaining: 2m 5s\n",
      "957:\tlearn: 0.0057346\ttotal: 1m 54s\tremaining: 2m 4s\n",
      "958:\tlearn: 0.0057226\ttotal: 1m 55s\tremaining: 2m 4s\n",
      "959:\tlearn: 0.0057218\ttotal: 1m 55s\tremaining: 2m 4s\n",
      "960:\tlearn: 0.0057161\ttotal: 1m 55s\tremaining: 2m 4s\n",
      "961:\tlearn: 0.0057124\ttotal: 1m 55s\tremaining: 2m 4s\n",
      "962:\tlearn: 0.0057018\ttotal: 1m 55s\tremaining: 2m 4s\n",
      "963:\tlearn: 0.0057005\ttotal: 1m 55s\tremaining: 2m 4s\n",
      "964:\tlearn: 0.0056942\ttotal: 1m 55s\tremaining: 2m 4s\n",
      "965:\tlearn: 0.0056903\ttotal: 1m 55s\tremaining: 2m 3s\n",
      "966:\tlearn: 0.0056857\ttotal: 1m 55s\tremaining: 2m 3s\n",
      "967:\tlearn: 0.0056841\ttotal: 1m 56s\tremaining: 2m 3s\n",
      "968:\tlearn: 0.0056773\ttotal: 1m 56s\tremaining: 2m 3s\n",
      "969:\tlearn: 0.0056745\ttotal: 1m 56s\tremaining: 2m 3s\n",
      "970:\tlearn: 0.0056693\ttotal: 1m 56s\tremaining: 2m 3s\n",
      "971:\tlearn: 0.0056680\ttotal: 1m 56s\tremaining: 2m 3s\n",
      "972:\tlearn: 0.0056671\ttotal: 1m 56s\tremaining: 2m 3s\n",
      "973:\tlearn: 0.0056638\ttotal: 1m 56s\tremaining: 2m 3s\n",
      "974:\tlearn: 0.0056593\ttotal: 1m 56s\tremaining: 2m 2s\n",
      "975:\tlearn: 0.0056581\ttotal: 1m 57s\tremaining: 2m 2s\n",
      "976:\tlearn: 0.0056547\ttotal: 1m 57s\tremaining: 2m 2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "977:\tlearn: 0.0056536\ttotal: 1m 57s\tremaining: 2m 2s\n",
      "978:\tlearn: 0.0056496\ttotal: 1m 57s\tremaining: 2m 2s\n",
      "979:\tlearn: 0.0056480\ttotal: 1m 57s\tremaining: 2m 2s\n",
      "980:\tlearn: 0.0056458\ttotal: 1m 57s\tremaining: 2m 2s\n",
      "981:\tlearn: 0.0056438\ttotal: 1m 57s\tremaining: 2m 2s\n",
      "982:\tlearn: 0.0056413\ttotal: 1m 57s\tremaining: 2m 1s\n",
      "983:\tlearn: 0.0056366\ttotal: 1m 57s\tremaining: 2m 1s\n",
      "984:\tlearn: 0.0056316\ttotal: 1m 58s\tremaining: 2m 1s\n",
      "985:\tlearn: 0.0056285\ttotal: 1m 58s\tremaining: 2m 1s\n",
      "986:\tlearn: 0.0056265\ttotal: 1m 58s\tremaining: 2m 1s\n",
      "987:\tlearn: 0.0056248\ttotal: 1m 58s\tremaining: 2m 1s\n",
      "988:\tlearn: 0.0056189\ttotal: 1m 58s\tremaining: 2m 1s\n",
      "989:\tlearn: 0.0056172\ttotal: 1m 58s\tremaining: 2m 1s\n",
      "990:\tlearn: 0.0056141\ttotal: 1m 58s\tremaining: 2m\n",
      "991:\tlearn: 0.0056132\ttotal: 1m 58s\tremaining: 2m\n",
      "992:\tlearn: 0.0056107\ttotal: 1m 59s\tremaining: 2m\n",
      "993:\tlearn: 0.0056088\ttotal: 1m 59s\tremaining: 2m\n",
      "994:\tlearn: 0.0056079\ttotal: 1m 59s\tremaining: 2m\n",
      "995:\tlearn: 0.0056026\ttotal: 1m 59s\tremaining: 2m\n",
      "996:\tlearn: 0.0056004\ttotal: 1m 59s\tremaining: 2m\n",
      "997:\tlearn: 0.0055992\ttotal: 1m 59s\tremaining: 2m\n",
      "998:\tlearn: 0.0055974\ttotal: 1m 59s\tremaining: 1m 59s\n",
      "999:\tlearn: 0.0055957\ttotal: 1m 59s\tremaining: 1m 59s\n",
      "1000:\tlearn: 0.0055868\ttotal: 1m 59s\tremaining: 1m 59s\n",
      "1001:\tlearn: 0.0055840\ttotal: 2m\tremaining: 1m 59s\n",
      "1002:\tlearn: 0.0055830\ttotal: 2m\tremaining: 1m 59s\n",
      "1003:\tlearn: 0.0055815\ttotal: 2m\tremaining: 1m 59s\n",
      "1004:\tlearn: 0.0055720\ttotal: 2m\tremaining: 1m 59s\n",
      "1005:\tlearn: 0.0055707\ttotal: 2m\tremaining: 1m 59s\n",
      "1006:\tlearn: 0.0055622\ttotal: 2m\tremaining: 1m 59s\n",
      "1007:\tlearn: 0.0055607\ttotal: 2m\tremaining: 1m 58s\n",
      "1008:\tlearn: 0.0055571\ttotal: 2m\tremaining: 1m 58s\n",
      "1009:\tlearn: 0.0055554\ttotal: 2m 1s\tremaining: 1m 58s\n",
      "1010:\tlearn: 0.0055500\ttotal: 2m 1s\tremaining: 1m 58s\n",
      "1011:\tlearn: 0.0055488\ttotal: 2m 1s\tremaining: 1m 58s\n",
      "1012:\tlearn: 0.0055473\ttotal: 2m 1s\tremaining: 1m 58s\n",
      "1013:\tlearn: 0.0055468\ttotal: 2m 1s\tremaining: 1m 58s\n",
      "1014:\tlearn: 0.0055462\ttotal: 2m 1s\tremaining: 1m 58s\n",
      "1015:\tlearn: 0.0055434\ttotal: 2m 1s\tremaining: 1m 57s\n",
      "1016:\tlearn: 0.0055341\ttotal: 2m 1s\tremaining: 1m 57s\n",
      "1017:\tlearn: 0.0055280\ttotal: 2m 1s\tremaining: 1m 57s\n",
      "1018:\tlearn: 0.0055269\ttotal: 2m 2s\tremaining: 1m 57s\n",
      "1019:\tlearn: 0.0055227\ttotal: 2m 2s\tremaining: 1m 57s\n",
      "1020:\tlearn: 0.0055223\ttotal: 2m 2s\tremaining: 1m 57s\n",
      "1021:\tlearn: 0.0055218\ttotal: 2m 2s\tremaining: 1m 57s\n",
      "1022:\tlearn: 0.0055207\ttotal: 2m 2s\tremaining: 1m 56s\n",
      "1023:\tlearn: 0.0055203\ttotal: 2m 2s\tremaining: 1m 56s\n",
      "1024:\tlearn: 0.0055133\ttotal: 2m 2s\tremaining: 1m 56s\n",
      "1025:\tlearn: 0.0055031\ttotal: 2m 2s\tremaining: 1m 56s\n",
      "1026:\tlearn: 0.0054997\ttotal: 2m 2s\tremaining: 1m 56s\n",
      "1027:\tlearn: 0.0054960\ttotal: 2m 3s\tremaining: 1m 56s\n",
      "1028:\tlearn: 0.0054891\ttotal: 2m 3s\tremaining: 1m 56s\n",
      "1029:\tlearn: 0.0054777\ttotal: 2m 3s\tremaining: 1m 56s\n",
      "1030:\tlearn: 0.0054753\ttotal: 2m 3s\tremaining: 1m 56s\n",
      "1031:\tlearn: 0.0054686\ttotal: 2m 3s\tremaining: 1m 55s\n",
      "1032:\tlearn: 0.0054647\ttotal: 2m 3s\tremaining: 1m 55s\n",
      "1033:\tlearn: 0.0054628\ttotal: 2m 3s\tremaining: 1m 55s\n",
      "1034:\tlearn: 0.0054610\ttotal: 2m 3s\tremaining: 1m 55s\n",
      "1035:\tlearn: 0.0054599\ttotal: 2m 4s\tremaining: 1m 55s\n",
      "1036:\tlearn: 0.0054566\ttotal: 2m 4s\tremaining: 1m 55s\n",
      "1037:\tlearn: 0.0054520\ttotal: 2m 4s\tremaining: 1m 55s\n",
      "1038:\tlearn: 0.0054516\ttotal: 2m 4s\tremaining: 1m 55s\n",
      "1039:\tlearn: 0.0054443\ttotal: 2m 4s\tremaining: 1m 54s\n",
      "1040:\tlearn: 0.0054411\ttotal: 2m 4s\tremaining: 1m 54s\n",
      "1041:\tlearn: 0.0054394\ttotal: 2m 4s\tremaining: 1m 54s\n",
      "1042:\tlearn: 0.0054366\ttotal: 2m 4s\tremaining: 1m 54s\n",
      "1043:\tlearn: 0.0054359\ttotal: 2m 4s\tremaining: 1m 54s\n",
      "1044:\tlearn: 0.0054349\ttotal: 2m 5s\tremaining: 1m 54s\n",
      "1045:\tlearn: 0.0054332\ttotal: 2m 5s\tremaining: 1m 54s\n",
      "1046:\tlearn: 0.0054326\ttotal: 2m 5s\tremaining: 1m 54s\n",
      "1047:\tlearn: 0.0054287\ttotal: 2m 5s\tremaining: 1m 53s\n",
      "1048:\tlearn: 0.0054240\ttotal: 2m 5s\tremaining: 1m 53s\n",
      "1049:\tlearn: 0.0054200\ttotal: 2m 5s\tremaining: 1m 53s\n",
      "1050:\tlearn: 0.0054134\ttotal: 2m 5s\tremaining: 1m 53s\n",
      "1051:\tlearn: 0.0054072\ttotal: 2m 5s\tremaining: 1m 53s\n",
      "1052:\tlearn: 0.0054038\ttotal: 2m 6s\tremaining: 1m 53s\n",
      "1053:\tlearn: 0.0053987\ttotal: 2m 6s\tremaining: 1m 53s\n",
      "1054:\tlearn: 0.0053983\ttotal: 2m 6s\tremaining: 1m 53s\n",
      "1055:\tlearn: 0.0053976\ttotal: 2m 6s\tremaining: 1m 52s\n",
      "1056:\tlearn: 0.0053958\ttotal: 2m 6s\tremaining: 1m 52s\n",
      "1057:\tlearn: 0.0053857\ttotal: 2m 6s\tremaining: 1m 52s\n",
      "1058:\tlearn: 0.0053829\ttotal: 2m 6s\tremaining: 1m 52s\n",
      "1059:\tlearn: 0.0053803\ttotal: 2m 6s\tremaining: 1m 52s\n",
      "1060:\tlearn: 0.0053794\ttotal: 2m 6s\tremaining: 1m 52s\n",
      "1061:\tlearn: 0.0053774\ttotal: 2m 7s\tremaining: 1m 52s\n",
      "1062:\tlearn: 0.0053759\ttotal: 2m 7s\tremaining: 1m 52s\n",
      "1063:\tlearn: 0.0053746\ttotal: 2m 7s\tremaining: 1m 52s\n",
      "1064:\tlearn: 0.0053724\ttotal: 2m 7s\tremaining: 1m 51s\n",
      "1065:\tlearn: 0.0053615\ttotal: 2m 7s\tremaining: 1m 51s\n",
      "1066:\tlearn: 0.0053593\ttotal: 2m 7s\tremaining: 1m 51s\n",
      "1067:\tlearn: 0.0053566\ttotal: 2m 7s\tremaining: 1m 51s\n",
      "1068:\tlearn: 0.0053556\ttotal: 2m 7s\tremaining: 1m 51s\n",
      "1069:\tlearn: 0.0053528\ttotal: 2m 8s\tremaining: 1m 51s\n",
      "1070:\tlearn: 0.0053521\ttotal: 2m 8s\tremaining: 1m 51s\n",
      "1071:\tlearn: 0.0053511\ttotal: 2m 8s\tremaining: 1m 51s\n",
      "1072:\tlearn: 0.0053500\ttotal: 2m 8s\tremaining: 1m 50s\n",
      "1073:\tlearn: 0.0053485\ttotal: 2m 8s\tremaining: 1m 50s\n",
      "1074:\tlearn: 0.0053471\ttotal: 2m 8s\tremaining: 1m 50s\n",
      "1075:\tlearn: 0.0053425\ttotal: 2m 8s\tremaining: 1m 50s\n",
      "1076:\tlearn: 0.0053399\ttotal: 2m 8s\tremaining: 1m 50s\n",
      "1077:\tlearn: 0.0053361\ttotal: 2m 8s\tremaining: 1m 50s\n",
      "1078:\tlearn: 0.0053332\ttotal: 2m 9s\tremaining: 1m 50s\n",
      "1079:\tlearn: 0.0053319\ttotal: 2m 9s\tremaining: 1m 50s\n",
      "1080:\tlearn: 0.0053290\ttotal: 2m 9s\tremaining: 1m 49s\n",
      "1081:\tlearn: 0.0053260\ttotal: 2m 9s\tremaining: 1m 49s\n",
      "1082:\tlearn: 0.0053250\ttotal: 2m 9s\tremaining: 1m 49s\n",
      "1083:\tlearn: 0.0053204\ttotal: 2m 9s\tremaining: 1m 49s\n",
      "1084:\tlearn: 0.0053174\ttotal: 2m 9s\tremaining: 1m 49s\n",
      "1085:\tlearn: 0.0053153\ttotal: 2m 9s\tremaining: 1m 49s\n",
      "1086:\tlearn: 0.0053092\ttotal: 2m 10s\tremaining: 1m 49s\n",
      "1087:\tlearn: 0.0053036\ttotal: 2m 10s\tremaining: 1m 49s\n",
      "1088:\tlearn: 0.0053031\ttotal: 2m 10s\tremaining: 1m 48s\n",
      "1089:\tlearn: 0.0052950\ttotal: 2m 10s\tremaining: 1m 48s\n",
      "1090:\tlearn: 0.0052933\ttotal: 2m 10s\tremaining: 1m 48s\n",
      "1091:\tlearn: 0.0052926\ttotal: 2m 10s\tremaining: 1m 48s\n",
      "1092:\tlearn: 0.0052895\ttotal: 2m 10s\tremaining: 1m 48s\n",
      "1093:\tlearn: 0.0052868\ttotal: 2m 10s\tremaining: 1m 48s\n",
      "1094:\tlearn: 0.0052842\ttotal: 2m 10s\tremaining: 1m 48s\n",
      "1095:\tlearn: 0.0052816\ttotal: 2m 11s\tremaining: 1m 48s\n",
      "1096:\tlearn: 0.0052800\ttotal: 2m 11s\tremaining: 1m 47s\n",
      "1097:\tlearn: 0.0052789\ttotal: 2m 11s\tremaining: 1m 47s\n",
      "1098:\tlearn: 0.0052766\ttotal: 2m 11s\tremaining: 1m 47s\n",
      "1099:\tlearn: 0.0052700\ttotal: 2m 11s\tremaining: 1m 47s\n",
      "1100:\tlearn: 0.0052695\ttotal: 2m 11s\tremaining: 1m 47s\n",
      "1101:\tlearn: 0.0052675\ttotal: 2m 11s\tremaining: 1m 47s\n",
      "1102:\tlearn: 0.0052656\ttotal: 2m 11s\tremaining: 1m 47s\n",
      "1103:\tlearn: 0.0052642\ttotal: 2m 12s\tremaining: 1m 47s\n",
      "1104:\tlearn: 0.0052585\ttotal: 2m 12s\tremaining: 1m 47s\n",
      "1105:\tlearn: 0.0052576\ttotal: 2m 12s\tremaining: 1m 46s\n",
      "1106:\tlearn: 0.0052545\ttotal: 2m 12s\tremaining: 1m 46s\n",
      "1107:\tlearn: 0.0052506\ttotal: 2m 12s\tremaining: 1m 46s\n",
      "1108:\tlearn: 0.0052497\ttotal: 2m 12s\tremaining: 1m 46s\n",
      "1109:\tlearn: 0.0052464\ttotal: 2m 12s\tremaining: 1m 46s\n",
      "1110:\tlearn: 0.0052367\ttotal: 2m 12s\tremaining: 1m 46s\n",
      "1111:\tlearn: 0.0052354\ttotal: 2m 12s\tremaining: 1m 46s\n",
      "1112:\tlearn: 0.0052341\ttotal: 2m 13s\tremaining: 1m 46s\n",
      "1113:\tlearn: 0.0052331\ttotal: 2m 13s\tremaining: 1m 45s\n",
      "1114:\tlearn: 0.0052275\ttotal: 2m 13s\tremaining: 1m 45s\n",
      "1115:\tlearn: 0.0052233\ttotal: 2m 13s\tremaining: 1m 45s\n",
      "1116:\tlearn: 0.0052204\ttotal: 2m 13s\tremaining: 1m 45s\n",
      "1117:\tlearn: 0.0052138\ttotal: 2m 13s\tremaining: 1m 45s\n",
      "1118:\tlearn: 0.0052101\ttotal: 2m 13s\tremaining: 1m 45s\n",
      "1119:\tlearn: 0.0052094\ttotal: 2m 13s\tremaining: 1m 45s\n",
      "1120:\tlearn: 0.0052077\ttotal: 2m 14s\tremaining: 1m 45s\n",
      "1121:\tlearn: 0.0052049\ttotal: 2m 14s\tremaining: 1m 44s\n",
      "1122:\tlearn: 0.0052032\ttotal: 2m 14s\tremaining: 1m 44s\n",
      "1123:\tlearn: 0.0052019\ttotal: 2m 14s\tremaining: 1m 44s\n",
      "1124:\tlearn: 0.0052013\ttotal: 2m 14s\tremaining: 1m 44s\n",
      "1125:\tlearn: 0.0052009\ttotal: 2m 14s\tremaining: 1m 44s\n",
      "1126:\tlearn: 0.0052004\ttotal: 2m 14s\tremaining: 1m 44s\n",
      "1127:\tlearn: 0.0051911\ttotal: 2m 14s\tremaining: 1m 44s\n",
      "1128:\tlearn: 0.0051834\ttotal: 2m 14s\tremaining: 1m 44s\n",
      "1129:\tlearn: 0.0051807\ttotal: 2m 15s\tremaining: 1m 43s\n",
      "1130:\tlearn: 0.0051713\ttotal: 2m 15s\tremaining: 1m 43s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1131:\tlearn: 0.0051679\ttotal: 2m 15s\tremaining: 1m 43s\n",
      "1132:\tlearn: 0.0051614\ttotal: 2m 15s\tremaining: 1m 43s\n",
      "1133:\tlearn: 0.0051600\ttotal: 2m 15s\tremaining: 1m 43s\n",
      "1134:\tlearn: 0.0051545\ttotal: 2m 15s\tremaining: 1m 43s\n",
      "1135:\tlearn: 0.0051540\ttotal: 2m 15s\tremaining: 1m 43s\n",
      "1136:\tlearn: 0.0051520\ttotal: 2m 15s\tremaining: 1m 43s\n",
      "1137:\tlearn: 0.0051471\ttotal: 2m 15s\tremaining: 1m 43s\n",
      "1138:\tlearn: 0.0051462\ttotal: 2m 16s\tremaining: 1m 42s\n",
      "1139:\tlearn: 0.0051435\ttotal: 2m 16s\tremaining: 1m 42s\n",
      "1140:\tlearn: 0.0051428\ttotal: 2m 16s\tremaining: 1m 42s\n",
      "1141:\tlearn: 0.0051410\ttotal: 2m 16s\tremaining: 1m 42s\n",
      "1142:\tlearn: 0.0051387\ttotal: 2m 16s\tremaining: 1m 42s\n",
      "1143:\tlearn: 0.0051381\ttotal: 2m 16s\tremaining: 1m 42s\n",
      "1144:\tlearn: 0.0051301\ttotal: 2m 16s\tremaining: 1m 42s\n",
      "1145:\tlearn: 0.0051296\ttotal: 2m 16s\tremaining: 1m 42s\n",
      "1146:\tlearn: 0.0051247\ttotal: 2m 17s\tremaining: 1m 41s\n",
      "1147:\tlearn: 0.0051207\ttotal: 2m 17s\tremaining: 1m 41s\n",
      "1148:\tlearn: 0.0051190\ttotal: 2m 17s\tremaining: 1m 41s\n",
      "1149:\tlearn: 0.0051166\ttotal: 2m 17s\tremaining: 1m 41s\n",
      "1150:\tlearn: 0.0051164\ttotal: 2m 17s\tremaining: 1m 41s\n",
      "1151:\tlearn: 0.0051130\ttotal: 2m 17s\tremaining: 1m 41s\n",
      "1152:\tlearn: 0.0051084\ttotal: 2m 17s\tremaining: 1m 41s\n",
      "1153:\tlearn: 0.0051075\ttotal: 2m 17s\tremaining: 1m 41s\n",
      "1154:\tlearn: 0.0051033\ttotal: 2m 17s\tremaining: 1m 40s\n",
      "1155:\tlearn: 0.0050997\ttotal: 2m 18s\tremaining: 1m 40s\n",
      "1156:\tlearn: 0.0050884\ttotal: 2m 18s\tremaining: 1m 40s\n",
      "1157:\tlearn: 0.0050866\ttotal: 2m 18s\tremaining: 1m 40s\n",
      "1158:\tlearn: 0.0050782\ttotal: 2m 18s\tremaining: 1m 40s\n",
      "1159:\tlearn: 0.0050763\ttotal: 2m 18s\tremaining: 1m 40s\n",
      "1160:\tlearn: 0.0050748\ttotal: 2m 18s\tremaining: 1m 40s\n",
      "1161:\tlearn: 0.0050585\ttotal: 2m 18s\tremaining: 1m 40s\n",
      "1162:\tlearn: 0.0050558\ttotal: 2m 18s\tremaining: 1m 39s\n",
      "1163:\tlearn: 0.0050550\ttotal: 2m 19s\tremaining: 1m 39s\n",
      "1164:\tlearn: 0.0050532\ttotal: 2m 19s\tremaining: 1m 39s\n",
      "1165:\tlearn: 0.0050456\ttotal: 2m 19s\tremaining: 1m 39s\n",
      "1166:\tlearn: 0.0050443\ttotal: 2m 19s\tremaining: 1m 39s\n",
      "1167:\tlearn: 0.0050413\ttotal: 2m 19s\tremaining: 1m 39s\n",
      "1168:\tlearn: 0.0050349\ttotal: 2m 19s\tremaining: 1m 39s\n",
      "1169:\tlearn: 0.0050316\ttotal: 2m 19s\tremaining: 1m 39s\n",
      "1170:\tlearn: 0.0050294\ttotal: 2m 19s\tremaining: 1m 39s\n",
      "1171:\tlearn: 0.0050287\ttotal: 2m 20s\tremaining: 1m 38s\n",
      "1172:\tlearn: 0.0050279\ttotal: 2m 20s\tremaining: 1m 38s\n",
      "1173:\tlearn: 0.0050268\ttotal: 2m 20s\tremaining: 1m 38s\n",
      "1174:\tlearn: 0.0050260\ttotal: 2m 20s\tremaining: 1m 38s\n",
      "1175:\tlearn: 0.0050246\ttotal: 2m 20s\tremaining: 1m 38s\n",
      "1176:\tlearn: 0.0050187\ttotal: 2m 20s\tremaining: 1m 38s\n",
      "1177:\tlearn: 0.0050158\ttotal: 2m 20s\tremaining: 1m 38s\n",
      "1178:\tlearn: 0.0050127\ttotal: 2m 20s\tremaining: 1m 38s\n",
      "1179:\tlearn: 0.0050096\ttotal: 2m 20s\tremaining: 1m 37s\n",
      "1180:\tlearn: 0.0050042\ttotal: 2m 21s\tremaining: 1m 37s\n",
      "1181:\tlearn: 0.0050031\ttotal: 2m 21s\tremaining: 1m 37s\n",
      "1182:\tlearn: 0.0050016\ttotal: 2m 21s\tremaining: 1m 37s\n",
      "1183:\tlearn: 0.0050006\ttotal: 2m 21s\tremaining: 1m 37s\n",
      "1184:\tlearn: 0.0049954\ttotal: 2m 21s\tremaining: 1m 37s\n",
      "1185:\tlearn: 0.0049839\ttotal: 2m 21s\tremaining: 1m 37s\n",
      "1186:\tlearn: 0.0049810\ttotal: 2m 21s\tremaining: 1m 37s\n",
      "1187:\tlearn: 0.0049802\ttotal: 2m 21s\tremaining: 1m 36s\n",
      "1188:\tlearn: 0.0049777\ttotal: 2m 22s\tremaining: 1m 36s\n",
      "1189:\tlearn: 0.0049764\ttotal: 2m 22s\tremaining: 1m 36s\n",
      "1190:\tlearn: 0.0049637\ttotal: 2m 22s\tremaining: 1m 36s\n",
      "1191:\tlearn: 0.0049630\ttotal: 2m 22s\tremaining: 1m 36s\n",
      "1192:\tlearn: 0.0049612\ttotal: 2m 22s\tremaining: 1m 36s\n",
      "1193:\tlearn: 0.0049604\ttotal: 2m 22s\tremaining: 1m 36s\n",
      "1194:\tlearn: 0.0049582\ttotal: 2m 22s\tremaining: 1m 36s\n",
      "1195:\tlearn: 0.0049563\ttotal: 2m 22s\tremaining: 1m 36s\n",
      "1196:\tlearn: 0.0049521\ttotal: 2m 22s\tremaining: 1m 35s\n",
      "1197:\tlearn: 0.0049474\ttotal: 2m 23s\tremaining: 1m 35s\n",
      "1198:\tlearn: 0.0049392\ttotal: 2m 23s\tremaining: 1m 35s\n",
      "1199:\tlearn: 0.0049384\ttotal: 2m 23s\tremaining: 1m 35s\n",
      "1200:\tlearn: 0.0049376\ttotal: 2m 23s\tremaining: 1m 35s\n",
      "1201:\tlearn: 0.0049352\ttotal: 2m 23s\tremaining: 1m 35s\n",
      "1202:\tlearn: 0.0049306\ttotal: 2m 23s\tremaining: 1m 35s\n",
      "1203:\tlearn: 0.0049300\ttotal: 2m 23s\tremaining: 1m 35s\n",
      "1204:\tlearn: 0.0049285\ttotal: 2m 23s\tremaining: 1m 34s\n",
      "1205:\tlearn: 0.0049233\ttotal: 2m 24s\tremaining: 1m 34s\n",
      "1206:\tlearn: 0.0049194\ttotal: 2m 24s\tremaining: 1m 34s\n",
      "1207:\tlearn: 0.0049106\ttotal: 2m 24s\tremaining: 1m 34s\n",
      "1208:\tlearn: 0.0049093\ttotal: 2m 24s\tremaining: 1m 34s\n",
      "1209:\tlearn: 0.0049045\ttotal: 2m 24s\tremaining: 1m 34s\n",
      "1210:\tlearn: 0.0049034\ttotal: 2m 24s\tremaining: 1m 34s\n",
      "1211:\tlearn: 0.0048916\ttotal: 2m 24s\tremaining: 1m 34s\n",
      "1212:\tlearn: 0.0048878\ttotal: 2m 24s\tremaining: 1m 33s\n",
      "1213:\tlearn: 0.0048853\ttotal: 2m 24s\tremaining: 1m 33s\n",
      "1214:\tlearn: 0.0048844\ttotal: 2m 25s\tremaining: 1m 33s\n",
      "1215:\tlearn: 0.0048841\ttotal: 2m 25s\tremaining: 1m 33s\n",
      "1216:\tlearn: 0.0048830\ttotal: 2m 25s\tremaining: 1m 33s\n",
      "1217:\tlearn: 0.0048812\ttotal: 2m 25s\tremaining: 1m 33s\n",
      "1218:\tlearn: 0.0048768\ttotal: 2m 25s\tremaining: 1m 33s\n",
      "1219:\tlearn: 0.0048695\ttotal: 2m 25s\tremaining: 1m 33s\n",
      "1220:\tlearn: 0.0048654\ttotal: 2m 25s\tremaining: 1m 33s\n",
      "1221:\tlearn: 0.0048580\ttotal: 2m 25s\tremaining: 1m 32s\n",
      "1222:\tlearn: 0.0048573\ttotal: 2m 26s\tremaining: 1m 32s\n",
      "1223:\tlearn: 0.0048524\ttotal: 2m 26s\tremaining: 1m 32s\n",
      "1224:\tlearn: 0.0048520\ttotal: 2m 26s\tremaining: 1m 32s\n",
      "1225:\tlearn: 0.0048504\ttotal: 2m 26s\tremaining: 1m 32s\n",
      "1226:\tlearn: 0.0048448\ttotal: 2m 26s\tremaining: 1m 32s\n",
      "1227:\tlearn: 0.0048430\ttotal: 2m 26s\tremaining: 1m 32s\n",
      "1228:\tlearn: 0.0048414\ttotal: 2m 26s\tremaining: 1m 32s\n",
      "1229:\tlearn: 0.0048275\ttotal: 2m 26s\tremaining: 1m 31s\n",
      "1230:\tlearn: 0.0048242\ttotal: 2m 26s\tremaining: 1m 31s\n",
      "1231:\tlearn: 0.0048137\ttotal: 2m 27s\tremaining: 1m 31s\n",
      "1232:\tlearn: 0.0048112\ttotal: 2m 27s\tremaining: 1m 31s\n",
      "1233:\tlearn: 0.0048053\ttotal: 2m 27s\tremaining: 1m 31s\n",
      "1234:\tlearn: 0.0048034\ttotal: 2m 27s\tremaining: 1m 31s\n",
      "1235:\tlearn: 0.0048004\ttotal: 2m 27s\tremaining: 1m 31s\n",
      "1236:\tlearn: 0.0047959\ttotal: 2m 27s\tremaining: 1m 31s\n",
      "1237:\tlearn: 0.0047935\ttotal: 2m 27s\tremaining: 1m 30s\n",
      "1238:\tlearn: 0.0047901\ttotal: 2m 27s\tremaining: 1m 30s\n",
      "1239:\tlearn: 0.0047877\ttotal: 2m 28s\tremaining: 1m 30s\n",
      "1240:\tlearn: 0.0047818\ttotal: 2m 28s\tremaining: 1m 30s\n",
      "1241:\tlearn: 0.0047732\ttotal: 2m 28s\tremaining: 1m 30s\n",
      "1242:\tlearn: 0.0047682\ttotal: 2m 28s\tremaining: 1m 30s\n",
      "1243:\tlearn: 0.0047680\ttotal: 2m 28s\tremaining: 1m 30s\n",
      "1244:\tlearn: 0.0047650\ttotal: 2m 28s\tremaining: 1m 30s\n",
      "1245:\tlearn: 0.0047608\ttotal: 2m 28s\tremaining: 1m 30s\n",
      "1246:\tlearn: 0.0047584\ttotal: 2m 28s\tremaining: 1m 29s\n",
      "1247:\tlearn: 0.0047571\ttotal: 2m 29s\tremaining: 1m 29s\n",
      "1248:\tlearn: 0.0047553\ttotal: 2m 29s\tremaining: 1m 29s\n",
      "1249:\tlearn: 0.0047532\ttotal: 2m 29s\tremaining: 1m 29s\n",
      "1250:\tlearn: 0.0047521\ttotal: 2m 29s\tremaining: 1m 29s\n",
      "1251:\tlearn: 0.0047519\ttotal: 2m 29s\tremaining: 1m 29s\n",
      "1252:\tlearn: 0.0047497\ttotal: 2m 29s\tremaining: 1m 29s\n",
      "1253:\tlearn: 0.0047485\ttotal: 2m 29s\tremaining: 1m 29s\n",
      "1254:\tlearn: 0.0047446\ttotal: 2m 29s\tremaining: 1m 28s\n",
      "1255:\tlearn: 0.0047401\ttotal: 2m 30s\tremaining: 1m 28s\n",
      "1256:\tlearn: 0.0047386\ttotal: 2m 30s\tremaining: 1m 28s\n",
      "1257:\tlearn: 0.0047359\ttotal: 2m 30s\tremaining: 1m 28s\n",
      "1258:\tlearn: 0.0047334\ttotal: 2m 30s\tremaining: 1m 28s\n",
      "1259:\tlearn: 0.0047280\ttotal: 2m 30s\tremaining: 1m 28s\n",
      "1260:\tlearn: 0.0047268\ttotal: 2m 30s\tremaining: 1m 28s\n",
      "1261:\tlearn: 0.0047258\ttotal: 2m 30s\tremaining: 1m 28s\n",
      "1262:\tlearn: 0.0047191\ttotal: 2m 30s\tremaining: 1m 28s\n",
      "1263:\tlearn: 0.0047129\ttotal: 2m 31s\tremaining: 1m 27s\n",
      "1264:\tlearn: 0.0047125\ttotal: 2m 31s\tremaining: 1m 27s\n",
      "1265:\tlearn: 0.0047115\ttotal: 2m 31s\tremaining: 1m 27s\n",
      "1266:\tlearn: 0.0047099\ttotal: 2m 31s\tremaining: 1m 27s\n",
      "1267:\tlearn: 0.0047085\ttotal: 2m 31s\tremaining: 1m 27s\n",
      "1268:\tlearn: 0.0047077\ttotal: 2m 31s\tremaining: 1m 27s\n",
      "1269:\tlearn: 0.0047069\ttotal: 2m 31s\tremaining: 1m 27s\n",
      "1270:\tlearn: 0.0047056\ttotal: 2m 31s\tremaining: 1m 27s\n",
      "1271:\tlearn: 0.0047048\ttotal: 2m 31s\tremaining: 1m 26s\n",
      "1272:\tlearn: 0.0047040\ttotal: 2m 32s\tremaining: 1m 26s\n",
      "1273:\tlearn: 0.0047037\ttotal: 2m 32s\tremaining: 1m 26s\n",
      "1274:\tlearn: 0.0047017\ttotal: 2m 32s\tremaining: 1m 26s\n",
      "1275:\tlearn: 0.0047013\ttotal: 2m 32s\tremaining: 1m 26s\n",
      "1276:\tlearn: 0.0046992\ttotal: 2m 32s\tremaining: 1m 26s\n",
      "1277:\tlearn: 0.0046979\ttotal: 2m 32s\tremaining: 1m 26s\n",
      "1278:\tlearn: 0.0046946\ttotal: 2m 32s\tremaining: 1m 26s\n",
      "1279:\tlearn: 0.0046914\ttotal: 2m 32s\tremaining: 1m 25s\n",
      "1280:\tlearn: 0.0046889\ttotal: 2m 33s\tremaining: 1m 25s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1281:\tlearn: 0.0046828\ttotal: 2m 33s\tremaining: 1m 25s\n",
      "1282:\tlearn: 0.0046816\ttotal: 2m 33s\tremaining: 1m 25s\n",
      "1283:\tlearn: 0.0046804\ttotal: 2m 33s\tremaining: 1m 25s\n",
      "1284:\tlearn: 0.0046771\ttotal: 2m 33s\tremaining: 1m 25s\n",
      "1285:\tlearn: 0.0046766\ttotal: 2m 33s\tremaining: 1m 25s\n",
      "1286:\tlearn: 0.0046752\ttotal: 2m 33s\tremaining: 1m 25s\n",
      "1287:\tlearn: 0.0046733\ttotal: 2m 33s\tremaining: 1m 25s\n",
      "1288:\tlearn: 0.0046725\ttotal: 2m 33s\tremaining: 1m 24s\n",
      "1289:\tlearn: 0.0046607\ttotal: 2m 34s\tremaining: 1m 24s\n",
      "1290:\tlearn: 0.0046595\ttotal: 2m 34s\tremaining: 1m 24s\n",
      "1291:\tlearn: 0.0046588\ttotal: 2m 34s\tremaining: 1m 24s\n",
      "1292:\tlearn: 0.0046580\ttotal: 2m 34s\tremaining: 1m 24s\n",
      "1293:\tlearn: 0.0046578\ttotal: 2m 34s\tremaining: 1m 24s\n",
      "1294:\tlearn: 0.0046576\ttotal: 2m 34s\tremaining: 1m 24s\n",
      "1295:\tlearn: 0.0046550\ttotal: 2m 34s\tremaining: 1m 24s\n",
      "1296:\tlearn: 0.0046543\ttotal: 2m 34s\tremaining: 1m 23s\n",
      "1297:\tlearn: 0.0046526\ttotal: 2m 34s\tremaining: 1m 23s\n",
      "1298:\tlearn: 0.0046506\ttotal: 2m 35s\tremaining: 1m 23s\n",
      "1299:\tlearn: 0.0046502\ttotal: 2m 35s\tremaining: 1m 23s\n",
      "1300:\tlearn: 0.0046449\ttotal: 2m 35s\tremaining: 1m 23s\n",
      "1301:\tlearn: 0.0046428\ttotal: 2m 35s\tremaining: 1m 23s\n",
      "1302:\tlearn: 0.0046416\ttotal: 2m 35s\tremaining: 1m 23s\n",
      "1303:\tlearn: 0.0046406\ttotal: 2m 35s\tremaining: 1m 23s\n",
      "1304:\tlearn: 0.0046385\ttotal: 2m 35s\tremaining: 1m 22s\n",
      "1305:\tlearn: 0.0046372\ttotal: 2m 35s\tremaining: 1m 22s\n",
      "1306:\tlearn: 0.0046359\ttotal: 2m 36s\tremaining: 1m 22s\n",
      "1307:\tlearn: 0.0046357\ttotal: 2m 36s\tremaining: 1m 22s\n",
      "1308:\tlearn: 0.0046343\ttotal: 2m 36s\tremaining: 1m 22s\n",
      "1309:\tlearn: 0.0046334\ttotal: 2m 36s\tremaining: 1m 22s\n",
      "1310:\tlearn: 0.0046307\ttotal: 2m 36s\tremaining: 1m 22s\n",
      "1311:\tlearn: 0.0046259\ttotal: 2m 36s\tremaining: 1m 22s\n",
      "1312:\tlearn: 0.0046248\ttotal: 2m 36s\tremaining: 1m 22s\n",
      "1313:\tlearn: 0.0046247\ttotal: 2m 36s\tremaining: 1m 21s\n",
      "1314:\tlearn: 0.0046244\ttotal: 2m 36s\tremaining: 1m 21s\n",
      "1315:\tlearn: 0.0046184\ttotal: 2m 37s\tremaining: 1m 21s\n",
      "1316:\tlearn: 0.0046169\ttotal: 2m 37s\tremaining: 1m 21s\n",
      "1317:\tlearn: 0.0046159\ttotal: 2m 37s\tremaining: 1m 21s\n",
      "1318:\tlearn: 0.0046129\ttotal: 2m 37s\tremaining: 1m 21s\n",
      "1319:\tlearn: 0.0046117\ttotal: 2m 37s\tremaining: 1m 21s\n",
      "1320:\tlearn: 0.0046112\ttotal: 2m 37s\tremaining: 1m 21s\n",
      "1321:\tlearn: 0.0046101\ttotal: 2m 37s\tremaining: 1m 20s\n",
      "1322:\tlearn: 0.0046098\ttotal: 2m 37s\tremaining: 1m 20s\n",
      "1323:\tlearn: 0.0046090\ttotal: 2m 38s\tremaining: 1m 20s\n",
      "1324:\tlearn: 0.0045965\ttotal: 2m 38s\tremaining: 1m 20s\n",
      "1325:\tlearn: 0.0045960\ttotal: 2m 38s\tremaining: 1m 20s\n",
      "1326:\tlearn: 0.0045959\ttotal: 2m 38s\tremaining: 1m 20s\n",
      "1327:\tlearn: 0.0045947\ttotal: 2m 38s\tremaining: 1m 20s\n",
      "1328:\tlearn: 0.0045941\ttotal: 2m 38s\tremaining: 1m 20s\n",
      "1329:\tlearn: 0.0045934\ttotal: 2m 38s\tremaining: 1m 19s\n",
      "1330:\tlearn: 0.0045916\ttotal: 2m 38s\tremaining: 1m 19s\n",
      "1331:\tlearn: 0.0045885\ttotal: 2m 38s\tremaining: 1m 19s\n",
      "1332:\tlearn: 0.0045881\ttotal: 2m 39s\tremaining: 1m 19s\n",
      "1333:\tlearn: 0.0045795\ttotal: 2m 39s\tremaining: 1m 19s\n",
      "1334:\tlearn: 0.0045775\ttotal: 2m 39s\tremaining: 1m 19s\n",
      "1335:\tlearn: 0.0045752\ttotal: 2m 39s\tremaining: 1m 19s\n",
      "1336:\tlearn: 0.0045737\ttotal: 2m 39s\tremaining: 1m 19s\n",
      "1337:\tlearn: 0.0045710\ttotal: 2m 39s\tremaining: 1m 18s\n",
      "1338:\tlearn: 0.0045682\ttotal: 2m 39s\tremaining: 1m 18s\n",
      "1339:\tlearn: 0.0045661\ttotal: 2m 39s\tremaining: 1m 18s\n",
      "1340:\tlearn: 0.0045633\ttotal: 2m 40s\tremaining: 1m 18s\n",
      "1341:\tlearn: 0.0045622\ttotal: 2m 40s\tremaining: 1m 18s\n",
      "1342:\tlearn: 0.0045618\ttotal: 2m 40s\tremaining: 1m 18s\n",
      "1343:\tlearn: 0.0045589\ttotal: 2m 40s\tremaining: 1m 18s\n",
      "1344:\tlearn: 0.0045555\ttotal: 2m 40s\tremaining: 1m 18s\n",
      "1345:\tlearn: 0.0045546\ttotal: 2m 40s\tremaining: 1m 18s\n",
      "1346:\tlearn: 0.0045519\ttotal: 2m 40s\tremaining: 1m 17s\n",
      "1347:\tlearn: 0.0045414\ttotal: 2m 40s\tremaining: 1m 17s\n",
      "1348:\tlearn: 0.0045348\ttotal: 2m 40s\tremaining: 1m 17s\n",
      "1349:\tlearn: 0.0045339\ttotal: 2m 41s\tremaining: 1m 17s\n",
      "1350:\tlearn: 0.0045322\ttotal: 2m 41s\tremaining: 1m 17s\n",
      "1351:\tlearn: 0.0045303\ttotal: 2m 41s\tremaining: 1m 17s\n",
      "1352:\tlearn: 0.0045297\ttotal: 2m 41s\tremaining: 1m 17s\n",
      "1353:\tlearn: 0.0045288\ttotal: 2m 41s\tremaining: 1m 17s\n",
      "1354:\tlearn: 0.0045263\ttotal: 2m 41s\tremaining: 1m 16s\n",
      "1355:\tlearn: 0.0045253\ttotal: 2m 41s\tremaining: 1m 16s\n",
      "1356:\tlearn: 0.0045231\ttotal: 2m 41s\tremaining: 1m 16s\n",
      "1357:\tlearn: 0.0045157\ttotal: 2m 41s\tremaining: 1m 16s\n",
      "1358:\tlearn: 0.0045150\ttotal: 2m 42s\tremaining: 1m 16s\n",
      "1359:\tlearn: 0.0045145\ttotal: 2m 42s\tremaining: 1m 16s\n",
      "1360:\tlearn: 0.0045133\ttotal: 2m 42s\tremaining: 1m 16s\n",
      "1361:\tlearn: 0.0045113\ttotal: 2m 42s\tremaining: 1m 16s\n",
      "1362:\tlearn: 0.0045100\ttotal: 2m 42s\tremaining: 1m 15s\n",
      "1363:\tlearn: 0.0045076\ttotal: 2m 42s\tremaining: 1m 15s\n",
      "1364:\tlearn: 0.0045040\ttotal: 2m 42s\tremaining: 1m 15s\n",
      "1365:\tlearn: 0.0044998\ttotal: 2m 42s\tremaining: 1m 15s\n",
      "1366:\tlearn: 0.0044966\ttotal: 2m 43s\tremaining: 1m 15s\n",
      "1367:\tlearn: 0.0044958\ttotal: 2m 43s\tremaining: 1m 15s\n",
      "1368:\tlearn: 0.0044952\ttotal: 2m 43s\tremaining: 1m 15s\n",
      "1369:\tlearn: 0.0044950\ttotal: 2m 43s\tremaining: 1m 15s\n",
      "1370:\tlearn: 0.0044932\ttotal: 2m 43s\tremaining: 1m 14s\n",
      "1371:\tlearn: 0.0044930\ttotal: 2m 43s\tremaining: 1m 14s\n",
      "1372:\tlearn: 0.0044908\ttotal: 2m 43s\tremaining: 1m 14s\n",
      "1373:\tlearn: 0.0044901\ttotal: 2m 43s\tremaining: 1m 14s\n",
      "1374:\tlearn: 0.0044879\ttotal: 2m 43s\tremaining: 1m 14s\n",
      "1375:\tlearn: 0.0044852\ttotal: 2m 44s\tremaining: 1m 14s\n",
      "1376:\tlearn: 0.0044817\ttotal: 2m 44s\tremaining: 1m 14s\n",
      "1377:\tlearn: 0.0044812\ttotal: 2m 44s\tremaining: 1m 14s\n",
      "1378:\tlearn: 0.0044776\ttotal: 2m 44s\tremaining: 1m 14s\n",
      "1379:\tlearn: 0.0044753\ttotal: 2m 44s\tremaining: 1m 13s\n",
      "1380:\tlearn: 0.0044732\ttotal: 2m 44s\tremaining: 1m 13s\n",
      "1381:\tlearn: 0.0044708\ttotal: 2m 44s\tremaining: 1m 13s\n",
      "1382:\tlearn: 0.0044669\ttotal: 2m 44s\tremaining: 1m 13s\n",
      "1383:\tlearn: 0.0044635\ttotal: 2m 44s\tremaining: 1m 13s\n",
      "1384:\tlearn: 0.0044607\ttotal: 2m 45s\tremaining: 1m 13s\n",
      "1385:\tlearn: 0.0044596\ttotal: 2m 45s\tremaining: 1m 13s\n",
      "1386:\tlearn: 0.0044583\ttotal: 2m 45s\tremaining: 1m 13s\n",
      "1387:\tlearn: 0.0044569\ttotal: 2m 45s\tremaining: 1m 12s\n",
      "1388:\tlearn: 0.0044544\ttotal: 2m 45s\tremaining: 1m 12s\n",
      "1389:\tlearn: 0.0044530\ttotal: 2m 45s\tremaining: 1m 12s\n",
      "1390:\tlearn: 0.0044513\ttotal: 2m 45s\tremaining: 1m 12s\n",
      "1391:\tlearn: 0.0044509\ttotal: 2m 45s\tremaining: 1m 12s\n",
      "1392:\tlearn: 0.0044491\ttotal: 2m 46s\tremaining: 1m 12s\n",
      "1393:\tlearn: 0.0044478\ttotal: 2m 46s\tremaining: 1m 12s\n",
      "1394:\tlearn: 0.0044461\ttotal: 2m 46s\tremaining: 1m 12s\n",
      "1395:\tlearn: 0.0044451\ttotal: 2m 46s\tremaining: 1m 11s\n",
      "1396:\tlearn: 0.0044446\ttotal: 2m 46s\tremaining: 1m 11s\n",
      "1397:\tlearn: 0.0044401\ttotal: 2m 46s\tremaining: 1m 11s\n",
      "1398:\tlearn: 0.0044396\ttotal: 2m 46s\tremaining: 1m 11s\n",
      "1399:\tlearn: 0.0044379\ttotal: 2m 46s\tremaining: 1m 11s\n",
      "1400:\tlearn: 0.0044350\ttotal: 2m 47s\tremaining: 1m 11s\n",
      "1401:\tlearn: 0.0044347\ttotal: 2m 47s\tremaining: 1m 11s\n",
      "1402:\tlearn: 0.0044344\ttotal: 2m 47s\tremaining: 1m 11s\n",
      "1403:\tlearn: 0.0044339\ttotal: 2m 47s\tremaining: 1m 11s\n",
      "1404:\tlearn: 0.0044335\ttotal: 2m 47s\tremaining: 1m 10s\n",
      "1405:\tlearn: 0.0044319\ttotal: 2m 47s\tremaining: 1m 10s\n",
      "1406:\tlearn: 0.0044287\ttotal: 2m 47s\tremaining: 1m 10s\n",
      "1407:\tlearn: 0.0044285\ttotal: 2m 47s\tremaining: 1m 10s\n",
      "1408:\tlearn: 0.0044249\ttotal: 2m 47s\tremaining: 1m 10s\n",
      "1409:\tlearn: 0.0044158\ttotal: 2m 48s\tremaining: 1m 10s\n",
      "1410:\tlearn: 0.0044144\ttotal: 2m 48s\tremaining: 1m 10s\n",
      "1411:\tlearn: 0.0044142\ttotal: 2m 48s\tremaining: 1m 10s\n",
      "1412:\tlearn: 0.0044135\ttotal: 2m 48s\tremaining: 1m 9s\n",
      "1413:\tlearn: 0.0044107\ttotal: 2m 48s\tremaining: 1m 9s\n",
      "1414:\tlearn: 0.0044094\ttotal: 2m 48s\tremaining: 1m 9s\n",
      "1415:\tlearn: 0.0044088\ttotal: 2m 48s\tremaining: 1m 9s\n",
      "1416:\tlearn: 0.0044069\ttotal: 2m 48s\tremaining: 1m 9s\n",
      "1417:\tlearn: 0.0043937\ttotal: 2m 49s\tremaining: 1m 9s\n",
      "1418:\tlearn: 0.0043924\ttotal: 2m 49s\tremaining: 1m 9s\n",
      "1419:\tlearn: 0.0043905\ttotal: 2m 49s\tremaining: 1m 9s\n",
      "1420:\tlearn: 0.0043880\ttotal: 2m 49s\tremaining: 1m 9s\n",
      "1421:\tlearn: 0.0043859\ttotal: 2m 49s\tremaining: 1m 8s\n",
      "1422:\tlearn: 0.0043798\ttotal: 2m 49s\tremaining: 1m 8s\n",
      "1423:\tlearn: 0.0043780\ttotal: 2m 49s\tremaining: 1m 8s\n",
      "1424:\tlearn: 0.0043753\ttotal: 2m 49s\tremaining: 1m 8s\n",
      "1425:\tlearn: 0.0043732\ttotal: 2m 49s\tremaining: 1m 8s\n",
      "1426:\tlearn: 0.0043726\ttotal: 2m 50s\tremaining: 1m 8s\n",
      "1427:\tlearn: 0.0043702\ttotal: 2m 50s\tremaining: 1m 8s\n",
      "1428:\tlearn: 0.0043699\ttotal: 2m 50s\tremaining: 1m 8s\n",
      "1429:\tlearn: 0.0043579\ttotal: 2m 50s\tremaining: 1m 7s\n",
      "1430:\tlearn: 0.0043559\ttotal: 2m 50s\tremaining: 1m 7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1431:\tlearn: 0.0043545\ttotal: 2m 50s\tremaining: 1m 7s\n",
      "1432:\tlearn: 0.0043535\ttotal: 2m 50s\tremaining: 1m 7s\n",
      "1433:\tlearn: 0.0043509\ttotal: 2m 50s\tremaining: 1m 7s\n",
      "1434:\tlearn: 0.0043509\ttotal: 2m 51s\tremaining: 1m 7s\n",
      "1435:\tlearn: 0.0043504\ttotal: 2m 51s\tremaining: 1m 7s\n",
      "1436:\tlearn: 0.0043502\ttotal: 2m 51s\tremaining: 1m 7s\n",
      "1437:\tlearn: 0.0043497\ttotal: 2m 51s\tremaining: 1m 6s\n",
      "1438:\tlearn: 0.0043496\ttotal: 2m 51s\tremaining: 1m 6s\n",
      "1439:\tlearn: 0.0043452\ttotal: 2m 51s\tremaining: 1m 6s\n",
      "1440:\tlearn: 0.0043440\ttotal: 2m 51s\tremaining: 1m 6s\n",
      "1441:\tlearn: 0.0043377\ttotal: 2m 51s\tremaining: 1m 6s\n",
      "1442:\tlearn: 0.0043375\ttotal: 2m 51s\tremaining: 1m 6s\n",
      "1443:\tlearn: 0.0043365\ttotal: 2m 52s\tremaining: 1m 6s\n",
      "1444:\tlearn: 0.0043353\ttotal: 2m 52s\tremaining: 1m 6s\n",
      "1445:\tlearn: 0.0043347\ttotal: 2m 52s\tremaining: 1m 6s\n",
      "1446:\tlearn: 0.0043321\ttotal: 2m 52s\tremaining: 1m 5s\n",
      "1447:\tlearn: 0.0043293\ttotal: 2m 52s\tremaining: 1m 5s\n",
      "1448:\tlearn: 0.0043258\ttotal: 2m 52s\tremaining: 1m 5s\n",
      "1449:\tlearn: 0.0043219\ttotal: 2m 52s\tremaining: 1m 5s\n",
      "1450:\tlearn: 0.0043140\ttotal: 2m 52s\tremaining: 1m 5s\n",
      "1451:\tlearn: 0.0043129\ttotal: 2m 53s\tremaining: 1m 5s\n",
      "1452:\tlearn: 0.0043124\ttotal: 2m 53s\tremaining: 1m 5s\n",
      "1453:\tlearn: 0.0043107\ttotal: 2m 53s\tremaining: 1m 5s\n",
      "1454:\tlearn: 0.0043106\ttotal: 2m 53s\tremaining: 1m 4s\n",
      "1455:\tlearn: 0.0043074\ttotal: 2m 53s\tremaining: 1m 4s\n",
      "1456:\tlearn: 0.0043071\ttotal: 2m 53s\tremaining: 1m 4s\n",
      "1457:\tlearn: 0.0043054\ttotal: 2m 53s\tremaining: 1m 4s\n",
      "1458:\tlearn: 0.0042993\ttotal: 2m 53s\tremaining: 1m 4s\n",
      "1459:\tlearn: 0.0042966\ttotal: 2m 53s\tremaining: 1m 4s\n",
      "1460:\tlearn: 0.0042935\ttotal: 2m 54s\tremaining: 1m 4s\n",
      "1461:\tlearn: 0.0042921\ttotal: 2m 54s\tremaining: 1m 4s\n",
      "1462:\tlearn: 0.0042916\ttotal: 2m 54s\tremaining: 1m 3s\n",
      "1463:\tlearn: 0.0042883\ttotal: 2m 54s\tremaining: 1m 3s\n",
      "1464:\tlearn: 0.0042880\ttotal: 2m 54s\tremaining: 1m 3s\n",
      "1465:\tlearn: 0.0042850\ttotal: 2m 54s\tremaining: 1m 3s\n",
      "1466:\tlearn: 0.0042827\ttotal: 2m 54s\tremaining: 1m 3s\n",
      "1467:\tlearn: 0.0042820\ttotal: 2m 54s\tremaining: 1m 3s\n",
      "1468:\tlearn: 0.0042798\ttotal: 2m 55s\tremaining: 1m 3s\n",
      "1469:\tlearn: 0.0042756\ttotal: 2m 55s\tremaining: 1m 3s\n",
      "1470:\tlearn: 0.0042748\ttotal: 2m 55s\tremaining: 1m 3s\n",
      "1471:\tlearn: 0.0042734\ttotal: 2m 55s\tremaining: 1m 2s\n",
      "1472:\tlearn: 0.0042726\ttotal: 2m 55s\tremaining: 1m 2s\n",
      "1473:\tlearn: 0.0042719\ttotal: 2m 55s\tremaining: 1m 2s\n",
      "1474:\tlearn: 0.0042711\ttotal: 2m 55s\tremaining: 1m 2s\n",
      "1475:\tlearn: 0.0042708\ttotal: 2m 55s\tremaining: 1m 2s\n",
      "1476:\tlearn: 0.0042700\ttotal: 2m 55s\tremaining: 1m 2s\n",
      "1477:\tlearn: 0.0042696\ttotal: 2m 56s\tremaining: 1m 2s\n",
      "1478:\tlearn: 0.0042685\ttotal: 2m 56s\tremaining: 1m 2s\n",
      "1479:\tlearn: 0.0042668\ttotal: 2m 56s\tremaining: 1m 1s\n",
      "1480:\tlearn: 0.0042660\ttotal: 2m 56s\tremaining: 1m 1s\n",
      "1481:\tlearn: 0.0042656\ttotal: 2m 56s\tremaining: 1m 1s\n",
      "1482:\tlearn: 0.0042627\ttotal: 2m 56s\tremaining: 1m 1s\n",
      "1483:\tlearn: 0.0042593\ttotal: 2m 56s\tremaining: 1m 1s\n",
      "1484:\tlearn: 0.0042589\ttotal: 2m 56s\tremaining: 1m 1s\n",
      "1485:\tlearn: 0.0042545\ttotal: 2m 57s\tremaining: 1m 1s\n",
      "1486:\tlearn: 0.0042525\ttotal: 2m 57s\tremaining: 1m 1s\n",
      "1487:\tlearn: 0.0042509\ttotal: 2m 57s\tremaining: 1m 1s\n",
      "1488:\tlearn: 0.0042482\ttotal: 2m 57s\tremaining: 1m\n",
      "1489:\tlearn: 0.0042478\ttotal: 2m 57s\tremaining: 1m\n",
      "1490:\tlearn: 0.0042457\ttotal: 2m 57s\tremaining: 1m\n",
      "1491:\tlearn: 0.0042455\ttotal: 2m 57s\tremaining: 1m\n",
      "1492:\tlearn: 0.0042452\ttotal: 2m 57s\tremaining: 1m\n",
      "1493:\tlearn: 0.0042451\ttotal: 2m 57s\tremaining: 1m\n",
      "1494:\tlearn: 0.0042430\ttotal: 2m 58s\tremaining: 1m\n",
      "1495:\tlearn: 0.0042428\ttotal: 2m 58s\tremaining: 1m\n",
      "1496:\tlearn: 0.0042426\ttotal: 2m 58s\tremaining: 59.9s\n",
      "1497:\tlearn: 0.0042421\ttotal: 2m 58s\tremaining: 59.8s\n",
      "1498:\tlearn: 0.0042391\ttotal: 2m 58s\tremaining: 59.7s\n",
      "1499:\tlearn: 0.0042377\ttotal: 2m 58s\tremaining: 59.6s\n",
      "1500:\tlearn: 0.0042370\ttotal: 2m 58s\tremaining: 59.4s\n",
      "1501:\tlearn: 0.0042366\ttotal: 2m 58s\tremaining: 59.3s\n",
      "1502:\tlearn: 0.0042355\ttotal: 2m 59s\tremaining: 59.2s\n",
      "1503:\tlearn: 0.0042341\ttotal: 2m 59s\tremaining: 59.1s\n",
      "1504:\tlearn: 0.0042321\ttotal: 2m 59s\tremaining: 59s\n",
      "1505:\tlearn: 0.0042258\ttotal: 2m 59s\tremaining: 58.9s\n",
      "1506:\tlearn: 0.0042252\ttotal: 2m 59s\tremaining: 58.7s\n",
      "1507:\tlearn: 0.0042232\ttotal: 2m 59s\tremaining: 58.6s\n",
      "1508:\tlearn: 0.0042225\ttotal: 2m 59s\tremaining: 58.5s\n",
      "1509:\tlearn: 0.0042214\ttotal: 2m 59s\tremaining: 58.4s\n",
      "1510:\tlearn: 0.0042208\ttotal: 3m\tremaining: 58.3s\n",
      "1511:\tlearn: 0.0042204\ttotal: 3m\tremaining: 58.1s\n",
      "1512:\tlearn: 0.0042194\ttotal: 3m\tremaining: 58s\n",
      "1513:\tlearn: 0.0042175\ttotal: 3m\tremaining: 57.9s\n",
      "1514:\tlearn: 0.0042158\ttotal: 3m\tremaining: 57.8s\n",
      "1515:\tlearn: 0.0042147\ttotal: 3m\tremaining: 57.7s\n",
      "1516:\tlearn: 0.0042121\ttotal: 3m\tremaining: 57.6s\n",
      "1517:\tlearn: 0.0042117\ttotal: 3m\tremaining: 57.4s\n",
      "1518:\tlearn: 0.0042114\ttotal: 3m 1s\tremaining: 57.3s\n",
      "1519:\tlearn: 0.0042110\ttotal: 3m 1s\tremaining: 57.2s\n",
      "1520:\tlearn: 0.0042104\ttotal: 3m 1s\tremaining: 57.1s\n",
      "1521:\tlearn: 0.0042099\ttotal: 3m 1s\tremaining: 57s\n",
      "1522:\tlearn: 0.0042084\ttotal: 3m 1s\tremaining: 56.8s\n",
      "1523:\tlearn: 0.0042074\ttotal: 3m 1s\tremaining: 56.7s\n",
      "1524:\tlearn: 0.0042056\ttotal: 3m 1s\tremaining: 56.6s\n",
      "1525:\tlearn: 0.0042036\ttotal: 3m 1s\tremaining: 56.5s\n",
      "1526:\tlearn: 0.0042032\ttotal: 3m 1s\tremaining: 56.4s\n",
      "1527:\tlearn: 0.0041968\ttotal: 3m 2s\tremaining: 56.2s\n",
      "1528:\tlearn: 0.0041966\ttotal: 3m 2s\tremaining: 56.1s\n",
      "1529:\tlearn: 0.0041961\ttotal: 3m 2s\tremaining: 56s\n",
      "1530:\tlearn: 0.0041952\ttotal: 3m 2s\tremaining: 55.9s\n",
      "1531:\tlearn: 0.0041944\ttotal: 3m 2s\tremaining: 55.8s\n",
      "1532:\tlearn: 0.0041926\ttotal: 3m 2s\tremaining: 55.6s\n",
      "1533:\tlearn: 0.0041906\ttotal: 3m 2s\tremaining: 55.5s\n",
      "1534:\tlearn: 0.0041898\ttotal: 3m 2s\tremaining: 55.4s\n",
      "1535:\tlearn: 0.0041898\ttotal: 3m 2s\tremaining: 55.3s\n",
      "1536:\tlearn: 0.0041884\ttotal: 3m 3s\tremaining: 55.2s\n",
      "1537:\tlearn: 0.0041861\ttotal: 3m 3s\tremaining: 55s\n",
      "1538:\tlearn: 0.0041844\ttotal: 3m 3s\tremaining: 54.9s\n",
      "1539:\tlearn: 0.0041826\ttotal: 3m 3s\tremaining: 54.8s\n",
      "1540:\tlearn: 0.0041815\ttotal: 3m 3s\tremaining: 54.7s\n",
      "1541:\tlearn: 0.0041807\ttotal: 3m 3s\tremaining: 54.6s\n",
      "1542:\tlearn: 0.0041805\ttotal: 3m 3s\tremaining: 54.4s\n",
      "1543:\tlearn: 0.0041796\ttotal: 3m 3s\tremaining: 54.3s\n",
      "1544:\tlearn: 0.0041787\ttotal: 3m 4s\tremaining: 54.2s\n",
      "1545:\tlearn: 0.0041780\ttotal: 3m 4s\tremaining: 54.1s\n",
      "1546:\tlearn: 0.0041779\ttotal: 3m 4s\tremaining: 54s\n",
      "1547:\tlearn: 0.0041730\ttotal: 3m 4s\tremaining: 53.8s\n",
      "1548:\tlearn: 0.0041721\ttotal: 3m 4s\tremaining: 53.7s\n",
      "1549:\tlearn: 0.0041707\ttotal: 3m 4s\tremaining: 53.6s\n",
      "1550:\tlearn: 0.0041693\ttotal: 3m 4s\tremaining: 53.5s\n",
      "1551:\tlearn: 0.0041632\ttotal: 3m 4s\tremaining: 53.4s\n",
      "1552:\tlearn: 0.0041613\ttotal: 3m 5s\tremaining: 53.3s\n",
      "1553:\tlearn: 0.0041595\ttotal: 3m 5s\tremaining: 53.1s\n",
      "1554:\tlearn: 0.0041551\ttotal: 3m 5s\tremaining: 53s\n",
      "1555:\tlearn: 0.0041542\ttotal: 3m 5s\tremaining: 52.9s\n",
      "1556:\tlearn: 0.0041537\ttotal: 3m 5s\tremaining: 52.8s\n",
      "1557:\tlearn: 0.0041531\ttotal: 3m 5s\tremaining: 52.7s\n",
      "1558:\tlearn: 0.0041523\ttotal: 3m 5s\tremaining: 52.5s\n",
      "1559:\tlearn: 0.0041451\ttotal: 3m 5s\tremaining: 52.4s\n",
      "1560:\tlearn: 0.0041443\ttotal: 3m 5s\tremaining: 52.3s\n",
      "1561:\tlearn: 0.0041417\ttotal: 3m 6s\tremaining: 52.2s\n",
      "1562:\tlearn: 0.0041376\ttotal: 3m 6s\tremaining: 52.1s\n",
      "1563:\tlearn: 0.0041360\ttotal: 3m 6s\tremaining: 52s\n",
      "1564:\tlearn: 0.0041355\ttotal: 3m 6s\tremaining: 51.8s\n",
      "1565:\tlearn: 0.0041353\ttotal: 3m 6s\tremaining: 51.7s\n",
      "1566:\tlearn: 0.0041336\ttotal: 3m 6s\tremaining: 51.6s\n",
      "1567:\tlearn: 0.0041320\ttotal: 3m 6s\tremaining: 51.5s\n",
      "1568:\tlearn: 0.0041303\ttotal: 3m 6s\tremaining: 51.4s\n",
      "1569:\tlearn: 0.0041297\ttotal: 3m 7s\tremaining: 51.3s\n",
      "1570:\tlearn: 0.0041279\ttotal: 3m 7s\tremaining: 51.1s\n",
      "1571:\tlearn: 0.0041243\ttotal: 3m 7s\tremaining: 51s\n",
      "1572:\tlearn: 0.0041239\ttotal: 3m 7s\tremaining: 50.9s\n",
      "1573:\tlearn: 0.0041224\ttotal: 3m 7s\tremaining: 50.8s\n",
      "1574:\tlearn: 0.0041220\ttotal: 3m 7s\tremaining: 50.6s\n",
      "1575:\tlearn: 0.0041219\ttotal: 3m 7s\tremaining: 50.5s\n",
      "1576:\tlearn: 0.0041209\ttotal: 3m 7s\tremaining: 50.4s\n",
      "1577:\tlearn: 0.0041197\ttotal: 3m 8s\tremaining: 50.3s\n",
      "1578:\tlearn: 0.0041179\ttotal: 3m 8s\tremaining: 50.2s\n",
      "1579:\tlearn: 0.0041174\ttotal: 3m 8s\tremaining: 50s\n",
      "1580:\tlearn: 0.0041166\ttotal: 3m 8s\tremaining: 49.9s\n",
      "1581:\tlearn: 0.0041153\ttotal: 3m 8s\tremaining: 49.8s\n",
      "1582:\tlearn: 0.0041139\ttotal: 3m 8s\tremaining: 49.7s\n",
      "1583:\tlearn: 0.0041136\ttotal: 3m 8s\tremaining: 49.6s\n",
      "1584:\tlearn: 0.0041129\ttotal: 3m 8s\tremaining: 49.5s\n",
      "1585:\tlearn: 0.0041047\ttotal: 3m 8s\tremaining: 49.3s\n",
      "1586:\tlearn: 0.0041037\ttotal: 3m 9s\tremaining: 49.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1587:\tlearn: 0.0041021\ttotal: 3m 9s\tremaining: 49.1s\n",
      "1588:\tlearn: 0.0040883\ttotal: 3m 9s\tremaining: 49s\n",
      "1589:\tlearn: 0.0040878\ttotal: 3m 9s\tremaining: 48.9s\n",
      "1590:\tlearn: 0.0040868\ttotal: 3m 9s\tremaining: 48.7s\n",
      "1591:\tlearn: 0.0040863\ttotal: 3m 9s\tremaining: 48.6s\n",
      "1592:\tlearn: 0.0040862\ttotal: 3m 9s\tremaining: 48.5s\n",
      "1593:\tlearn: 0.0040824\ttotal: 3m 9s\tremaining: 48.4s\n",
      "1594:\tlearn: 0.0040819\ttotal: 3m 10s\tremaining: 48.3s\n",
      "1595:\tlearn: 0.0040798\ttotal: 3m 10s\tremaining: 48.1s\n",
      "1596:\tlearn: 0.0040789\ttotal: 3m 10s\tremaining: 48s\n",
      "1597:\tlearn: 0.0040786\ttotal: 3m 10s\tremaining: 47.9s\n",
      "1598:\tlearn: 0.0040723\ttotal: 3m 10s\tremaining: 47.8s\n",
      "1599:\tlearn: 0.0040713\ttotal: 3m 10s\tremaining: 47.7s\n",
      "1600:\tlearn: 0.0040704\ttotal: 3m 10s\tremaining: 47.5s\n",
      "1601:\tlearn: 0.0040660\ttotal: 3m 10s\tremaining: 47.4s\n",
      "1602:\tlearn: 0.0040653\ttotal: 3m 11s\tremaining: 47.3s\n",
      "1603:\tlearn: 0.0040644\ttotal: 3m 11s\tremaining: 47.2s\n",
      "1604:\tlearn: 0.0040525\ttotal: 3m 11s\tremaining: 47.1s\n",
      "1605:\tlearn: 0.0040522\ttotal: 3m 11s\tremaining: 47s\n",
      "1606:\tlearn: 0.0040512\ttotal: 3m 11s\tremaining: 46.8s\n",
      "1607:\tlearn: 0.0040511\ttotal: 3m 11s\tremaining: 46.7s\n",
      "1608:\tlearn: 0.0040492\ttotal: 3m 11s\tremaining: 46.6s\n",
      "1609:\tlearn: 0.0040489\ttotal: 3m 11s\tremaining: 46.5s\n",
      "1610:\tlearn: 0.0040482\ttotal: 3m 12s\tremaining: 46.4s\n",
      "1611:\tlearn: 0.0040473\ttotal: 3m 12s\tremaining: 46.2s\n",
      "1612:\tlearn: 0.0040439\ttotal: 3m 12s\tremaining: 46.1s\n",
      "1613:\tlearn: 0.0040413\ttotal: 3m 12s\tremaining: 46s\n",
      "1614:\tlearn: 0.0040388\ttotal: 3m 12s\tremaining: 45.9s\n",
      "1615:\tlearn: 0.0040382\ttotal: 3m 12s\tremaining: 45.8s\n",
      "1616:\tlearn: 0.0040370\ttotal: 3m 12s\tremaining: 45.6s\n",
      "1617:\tlearn: 0.0040353\ttotal: 3m 12s\tremaining: 45.5s\n",
      "1618:\tlearn: 0.0040324\ttotal: 3m 12s\tremaining: 45.4s\n",
      "1619:\tlearn: 0.0040282\ttotal: 3m 13s\tremaining: 45.3s\n",
      "1620:\tlearn: 0.0040191\ttotal: 3m 13s\tremaining: 45.2s\n",
      "1621:\tlearn: 0.0040179\ttotal: 3m 13s\tremaining: 45.1s\n",
      "1622:\tlearn: 0.0040177\ttotal: 3m 13s\tremaining: 44.9s\n",
      "1623:\tlearn: 0.0040171\ttotal: 3m 13s\tremaining: 44.8s\n",
      "1624:\tlearn: 0.0040163\ttotal: 3m 13s\tremaining: 44.7s\n",
      "1625:\tlearn: 0.0040150\ttotal: 3m 13s\tremaining: 44.6s\n",
      "1626:\tlearn: 0.0040147\ttotal: 3m 13s\tremaining: 44.5s\n",
      "1627:\tlearn: 0.0040146\ttotal: 3m 14s\tremaining: 44.3s\n",
      "1628:\tlearn: 0.0040140\ttotal: 3m 14s\tremaining: 44.2s\n",
      "1629:\tlearn: 0.0040136\ttotal: 3m 14s\tremaining: 44.1s\n",
      "1630:\tlearn: 0.0040130\ttotal: 3m 14s\tremaining: 44s\n",
      "1631:\tlearn: 0.0040114\ttotal: 3m 14s\tremaining: 43.9s\n",
      "1632:\tlearn: 0.0040081\ttotal: 3m 14s\tremaining: 43.7s\n",
      "1633:\tlearn: 0.0040053\ttotal: 3m 14s\tremaining: 43.6s\n",
      "1634:\tlearn: 0.0040052\ttotal: 3m 14s\tremaining: 43.5s\n",
      "1635:\tlearn: 0.0040038\ttotal: 3m 14s\tremaining: 43.4s\n",
      "1636:\tlearn: 0.0040035\ttotal: 3m 15s\tremaining: 43.3s\n",
      "1637:\tlearn: 0.0039992\ttotal: 3m 15s\tremaining: 43.1s\n",
      "1638:\tlearn: 0.0039970\ttotal: 3m 15s\tremaining: 43s\n",
      "1639:\tlearn: 0.0039945\ttotal: 3m 15s\tremaining: 42.9s\n",
      "1640:\tlearn: 0.0039890\ttotal: 3m 15s\tremaining: 42.8s\n",
      "1641:\tlearn: 0.0039879\ttotal: 3m 15s\tremaining: 42.7s\n",
      "1642:\tlearn: 0.0039794\ttotal: 3m 15s\tremaining: 42.5s\n",
      "1643:\tlearn: 0.0039787\ttotal: 3m 15s\tremaining: 42.4s\n",
      "1644:\tlearn: 0.0039781\ttotal: 3m 16s\tremaining: 42.3s\n",
      "1645:\tlearn: 0.0039765\ttotal: 3m 16s\tremaining: 42.2s\n",
      "1646:\tlearn: 0.0039738\ttotal: 3m 16s\tremaining: 42.1s\n",
      "1647:\tlearn: 0.0039737\ttotal: 3m 16s\tremaining: 42s\n",
      "1648:\tlearn: 0.0039734\ttotal: 3m 16s\tremaining: 41.8s\n",
      "1649:\tlearn: 0.0039733\ttotal: 3m 16s\tremaining: 41.7s\n",
      "1650:\tlearn: 0.0039684\ttotal: 3m 16s\tremaining: 41.6s\n",
      "1651:\tlearn: 0.0039655\ttotal: 3m 16s\tremaining: 41.5s\n",
      "1652:\tlearn: 0.0039652\ttotal: 3m 17s\tremaining: 41.4s\n",
      "1653:\tlearn: 0.0039645\ttotal: 3m 17s\tremaining: 41.2s\n",
      "1654:\tlearn: 0.0039630\ttotal: 3m 17s\tremaining: 41.1s\n",
      "1655:\tlearn: 0.0039623\ttotal: 3m 17s\tremaining: 41s\n",
      "1656:\tlearn: 0.0039616\ttotal: 3m 17s\tremaining: 40.9s\n",
      "1657:\tlearn: 0.0039613\ttotal: 3m 17s\tremaining: 40.8s\n",
      "1658:\tlearn: 0.0039592\ttotal: 3m 17s\tremaining: 40.7s\n",
      "1659:\tlearn: 0.0039582\ttotal: 3m 17s\tremaining: 40.5s\n",
      "1660:\tlearn: 0.0039547\ttotal: 3m 18s\tremaining: 40.4s\n",
      "1661:\tlearn: 0.0039540\ttotal: 3m 18s\tremaining: 40.3s\n",
      "1662:\tlearn: 0.0039360\ttotal: 3m 18s\tremaining: 40.2s\n",
      "1663:\tlearn: 0.0039311\ttotal: 3m 18s\tremaining: 40.1s\n",
      "1664:\tlearn: 0.0039298\ttotal: 3m 18s\tremaining: 39.9s\n",
      "1665:\tlearn: 0.0039293\ttotal: 3m 18s\tremaining: 39.8s\n",
      "1666:\tlearn: 0.0039288\ttotal: 3m 18s\tremaining: 39.7s\n",
      "1667:\tlearn: 0.0039261\ttotal: 3m 18s\tremaining: 39.6s\n",
      "1668:\tlearn: 0.0039257\ttotal: 3m 18s\tremaining: 39.5s\n",
      "1669:\tlearn: 0.0039210\ttotal: 3m 19s\tremaining: 39.3s\n",
      "1670:\tlearn: 0.0039209\ttotal: 3m 19s\tremaining: 39.2s\n",
      "1671:\tlearn: 0.0039206\ttotal: 3m 19s\tremaining: 39.1s\n",
      "1672:\tlearn: 0.0039126\ttotal: 3m 19s\tremaining: 39s\n",
      "1673:\tlearn: 0.0039120\ttotal: 3m 19s\tremaining: 38.9s\n",
      "1674:\tlearn: 0.0039068\ttotal: 3m 19s\tremaining: 38.7s\n",
      "1675:\tlearn: 0.0039063\ttotal: 3m 19s\tremaining: 38.6s\n",
      "1676:\tlearn: 0.0039024\ttotal: 3m 19s\tremaining: 38.5s\n",
      "1677:\tlearn: 0.0039021\ttotal: 3m 20s\tremaining: 38.4s\n",
      "1678:\tlearn: 0.0039005\ttotal: 3m 20s\tremaining: 38.3s\n",
      "1679:\tlearn: 0.0039004\ttotal: 3m 20s\tremaining: 38.2s\n",
      "1680:\tlearn: 0.0038974\ttotal: 3m 20s\tremaining: 38s\n",
      "1681:\tlearn: 0.0038964\ttotal: 3m 20s\tremaining: 37.9s\n",
      "1682:\tlearn: 0.0038958\ttotal: 3m 20s\tremaining: 37.8s\n",
      "1683:\tlearn: 0.0038951\ttotal: 3m 20s\tremaining: 37.7s\n",
      "1684:\tlearn: 0.0038947\ttotal: 3m 20s\tremaining: 37.6s\n",
      "1685:\tlearn: 0.0038928\ttotal: 3m 21s\tremaining: 37.4s\n",
      "1686:\tlearn: 0.0038918\ttotal: 3m 21s\tremaining: 37.3s\n",
      "1687:\tlearn: 0.0038903\ttotal: 3m 21s\tremaining: 37.2s\n",
      "1688:\tlearn: 0.0038900\ttotal: 3m 21s\tremaining: 37.1s\n",
      "1689:\tlearn: 0.0038895\ttotal: 3m 21s\tremaining: 37s\n",
      "1690:\tlearn: 0.0038851\ttotal: 3m 21s\tremaining: 36.8s\n",
      "1691:\tlearn: 0.0038833\ttotal: 3m 21s\tremaining: 36.7s\n",
      "1692:\tlearn: 0.0038815\ttotal: 3m 21s\tremaining: 36.6s\n",
      "1693:\tlearn: 0.0038794\ttotal: 3m 21s\tremaining: 36.5s\n",
      "1694:\tlearn: 0.0038772\ttotal: 3m 22s\tremaining: 36.4s\n",
      "1695:\tlearn: 0.0038764\ttotal: 3m 22s\tremaining: 36.3s\n",
      "1696:\tlearn: 0.0038758\ttotal: 3m 22s\tremaining: 36.1s\n",
      "1697:\tlearn: 0.0038734\ttotal: 3m 22s\tremaining: 36s\n",
      "1698:\tlearn: 0.0038727\ttotal: 3m 22s\tremaining: 35.9s\n",
      "1699:\tlearn: 0.0038692\ttotal: 3m 22s\tremaining: 35.8s\n",
      "1700:\tlearn: 0.0038685\ttotal: 3m 22s\tremaining: 35.7s\n",
      "1701:\tlearn: 0.0038584\ttotal: 3m 22s\tremaining: 35.5s\n",
      "1702:\tlearn: 0.0038551\ttotal: 3m 23s\tremaining: 35.4s\n",
      "1703:\tlearn: 0.0038543\ttotal: 3m 23s\tremaining: 35.3s\n",
      "1704:\tlearn: 0.0038514\ttotal: 3m 23s\tremaining: 35.2s\n",
      "1705:\tlearn: 0.0038505\ttotal: 3m 23s\tremaining: 35.1s\n",
      "1706:\tlearn: 0.0038489\ttotal: 3m 23s\tremaining: 34.9s\n",
      "1707:\tlearn: 0.0038477\ttotal: 3m 23s\tremaining: 34.8s\n",
      "1708:\tlearn: 0.0038473\ttotal: 3m 23s\tremaining: 34.7s\n",
      "1709:\tlearn: 0.0038469\ttotal: 3m 23s\tremaining: 34.6s\n",
      "1710:\tlearn: 0.0038461\ttotal: 3m 24s\tremaining: 34.5s\n",
      "1711:\tlearn: 0.0038451\ttotal: 3m 24s\tremaining: 34.3s\n",
      "1712:\tlearn: 0.0038422\ttotal: 3m 24s\tremaining: 34.2s\n",
      "1713:\tlearn: 0.0038395\ttotal: 3m 24s\tremaining: 34.1s\n",
      "1714:\tlearn: 0.0038379\ttotal: 3m 24s\tremaining: 34s\n",
      "1715:\tlearn: 0.0038377\ttotal: 3m 24s\tremaining: 33.9s\n",
      "1716:\tlearn: 0.0038365\ttotal: 3m 24s\tremaining: 33.8s\n",
      "1717:\tlearn: 0.0038337\ttotal: 3m 24s\tremaining: 33.6s\n",
      "1718:\tlearn: 0.0038312\ttotal: 3m 25s\tremaining: 33.5s\n",
      "1719:\tlearn: 0.0038293\ttotal: 3m 25s\tremaining: 33.4s\n",
      "1720:\tlearn: 0.0038286\ttotal: 3m 25s\tremaining: 33.3s\n",
      "1721:\tlearn: 0.0038280\ttotal: 3m 25s\tremaining: 33.2s\n",
      "1722:\tlearn: 0.0038270\ttotal: 3m 25s\tremaining: 33s\n",
      "1723:\tlearn: 0.0038255\ttotal: 3m 25s\tremaining: 32.9s\n",
      "1724:\tlearn: 0.0038233\ttotal: 3m 25s\tremaining: 32.8s\n",
      "1725:\tlearn: 0.0038197\ttotal: 3m 25s\tremaining: 32.7s\n",
      "1726:\tlearn: 0.0038183\ttotal: 3m 26s\tremaining: 32.6s\n",
      "1727:\tlearn: 0.0038170\ttotal: 3m 26s\tremaining: 32.5s\n",
      "1728:\tlearn: 0.0038165\ttotal: 3m 26s\tremaining: 32.3s\n",
      "1729:\tlearn: 0.0038152\ttotal: 3m 26s\tremaining: 32.2s\n",
      "1730:\tlearn: 0.0038147\ttotal: 3m 26s\tremaining: 32.1s\n",
      "1731:\tlearn: 0.0038143\ttotal: 3m 26s\tremaining: 32s\n",
      "1732:\tlearn: 0.0038137\ttotal: 3m 26s\tremaining: 31.9s\n",
      "1733:\tlearn: 0.0038135\ttotal: 3m 26s\tremaining: 31.7s\n",
      "1734:\tlearn: 0.0038110\ttotal: 3m 26s\tremaining: 31.6s\n",
      "1735:\tlearn: 0.0038086\ttotal: 3m 27s\tremaining: 31.5s\n",
      "1736:\tlearn: 0.0038039\ttotal: 3m 27s\tremaining: 31.4s\n",
      "1737:\tlearn: 0.0037999\ttotal: 3m 27s\tremaining: 31.3s\n",
      "1738:\tlearn: 0.0037984\ttotal: 3m 27s\tremaining: 31.1s\n",
      "1739:\tlearn: 0.0037972\ttotal: 3m 27s\tremaining: 31s\n",
      "1740:\tlearn: 0.0037967\ttotal: 3m 27s\tremaining: 30.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1741:\tlearn: 0.0037943\ttotal: 3m 27s\tremaining: 30.8s\n",
      "1742:\tlearn: 0.0037933\ttotal: 3m 27s\tremaining: 30.7s\n",
      "1743:\tlearn: 0.0037933\ttotal: 3m 28s\tremaining: 30.5s\n",
      "1744:\tlearn: 0.0037930\ttotal: 3m 28s\tremaining: 30.4s\n",
      "1745:\tlearn: 0.0037925\ttotal: 3m 28s\tremaining: 30.3s\n",
      "1746:\tlearn: 0.0037898\ttotal: 3m 28s\tremaining: 30.2s\n",
      "1747:\tlearn: 0.0037892\ttotal: 3m 28s\tremaining: 30.1s\n",
      "1748:\tlearn: 0.0037884\ttotal: 3m 28s\tremaining: 29.9s\n",
      "1749:\tlearn: 0.0037859\ttotal: 3m 28s\tremaining: 29.8s\n",
      "1750:\tlearn: 0.0037845\ttotal: 3m 28s\tremaining: 29.7s\n",
      "1751:\tlearn: 0.0037834\ttotal: 3m 29s\tremaining: 29.6s\n",
      "1752:\tlearn: 0.0037833\ttotal: 3m 29s\tremaining: 29.5s\n",
      "1753:\tlearn: 0.0037796\ttotal: 3m 29s\tremaining: 29.4s\n",
      "1754:\tlearn: 0.0037784\ttotal: 3m 29s\tremaining: 29.2s\n",
      "1755:\tlearn: 0.0037774\ttotal: 3m 29s\tremaining: 29.1s\n",
      "1756:\tlearn: 0.0037762\ttotal: 3m 29s\tremaining: 29s\n",
      "1757:\tlearn: 0.0037756\ttotal: 3m 29s\tremaining: 28.9s\n",
      "1758:\tlearn: 0.0037750\ttotal: 3m 30s\tremaining: 28.8s\n",
      "1759:\tlearn: 0.0037744\ttotal: 3m 30s\tremaining: 28.7s\n",
      "1760:\tlearn: 0.0037728\ttotal: 3m 30s\tremaining: 28.5s\n",
      "1761:\tlearn: 0.0037718\ttotal: 3m 30s\tremaining: 28.4s\n",
      "1762:\tlearn: 0.0037711\ttotal: 3m 30s\tremaining: 28.3s\n",
      "1763:\tlearn: 0.0037700\ttotal: 3m 30s\tremaining: 28.2s\n",
      "1764:\tlearn: 0.0037687\ttotal: 3m 30s\tremaining: 28.1s\n",
      "1765:\tlearn: 0.0037648\ttotal: 3m 30s\tremaining: 28s\n",
      "1766:\tlearn: 0.0037619\ttotal: 3m 31s\tremaining: 27.8s\n",
      "1767:\tlearn: 0.0037605\ttotal: 3m 31s\tremaining: 27.7s\n",
      "1768:\tlearn: 0.0037586\ttotal: 3m 31s\tremaining: 27.6s\n",
      "1769:\tlearn: 0.0037584\ttotal: 3m 31s\tremaining: 27.5s\n",
      "1770:\tlearn: 0.0037559\ttotal: 3m 31s\tremaining: 27.4s\n",
      "1771:\tlearn: 0.0037545\ttotal: 3m 31s\tremaining: 27.2s\n",
      "1772:\tlearn: 0.0037532\ttotal: 3m 31s\tremaining: 27.1s\n",
      "1773:\tlearn: 0.0037526\ttotal: 3m 31s\tremaining: 27s\n",
      "1774:\tlearn: 0.0037516\ttotal: 3m 32s\tremaining: 26.9s\n",
      "1775:\tlearn: 0.0037473\ttotal: 3m 32s\tremaining: 26.8s\n",
      "1776:\tlearn: 0.0037444\ttotal: 3m 32s\tremaining: 26.6s\n",
      "1777:\tlearn: 0.0037437\ttotal: 3m 32s\tremaining: 26.5s\n",
      "1778:\tlearn: 0.0037385\ttotal: 3m 32s\tremaining: 26.4s\n",
      "1779:\tlearn: 0.0037382\ttotal: 3m 32s\tremaining: 26.3s\n",
      "1780:\tlearn: 0.0037359\ttotal: 3m 32s\tremaining: 26.2s\n",
      "1781:\tlearn: 0.0037354\ttotal: 3m 32s\tremaining: 26s\n",
      "1782:\tlearn: 0.0037349\ttotal: 3m 33s\tremaining: 25.9s\n",
      "1783:\tlearn: 0.0037337\ttotal: 3m 33s\tremaining: 25.8s\n",
      "1784:\tlearn: 0.0037321\ttotal: 3m 33s\tremaining: 25.7s\n",
      "1785:\tlearn: 0.0037314\ttotal: 3m 33s\tremaining: 25.6s\n",
      "1786:\tlearn: 0.0037311\ttotal: 3m 33s\tremaining: 25.4s\n",
      "1787:\tlearn: 0.0037308\ttotal: 3m 33s\tremaining: 25.3s\n",
      "1788:\tlearn: 0.0037295\ttotal: 3m 33s\tremaining: 25.2s\n",
      "1789:\tlearn: 0.0037287\ttotal: 3m 33s\tremaining: 25.1s\n",
      "1790:\tlearn: 0.0037243\ttotal: 3m 33s\tremaining: 25s\n",
      "1791:\tlearn: 0.0037235\ttotal: 3m 34s\tremaining: 24.8s\n",
      "1792:\tlearn: 0.0037223\ttotal: 3m 34s\tremaining: 24.7s\n",
      "1793:\tlearn: 0.0037211\ttotal: 3m 34s\tremaining: 24.6s\n",
      "1794:\tlearn: 0.0037204\ttotal: 3m 34s\tremaining: 24.5s\n",
      "1795:\tlearn: 0.0037196\ttotal: 3m 34s\tremaining: 24.4s\n",
      "1796:\tlearn: 0.0037192\ttotal: 3m 34s\tremaining: 24.2s\n",
      "1797:\tlearn: 0.0037134\ttotal: 3m 34s\tremaining: 24.1s\n",
      "1798:\tlearn: 0.0037101\ttotal: 3m 34s\tremaining: 24s\n",
      "1799:\tlearn: 0.0037052\ttotal: 3m 35s\tremaining: 23.9s\n",
      "1800:\tlearn: 0.0037042\ttotal: 3m 35s\tremaining: 23.8s\n",
      "1801:\tlearn: 0.0037023\ttotal: 3m 35s\tremaining: 23.7s\n",
      "1802:\tlearn: 0.0037018\ttotal: 3m 35s\tremaining: 23.5s\n",
      "1803:\tlearn: 0.0037006\ttotal: 3m 35s\tremaining: 23.4s\n",
      "1804:\tlearn: 0.0036981\ttotal: 3m 35s\tremaining: 23.3s\n",
      "1805:\tlearn: 0.0036956\ttotal: 3m 35s\tremaining: 23.2s\n",
      "1806:\tlearn: 0.0036954\ttotal: 3m 35s\tremaining: 23.1s\n",
      "1807:\tlearn: 0.0036950\ttotal: 3m 35s\tremaining: 22.9s\n",
      "1808:\tlearn: 0.0036949\ttotal: 3m 36s\tremaining: 22.8s\n",
      "1809:\tlearn: 0.0036944\ttotal: 3m 36s\tremaining: 22.7s\n",
      "1810:\tlearn: 0.0036941\ttotal: 3m 36s\tremaining: 22.6s\n",
      "1811:\tlearn: 0.0036925\ttotal: 3m 36s\tremaining: 22.5s\n",
      "1812:\tlearn: 0.0036924\ttotal: 3m 36s\tremaining: 22.3s\n",
      "1813:\tlearn: 0.0036912\ttotal: 3m 36s\tremaining: 22.2s\n",
      "1814:\tlearn: 0.0036903\ttotal: 3m 36s\tremaining: 22.1s\n",
      "1815:\tlearn: 0.0036901\ttotal: 3m 36s\tremaining: 22s\n",
      "1816:\tlearn: 0.0036900\ttotal: 3m 37s\tremaining: 21.9s\n",
      "1817:\tlearn: 0.0036895\ttotal: 3m 37s\tremaining: 21.7s\n",
      "1818:\tlearn: 0.0036877\ttotal: 3m 37s\tremaining: 21.6s\n",
      "1819:\tlearn: 0.0036851\ttotal: 3m 37s\tremaining: 21.5s\n",
      "1820:\tlearn: 0.0036834\ttotal: 3m 37s\tremaining: 21.4s\n",
      "1821:\tlearn: 0.0036827\ttotal: 3m 37s\tremaining: 21.3s\n",
      "1822:\tlearn: 0.0036816\ttotal: 3m 37s\tremaining: 21.1s\n",
      "1823:\tlearn: 0.0036810\ttotal: 3m 37s\tremaining: 21s\n",
      "1824:\tlearn: 0.0036792\ttotal: 3m 38s\tremaining: 20.9s\n",
      "1825:\tlearn: 0.0036781\ttotal: 3m 38s\tremaining: 20.8s\n",
      "1826:\tlearn: 0.0036772\ttotal: 3m 38s\tremaining: 20.7s\n",
      "1827:\tlearn: 0.0036756\ttotal: 3m 38s\tremaining: 20.6s\n",
      "1828:\tlearn: 0.0036753\ttotal: 3m 38s\tremaining: 20.4s\n",
      "1829:\tlearn: 0.0036740\ttotal: 3m 38s\tremaining: 20.3s\n",
      "1830:\tlearn: 0.0036716\ttotal: 3m 38s\tremaining: 20.2s\n",
      "1831:\tlearn: 0.0036709\ttotal: 3m 39s\tremaining: 20.1s\n",
      "1832:\tlearn: 0.0036694\ttotal: 3m 39s\tremaining: 20s\n",
      "1833:\tlearn: 0.0036689\ttotal: 3m 39s\tremaining: 19.9s\n",
      "1834:\tlearn: 0.0036685\ttotal: 3m 39s\tremaining: 19.7s\n",
      "1835:\tlearn: 0.0036678\ttotal: 3m 39s\tremaining: 19.6s\n",
      "1836:\tlearn: 0.0036674\ttotal: 3m 39s\tremaining: 19.5s\n",
      "1837:\tlearn: 0.0036673\ttotal: 3m 39s\tremaining: 19.4s\n",
      "1838:\tlearn: 0.0036665\ttotal: 3m 40s\tremaining: 19.3s\n",
      "1839:\tlearn: 0.0036660\ttotal: 3m 40s\tremaining: 19.1s\n",
      "1840:\tlearn: 0.0036657\ttotal: 3m 40s\tremaining: 19s\n",
      "1841:\tlearn: 0.0036586\ttotal: 3m 40s\tremaining: 18.9s\n",
      "1842:\tlearn: 0.0036557\ttotal: 3m 40s\tremaining: 18.8s\n",
      "1843:\tlearn: 0.0036554\ttotal: 3m 40s\tremaining: 18.7s\n",
      "1844:\tlearn: 0.0036549\ttotal: 3m 40s\tremaining: 18.5s\n",
      "1845:\tlearn: 0.0036546\ttotal: 3m 40s\tremaining: 18.4s\n",
      "1846:\tlearn: 0.0036518\ttotal: 3m 40s\tremaining: 18.3s\n",
      "1847:\tlearn: 0.0036514\ttotal: 3m 41s\tremaining: 18.2s\n",
      "1848:\tlearn: 0.0036501\ttotal: 3m 41s\tremaining: 18.1s\n",
      "1849:\tlearn: 0.0036474\ttotal: 3m 41s\tremaining: 17.9s\n",
      "1850:\tlearn: 0.0036467\ttotal: 3m 41s\tremaining: 17.8s\n",
      "1851:\tlearn: 0.0036458\ttotal: 3m 41s\tremaining: 17.7s\n",
      "1852:\tlearn: 0.0036455\ttotal: 3m 41s\tremaining: 17.6s\n",
      "1853:\tlearn: 0.0036447\ttotal: 3m 41s\tremaining: 17.5s\n",
      "1854:\tlearn: 0.0036445\ttotal: 3m 41s\tremaining: 17.3s\n",
      "1855:\tlearn: 0.0036423\ttotal: 3m 42s\tremaining: 17.2s\n",
      "1856:\tlearn: 0.0036422\ttotal: 3m 42s\tremaining: 17.1s\n",
      "1857:\tlearn: 0.0036415\ttotal: 3m 42s\tremaining: 17s\n",
      "1858:\tlearn: 0.0036405\ttotal: 3m 42s\tremaining: 16.9s\n",
      "1859:\tlearn: 0.0036390\ttotal: 3m 42s\tremaining: 16.7s\n",
      "1860:\tlearn: 0.0036369\ttotal: 3m 42s\tremaining: 16.6s\n",
      "1861:\tlearn: 0.0036363\ttotal: 3m 42s\tremaining: 16.5s\n",
      "1862:\tlearn: 0.0036338\ttotal: 3m 42s\tremaining: 16.4s\n",
      "1863:\tlearn: 0.0036314\ttotal: 3m 42s\tremaining: 16.3s\n",
      "1864:\tlearn: 0.0036307\ttotal: 3m 43s\tremaining: 16.1s\n",
      "1865:\tlearn: 0.0036302\ttotal: 3m 43s\tremaining: 16s\n",
      "1866:\tlearn: 0.0036300\ttotal: 3m 43s\tremaining: 15.9s\n",
      "1867:\tlearn: 0.0036298\ttotal: 3m 43s\tremaining: 15.8s\n",
      "1868:\tlearn: 0.0036295\ttotal: 3m 43s\tremaining: 15.7s\n",
      "1869:\tlearn: 0.0036287\ttotal: 3m 43s\tremaining: 15.6s\n",
      "1870:\tlearn: 0.0036277\ttotal: 3m 43s\tremaining: 15.4s\n",
      "1871:\tlearn: 0.0036273\ttotal: 3m 43s\tremaining: 15.3s\n",
      "1872:\tlearn: 0.0036270\ttotal: 3m 44s\tremaining: 15.2s\n",
      "1873:\tlearn: 0.0036258\ttotal: 3m 44s\tremaining: 15.1s\n",
      "1874:\tlearn: 0.0036229\ttotal: 3m 44s\tremaining: 15s\n",
      "1875:\tlearn: 0.0036226\ttotal: 3m 44s\tremaining: 14.8s\n",
      "1876:\tlearn: 0.0036202\ttotal: 3m 44s\tremaining: 14.7s\n",
      "1877:\tlearn: 0.0036199\ttotal: 3m 44s\tremaining: 14.6s\n",
      "1878:\tlearn: 0.0036177\ttotal: 3m 44s\tremaining: 14.5s\n",
      "1879:\tlearn: 0.0036172\ttotal: 3m 44s\tremaining: 14.4s\n",
      "1880:\tlearn: 0.0036158\ttotal: 3m 45s\tremaining: 14.2s\n",
      "1881:\tlearn: 0.0036151\ttotal: 3m 45s\tremaining: 14.1s\n",
      "1882:\tlearn: 0.0036124\ttotal: 3m 45s\tremaining: 14s\n",
      "1883:\tlearn: 0.0036114\ttotal: 3m 45s\tremaining: 13.9s\n",
      "1884:\tlearn: 0.0036094\ttotal: 3m 45s\tremaining: 13.8s\n",
      "1885:\tlearn: 0.0036089\ttotal: 3m 45s\tremaining: 13.6s\n",
      "1886:\tlearn: 0.0036080\ttotal: 3m 45s\tremaining: 13.5s\n",
      "1887:\tlearn: 0.0036078\ttotal: 3m 45s\tremaining: 13.4s\n",
      "1888:\tlearn: 0.0036068\ttotal: 3m 46s\tremaining: 13.3s\n",
      "1889:\tlearn: 0.0036065\ttotal: 3m 46s\tremaining: 13.2s\n",
      "1890:\tlearn: 0.0036061\ttotal: 3m 46s\tremaining: 13s\n",
      "1891:\tlearn: 0.0036060\ttotal: 3m 46s\tremaining: 12.9s\n",
      "1892:\tlearn: 0.0036057\ttotal: 3m 46s\tremaining: 12.8s\n",
      "1893:\tlearn: 0.0036056\ttotal: 3m 46s\tremaining: 12.7s\n",
      "1894:\tlearn: 0.0036044\ttotal: 3m 46s\tremaining: 12.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1895:\tlearn: 0.0036041\ttotal: 3m 46s\tremaining: 12.4s\n",
      "1896:\tlearn: 0.0036040\ttotal: 3m 46s\tremaining: 12.3s\n",
      "1897:\tlearn: 0.0036039\ttotal: 3m 47s\tremaining: 12.2s\n",
      "1898:\tlearn: 0.0036034\ttotal: 3m 47s\tremaining: 12.1s\n",
      "1899:\tlearn: 0.0036023\ttotal: 3m 47s\tremaining: 12s\n",
      "1900:\tlearn: 0.0035985\ttotal: 3m 47s\tremaining: 11.8s\n",
      "1901:\tlearn: 0.0035984\ttotal: 3m 47s\tremaining: 11.7s\n",
      "1902:\tlearn: 0.0035978\ttotal: 3m 47s\tremaining: 11.6s\n",
      "1903:\tlearn: 0.0035966\ttotal: 3m 47s\tremaining: 11.5s\n",
      "1904:\tlearn: 0.0035965\ttotal: 3m 47s\tremaining: 11.4s\n",
      "1905:\tlearn: 0.0035961\ttotal: 3m 47s\tremaining: 11.2s\n",
      "1906:\tlearn: 0.0035957\ttotal: 3m 48s\tremaining: 11.1s\n",
      "1907:\tlearn: 0.0035954\ttotal: 3m 48s\tremaining: 11s\n",
      "1908:\tlearn: 0.0035934\ttotal: 3m 48s\tremaining: 10.9s\n",
      "1909:\tlearn: 0.0035930\ttotal: 3m 48s\tremaining: 10.8s\n",
      "1910:\tlearn: 0.0035886\ttotal: 3m 48s\tremaining: 10.6s\n",
      "1911:\tlearn: 0.0035876\ttotal: 3m 48s\tremaining: 10.5s\n",
      "1912:\tlearn: 0.0035847\ttotal: 3m 48s\tremaining: 10.4s\n",
      "1913:\tlearn: 0.0035785\ttotal: 3m 48s\tremaining: 10.3s\n",
      "1914:\tlearn: 0.0035784\ttotal: 3m 49s\tremaining: 10.2s\n",
      "1915:\tlearn: 0.0035776\ttotal: 3m 49s\tremaining: 10s\n",
      "1916:\tlearn: 0.0035766\ttotal: 3m 49s\tremaining: 9.93s\n",
      "1917:\tlearn: 0.0035762\ttotal: 3m 49s\tremaining: 9.81s\n",
      "1918:\tlearn: 0.0035757\ttotal: 3m 49s\tremaining: 9.69s\n",
      "1919:\tlearn: 0.0035748\ttotal: 3m 49s\tremaining: 9.57s\n",
      "1920:\tlearn: 0.0035748\ttotal: 3m 49s\tremaining: 9.45s\n",
      "1921:\tlearn: 0.0035744\ttotal: 3m 49s\tremaining: 9.33s\n",
      "1922:\tlearn: 0.0035692\ttotal: 3m 49s\tremaining: 9.21s\n",
      "1923:\tlearn: 0.0035691\ttotal: 3m 50s\tremaining: 9.09s\n",
      "1924:\tlearn: 0.0035682\ttotal: 3m 50s\tremaining: 8.97s\n",
      "1925:\tlearn: 0.0035611\ttotal: 3m 50s\tremaining: 8.85s\n",
      "1926:\tlearn: 0.0035560\ttotal: 3m 50s\tremaining: 8.73s\n",
      "1927:\tlearn: 0.0035533\ttotal: 3m 50s\tremaining: 8.61s\n",
      "1928:\tlearn: 0.0035523\ttotal: 3m 50s\tremaining: 8.49s\n",
      "1929:\tlearn: 0.0035516\ttotal: 3m 50s\tremaining: 8.37s\n",
      "1930:\tlearn: 0.0035514\ttotal: 3m 50s\tremaining: 8.25s\n",
      "1931:\tlearn: 0.0035504\ttotal: 3m 50s\tremaining: 8.13s\n",
      "1932:\tlearn: 0.0035503\ttotal: 3m 51s\tremaining: 8.01s\n",
      "1933:\tlearn: 0.0035498\ttotal: 3m 51s\tremaining: 7.89s\n",
      "1934:\tlearn: 0.0035495\ttotal: 3m 51s\tremaining: 7.77s\n",
      "1935:\tlearn: 0.0035489\ttotal: 3m 51s\tremaining: 7.65s\n",
      "1936:\tlearn: 0.0035483\ttotal: 3m 51s\tremaining: 7.53s\n",
      "1937:\tlearn: 0.0035475\ttotal: 3m 51s\tremaining: 7.41s\n",
      "1938:\tlearn: 0.0035473\ttotal: 3m 51s\tremaining: 7.29s\n",
      "1939:\tlearn: 0.0035467\ttotal: 3m 51s\tremaining: 7.17s\n",
      "1940:\tlearn: 0.0035466\ttotal: 3m 52s\tremaining: 7.05s\n",
      "1941:\tlearn: 0.0035409\ttotal: 3m 52s\tremaining: 6.93s\n",
      "1942:\tlearn: 0.0035386\ttotal: 3m 52s\tremaining: 6.81s\n",
      "1943:\tlearn: 0.0035353\ttotal: 3m 52s\tremaining: 6.69s\n",
      "1944:\tlearn: 0.0035352\ttotal: 3m 52s\tremaining: 6.57s\n",
      "1945:\tlearn: 0.0035348\ttotal: 3m 52s\tremaining: 6.46s\n",
      "1946:\tlearn: 0.0035276\ttotal: 3m 52s\tremaining: 6.33s\n",
      "1947:\tlearn: 0.0035264\ttotal: 3m 52s\tremaining: 6.22s\n",
      "1948:\tlearn: 0.0035259\ttotal: 3m 52s\tremaining: 6.1s\n",
      "1949:\tlearn: 0.0035257\ttotal: 3m 53s\tremaining: 5.98s\n",
      "1950:\tlearn: 0.0035228\ttotal: 3m 53s\tremaining: 5.86s\n",
      "1951:\tlearn: 0.0035223\ttotal: 3m 53s\tremaining: 5.74s\n",
      "1952:\tlearn: 0.0035217\ttotal: 3m 53s\tremaining: 5.62s\n",
      "1953:\tlearn: 0.0035209\ttotal: 3m 53s\tremaining: 5.5s\n",
      "1954:\tlearn: 0.0035195\ttotal: 3m 53s\tremaining: 5.38s\n",
      "1955:\tlearn: 0.0035185\ttotal: 3m 53s\tremaining: 5.26s\n",
      "1956:\tlearn: 0.0035183\ttotal: 3m 53s\tremaining: 5.14s\n",
      "1957:\tlearn: 0.0035180\ttotal: 3m 54s\tremaining: 5.02s\n",
      "1958:\tlearn: 0.0035158\ttotal: 3m 54s\tremaining: 4.9s\n",
      "1959:\tlearn: 0.0035141\ttotal: 3m 54s\tremaining: 4.78s\n",
      "1960:\tlearn: 0.0035140\ttotal: 3m 54s\tremaining: 4.66s\n",
      "1961:\tlearn: 0.0035137\ttotal: 3m 54s\tremaining: 4.54s\n",
      "1962:\tlearn: 0.0035134\ttotal: 3m 54s\tremaining: 4.42s\n",
      "1963:\tlearn: 0.0035130\ttotal: 3m 54s\tremaining: 4.3s\n",
      "1964:\tlearn: 0.0035121\ttotal: 3m 54s\tremaining: 4.18s\n",
      "1965:\tlearn: 0.0035110\ttotal: 3m 54s\tremaining: 4.06s\n",
      "1966:\tlearn: 0.0035093\ttotal: 3m 55s\tremaining: 3.94s\n",
      "1967:\tlearn: 0.0035050\ttotal: 3m 55s\tremaining: 3.82s\n",
      "1968:\tlearn: 0.0035048\ttotal: 3m 55s\tremaining: 3.7s\n",
      "1969:\tlearn: 0.0035042\ttotal: 3m 55s\tremaining: 3.58s\n",
      "1970:\tlearn: 0.0035018\ttotal: 3m 55s\tremaining: 3.46s\n",
      "1971:\tlearn: 0.0035010\ttotal: 3m 55s\tremaining: 3.35s\n",
      "1972:\tlearn: 0.0034987\ttotal: 3m 55s\tremaining: 3.23s\n",
      "1973:\tlearn: 0.0034958\ttotal: 3m 55s\tremaining: 3.11s\n",
      "1974:\tlearn: 0.0034957\ttotal: 3m 56s\tremaining: 2.99s\n",
      "1975:\tlearn: 0.0034948\ttotal: 3m 56s\tremaining: 2.87s\n",
      "1976:\tlearn: 0.0034914\ttotal: 3m 56s\tremaining: 2.75s\n",
      "1977:\tlearn: 0.0034913\ttotal: 3m 56s\tremaining: 2.63s\n",
      "1978:\tlearn: 0.0034909\ttotal: 3m 56s\tremaining: 2.51s\n",
      "1979:\tlearn: 0.0034899\ttotal: 3m 56s\tremaining: 2.39s\n",
      "1980:\tlearn: 0.0034895\ttotal: 3m 56s\tremaining: 2.27s\n",
      "1981:\tlearn: 0.0034886\ttotal: 3m 56s\tremaining: 2.15s\n",
      "1982:\tlearn: 0.0034871\ttotal: 3m 56s\tremaining: 2.03s\n",
      "1983:\tlearn: 0.0034870\ttotal: 3m 57s\tremaining: 1.91s\n",
      "1984:\tlearn: 0.0034814\ttotal: 3m 57s\tremaining: 1.79s\n",
      "1985:\tlearn: 0.0034812\ttotal: 3m 57s\tremaining: 1.67s\n",
      "1986:\tlearn: 0.0034802\ttotal: 3m 57s\tremaining: 1.55s\n",
      "1987:\tlearn: 0.0034796\ttotal: 3m 57s\tremaining: 1.43s\n",
      "1988:\tlearn: 0.0034776\ttotal: 3m 57s\tremaining: 1.31s\n",
      "1989:\tlearn: 0.0034767\ttotal: 3m 57s\tremaining: 1.19s\n",
      "1990:\tlearn: 0.0034763\ttotal: 3m 57s\tremaining: 1.07s\n",
      "1991:\tlearn: 0.0034763\ttotal: 3m 58s\tremaining: 956ms\n",
      "1992:\tlearn: 0.0034756\ttotal: 3m 58s\tremaining: 836ms\n",
      "1993:\tlearn: 0.0034749\ttotal: 3m 58s\tremaining: 717ms\n",
      "1994:\tlearn: 0.0034651\ttotal: 3m 58s\tremaining: 597ms\n",
      "1995:\tlearn: 0.0034633\ttotal: 3m 58s\tremaining: 478ms\n",
      "1996:\tlearn: 0.0034617\ttotal: 3m 58s\tremaining: 358ms\n",
      "1997:\tlearn: 0.0034613\ttotal: 3m 58s\tremaining: 239ms\n",
      "1998:\tlearn: 0.0034609\ttotal: 3m 58s\tremaining: 119ms\n",
      "1999:\tlearn: 0.0034586\ttotal: 3m 58s\tremaining: 0us\n",
      "Train Result:0.9991585498479832\n",
      "Test Result:0.7689850958126331\n",
      "Test Result:0.5605063291139241\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "cat1=CatBoostClassifier()\n",
    "param_grid = {\"n_estimators\":[2000]}\n",
    "cat_gscv = GridSearchCV(cat1, param_grid, cv=3)\n",
    "cat_gscv.fit(X_train, y_train)\n",
    "print('Train Result:{}'.format(cat_gscv.score(X_train, y_train)))\n",
    "print('Test Result:{}'.format(cat_gscv.score(X_test, y_test)))\n",
    "print('Test Result:{}'.format(cat_gscv.score(X_test21, y_test21)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=10\n",
    "def get_models():\n",
    "    \"\"\"Generate a library of base learners.\"\"\"\n",
    "    cat = cb.CatBoostClassifier()\n",
    "    bme= BaggingClassifier(tree.DecisionTreeClassifier())\n",
    "    xg=xgb.XGBClassifier()\n",
    "    lgbm = lgb.LGBMClassifier(silent=False)\n",
    "    ada = AdaBoostClassifier()\n",
    "    gb = GradientBoostingClassifier(n_estimators=500, random_state=SEED)\n",
    "    rf = RandomForestClassifier(n_estimators=500, max_features=3, random_state=SEED)\n",
    "\n",
    "    models = {'CATBOOST': cat,\n",
    "              'XGBOOST': xg,\n",
    "              'LIGHTGBM': lgbm,\n",
    "              'ADABOOST': ada,\n",
    "              'GBM': gb,\n",
    "              'RANDOM FOREST':rf,\n",
    "              'BME':bme\n",
    "              }\n",
    "\n",
    "    return models\n",
    "\n",
    "\n",
    "def train_predict(model_list):\n",
    "    \"\"\"Fit models in list on training set and return preds\"\"\"\n",
    "    P = np.zeros((y_test.shape[0], len(model_list)))\n",
    "    P = pd.DataFrame(P)\n",
    "\n",
    "    print(\"Fitting models.\")\n",
    "    cols = list()\n",
    "    for i, (name, m) in enumerate(models.items()):\n",
    "        print(\"%s...\" % name, end=\" \", flush=False)\n",
    "        m.fit(X_train, y_train)\n",
    "        P.iloc[:, i] = m.predict_proba(X_test)[:, 1]\n",
    "        cols.append(name)\n",
    "        print(\"done\")\n",
    "\n",
    "    P.columns = cols\n",
    "    print(\"Done.\\n\")\n",
    "    return P\n",
    "\n",
    "\n",
    "def score_models(P, y):\n",
    "    \"\"\"Score model in prediction DF\"\"\"\n",
    "    print(\"Scoring models.\")\n",
    "    for m in P.columns:\n",
    "        score = accuracy_score(y, P.loc[:, m].round())\n",
    "        print(\"%-26s: %.3f\" % (m, score))\n",
    "    print(\"Done.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting models.\n",
      "CATBOOST... Learning rate set to 0.065842\n",
      "0:\tlearn: 0.5495733\ttotal: 117ms\tremaining: 1m 57s\n",
      "1:\tlearn: 0.4674469\ttotal: 208ms\tremaining: 1m 44s\n",
      "2:\tlearn: 0.4102278\ttotal: 294ms\tremaining: 1m 37s\n",
      "3:\tlearn: 0.3466145\ttotal: 410ms\tremaining: 1m 42s\n",
      "4:\tlearn: 0.2831823\ttotal: 510ms\tremaining: 1m 41s\n",
      "5:\tlearn: 0.2561090\ttotal: 594ms\tremaining: 1m 38s\n",
      "6:\tlearn: 0.2274035\ttotal: 718ms\tremaining: 1m 41s\n",
      "7:\tlearn: 0.2031198\ttotal: 842ms\tremaining: 1m 44s\n",
      "8:\tlearn: 0.1814016\ttotal: 948ms\tremaining: 1m 44s\n",
      "9:\tlearn: 0.1646538\ttotal: 1.04s\tremaining: 1m 42s\n",
      "10:\tlearn: 0.1514548\ttotal: 1.15s\tremaining: 1m 43s\n",
      "11:\tlearn: 0.1404176\ttotal: 1.24s\tremaining: 1m 41s\n",
      "12:\tlearn: 0.1258591\ttotal: 1.35s\tremaining: 1m 42s\n",
      "13:\tlearn: 0.1170174\ttotal: 1.44s\tremaining: 1m 41s\n",
      "14:\tlearn: 0.1109626\ttotal: 1.54s\tremaining: 1m 41s\n",
      "15:\tlearn: 0.1044716\ttotal: 1.63s\tremaining: 1m 40s\n",
      "16:\tlearn: 0.0934281\ttotal: 1.74s\tremaining: 1m 40s\n",
      "17:\tlearn: 0.0886333\ttotal: 1.83s\tremaining: 1m 39s\n",
      "18:\tlearn: 0.0851115\ttotal: 1.93s\tremaining: 1m 39s\n",
      "19:\tlearn: 0.0795187\ttotal: 2.02s\tremaining: 1m 39s\n",
      "20:\tlearn: 0.0763569\ttotal: 2.11s\tremaining: 1m 38s\n",
      "21:\tlearn: 0.0729413\ttotal: 2.22s\tremaining: 1m 38s\n",
      "22:\tlearn: 0.0710004\ttotal: 2.3s\tremaining: 1m 37s\n",
      "23:\tlearn: 0.0685390\ttotal: 2.38s\tremaining: 1m 36s\n",
      "24:\tlearn: 0.0667144\ttotal: 2.48s\tremaining: 1m 36s\n",
      "25:\tlearn: 0.0656053\ttotal: 2.56s\tremaining: 1m 36s\n",
      "26:\tlearn: 0.0632418\ttotal: 2.65s\tremaining: 1m 35s\n",
      "27:\tlearn: 0.0618596\ttotal: 2.75s\tremaining: 1m 35s\n",
      "28:\tlearn: 0.0596275\ttotal: 2.85s\tremaining: 1m 35s\n",
      "29:\tlearn: 0.0578243\ttotal: 2.93s\tremaining: 1m 34s\n",
      "30:\tlearn: 0.0566194\ttotal: 3.04s\tremaining: 1m 35s\n",
      "31:\tlearn: 0.0544891\ttotal: 3.13s\tremaining: 1m 34s\n",
      "32:\tlearn: 0.0532162\ttotal: 3.22s\tremaining: 1m 34s\n",
      "33:\tlearn: 0.0519943\ttotal: 3.33s\tremaining: 1m 34s\n",
      "34:\tlearn: 0.0510696\ttotal: 3.41s\tremaining: 1m 34s\n",
      "35:\tlearn: 0.0504240\ttotal: 3.49s\tremaining: 1m 33s\n",
      "36:\tlearn: 0.0499104\ttotal: 3.58s\tremaining: 1m 33s\n",
      "37:\tlearn: 0.0475385\ttotal: 3.68s\tremaining: 1m 33s\n",
      "38:\tlearn: 0.0465330\ttotal: 3.77s\tremaining: 1m 32s\n",
      "39:\tlearn: 0.0460819\ttotal: 3.88s\tremaining: 1m 33s\n",
      "40:\tlearn: 0.0452273\ttotal: 3.97s\tremaining: 1m 32s\n",
      "41:\tlearn: 0.0448337\ttotal: 4.08s\tremaining: 1m 32s\n",
      "42:\tlearn: 0.0444828\ttotal: 4.15s\tremaining: 1m 32s\n",
      "43:\tlearn: 0.0440253\ttotal: 4.25s\tremaining: 1m 32s\n",
      "44:\tlearn: 0.0428767\ttotal: 4.35s\tremaining: 1m 32s\n",
      "45:\tlearn: 0.0424863\ttotal: 4.43s\tremaining: 1m 31s\n",
      "46:\tlearn: 0.0419930\ttotal: 4.53s\tremaining: 1m 31s\n",
      "47:\tlearn: 0.0413056\ttotal: 4.63s\tremaining: 1m 31s\n",
      "48:\tlearn: 0.0407545\ttotal: 4.72s\tremaining: 1m 31s\n",
      "49:\tlearn: 0.0402536\ttotal: 4.83s\tremaining: 1m 31s\n",
      "50:\tlearn: 0.0398385\ttotal: 4.91s\tremaining: 1m 31s\n",
      "51:\tlearn: 0.0395325\ttotal: 4.99s\tremaining: 1m 30s\n",
      "52:\tlearn: 0.0390119\ttotal: 5.09s\tremaining: 1m 30s\n",
      "53:\tlearn: 0.0387001\ttotal: 5.18s\tremaining: 1m 30s\n",
      "54:\tlearn: 0.0382415\ttotal: 5.27s\tremaining: 1m 30s\n",
      "55:\tlearn: 0.0378727\ttotal: 5.37s\tremaining: 1m 30s\n",
      "56:\tlearn: 0.0373272\ttotal: 5.45s\tremaining: 1m 30s\n",
      "57:\tlearn: 0.0369470\ttotal: 5.56s\tremaining: 1m 30s\n",
      "58:\tlearn: 0.0363035\ttotal: 5.65s\tremaining: 1m 30s\n",
      "59:\tlearn: 0.0358361\ttotal: 5.75s\tremaining: 1m 30s\n",
      "60:\tlearn: 0.0352772\ttotal: 5.86s\tremaining: 1m 30s\n",
      "61:\tlearn: 0.0349343\ttotal: 5.94s\tremaining: 1m 29s\n",
      "62:\tlearn: 0.0347860\ttotal: 6.04s\tremaining: 1m 29s\n",
      "63:\tlearn: 0.0345591\ttotal: 6.12s\tremaining: 1m 29s\n",
      "64:\tlearn: 0.0343497\ttotal: 6.22s\tremaining: 1m 29s\n",
      "65:\tlearn: 0.0340963\ttotal: 6.32s\tremaining: 1m 29s\n",
      "66:\tlearn: 0.0338204\ttotal: 6.41s\tremaining: 1m 29s\n",
      "67:\tlearn: 0.0334261\ttotal: 6.51s\tremaining: 1m 29s\n",
      "68:\tlearn: 0.0331804\ttotal: 6.59s\tremaining: 1m 28s\n",
      "69:\tlearn: 0.0328918\ttotal: 6.71s\tremaining: 1m 29s\n",
      "70:\tlearn: 0.0327436\ttotal: 6.79s\tremaining: 1m 28s\n",
      "71:\tlearn: 0.0325374\ttotal: 6.88s\tremaining: 1m 28s\n",
      "72:\tlearn: 0.0321535\ttotal: 6.99s\tremaining: 1m 28s\n",
      "73:\tlearn: 0.0319845\ttotal: 7.08s\tremaining: 1m 28s\n",
      "74:\tlearn: 0.0316244\ttotal: 7.16s\tremaining: 1m 28s\n",
      "75:\tlearn: 0.0313282\ttotal: 7.26s\tremaining: 1m 28s\n",
      "76:\tlearn: 0.0310477\ttotal: 7.36s\tremaining: 1m 28s\n",
      "77:\tlearn: 0.0309143\ttotal: 7.45s\tremaining: 1m 28s\n",
      "78:\tlearn: 0.0307769\ttotal: 7.56s\tremaining: 1m 28s\n",
      "79:\tlearn: 0.0306175\ttotal: 7.64s\tremaining: 1m 27s\n",
      "80:\tlearn: 0.0304105\ttotal: 7.74s\tremaining: 1m 27s\n",
      "81:\tlearn: 0.0301911\ttotal: 7.84s\tremaining: 1m 27s\n",
      "82:\tlearn: 0.0301055\ttotal: 7.95s\tremaining: 1m 27s\n",
      "83:\tlearn: 0.0298575\ttotal: 8.04s\tremaining: 1m 27s\n",
      "84:\tlearn: 0.0296505\ttotal: 8.14s\tremaining: 1m 27s\n",
      "85:\tlearn: 0.0295394\ttotal: 8.23s\tremaining: 1m 27s\n",
      "86:\tlearn: 0.0294427\ttotal: 8.34s\tremaining: 1m 27s\n",
      "87:\tlearn: 0.0293075\ttotal: 8.43s\tremaining: 1m 27s\n",
      "88:\tlearn: 0.0290869\ttotal: 8.53s\tremaining: 1m 27s\n",
      "89:\tlearn: 0.0289362\ttotal: 8.63s\tremaining: 1m 27s\n",
      "90:\tlearn: 0.0287284\ttotal: 8.74s\tremaining: 1m 27s\n",
      "91:\tlearn: 0.0284545\ttotal: 8.82s\tremaining: 1m 27s\n",
      "92:\tlearn: 0.0283130\ttotal: 8.93s\tremaining: 1m 27s\n",
      "93:\tlearn: 0.0282328\ttotal: 9.01s\tremaining: 1m 26s\n",
      "94:\tlearn: 0.0281123\ttotal: 9.12s\tremaining: 1m 26s\n",
      "95:\tlearn: 0.0278372\ttotal: 9.22s\tremaining: 1m 26s\n",
      "96:\tlearn: 0.0277040\ttotal: 9.34s\tremaining: 1m 26s\n",
      "97:\tlearn: 0.0275958\ttotal: 9.42s\tremaining: 1m 26s\n",
      "98:\tlearn: 0.0273300\ttotal: 9.52s\tremaining: 1m 26s\n",
      "99:\tlearn: 0.0270980\ttotal: 9.61s\tremaining: 1m 26s\n",
      "100:\tlearn: 0.0268566\ttotal: 9.72s\tremaining: 1m 26s\n",
      "101:\tlearn: 0.0267039\ttotal: 9.8s\tremaining: 1m 26s\n",
      "102:\tlearn: 0.0266319\ttotal: 9.89s\tremaining: 1m 26s\n",
      "103:\tlearn: 0.0264993\ttotal: 10s\tremaining: 1m 26s\n",
      "104:\tlearn: 0.0263199\ttotal: 10.1s\tremaining: 1m 26s\n",
      "105:\tlearn: 0.0261553\ttotal: 10.2s\tremaining: 1m 25s\n",
      "106:\tlearn: 0.0260252\ttotal: 10.3s\tremaining: 1m 25s\n",
      "107:\tlearn: 0.0259752\ttotal: 10.4s\tremaining: 1m 25s\n",
      "108:\tlearn: 0.0258396\ttotal: 10.5s\tremaining: 1m 25s\n",
      "109:\tlearn: 0.0257874\ttotal: 10.6s\tremaining: 1m 25s\n",
      "110:\tlearn: 0.0256916\ttotal: 10.7s\tremaining: 1m 25s\n",
      "111:\tlearn: 0.0254799\ttotal: 10.8s\tremaining: 1m 25s\n",
      "112:\tlearn: 0.0253436\ttotal: 10.9s\tremaining: 1m 25s\n",
      "113:\tlearn: 0.0251329\ttotal: 11s\tremaining: 1m 25s\n",
      "114:\tlearn: 0.0250531\ttotal: 11.1s\tremaining: 1m 25s\n",
      "115:\tlearn: 0.0249432\ttotal: 11.2s\tremaining: 1m 25s\n",
      "116:\tlearn: 0.0247921\ttotal: 11.3s\tremaining: 1m 25s\n",
      "117:\tlearn: 0.0247251\ttotal: 11.4s\tremaining: 1m 24s\n",
      "118:\tlearn: 0.0246872\ttotal: 11.5s\tremaining: 1m 24s\n",
      "119:\tlearn: 0.0246077\ttotal: 11.6s\tremaining: 1m 24s\n",
      "120:\tlearn: 0.0244726\ttotal: 11.6s\tremaining: 1m 24s\n",
      "121:\tlearn: 0.0244012\ttotal: 11.7s\tremaining: 1m 24s\n",
      "122:\tlearn: 0.0243561\ttotal: 11.8s\tremaining: 1m 24s\n",
      "123:\tlearn: 0.0243043\ttotal: 11.9s\tremaining: 1m 24s\n",
      "124:\tlearn: 0.0242621\ttotal: 12s\tremaining: 1m 23s\n",
      "125:\tlearn: 0.0241792\ttotal: 12.1s\tremaining: 1m 23s\n",
      "126:\tlearn: 0.0241265\ttotal: 12.2s\tremaining: 1m 23s\n",
      "127:\tlearn: 0.0240287\ttotal: 12.3s\tremaining: 1m 23s\n",
      "128:\tlearn: 0.0239803\ttotal: 12.4s\tremaining: 1m 23s\n",
      "129:\tlearn: 0.0238665\ttotal: 12.5s\tremaining: 1m 23s\n",
      "130:\tlearn: 0.0237101\ttotal: 12.6s\tremaining: 1m 23s\n",
      "131:\tlearn: 0.0236869\ttotal: 12.6s\tremaining: 1m 23s\n",
      "132:\tlearn: 0.0235872\ttotal: 12.7s\tremaining: 1m 23s\n",
      "133:\tlearn: 0.0234584\ttotal: 12.8s\tremaining: 1m 22s\n",
      "134:\tlearn: 0.0233501\ttotal: 12.9s\tremaining: 1m 22s\n",
      "135:\tlearn: 0.0232981\ttotal: 13s\tremaining: 1m 22s\n",
      "136:\tlearn: 0.0232302\ttotal: 13.1s\tremaining: 1m 22s\n",
      "137:\tlearn: 0.0231892\ttotal: 13.2s\tremaining: 1m 22s\n",
      "138:\tlearn: 0.0231293\ttotal: 13.3s\tremaining: 1m 22s\n",
      "139:\tlearn: 0.0230871\ttotal: 13.4s\tremaining: 1m 22s\n",
      "140:\tlearn: 0.0229713\ttotal: 13.5s\tremaining: 1m 22s\n",
      "141:\tlearn: 0.0228497\ttotal: 13.5s\tremaining: 1m 21s\n",
      "142:\tlearn: 0.0228172\ttotal: 13.7s\tremaining: 1m 21s\n",
      "143:\tlearn: 0.0227774\ttotal: 13.7s\tremaining: 1m 21s\n",
      "144:\tlearn: 0.0227523\ttotal: 13.8s\tremaining: 1m 21s\n",
      "145:\tlearn: 0.0227104\ttotal: 13.9s\tremaining: 1m 21s\n",
      "146:\tlearn: 0.0226776\ttotal: 14s\tremaining: 1m 21s\n",
      "147:\tlearn: 0.0226174\ttotal: 14.1s\tremaining: 1m 21s\n",
      "148:\tlearn: 0.0225904\ttotal: 14.2s\tremaining: 1m 21s\n",
      "149:\tlearn: 0.0225686\ttotal: 14.3s\tremaining: 1m 21s\n",
      "150:\tlearn: 0.0224530\ttotal: 14.4s\tremaining: 1m 20s\n",
      "151:\tlearn: 0.0223770\ttotal: 14.5s\tremaining: 1m 20s\n",
      "152:\tlearn: 0.0223056\ttotal: 14.6s\tremaining: 1m 20s\n",
      "153:\tlearn: 0.0222645\ttotal: 14.7s\tremaining: 1m 20s\n",
      "154:\tlearn: 0.0221875\ttotal: 14.8s\tremaining: 1m 20s\n",
      "155:\tlearn: 0.0221730\ttotal: 14.9s\tremaining: 1m 20s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156:\tlearn: 0.0221010\ttotal: 15s\tremaining: 1m 20s\n",
      "157:\tlearn: 0.0220466\ttotal: 15s\tremaining: 1m 20s\n",
      "158:\tlearn: 0.0220232\ttotal: 15.2s\tremaining: 1m 20s\n",
      "159:\tlearn: 0.0220047\ttotal: 15.2s\tremaining: 1m 19s\n",
      "160:\tlearn: 0.0219826\ttotal: 15.3s\tremaining: 1m 19s\n",
      "161:\tlearn: 0.0219439\ttotal: 15.4s\tremaining: 1m 19s\n",
      "162:\tlearn: 0.0219144\ttotal: 15.5s\tremaining: 1m 19s\n",
      "163:\tlearn: 0.0218387\ttotal: 15.6s\tremaining: 1m 19s\n",
      "164:\tlearn: 0.0217656\ttotal: 15.7s\tremaining: 1m 19s\n",
      "165:\tlearn: 0.0216731\ttotal: 15.8s\tremaining: 1m 19s\n",
      "166:\tlearn: 0.0215970\ttotal: 15.9s\tremaining: 1m 19s\n",
      "167:\tlearn: 0.0215189\ttotal: 16s\tremaining: 1m 19s\n",
      "168:\tlearn: 0.0213705\ttotal: 16.1s\tremaining: 1m 19s\n",
      "169:\tlearn: 0.0213045\ttotal: 16.2s\tremaining: 1m 19s\n",
      "170:\tlearn: 0.0212728\ttotal: 16.3s\tremaining: 1m 19s\n",
      "171:\tlearn: 0.0212296\ttotal: 16.4s\tremaining: 1m 18s\n",
      "172:\tlearn: 0.0211052\ttotal: 16.5s\tremaining: 1m 18s\n",
      "173:\tlearn: 0.0210451\ttotal: 16.6s\tremaining: 1m 18s\n",
      "174:\tlearn: 0.0209856\ttotal: 16.7s\tremaining: 1m 18s\n",
      "175:\tlearn: 0.0209660\ttotal: 16.8s\tremaining: 1m 18s\n",
      "176:\tlearn: 0.0209188\ttotal: 16.8s\tremaining: 1m 18s\n",
      "177:\tlearn: 0.0208627\ttotal: 16.9s\tremaining: 1m 18s\n",
      "178:\tlearn: 0.0206661\ttotal: 17s\tremaining: 1m 18s\n",
      "179:\tlearn: 0.0206131\ttotal: 17.1s\tremaining: 1m 17s\n",
      "180:\tlearn: 0.0205764\ttotal: 17.2s\tremaining: 1m 17s\n",
      "181:\tlearn: 0.0205452\ttotal: 17.3s\tremaining: 1m 17s\n",
      "182:\tlearn: 0.0204586\ttotal: 17.4s\tremaining: 1m 17s\n",
      "183:\tlearn: 0.0204061\ttotal: 17.5s\tremaining: 1m 17s\n",
      "184:\tlearn: 0.0203725\ttotal: 17.6s\tremaining: 1m 17s\n",
      "185:\tlearn: 0.0203339\ttotal: 17.7s\tremaining: 1m 17s\n",
      "186:\tlearn: 0.0202946\ttotal: 17.8s\tremaining: 1m 17s\n",
      "187:\tlearn: 0.0202367\ttotal: 17.9s\tremaining: 1m 17s\n",
      "188:\tlearn: 0.0202057\ttotal: 17.9s\tremaining: 1m 17s\n",
      "189:\tlearn: 0.0201805\ttotal: 18s\tremaining: 1m 16s\n",
      "190:\tlearn: 0.0201679\ttotal: 18.1s\tremaining: 1m 16s\n",
      "191:\tlearn: 0.0201232\ttotal: 18.2s\tremaining: 1m 16s\n",
      "192:\tlearn: 0.0200634\ttotal: 18.3s\tremaining: 1m 16s\n",
      "193:\tlearn: 0.0200534\ttotal: 18.4s\tremaining: 1m 16s\n",
      "194:\tlearn: 0.0200057\ttotal: 18.5s\tremaining: 1m 16s\n",
      "195:\tlearn: 0.0199608\ttotal: 18.6s\tremaining: 1m 16s\n",
      "196:\tlearn: 0.0199355\ttotal: 18.7s\tremaining: 1m 16s\n",
      "197:\tlearn: 0.0198679\ttotal: 18.8s\tremaining: 1m 15s\n",
      "198:\tlearn: 0.0197980\ttotal: 18.9s\tremaining: 1m 15s\n",
      "199:\tlearn: 0.0197315\ttotal: 18.9s\tremaining: 1m 15s\n",
      "200:\tlearn: 0.0196713\ttotal: 19s\tremaining: 1m 15s\n",
      "201:\tlearn: 0.0196126\ttotal: 19.1s\tremaining: 1m 15s\n",
      "202:\tlearn: 0.0195766\ttotal: 19.2s\tremaining: 1m 15s\n",
      "203:\tlearn: 0.0195556\ttotal: 19.3s\tremaining: 1m 15s\n",
      "204:\tlearn: 0.0195140\ttotal: 19.4s\tremaining: 1m 15s\n",
      "205:\tlearn: 0.0195050\ttotal: 19.5s\tremaining: 1m 15s\n",
      "206:\tlearn: 0.0194924\ttotal: 19.6s\tremaining: 1m 15s\n",
      "207:\tlearn: 0.0194742\ttotal: 19.7s\tremaining: 1m 15s\n",
      "208:\tlearn: 0.0194201\ttotal: 19.8s\tremaining: 1m 14s\n",
      "209:\tlearn: 0.0193716\ttotal: 19.9s\tremaining: 1m 14s\n",
      "210:\tlearn: 0.0193122\ttotal: 20s\tremaining: 1m 14s\n",
      "211:\tlearn: 0.0192901\ttotal: 20.1s\tremaining: 1m 14s\n",
      "212:\tlearn: 0.0192660\ttotal: 20.2s\tremaining: 1m 14s\n",
      "213:\tlearn: 0.0192228\ttotal: 20.3s\tremaining: 1m 14s\n",
      "214:\tlearn: 0.0192106\ttotal: 20.4s\tremaining: 1m 14s\n",
      "215:\tlearn: 0.0191937\ttotal: 20.5s\tremaining: 1m 14s\n",
      "216:\tlearn: 0.0191497\ttotal: 20.6s\tremaining: 1m 14s\n",
      "217:\tlearn: 0.0191116\ttotal: 20.7s\tremaining: 1m 14s\n",
      "218:\tlearn: 0.0190928\ttotal: 20.8s\tremaining: 1m 14s\n",
      "219:\tlearn: 0.0190585\ttotal: 20.9s\tremaining: 1m 13s\n",
      "220:\tlearn: 0.0190110\ttotal: 20.9s\tremaining: 1m 13s\n",
      "221:\tlearn: 0.0189931\ttotal: 21s\tremaining: 1m 13s\n",
      "222:\tlearn: 0.0189660\ttotal: 21.1s\tremaining: 1m 13s\n",
      "223:\tlearn: 0.0189315\ttotal: 21.2s\tremaining: 1m 13s\n",
      "224:\tlearn: 0.0189084\ttotal: 21.3s\tremaining: 1m 13s\n",
      "225:\tlearn: 0.0188840\ttotal: 21.4s\tremaining: 1m 13s\n",
      "226:\tlearn: 0.0188630\ttotal: 21.5s\tremaining: 1m 13s\n",
      "227:\tlearn: 0.0188300\ttotal: 21.6s\tremaining: 1m 13s\n",
      "228:\tlearn: 0.0188062\ttotal: 21.7s\tremaining: 1m 12s\n",
      "229:\tlearn: 0.0187979\ttotal: 21.8s\tremaining: 1m 12s\n",
      "230:\tlearn: 0.0187779\ttotal: 21.9s\tremaining: 1m 12s\n",
      "231:\tlearn: 0.0187403\ttotal: 22s\tremaining: 1m 12s\n",
      "232:\tlearn: 0.0187154\ttotal: 22s\tremaining: 1m 12s\n",
      "233:\tlearn: 0.0186746\ttotal: 22.2s\tremaining: 1m 12s\n",
      "234:\tlearn: 0.0186594\ttotal: 22.2s\tremaining: 1m 12s\n",
      "235:\tlearn: 0.0186403\ttotal: 22.3s\tremaining: 1m 12s\n",
      "236:\tlearn: 0.0186087\ttotal: 22.4s\tremaining: 1m 12s\n",
      "237:\tlearn: 0.0185856\ttotal: 22.5s\tremaining: 1m 12s\n",
      "238:\tlearn: 0.0185713\ttotal: 22.6s\tremaining: 1m 12s\n",
      "239:\tlearn: 0.0185322\ttotal: 22.7s\tremaining: 1m 11s\n",
      "240:\tlearn: 0.0185110\ttotal: 22.8s\tremaining: 1m 11s\n",
      "241:\tlearn: 0.0184589\ttotal: 22.9s\tremaining: 1m 11s\n",
      "242:\tlearn: 0.0184466\ttotal: 23s\tremaining: 1m 11s\n",
      "243:\tlearn: 0.0183726\ttotal: 23.1s\tremaining: 1m 11s\n",
      "244:\tlearn: 0.0183388\ttotal: 23.2s\tremaining: 1m 11s\n",
      "245:\tlearn: 0.0183097\ttotal: 23.3s\tremaining: 1m 11s\n",
      "246:\tlearn: 0.0182845\ttotal: 23.4s\tremaining: 1m 11s\n",
      "247:\tlearn: 0.0182715\ttotal: 23.4s\tremaining: 1m 11s\n",
      "248:\tlearn: 0.0182397\ttotal: 23.5s\tremaining: 1m 10s\n",
      "249:\tlearn: 0.0182317\ttotal: 23.6s\tremaining: 1m 10s\n",
      "250:\tlearn: 0.0182177\ttotal: 23.7s\tremaining: 1m 10s\n",
      "251:\tlearn: 0.0182013\ttotal: 23.8s\tremaining: 1m 10s\n",
      "252:\tlearn: 0.0181692\ttotal: 23.9s\tremaining: 1m 10s\n",
      "253:\tlearn: 0.0181342\ttotal: 24s\tremaining: 1m 10s\n",
      "254:\tlearn: 0.0181194\ttotal: 24.1s\tremaining: 1m 10s\n",
      "255:\tlearn: 0.0180512\ttotal: 24.2s\tremaining: 1m 10s\n",
      "256:\tlearn: 0.0180201\ttotal: 24.3s\tremaining: 1m 10s\n",
      "257:\tlearn: 0.0179896\ttotal: 24.3s\tremaining: 1m 10s\n",
      "258:\tlearn: 0.0179754\ttotal: 24.4s\tremaining: 1m 9s\n",
      "259:\tlearn: 0.0179629\ttotal: 24.5s\tremaining: 1m 9s\n",
      "260:\tlearn: 0.0179505\ttotal: 24.6s\tremaining: 1m 9s\n",
      "261:\tlearn: 0.0179302\ttotal: 24.7s\tremaining: 1m 9s\n",
      "262:\tlearn: 0.0179115\ttotal: 24.8s\tremaining: 1m 9s\n",
      "263:\tlearn: 0.0178759\ttotal: 24.9s\tremaining: 1m 9s\n",
      "264:\tlearn: 0.0178273\ttotal: 25s\tremaining: 1m 9s\n",
      "265:\tlearn: 0.0178166\ttotal: 25.1s\tremaining: 1m 9s\n",
      "266:\tlearn: 0.0177718\ttotal: 25.2s\tremaining: 1m 9s\n",
      "267:\tlearn: 0.0177615\ttotal: 25.3s\tremaining: 1m 8s\n",
      "268:\tlearn: 0.0177477\ttotal: 25.3s\tremaining: 1m 8s\n",
      "269:\tlearn: 0.0177136\ttotal: 25.4s\tremaining: 1m 8s\n",
      "270:\tlearn: 0.0176919\ttotal: 25.5s\tremaining: 1m 8s\n",
      "271:\tlearn: 0.0176666\ttotal: 25.6s\tremaining: 1m 8s\n",
      "272:\tlearn: 0.0176354\ttotal: 25.7s\tremaining: 1m 8s\n",
      "273:\tlearn: 0.0175860\ttotal: 25.8s\tremaining: 1m 8s\n",
      "274:\tlearn: 0.0175642\ttotal: 25.9s\tremaining: 1m 8s\n",
      "275:\tlearn: 0.0175520\ttotal: 26s\tremaining: 1m 8s\n",
      "276:\tlearn: 0.0175381\ttotal: 26.1s\tremaining: 1m 8s\n",
      "277:\tlearn: 0.0175071\ttotal: 26.2s\tremaining: 1m 7s\n",
      "278:\tlearn: 0.0174769\ttotal: 26.2s\tremaining: 1m 7s\n",
      "279:\tlearn: 0.0174573\ttotal: 26.4s\tremaining: 1m 7s\n",
      "280:\tlearn: 0.0174394\ttotal: 26.4s\tremaining: 1m 7s\n",
      "281:\tlearn: 0.0173908\ttotal: 26.5s\tremaining: 1m 7s\n",
      "282:\tlearn: 0.0173821\ttotal: 26.6s\tremaining: 1m 7s\n",
      "283:\tlearn: 0.0173656\ttotal: 26.7s\tremaining: 1m 7s\n",
      "284:\tlearn: 0.0173565\ttotal: 26.8s\tremaining: 1m 7s\n",
      "285:\tlearn: 0.0173418\ttotal: 26.9s\tremaining: 1m 7s\n",
      "286:\tlearn: 0.0172807\ttotal: 27s\tremaining: 1m 7s\n",
      "287:\tlearn: 0.0172584\ttotal: 27.1s\tremaining: 1m 6s\n",
      "288:\tlearn: 0.0172294\ttotal: 27.2s\tremaining: 1m 6s\n",
      "289:\tlearn: 0.0172167\ttotal: 27.3s\tremaining: 1m 6s\n",
      "290:\tlearn: 0.0171826\ttotal: 27.3s\tremaining: 1m 6s\n",
      "291:\tlearn: 0.0171720\ttotal: 27.4s\tremaining: 1m 6s\n",
      "292:\tlearn: 0.0171646\ttotal: 27.5s\tremaining: 1m 6s\n",
      "293:\tlearn: 0.0171444\ttotal: 27.6s\tremaining: 1m 6s\n",
      "294:\tlearn: 0.0171312\ttotal: 27.7s\tremaining: 1m 6s\n",
      "295:\tlearn: 0.0170988\ttotal: 27.8s\tremaining: 1m 6s\n",
      "296:\tlearn: 0.0170520\ttotal: 27.9s\tremaining: 1m 6s\n",
      "297:\tlearn: 0.0170408\ttotal: 28s\tremaining: 1m 5s\n",
      "298:\tlearn: 0.0170048\ttotal: 28.1s\tremaining: 1m 5s\n",
      "299:\tlearn: 0.0169949\ttotal: 28.2s\tremaining: 1m 5s\n",
      "300:\tlearn: 0.0169567\ttotal: 28.3s\tremaining: 1m 5s\n",
      "301:\tlearn: 0.0169497\ttotal: 28.4s\tremaining: 1m 5s\n",
      "302:\tlearn: 0.0169339\ttotal: 28.4s\tremaining: 1m 5s\n",
      "303:\tlearn: 0.0169240\ttotal: 28.6s\tremaining: 1m 5s\n",
      "304:\tlearn: 0.0169091\ttotal: 28.6s\tremaining: 1m 5s\n",
      "305:\tlearn: 0.0168922\ttotal: 28.7s\tremaining: 1m 5s\n",
      "306:\tlearn: 0.0168634\ttotal: 28.8s\tremaining: 1m 5s\n",
      "307:\tlearn: 0.0168423\ttotal: 28.9s\tremaining: 1m 5s\n",
      "308:\tlearn: 0.0168166\ttotal: 29s\tremaining: 1m 4s\n",
      "309:\tlearn: 0.0167954\ttotal: 29.1s\tremaining: 1m 4s\n",
      "310:\tlearn: 0.0167709\ttotal: 29.2s\tremaining: 1m 4s\n",
      "311:\tlearn: 0.0167264\ttotal: 29.3s\tremaining: 1m 4s\n",
      "312:\tlearn: 0.0166990\ttotal: 29.4s\tremaining: 1m 4s\n",
      "313:\tlearn: 0.0166850\ttotal: 29.5s\tremaining: 1m 4s\n",
      "314:\tlearn: 0.0166710\ttotal: 29.6s\tremaining: 1m 4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315:\tlearn: 0.0166467\ttotal: 29.7s\tremaining: 1m 4s\n",
      "316:\tlearn: 0.0166353\ttotal: 29.8s\tremaining: 1m 4s\n",
      "317:\tlearn: 0.0166310\ttotal: 29.9s\tremaining: 1m 4s\n",
      "318:\tlearn: 0.0166109\ttotal: 30s\tremaining: 1m 4s\n",
      "319:\tlearn: 0.0165733\ttotal: 30.1s\tremaining: 1m 3s\n",
      "320:\tlearn: 0.0165602\ttotal: 30.2s\tremaining: 1m 3s\n",
      "321:\tlearn: 0.0165476\ttotal: 30.3s\tremaining: 1m 3s\n",
      "322:\tlearn: 0.0165302\ttotal: 30.4s\tremaining: 1m 3s\n",
      "323:\tlearn: 0.0165175\ttotal: 30.5s\tremaining: 1m 3s\n",
      "324:\tlearn: 0.0164915\ttotal: 30.6s\tremaining: 1m 3s\n",
      "325:\tlearn: 0.0164665\ttotal: 30.7s\tremaining: 1m 3s\n",
      "326:\tlearn: 0.0164343\ttotal: 30.7s\tremaining: 1m 3s\n",
      "327:\tlearn: 0.0164090\ttotal: 30.9s\tremaining: 1m 3s\n",
      "328:\tlearn: 0.0163880\ttotal: 30.9s\tremaining: 1m 3s\n",
      "329:\tlearn: 0.0163797\ttotal: 31s\tremaining: 1m 3s\n",
      "330:\tlearn: 0.0163525\ttotal: 31.1s\tremaining: 1m 2s\n",
      "331:\tlearn: 0.0163298\ttotal: 31.2s\tremaining: 1m 2s\n",
      "332:\tlearn: 0.0163263\ttotal: 31.3s\tremaining: 1m 2s\n",
      "333:\tlearn: 0.0163173\ttotal: 31.4s\tremaining: 1m 2s\n",
      "334:\tlearn: 0.0162713\ttotal: 31.5s\tremaining: 1m 2s\n",
      "335:\tlearn: 0.0162409\ttotal: 31.6s\tremaining: 1m 2s\n",
      "336:\tlearn: 0.0162170\ttotal: 31.7s\tremaining: 1m 2s\n",
      "337:\tlearn: 0.0161988\ttotal: 31.8s\tremaining: 1m 2s\n",
      "338:\tlearn: 0.0161922\ttotal: 31.9s\tremaining: 1m 2s\n",
      "339:\tlearn: 0.0161843\ttotal: 32s\tremaining: 1m 2s\n",
      "340:\tlearn: 0.0161623\ttotal: 32.1s\tremaining: 1m 1s\n",
      "341:\tlearn: 0.0161463\ttotal: 32.1s\tremaining: 1m 1s\n",
      "342:\tlearn: 0.0161411\ttotal: 32.2s\tremaining: 1m 1s\n",
      "343:\tlearn: 0.0161072\ttotal: 32.3s\tremaining: 1m 1s\n",
      "344:\tlearn: 0.0160879\ttotal: 32.4s\tremaining: 1m 1s\n",
      "345:\tlearn: 0.0160845\ttotal: 32.5s\tremaining: 1m 1s\n",
      "346:\tlearn: 0.0160674\ttotal: 32.6s\tremaining: 1m 1s\n",
      "347:\tlearn: 0.0160363\ttotal: 32.7s\tremaining: 1m 1s\n",
      "348:\tlearn: 0.0160007\ttotal: 32.8s\tremaining: 1m 1s\n",
      "349:\tlearn: 0.0159458\ttotal: 32.9s\tremaining: 1m 1s\n",
      "350:\tlearn: 0.0159250\ttotal: 33s\tremaining: 1m\n",
      "351:\tlearn: 0.0158950\ttotal: 33.1s\tremaining: 1m\n",
      "352:\tlearn: 0.0158803\ttotal: 33.2s\tremaining: 1m\n",
      "353:\tlearn: 0.0158743\ttotal: 33.3s\tremaining: 1m\n",
      "354:\tlearn: 0.0158655\ttotal: 33.4s\tremaining: 1m\n",
      "355:\tlearn: 0.0158424\ttotal: 33.4s\tremaining: 1m\n",
      "356:\tlearn: 0.0158228\ttotal: 33.5s\tremaining: 1m\n",
      "357:\tlearn: 0.0158176\ttotal: 33.6s\tremaining: 1m\n",
      "358:\tlearn: 0.0157917\ttotal: 33.7s\tremaining: 1m\n",
      "359:\tlearn: 0.0157827\ttotal: 33.8s\tremaining: 1m\n",
      "360:\tlearn: 0.0157487\ttotal: 33.9s\tremaining: 1m\n",
      "361:\tlearn: 0.0157051\ttotal: 34s\tremaining: 59.9s\n",
      "362:\tlearn: 0.0156654\ttotal: 34.1s\tremaining: 59.9s\n",
      "363:\tlearn: 0.0156534\ttotal: 34.2s\tremaining: 59.7s\n",
      "364:\tlearn: 0.0156474\ttotal: 34.3s\tremaining: 59.6s\n",
      "365:\tlearn: 0.0156239\ttotal: 34.4s\tremaining: 59.6s\n",
      "366:\tlearn: 0.0156193\ttotal: 34.5s\tremaining: 59.5s\n",
      "367:\tlearn: 0.0156069\ttotal: 34.6s\tremaining: 59.3s\n",
      "368:\tlearn: 0.0155971\ttotal: 34.7s\tremaining: 59.3s\n",
      "369:\tlearn: 0.0155924\ttotal: 34.7s\tremaining: 59.1s\n",
      "370:\tlearn: 0.0155715\ttotal: 34.8s\tremaining: 59s\n",
      "371:\tlearn: 0.0155636\ttotal: 34.9s\tremaining: 58.9s\n",
      "372:\tlearn: 0.0155592\ttotal: 35s\tremaining: 58.8s\n",
      "373:\tlearn: 0.0155281\ttotal: 35.1s\tremaining: 58.7s\n",
      "374:\tlearn: 0.0155208\ttotal: 35.2s\tremaining: 58.6s\n",
      "375:\tlearn: 0.0154973\ttotal: 35.3s\tremaining: 58.5s\n",
      "376:\tlearn: 0.0154822\ttotal: 35.4s\tremaining: 58.4s\n",
      "377:\tlearn: 0.0154781\ttotal: 35.5s\tremaining: 58.4s\n",
      "378:\tlearn: 0.0154667\ttotal: 35.5s\tremaining: 58.2s\n",
      "379:\tlearn: 0.0154534\ttotal: 35.6s\tremaining: 58.2s\n",
      "380:\tlearn: 0.0154403\ttotal: 35.7s\tremaining: 58.1s\n",
      "381:\tlearn: 0.0154013\ttotal: 35.8s\tremaining: 58s\n",
      "382:\tlearn: 0.0153929\ttotal: 35.9s\tremaining: 57.9s\n",
      "383:\tlearn: 0.0153879\ttotal: 36s\tremaining: 57.8s\n",
      "384:\tlearn: 0.0153685\ttotal: 36.1s\tremaining: 57.7s\n",
      "385:\tlearn: 0.0153607\ttotal: 36.2s\tremaining: 57.6s\n",
      "386:\tlearn: 0.0153495\ttotal: 36.3s\tremaining: 57.5s\n",
      "387:\tlearn: 0.0153322\ttotal: 36.4s\tremaining: 57.4s\n",
      "388:\tlearn: 0.0153165\ttotal: 36.5s\tremaining: 57.3s\n",
      "389:\tlearn: 0.0153011\ttotal: 36.6s\tremaining: 57.2s\n",
      "390:\tlearn: 0.0152841\ttotal: 36.7s\tremaining: 57.1s\n",
      "391:\tlearn: 0.0152756\ttotal: 36.8s\tremaining: 57s\n",
      "392:\tlearn: 0.0152655\ttotal: 36.9s\tremaining: 56.9s\n",
      "393:\tlearn: 0.0152450\ttotal: 36.9s\tremaining: 56.8s\n",
      "394:\tlearn: 0.0152313\ttotal: 37s\tremaining: 56.7s\n",
      "395:\tlearn: 0.0152221\ttotal: 37.1s\tremaining: 56.6s\n",
      "396:\tlearn: 0.0152056\ttotal: 37.2s\tremaining: 56.5s\n",
      "397:\tlearn: 0.0151907\ttotal: 37.3s\tremaining: 56.4s\n",
      "398:\tlearn: 0.0151547\ttotal: 37.4s\tremaining: 56.3s\n",
      "399:\tlearn: 0.0151377\ttotal: 37.5s\tremaining: 56.2s\n",
      "400:\tlearn: 0.0151226\ttotal: 37.6s\tremaining: 56.2s\n",
      "401:\tlearn: 0.0151157\ttotal: 37.7s\tremaining: 56s\n",
      "402:\tlearn: 0.0150928\ttotal: 37.8s\tremaining: 55.9s\n",
      "403:\tlearn: 0.0150733\ttotal: 37.9s\tremaining: 55.9s\n",
      "404:\tlearn: 0.0150004\ttotal: 38s\tremaining: 55.8s\n",
      "405:\tlearn: 0.0149803\ttotal: 38.1s\tremaining: 55.7s\n",
      "406:\tlearn: 0.0149689\ttotal: 38.1s\tremaining: 55.6s\n",
      "407:\tlearn: 0.0149296\ttotal: 38.2s\tremaining: 55.5s\n",
      "408:\tlearn: 0.0149181\ttotal: 38.3s\tremaining: 55.4s\n",
      "409:\tlearn: 0.0149007\ttotal: 38.4s\tremaining: 55.3s\n",
      "410:\tlearn: 0.0148818\ttotal: 38.5s\tremaining: 55.2s\n",
      "411:\tlearn: 0.0148648\ttotal: 38.6s\tremaining: 55.1s\n",
      "412:\tlearn: 0.0148450\ttotal: 38.7s\tremaining: 55s\n",
      "413:\tlearn: 0.0148162\ttotal: 38.8s\tremaining: 54.9s\n",
      "414:\tlearn: 0.0148092\ttotal: 38.9s\tremaining: 54.8s\n",
      "415:\tlearn: 0.0148006\ttotal: 39s\tremaining: 54.7s\n",
      "416:\tlearn: 0.0147594\ttotal: 39.1s\tremaining: 54.6s\n",
      "417:\tlearn: 0.0147442\ttotal: 39.2s\tremaining: 54.6s\n",
      "418:\tlearn: 0.0147346\ttotal: 39.3s\tremaining: 54.5s\n",
      "419:\tlearn: 0.0147217\ttotal: 39.4s\tremaining: 54.4s\n",
      "420:\tlearn: 0.0147005\ttotal: 39.5s\tremaining: 54.3s\n",
      "421:\tlearn: 0.0146935\ttotal: 39.6s\tremaining: 54.2s\n",
      "422:\tlearn: 0.0146851\ttotal: 39.6s\tremaining: 54.1s\n",
      "423:\tlearn: 0.0146767\ttotal: 39.7s\tremaining: 54s\n",
      "424:\tlearn: 0.0146622\ttotal: 39.8s\tremaining: 53.9s\n",
      "425:\tlearn: 0.0146484\ttotal: 39.9s\tremaining: 53.8s\n",
      "426:\tlearn: 0.0146396\ttotal: 40s\tremaining: 53.7s\n",
      "427:\tlearn: 0.0146254\ttotal: 40.1s\tremaining: 53.6s\n",
      "428:\tlearn: 0.0145884\ttotal: 40.2s\tremaining: 53.5s\n",
      "429:\tlearn: 0.0145744\ttotal: 40.3s\tremaining: 53.4s\n",
      "430:\tlearn: 0.0145695\ttotal: 40.4s\tremaining: 53.3s\n",
      "431:\tlearn: 0.0145512\ttotal: 40.5s\tremaining: 53.2s\n",
      "432:\tlearn: 0.0145478\ttotal: 40.6s\tremaining: 53.1s\n",
      "433:\tlearn: 0.0145057\ttotal: 40.7s\tremaining: 53s\n",
      "434:\tlearn: 0.0144840\ttotal: 40.8s\tremaining: 52.9s\n",
      "435:\tlearn: 0.0144764\ttotal: 40.9s\tremaining: 52.8s\n",
      "436:\tlearn: 0.0144538\ttotal: 40.9s\tremaining: 52.8s\n",
      "437:\tlearn: 0.0144409\ttotal: 41s\tremaining: 52.6s\n",
      "438:\tlearn: 0.0144374\ttotal: 41.1s\tremaining: 52.6s\n",
      "439:\tlearn: 0.0144175\ttotal: 41.2s\tremaining: 52.5s\n",
      "440:\tlearn: 0.0144104\ttotal: 41.3s\tremaining: 52.4s\n",
      "441:\tlearn: 0.0144048\ttotal: 41.4s\tremaining: 52.3s\n",
      "442:\tlearn: 0.0143787\ttotal: 41.5s\tremaining: 52.2s\n",
      "443:\tlearn: 0.0143725\ttotal: 41.6s\tremaining: 52.1s\n",
      "444:\tlearn: 0.0143660\ttotal: 41.7s\tremaining: 52s\n",
      "445:\tlearn: 0.0143463\ttotal: 41.8s\tremaining: 51.9s\n",
      "446:\tlearn: 0.0143352\ttotal: 41.9s\tremaining: 51.8s\n",
      "447:\tlearn: 0.0143170\ttotal: 42s\tremaining: 51.7s\n",
      "448:\tlearn: 0.0143098\ttotal: 42.1s\tremaining: 51.6s\n",
      "449:\tlearn: 0.0142940\ttotal: 42.2s\tremaining: 51.5s\n",
      "450:\tlearn: 0.0142854\ttotal: 42.3s\tremaining: 51.4s\n",
      "451:\tlearn: 0.0142793\ttotal: 42.3s\tremaining: 51.3s\n",
      "452:\tlearn: 0.0142650\ttotal: 42.4s\tremaining: 51.3s\n",
      "453:\tlearn: 0.0142555\ttotal: 42.5s\tremaining: 51.1s\n",
      "454:\tlearn: 0.0142491\ttotal: 42.6s\tremaining: 51s\n",
      "455:\tlearn: 0.0142334\ttotal: 42.7s\tremaining: 51s\n",
      "456:\tlearn: 0.0142173\ttotal: 42.8s\tremaining: 50.9s\n",
      "457:\tlearn: 0.0142086\ttotal: 42.9s\tremaining: 50.8s\n",
      "458:\tlearn: 0.0141903\ttotal: 43s\tremaining: 50.7s\n",
      "459:\tlearn: 0.0141853\ttotal: 43.1s\tremaining: 50.6s\n",
      "460:\tlearn: 0.0141730\ttotal: 43.2s\tremaining: 50.5s\n",
      "461:\tlearn: 0.0141690\ttotal: 43.3s\tremaining: 50.4s\n",
      "462:\tlearn: 0.0141657\ttotal: 43.4s\tremaining: 50.3s\n",
      "463:\tlearn: 0.0141599\ttotal: 43.5s\tremaining: 50.2s\n",
      "464:\tlearn: 0.0141405\ttotal: 43.6s\tremaining: 50.1s\n",
      "465:\tlearn: 0.0141277\ttotal: 43.7s\tremaining: 50.1s\n",
      "466:\tlearn: 0.0141218\ttotal: 43.8s\tremaining: 50s\n",
      "467:\tlearn: 0.0141148\ttotal: 43.9s\tremaining: 49.9s\n",
      "468:\tlearn: 0.0141014\ttotal: 44s\tremaining: 49.8s\n",
      "469:\tlearn: 0.0140958\ttotal: 44.1s\tremaining: 49.7s\n",
      "470:\tlearn: 0.0140837\ttotal: 44.2s\tremaining: 49.6s\n",
      "471:\tlearn: 0.0140739\ttotal: 44.3s\tremaining: 49.6s\n",
      "472:\tlearn: 0.0140672\ttotal: 44.4s\tremaining: 49.5s\n",
      "473:\tlearn: 0.0140543\ttotal: 44.5s\tremaining: 49.4s\n",
      "474:\tlearn: 0.0140432\ttotal: 44.6s\tremaining: 49.3s\n",
      "475:\tlearn: 0.0140374\ttotal: 44.7s\tremaining: 49.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476:\tlearn: 0.0140300\ttotal: 44.8s\tremaining: 49.1s\n",
      "477:\tlearn: 0.0140194\ttotal: 44.9s\tremaining: 49s\n",
      "478:\tlearn: 0.0140166\ttotal: 45s\tremaining: 49s\n",
      "479:\tlearn: 0.0140085\ttotal: 45.1s\tremaining: 48.9s\n",
      "480:\tlearn: 0.0140001\ttotal: 45.2s\tremaining: 48.8s\n",
      "481:\tlearn: 0.0139854\ttotal: 45.3s\tremaining: 48.7s\n",
      "482:\tlearn: 0.0139724\ttotal: 45.4s\tremaining: 48.6s\n",
      "483:\tlearn: 0.0139706\ttotal: 45.5s\tremaining: 48.5s\n",
      "484:\tlearn: 0.0139564\ttotal: 45.6s\tremaining: 48.4s\n",
      "485:\tlearn: 0.0139513\ttotal: 45.6s\tremaining: 48.3s\n",
      "486:\tlearn: 0.0139310\ttotal: 45.7s\tremaining: 48.2s\n",
      "487:\tlearn: 0.0139267\ttotal: 45.8s\tremaining: 48.1s\n",
      "488:\tlearn: 0.0139244\ttotal: 45.9s\tremaining: 48s\n",
      "489:\tlearn: 0.0139098\ttotal: 46s\tremaining: 47.9s\n",
      "490:\tlearn: 0.0138999\ttotal: 46.1s\tremaining: 47.8s\n",
      "491:\tlearn: 0.0138947\ttotal: 46.2s\tremaining: 47.7s\n",
      "492:\tlearn: 0.0138788\ttotal: 46.3s\tremaining: 47.6s\n",
      "493:\tlearn: 0.0138642\ttotal: 46.4s\tremaining: 47.5s\n",
      "494:\tlearn: 0.0138582\ttotal: 46.5s\tremaining: 47.4s\n",
      "495:\tlearn: 0.0138511\ttotal: 46.6s\tremaining: 47.3s\n",
      "496:\tlearn: 0.0138426\ttotal: 46.7s\tremaining: 47.2s\n",
      "497:\tlearn: 0.0138350\ttotal: 46.8s\tremaining: 47.1s\n",
      "498:\tlearn: 0.0138239\ttotal: 46.9s\tremaining: 47s\n",
      "499:\tlearn: 0.0138215\ttotal: 47s\tremaining: 47s\n",
      "500:\tlearn: 0.0138145\ttotal: 47s\tremaining: 46.9s\n",
      "501:\tlearn: 0.0138094\ttotal: 47.1s\tremaining: 46.8s\n",
      "502:\tlearn: 0.0137922\ttotal: 47.2s\tremaining: 46.7s\n",
      "503:\tlearn: 0.0137522\ttotal: 47.3s\tremaining: 46.6s\n",
      "504:\tlearn: 0.0137450\ttotal: 47.4s\tremaining: 46.5s\n",
      "505:\tlearn: 0.0137354\ttotal: 47.5s\tremaining: 46.4s\n",
      "506:\tlearn: 0.0137315\ttotal: 47.6s\tremaining: 46.3s\n",
      "507:\tlearn: 0.0137170\ttotal: 47.7s\tremaining: 46.2s\n",
      "508:\tlearn: 0.0137113\ttotal: 47.8s\tremaining: 46.1s\n",
      "509:\tlearn: 0.0136970\ttotal: 47.9s\tremaining: 46s\n",
      "510:\tlearn: 0.0136930\ttotal: 48s\tremaining: 45.9s\n",
      "511:\tlearn: 0.0136596\ttotal: 48.1s\tremaining: 45.8s\n",
      "512:\tlearn: 0.0136572\ttotal: 48.2s\tremaining: 45.7s\n",
      "513:\tlearn: 0.0136435\ttotal: 48.3s\tremaining: 45.6s\n",
      "514:\tlearn: 0.0136115\ttotal: 48.4s\tremaining: 45.5s\n",
      "515:\tlearn: 0.0135994\ttotal: 48.5s\tremaining: 45.4s\n",
      "516:\tlearn: 0.0135963\ttotal: 48.5s\tremaining: 45.3s\n",
      "517:\tlearn: 0.0135903\ttotal: 48.6s\tremaining: 45.3s\n",
      "518:\tlearn: 0.0135850\ttotal: 48.7s\tremaining: 45.2s\n",
      "519:\tlearn: 0.0135806\ttotal: 48.8s\tremaining: 45.1s\n",
      "520:\tlearn: 0.0135544\ttotal: 48.9s\tremaining: 45s\n",
      "521:\tlearn: 0.0135509\ttotal: 49s\tremaining: 44.9s\n",
      "522:\tlearn: 0.0135471\ttotal: 49.1s\tremaining: 44.8s\n",
      "523:\tlearn: 0.0135446\ttotal: 49.2s\tremaining: 44.7s\n",
      "524:\tlearn: 0.0135402\ttotal: 49.3s\tremaining: 44.6s\n",
      "525:\tlearn: 0.0135340\ttotal: 49.4s\tremaining: 44.5s\n",
      "526:\tlearn: 0.0135173\ttotal: 49.5s\tremaining: 44.4s\n",
      "527:\tlearn: 0.0135132\ttotal: 49.5s\tremaining: 44.3s\n",
      "528:\tlearn: 0.0135078\ttotal: 49.6s\tremaining: 44.2s\n",
      "529:\tlearn: 0.0134984\ttotal: 49.7s\tremaining: 44.1s\n",
      "530:\tlearn: 0.0134904\ttotal: 49.8s\tremaining: 44s\n",
      "531:\tlearn: 0.0134857\ttotal: 49.9s\tremaining: 43.9s\n",
      "532:\tlearn: 0.0134583\ttotal: 50s\tremaining: 43.8s\n",
      "533:\tlearn: 0.0134505\ttotal: 50.1s\tremaining: 43.7s\n",
      "534:\tlearn: 0.0134414\ttotal: 50.2s\tremaining: 43.6s\n",
      "535:\tlearn: 0.0134286\ttotal: 50.3s\tremaining: 43.5s\n",
      "536:\tlearn: 0.0134211\ttotal: 50.4s\tremaining: 43.4s\n",
      "537:\tlearn: 0.0134175\ttotal: 50.5s\tremaining: 43.3s\n",
      "538:\tlearn: 0.0133996\ttotal: 50.6s\tremaining: 43.2s\n",
      "539:\tlearn: 0.0133933\ttotal: 50.6s\tremaining: 43.1s\n",
      "540:\tlearn: 0.0133825\ttotal: 50.8s\tremaining: 43.1s\n",
      "541:\tlearn: 0.0133761\ttotal: 50.9s\tremaining: 43s\n",
      "542:\tlearn: 0.0133716\ttotal: 51s\tremaining: 42.9s\n",
      "543:\tlearn: 0.0133696\ttotal: 51.1s\tremaining: 42.8s\n",
      "544:\tlearn: 0.0133672\ttotal: 51.2s\tremaining: 42.7s\n",
      "545:\tlearn: 0.0133598\ttotal: 51.3s\tremaining: 42.6s\n",
      "546:\tlearn: 0.0133533\ttotal: 51.3s\tremaining: 42.5s\n",
      "547:\tlearn: 0.0133363\ttotal: 51.5s\tremaining: 42.4s\n",
      "548:\tlearn: 0.0133287\ttotal: 51.5s\tremaining: 42.3s\n",
      "549:\tlearn: 0.0132930\ttotal: 51.6s\tremaining: 42.3s\n",
      "550:\tlearn: 0.0132911\ttotal: 51.7s\tremaining: 42.2s\n",
      "551:\tlearn: 0.0132864\ttotal: 51.8s\tremaining: 42.1s\n",
      "552:\tlearn: 0.0132777\ttotal: 51.9s\tremaining: 42s\n",
      "553:\tlearn: 0.0132732\ttotal: 52s\tremaining: 41.9s\n",
      "554:\tlearn: 0.0132655\ttotal: 52.1s\tremaining: 41.8s\n",
      "555:\tlearn: 0.0132562\ttotal: 52.2s\tremaining: 41.7s\n",
      "556:\tlearn: 0.0132471\ttotal: 52.3s\tremaining: 41.6s\n",
      "557:\tlearn: 0.0132437\ttotal: 52.4s\tremaining: 41.5s\n",
      "558:\tlearn: 0.0132351\ttotal: 52.5s\tremaining: 41.4s\n",
      "559:\tlearn: 0.0132289\ttotal: 52.6s\tremaining: 41.3s\n",
      "560:\tlearn: 0.0132226\ttotal: 52.6s\tremaining: 41.2s\n",
      "561:\tlearn: 0.0132148\ttotal: 52.7s\tremaining: 41.1s\n",
      "562:\tlearn: 0.0132013\ttotal: 52.8s\tremaining: 41s\n",
      "563:\tlearn: 0.0131731\ttotal: 52.9s\tremaining: 40.9s\n",
      "564:\tlearn: 0.0131705\ttotal: 53s\tremaining: 40.8s\n",
      "565:\tlearn: 0.0131580\ttotal: 53.1s\tremaining: 40.7s\n",
      "566:\tlearn: 0.0131566\ttotal: 53.2s\tremaining: 40.6s\n",
      "567:\tlearn: 0.0131481\ttotal: 53.3s\tremaining: 40.5s\n",
      "568:\tlearn: 0.0131435\ttotal: 53.4s\tremaining: 40.4s\n",
      "569:\tlearn: 0.0131167\ttotal: 53.5s\tremaining: 40.4s\n",
      "570:\tlearn: 0.0131133\ttotal: 53.6s\tremaining: 40.3s\n",
      "571:\tlearn: 0.0131014\ttotal: 53.7s\tremaining: 40.2s\n",
      "572:\tlearn: 0.0130976\ttotal: 53.8s\tremaining: 40.1s\n",
      "573:\tlearn: 0.0130820\ttotal: 53.9s\tremaining: 40s\n",
      "574:\tlearn: 0.0130783\ttotal: 54s\tremaining: 39.9s\n",
      "575:\tlearn: 0.0130644\ttotal: 54.1s\tremaining: 39.8s\n",
      "576:\tlearn: 0.0130385\ttotal: 54.2s\tremaining: 39.7s\n",
      "577:\tlearn: 0.0130350\ttotal: 54.3s\tremaining: 39.6s\n",
      "578:\tlearn: 0.0130279\ttotal: 54.3s\tremaining: 39.5s\n",
      "579:\tlearn: 0.0130260\ttotal: 54.4s\tremaining: 39.4s\n",
      "580:\tlearn: 0.0130181\ttotal: 54.5s\tremaining: 39.3s\n",
      "581:\tlearn: 0.0130149\ttotal: 54.6s\tremaining: 39.2s\n",
      "582:\tlearn: 0.0129993\ttotal: 54.7s\tremaining: 39.1s\n",
      "583:\tlearn: 0.0129945\ttotal: 54.8s\tremaining: 39s\n",
      "584:\tlearn: 0.0129860\ttotal: 54.9s\tremaining: 38.9s\n",
      "585:\tlearn: 0.0129756\ttotal: 55s\tremaining: 38.9s\n",
      "586:\tlearn: 0.0129691\ttotal: 55.1s\tremaining: 38.8s\n",
      "587:\tlearn: 0.0129638\ttotal: 55.2s\tremaining: 38.7s\n",
      "588:\tlearn: 0.0129594\ttotal: 55.3s\tremaining: 38.6s\n",
      "589:\tlearn: 0.0129503\ttotal: 55.4s\tremaining: 38.5s\n",
      "590:\tlearn: 0.0129492\ttotal: 55.5s\tremaining: 38.4s\n",
      "591:\tlearn: 0.0129423\ttotal: 55.6s\tremaining: 38.3s\n",
      "592:\tlearn: 0.0129373\ttotal: 55.7s\tremaining: 38.2s\n",
      "593:\tlearn: 0.0129291\ttotal: 55.8s\tremaining: 38.1s\n",
      "594:\tlearn: 0.0129226\ttotal: 55.9s\tremaining: 38s\n",
      "595:\tlearn: 0.0129154\ttotal: 55.9s\tremaining: 37.9s\n",
      "596:\tlearn: 0.0128945\ttotal: 56s\tremaining: 37.8s\n",
      "597:\tlearn: 0.0128840\ttotal: 56.2s\tremaining: 37.8s\n",
      "598:\tlearn: 0.0128776\ttotal: 56.2s\tremaining: 37.7s\n",
      "599:\tlearn: 0.0128750\ttotal: 56.3s\tremaining: 37.6s\n",
      "600:\tlearn: 0.0128703\ttotal: 56.4s\tremaining: 37.5s\n",
      "601:\tlearn: 0.0128634\ttotal: 56.5s\tremaining: 37.4s\n",
      "602:\tlearn: 0.0128375\ttotal: 56.6s\tremaining: 37.3s\n",
      "603:\tlearn: 0.0128325\ttotal: 56.7s\tremaining: 37.2s\n",
      "604:\tlearn: 0.0128266\ttotal: 56.8s\tremaining: 37.1s\n",
      "605:\tlearn: 0.0128251\ttotal: 56.9s\tremaining: 37s\n",
      "606:\tlearn: 0.0128206\ttotal: 57s\tremaining: 36.9s\n",
      "607:\tlearn: 0.0128089\ttotal: 57.1s\tremaining: 36.8s\n",
      "608:\tlearn: 0.0127942\ttotal: 57.2s\tremaining: 36.7s\n",
      "609:\tlearn: 0.0127923\ttotal: 57.3s\tremaining: 36.6s\n",
      "610:\tlearn: 0.0127885\ttotal: 57.4s\tremaining: 36.5s\n",
      "611:\tlearn: 0.0127808\ttotal: 57.5s\tremaining: 36.4s\n",
      "612:\tlearn: 0.0127706\ttotal: 57.6s\tremaining: 36.3s\n",
      "613:\tlearn: 0.0127670\ttotal: 57.7s\tremaining: 36.2s\n",
      "614:\tlearn: 0.0127649\ttotal: 57.8s\tremaining: 36.2s\n",
      "615:\tlearn: 0.0127618\ttotal: 57.9s\tremaining: 36.1s\n",
      "616:\tlearn: 0.0127586\ttotal: 58s\tremaining: 36s\n",
      "617:\tlearn: 0.0127556\ttotal: 58.1s\tremaining: 35.9s\n",
      "618:\tlearn: 0.0127528\ttotal: 58.2s\tremaining: 35.8s\n",
      "619:\tlearn: 0.0127506\ttotal: 58.3s\tremaining: 35.7s\n",
      "620:\tlearn: 0.0127405\ttotal: 58.4s\tremaining: 35.6s\n",
      "621:\tlearn: 0.0127372\ttotal: 58.5s\tremaining: 35.5s\n",
      "622:\tlearn: 0.0127340\ttotal: 58.6s\tremaining: 35.4s\n",
      "623:\tlearn: 0.0127329\ttotal: 58.7s\tremaining: 35.3s\n",
      "624:\tlearn: 0.0127277\ttotal: 58.7s\tremaining: 35.2s\n",
      "625:\tlearn: 0.0127211\ttotal: 58.8s\tremaining: 35.2s\n",
      "626:\tlearn: 0.0127152\ttotal: 58.9s\tremaining: 35.1s\n",
      "627:\tlearn: 0.0127083\ttotal: 59s\tremaining: 35s\n",
      "628:\tlearn: 0.0127060\ttotal: 59.1s\tremaining: 34.9s\n",
      "629:\tlearn: 0.0126994\ttotal: 59.2s\tremaining: 34.8s\n",
      "630:\tlearn: 0.0126950\ttotal: 59.3s\tremaining: 34.7s\n",
      "631:\tlearn: 0.0126941\ttotal: 59.4s\tremaining: 34.6s\n",
      "632:\tlearn: 0.0126912\ttotal: 59.5s\tremaining: 34.5s\n",
      "633:\tlearn: 0.0126879\ttotal: 59.6s\tremaining: 34.4s\n",
      "634:\tlearn: 0.0126854\ttotal: 59.7s\tremaining: 34.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635:\tlearn: 0.0126805\ttotal: 59.8s\tremaining: 34.2s\n",
      "636:\tlearn: 0.0126694\ttotal: 59.9s\tremaining: 34.1s\n",
      "637:\tlearn: 0.0126636\ttotal: 60s\tremaining: 34s\n",
      "638:\tlearn: 0.0126552\ttotal: 1m\tremaining: 33.9s\n",
      "639:\tlearn: 0.0126517\ttotal: 1m\tremaining: 33.8s\n",
      "640:\tlearn: 0.0126474\ttotal: 1m\tremaining: 33.7s\n",
      "641:\tlearn: 0.0126457\ttotal: 1m\tremaining: 33.6s\n",
      "642:\tlearn: 0.0126327\ttotal: 1m\tremaining: 33.5s\n",
      "643:\tlearn: 0.0126249\ttotal: 1m\tremaining: 33.4s\n",
      "644:\tlearn: 0.0126188\ttotal: 1m\tremaining: 33.4s\n",
      "645:\tlearn: 0.0126059\ttotal: 1m\tremaining: 33.3s\n",
      "646:\tlearn: 0.0126030\ttotal: 1m\tremaining: 33.2s\n",
      "647:\tlearn: 0.0125978\ttotal: 1m\tremaining: 33.1s\n",
      "648:\tlearn: 0.0125966\ttotal: 1m\tremaining: 33s\n",
      "649:\tlearn: 0.0125856\ttotal: 1m 1s\tremaining: 32.9s\n",
      "650:\tlearn: 0.0125774\ttotal: 1m 1s\tremaining: 32.8s\n",
      "651:\tlearn: 0.0125671\ttotal: 1m 1s\tremaining: 32.7s\n",
      "652:\tlearn: 0.0125620\ttotal: 1m 1s\tremaining: 32.6s\n",
      "653:\tlearn: 0.0125547\ttotal: 1m 1s\tremaining: 32.5s\n",
      "654:\tlearn: 0.0125473\ttotal: 1m 1s\tremaining: 32.4s\n",
      "655:\tlearn: 0.0125446\ttotal: 1m 1s\tremaining: 32.3s\n",
      "656:\tlearn: 0.0125348\ttotal: 1m 1s\tremaining: 32.2s\n",
      "657:\tlearn: 0.0125317\ttotal: 1m 1s\tremaining: 32.1s\n",
      "658:\tlearn: 0.0125308\ttotal: 1m 1s\tremaining: 32s\n",
      "659:\tlearn: 0.0125128\ttotal: 1m 1s\tremaining: 31.9s\n",
      "660:\tlearn: 0.0125066\ttotal: 1m 2s\tremaining: 31.8s\n",
      "661:\tlearn: 0.0124967\ttotal: 1m 2s\tremaining: 31.7s\n",
      "662:\tlearn: 0.0124939\ttotal: 1m 2s\tremaining: 31.6s\n",
      "663:\tlearn: 0.0124933\ttotal: 1m 2s\tremaining: 31.5s\n",
      "664:\tlearn: 0.0124880\ttotal: 1m 2s\tremaining: 31.4s\n",
      "665:\tlearn: 0.0124836\ttotal: 1m 2s\tremaining: 31.3s\n",
      "666:\tlearn: 0.0124799\ttotal: 1m 2s\tremaining: 31.3s\n",
      "667:\tlearn: 0.0124768\ttotal: 1m 2s\tremaining: 31.2s\n",
      "668:\tlearn: 0.0124732\ttotal: 1m 2s\tremaining: 31.1s\n",
      "669:\tlearn: 0.0124670\ttotal: 1m 2s\tremaining: 31s\n",
      "670:\tlearn: 0.0124578\ttotal: 1m 2s\tremaining: 30.9s\n",
      "671:\tlearn: 0.0124554\ttotal: 1m 3s\tremaining: 30.8s\n",
      "672:\tlearn: 0.0124467\ttotal: 1m 3s\tremaining: 30.7s\n",
      "673:\tlearn: 0.0124437\ttotal: 1m 3s\tremaining: 30.6s\n",
      "674:\tlearn: 0.0124401\ttotal: 1m 3s\tremaining: 30.5s\n",
      "675:\tlearn: 0.0124379\ttotal: 1m 3s\tremaining: 30.4s\n",
      "676:\tlearn: 0.0124363\ttotal: 1m 3s\tremaining: 30.3s\n",
      "677:\tlearn: 0.0124303\ttotal: 1m 3s\tremaining: 30.2s\n",
      "678:\tlearn: 0.0124287\ttotal: 1m 3s\tremaining: 30.1s\n",
      "679:\tlearn: 0.0124232\ttotal: 1m 3s\tremaining: 30s\n",
      "680:\tlearn: 0.0124139\ttotal: 1m 3s\tremaining: 30s\n",
      "681:\tlearn: 0.0123991\ttotal: 1m 4s\tremaining: 29.9s\n",
      "682:\tlearn: 0.0123962\ttotal: 1m 4s\tremaining: 29.8s\n",
      "683:\tlearn: 0.0123945\ttotal: 1m 4s\tremaining: 29.7s\n",
      "684:\tlearn: 0.0123885\ttotal: 1m 4s\tremaining: 29.6s\n",
      "685:\tlearn: 0.0123836\ttotal: 1m 4s\tremaining: 29.5s\n",
      "686:\tlearn: 0.0123733\ttotal: 1m 4s\tremaining: 29.4s\n",
      "687:\tlearn: 0.0123615\ttotal: 1m 4s\tremaining: 29.3s\n",
      "688:\tlearn: 0.0123460\ttotal: 1m 4s\tremaining: 29.2s\n",
      "689:\tlearn: 0.0123450\ttotal: 1m 4s\tremaining: 29.1s\n",
      "690:\tlearn: 0.0123416\ttotal: 1m 4s\tremaining: 29s\n",
      "691:\tlearn: 0.0123407\ttotal: 1m 4s\tremaining: 28.9s\n",
      "692:\tlearn: 0.0123372\ttotal: 1m 5s\tremaining: 28.8s\n",
      "693:\tlearn: 0.0123291\ttotal: 1m 5s\tremaining: 28.7s\n",
      "694:\tlearn: 0.0123271\ttotal: 1m 5s\tremaining: 28.6s\n",
      "695:\tlearn: 0.0123243\ttotal: 1m 5s\tremaining: 28.5s\n",
      "696:\tlearn: 0.0123153\ttotal: 1m 5s\tremaining: 28.4s\n",
      "697:\tlearn: 0.0123140\ttotal: 1m 5s\tremaining: 28.3s\n",
      "698:\tlearn: 0.0123096\ttotal: 1m 5s\tremaining: 28.2s\n",
      "699:\tlearn: 0.0123040\ttotal: 1m 5s\tremaining: 28.1s\n",
      "700:\tlearn: 0.0122998\ttotal: 1m 5s\tremaining: 28.1s\n",
      "701:\tlearn: 0.0122816\ttotal: 1m 5s\tremaining: 28s\n",
      "702:\tlearn: 0.0122802\ttotal: 1m 5s\tremaining: 27.9s\n",
      "703:\tlearn: 0.0122779\ttotal: 1m 6s\tremaining: 27.8s\n",
      "704:\tlearn: 0.0122747\ttotal: 1m 6s\tremaining: 27.7s\n",
      "705:\tlearn: 0.0122706\ttotal: 1m 6s\tremaining: 27.6s\n",
      "706:\tlearn: 0.0122658\ttotal: 1m 6s\tremaining: 27.6s\n",
      "707:\tlearn: 0.0122573\ttotal: 1m 6s\tremaining: 27.5s\n",
      "708:\tlearn: 0.0122533\ttotal: 1m 6s\tremaining: 27.4s\n",
      "709:\tlearn: 0.0122503\ttotal: 1m 6s\tremaining: 27.3s\n",
      "710:\tlearn: 0.0122487\ttotal: 1m 7s\tremaining: 27.2s\n",
      "711:\tlearn: 0.0122473\ttotal: 1m 7s\tremaining: 27.2s\n",
      "712:\tlearn: 0.0122439\ttotal: 1m 7s\tremaining: 27.1s\n",
      "713:\tlearn: 0.0122428\ttotal: 1m 7s\tremaining: 27s\n",
      "714:\tlearn: 0.0122405\ttotal: 1m 7s\tremaining: 26.9s\n",
      "715:\tlearn: 0.0122386\ttotal: 1m 7s\tremaining: 26.8s\n",
      "716:\tlearn: 0.0122375\ttotal: 1m 7s\tremaining: 26.8s\n",
      "717:\tlearn: 0.0122313\ttotal: 1m 7s\tremaining: 26.7s\n",
      "718:\tlearn: 0.0122248\ttotal: 1m 8s\tremaining: 26.6s\n",
      "719:\tlearn: 0.0122213\ttotal: 1m 8s\tremaining: 26.5s\n",
      "720:\tlearn: 0.0122196\ttotal: 1m 8s\tremaining: 26.4s\n",
      "721:\tlearn: 0.0122122\ttotal: 1m 8s\tremaining: 26.4s\n",
      "722:\tlearn: 0.0122105\ttotal: 1m 8s\tremaining: 26.3s\n",
      "723:\tlearn: 0.0122098\ttotal: 1m 8s\tremaining: 26.2s\n",
      "724:\tlearn: 0.0122023\ttotal: 1m 8s\tremaining: 26.1s\n",
      "725:\tlearn: 0.0121987\ttotal: 1m 9s\tremaining: 26s\n",
      "726:\tlearn: 0.0121937\ttotal: 1m 9s\tremaining: 26s\n",
      "727:\tlearn: 0.0121911\ttotal: 1m 9s\tremaining: 25.9s\n",
      "728:\tlearn: 0.0121857\ttotal: 1m 9s\tremaining: 25.8s\n",
      "729:\tlearn: 0.0121820\ttotal: 1m 9s\tremaining: 25.7s\n",
      "730:\tlearn: 0.0121783\ttotal: 1m 9s\tremaining: 25.6s\n",
      "731:\tlearn: 0.0121752\ttotal: 1m 9s\tremaining: 25.5s\n",
      "732:\tlearn: 0.0121645\ttotal: 1m 9s\tremaining: 25.5s\n",
      "733:\tlearn: 0.0121628\ttotal: 1m 10s\tremaining: 25.4s\n",
      "734:\tlearn: 0.0121613\ttotal: 1m 10s\tremaining: 25.3s\n",
      "735:\tlearn: 0.0121595\ttotal: 1m 10s\tremaining: 25.2s\n",
      "736:\tlearn: 0.0121566\ttotal: 1m 10s\tremaining: 25.1s\n",
      "737:\tlearn: 0.0121515\ttotal: 1m 10s\tremaining: 25s\n",
      "738:\tlearn: 0.0121485\ttotal: 1m 10s\tremaining: 24.9s\n",
      "739:\tlearn: 0.0121407\ttotal: 1m 10s\tremaining: 24.9s\n",
      "740:\tlearn: 0.0121385\ttotal: 1m 10s\tremaining: 24.8s\n",
      "741:\tlearn: 0.0121313\ttotal: 1m 10s\tremaining: 24.7s\n",
      "742:\tlearn: 0.0121306\ttotal: 1m 11s\tremaining: 24.6s\n",
      "743:\tlearn: 0.0121237\ttotal: 1m 11s\tremaining: 24.5s\n",
      "744:\tlearn: 0.0121218\ttotal: 1m 11s\tremaining: 24.4s\n",
      "745:\tlearn: 0.0121146\ttotal: 1m 11s\tremaining: 24.3s\n",
      "746:\tlearn: 0.0121138\ttotal: 1m 11s\tremaining: 24.2s\n",
      "747:\tlearn: 0.0121058\ttotal: 1m 11s\tremaining: 24.1s\n",
      "748:\tlearn: 0.0121024\ttotal: 1m 11s\tremaining: 24.1s\n",
      "749:\tlearn: 0.0121015\ttotal: 1m 11s\tremaining: 24s\n",
      "750:\tlearn: 0.0120943\ttotal: 1m 12s\tremaining: 23.9s\n",
      "751:\tlearn: 0.0120772\ttotal: 1m 12s\tremaining: 23.8s\n",
      "752:\tlearn: 0.0120740\ttotal: 1m 12s\tremaining: 23.7s\n",
      "753:\tlearn: 0.0120527\ttotal: 1m 12s\tremaining: 23.7s\n",
      "754:\tlearn: 0.0120508\ttotal: 1m 12s\tremaining: 23.6s\n",
      "755:\tlearn: 0.0120494\ttotal: 1m 12s\tremaining: 23.5s\n",
      "756:\tlearn: 0.0120425\ttotal: 1m 12s\tremaining: 23.4s\n",
      "757:\tlearn: 0.0120421\ttotal: 1m 13s\tremaining: 23.3s\n",
      "758:\tlearn: 0.0120349\ttotal: 1m 13s\tremaining: 23.2s\n",
      "759:\tlearn: 0.0120318\ttotal: 1m 13s\tremaining: 23.1s\n",
      "760:\tlearn: 0.0120238\ttotal: 1m 13s\tremaining: 23.1s\n",
      "761:\tlearn: 0.0120067\ttotal: 1m 13s\tremaining: 23s\n",
      "762:\tlearn: 0.0120053\ttotal: 1m 13s\tremaining: 22.9s\n",
      "763:\tlearn: 0.0120041\ttotal: 1m 13s\tremaining: 22.8s\n",
      "764:\tlearn: 0.0120033\ttotal: 1m 13s\tremaining: 22.7s\n",
      "765:\tlearn: 0.0119929\ttotal: 1m 13s\tremaining: 22.6s\n",
      "766:\tlearn: 0.0119902\ttotal: 1m 14s\tremaining: 22.5s\n",
      "767:\tlearn: 0.0119862\ttotal: 1m 14s\tremaining: 22.4s\n",
      "768:\tlearn: 0.0119822\ttotal: 1m 14s\tremaining: 22.3s\n",
      "769:\tlearn: 0.0119766\ttotal: 1m 14s\tremaining: 22.2s\n",
      "770:\tlearn: 0.0119751\ttotal: 1m 14s\tremaining: 22.1s\n",
      "771:\tlearn: 0.0119742\ttotal: 1m 14s\tremaining: 22s\n",
      "772:\tlearn: 0.0119701\ttotal: 1m 14s\tremaining: 21.9s\n",
      "773:\tlearn: 0.0119679\ttotal: 1m 14s\tremaining: 21.8s\n",
      "774:\tlearn: 0.0119663\ttotal: 1m 14s\tremaining: 21.7s\n",
      "775:\tlearn: 0.0119616\ttotal: 1m 14s\tremaining: 21.6s\n",
      "776:\tlearn: 0.0119597\ttotal: 1m 15s\tremaining: 21.5s\n",
      "777:\tlearn: 0.0119567\ttotal: 1m 15s\tremaining: 21.4s\n",
      "778:\tlearn: 0.0119531\ttotal: 1m 15s\tremaining: 21.3s\n",
      "779:\tlearn: 0.0119488\ttotal: 1m 15s\tremaining: 21.2s\n",
      "780:\tlearn: 0.0119264\ttotal: 1m 15s\tremaining: 21.1s\n",
      "781:\tlearn: 0.0119253\ttotal: 1m 15s\tremaining: 21.1s\n",
      "782:\tlearn: 0.0119198\ttotal: 1m 15s\tremaining: 21s\n",
      "783:\tlearn: 0.0119182\ttotal: 1m 15s\tremaining: 20.9s\n",
      "784:\tlearn: 0.0119129\ttotal: 1m 15s\tremaining: 20.8s\n",
      "785:\tlearn: 0.0119116\ttotal: 1m 15s\tremaining: 20.7s\n",
      "786:\tlearn: 0.0119087\ttotal: 1m 15s\tremaining: 20.6s\n",
      "787:\tlearn: 0.0119058\ttotal: 1m 16s\tremaining: 20.5s\n",
      "788:\tlearn: 0.0119048\ttotal: 1m 16s\tremaining: 20.4s\n",
      "789:\tlearn: 0.0118942\ttotal: 1m 16s\tremaining: 20.3s\n",
      "790:\tlearn: 0.0118893\ttotal: 1m 16s\tremaining: 20.2s\n",
      "791:\tlearn: 0.0118857\ttotal: 1m 16s\tremaining: 20.1s\n",
      "792:\tlearn: 0.0118834\ttotal: 1m 16s\tremaining: 20s\n",
      "793:\tlearn: 0.0118825\ttotal: 1m 16s\tremaining: 19.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "794:\tlearn: 0.0118764\ttotal: 1m 16s\tremaining: 19.8s\n",
      "795:\tlearn: 0.0118759\ttotal: 1m 16s\tremaining: 19.7s\n",
      "796:\tlearn: 0.0118743\ttotal: 1m 16s\tremaining: 19.6s\n",
      "797:\tlearn: 0.0118704\ttotal: 1m 17s\tremaining: 19.5s\n",
      "798:\tlearn: 0.0118635\ttotal: 1m 17s\tremaining: 19.4s\n",
      "799:\tlearn: 0.0118617\ttotal: 1m 17s\tremaining: 19.3s\n",
      "800:\tlearn: 0.0118484\ttotal: 1m 17s\tremaining: 19.2s\n",
      "801:\tlearn: 0.0118423\ttotal: 1m 17s\tremaining: 19.1s\n",
      "802:\tlearn: 0.0118289\ttotal: 1m 17s\tremaining: 19s\n",
      "803:\tlearn: 0.0118276\ttotal: 1m 17s\tremaining: 18.9s\n",
      "804:\tlearn: 0.0118199\ttotal: 1m 17s\tremaining: 18.8s\n",
      "805:\tlearn: 0.0118174\ttotal: 1m 17s\tremaining: 18.7s\n",
      "806:\tlearn: 0.0118151\ttotal: 1m 17s\tremaining: 18.6s\n",
      "807:\tlearn: 0.0118140\ttotal: 1m 17s\tremaining: 18.5s\n",
      "808:\tlearn: 0.0118114\ttotal: 1m 18s\tremaining: 18.4s\n",
      "809:\tlearn: 0.0118101\ttotal: 1m 18s\tremaining: 18.3s\n",
      "810:\tlearn: 0.0118072\ttotal: 1m 18s\tremaining: 18.2s\n",
      "811:\tlearn: 0.0117982\ttotal: 1m 18s\tremaining: 18.1s\n",
      "812:\tlearn: 0.0117954\ttotal: 1m 18s\tremaining: 18s\n",
      "813:\tlearn: 0.0117830\ttotal: 1m 18s\tremaining: 17.9s\n",
      "814:\tlearn: 0.0117673\ttotal: 1m 18s\tremaining: 17.8s\n",
      "815:\tlearn: 0.0117630\ttotal: 1m 18s\tremaining: 17.8s\n",
      "816:\tlearn: 0.0117617\ttotal: 1m 18s\tremaining: 17.7s\n",
      "817:\tlearn: 0.0117586\ttotal: 1m 18s\tremaining: 17.6s\n",
      "818:\tlearn: 0.0117518\ttotal: 1m 18s\tremaining: 17.5s\n",
      "819:\tlearn: 0.0117442\ttotal: 1m 19s\tremaining: 17.4s\n",
      "820:\tlearn: 0.0117408\ttotal: 1m 19s\tremaining: 17.3s\n",
      "821:\tlearn: 0.0117315\ttotal: 1m 19s\tremaining: 17.2s\n",
      "822:\tlearn: 0.0117305\ttotal: 1m 19s\tremaining: 17.1s\n",
      "823:\tlearn: 0.0117276\ttotal: 1m 19s\tremaining: 17s\n",
      "824:\tlearn: 0.0117265\ttotal: 1m 19s\tremaining: 16.9s\n",
      "825:\tlearn: 0.0117259\ttotal: 1m 19s\tremaining: 16.8s\n",
      "826:\tlearn: 0.0117219\ttotal: 1m 19s\tremaining: 16.7s\n",
      "827:\tlearn: 0.0117201\ttotal: 1m 19s\tremaining: 16.6s\n",
      "828:\tlearn: 0.0117191\ttotal: 1m 19s\tremaining: 16.5s\n",
      "829:\tlearn: 0.0117166\ttotal: 1m 20s\tremaining: 16.4s\n",
      "830:\tlearn: 0.0117135\ttotal: 1m 20s\tremaining: 16.3s\n",
      "831:\tlearn: 0.0117061\ttotal: 1m 20s\tremaining: 16.2s\n",
      "832:\tlearn: 0.0116988\ttotal: 1m 20s\tremaining: 16.1s\n",
      "833:\tlearn: 0.0116947\ttotal: 1m 20s\tremaining: 16s\n",
      "834:\tlearn: 0.0116901\ttotal: 1m 20s\tremaining: 15.9s\n",
      "835:\tlearn: 0.0116884\ttotal: 1m 20s\tremaining: 15.8s\n",
      "836:\tlearn: 0.0116876\ttotal: 1m 20s\tremaining: 15.7s\n",
      "837:\tlearn: 0.0116806\ttotal: 1m 20s\tremaining: 15.6s\n",
      "838:\tlearn: 0.0116723\ttotal: 1m 20s\tremaining: 15.5s\n",
      "839:\tlearn: 0.0116709\ttotal: 1m 20s\tremaining: 15.4s\n",
      "840:\tlearn: 0.0116673\ttotal: 1m 21s\tremaining: 15.3s\n",
      "841:\tlearn: 0.0116620\ttotal: 1m 21s\tremaining: 15.2s\n",
      "842:\tlearn: 0.0116602\ttotal: 1m 21s\tremaining: 15.1s\n",
      "843:\tlearn: 0.0116555\ttotal: 1m 21s\tremaining: 15s\n",
      "844:\tlearn: 0.0116549\ttotal: 1m 21s\tremaining: 14.9s\n",
      "845:\tlearn: 0.0116538\ttotal: 1m 21s\tremaining: 14.8s\n",
      "846:\tlearn: 0.0116508\ttotal: 1m 21s\tremaining: 14.7s\n",
      "847:\tlearn: 0.0116430\ttotal: 1m 21s\tremaining: 14.6s\n",
      "848:\tlearn: 0.0116389\ttotal: 1m 21s\tremaining: 14.5s\n",
      "849:\tlearn: 0.0116364\ttotal: 1m 21s\tremaining: 14.4s\n",
      "850:\tlearn: 0.0116356\ttotal: 1m 21s\tremaining: 14.3s\n",
      "851:\tlearn: 0.0116336\ttotal: 1m 22s\tremaining: 14.2s\n",
      "852:\tlearn: 0.0116328\ttotal: 1m 22s\tremaining: 14.2s\n",
      "853:\tlearn: 0.0116317\ttotal: 1m 22s\tremaining: 14.1s\n",
      "854:\tlearn: 0.0116293\ttotal: 1m 22s\tremaining: 14s\n",
      "855:\tlearn: 0.0116273\ttotal: 1m 22s\tremaining: 13.9s\n",
      "856:\tlearn: 0.0116260\ttotal: 1m 22s\tremaining: 13.8s\n",
      "857:\tlearn: 0.0116251\ttotal: 1m 22s\tremaining: 13.7s\n",
      "858:\tlearn: 0.0116224\ttotal: 1m 22s\tremaining: 13.6s\n",
      "859:\tlearn: 0.0116208\ttotal: 1m 22s\tremaining: 13.5s\n",
      "860:\tlearn: 0.0116194\ttotal: 1m 22s\tremaining: 13.4s\n",
      "861:\tlearn: 0.0116152\ttotal: 1m 22s\tremaining: 13.3s\n",
      "862:\tlearn: 0.0116146\ttotal: 1m 23s\tremaining: 13.2s\n",
      "863:\tlearn: 0.0116095\ttotal: 1m 23s\tremaining: 13.1s\n",
      "864:\tlearn: 0.0116051\ttotal: 1m 23s\tremaining: 13s\n",
      "865:\tlearn: 0.0115988\ttotal: 1m 23s\tremaining: 12.9s\n",
      "866:\tlearn: 0.0115946\ttotal: 1m 23s\tremaining: 12.8s\n",
      "867:\tlearn: 0.0115905\ttotal: 1m 23s\tremaining: 12.7s\n",
      "868:\tlearn: 0.0115754\ttotal: 1m 23s\tremaining: 12.6s\n",
      "869:\tlearn: 0.0115718\ttotal: 1m 23s\tremaining: 12.5s\n",
      "870:\tlearn: 0.0115700\ttotal: 1m 23s\tremaining: 12.4s\n",
      "871:\tlearn: 0.0115592\ttotal: 1m 23s\tremaining: 12.3s\n",
      "872:\tlearn: 0.0115576\ttotal: 1m 23s\tremaining: 12.2s\n",
      "873:\tlearn: 0.0115538\ttotal: 1m 24s\tremaining: 12.1s\n",
      "874:\tlearn: 0.0115443\ttotal: 1m 24s\tremaining: 12s\n",
      "875:\tlearn: 0.0115396\ttotal: 1m 24s\tremaining: 11.9s\n",
      "876:\tlearn: 0.0115390\ttotal: 1m 24s\tremaining: 11.8s\n",
      "877:\tlearn: 0.0115348\ttotal: 1m 24s\tremaining: 11.7s\n",
      "878:\tlearn: 0.0115316\ttotal: 1m 24s\tremaining: 11.6s\n",
      "879:\tlearn: 0.0115298\ttotal: 1m 24s\tremaining: 11.5s\n",
      "880:\tlearn: 0.0115221\ttotal: 1m 24s\tremaining: 11.4s\n",
      "881:\tlearn: 0.0115182\ttotal: 1m 24s\tremaining: 11.4s\n",
      "882:\tlearn: 0.0115148\ttotal: 1m 24s\tremaining: 11.3s\n",
      "883:\tlearn: 0.0115102\ttotal: 1m 25s\tremaining: 11.2s\n",
      "884:\tlearn: 0.0115009\ttotal: 1m 25s\tremaining: 11.1s\n",
      "885:\tlearn: 0.0114984\ttotal: 1m 25s\tremaining: 11s\n",
      "886:\tlearn: 0.0114975\ttotal: 1m 25s\tremaining: 10.9s\n",
      "887:\tlearn: 0.0114967\ttotal: 1m 25s\tremaining: 10.8s\n",
      "888:\tlearn: 0.0114929\ttotal: 1m 25s\tremaining: 10.7s\n",
      "889:\tlearn: 0.0114923\ttotal: 1m 25s\tremaining: 10.6s\n",
      "890:\tlearn: 0.0114904\ttotal: 1m 25s\tremaining: 10.5s\n",
      "891:\tlearn: 0.0114788\ttotal: 1m 25s\tremaining: 10.4s\n",
      "892:\tlearn: 0.0114749\ttotal: 1m 25s\tremaining: 10.3s\n",
      "893:\tlearn: 0.0114717\ttotal: 1m 25s\tremaining: 10.2s\n",
      "894:\tlearn: 0.0114566\ttotal: 1m 26s\tremaining: 10.1s\n",
      "895:\tlearn: 0.0114561\ttotal: 1m 26s\tremaining: 10s\n",
      "896:\tlearn: 0.0114554\ttotal: 1m 26s\tremaining: 9.9s\n",
      "897:\tlearn: 0.0114520\ttotal: 1m 26s\tremaining: 9.8s\n",
      "898:\tlearn: 0.0114507\ttotal: 1m 26s\tremaining: 9.71s\n",
      "899:\tlearn: 0.0114497\ttotal: 1m 26s\tremaining: 9.61s\n",
      "900:\tlearn: 0.0114467\ttotal: 1m 26s\tremaining: 9.52s\n",
      "901:\tlearn: 0.0114333\ttotal: 1m 26s\tremaining: 9.42s\n",
      "902:\tlearn: 0.0114316\ttotal: 1m 26s\tremaining: 9.32s\n",
      "903:\tlearn: 0.0114304\ttotal: 1m 26s\tremaining: 9.23s\n",
      "904:\tlearn: 0.0114299\ttotal: 1m 26s\tremaining: 9.13s\n",
      "905:\tlearn: 0.0114286\ttotal: 1m 27s\tremaining: 9.04s\n",
      "906:\tlearn: 0.0114236\ttotal: 1m 27s\tremaining: 8.94s\n",
      "907:\tlearn: 0.0114199\ttotal: 1m 27s\tremaining: 8.84s\n",
      "908:\tlearn: 0.0114192\ttotal: 1m 27s\tremaining: 8.75s\n",
      "909:\tlearn: 0.0114170\ttotal: 1m 27s\tremaining: 8.65s\n",
      "910:\tlearn: 0.0114160\ttotal: 1m 27s\tremaining: 8.55s\n",
      "911:\tlearn: 0.0114143\ttotal: 1m 27s\tremaining: 8.46s\n",
      "912:\tlearn: 0.0114124\ttotal: 1m 27s\tremaining: 8.36s\n",
      "913:\tlearn: 0.0114118\ttotal: 1m 27s\tremaining: 8.26s\n",
      "914:\tlearn: 0.0114094\ttotal: 1m 27s\tremaining: 8.17s\n",
      "915:\tlearn: 0.0114057\ttotal: 1m 28s\tremaining: 8.07s\n",
      "916:\tlearn: 0.0114045\ttotal: 1m 28s\tremaining: 7.97s\n",
      "917:\tlearn: 0.0113999\ttotal: 1m 28s\tremaining: 7.88s\n",
      "918:\tlearn: 0.0113988\ttotal: 1m 28s\tremaining: 7.78s\n",
      "919:\tlearn: 0.0113902\ttotal: 1m 28s\tremaining: 7.68s\n",
      "920:\tlearn: 0.0113871\ttotal: 1m 28s\tremaining: 7.59s\n",
      "921:\tlearn: 0.0113795\ttotal: 1m 28s\tremaining: 7.49s\n",
      "922:\tlearn: 0.0113781\ttotal: 1m 28s\tremaining: 7.4s\n",
      "923:\tlearn: 0.0113749\ttotal: 1m 28s\tremaining: 7.3s\n",
      "924:\tlearn: 0.0113732\ttotal: 1m 28s\tremaining: 7.21s\n",
      "925:\tlearn: 0.0113691\ttotal: 1m 28s\tremaining: 7.11s\n",
      "926:\tlearn: 0.0113685\ttotal: 1m 29s\tremaining: 7.01s\n",
      "927:\tlearn: 0.0113640\ttotal: 1m 29s\tremaining: 6.92s\n",
      "928:\tlearn: 0.0113587\ttotal: 1m 29s\tremaining: 6.82s\n",
      "929:\tlearn: 0.0113574\ttotal: 1m 29s\tremaining: 6.72s\n",
      "930:\tlearn: 0.0113546\ttotal: 1m 29s\tremaining: 6.63s\n",
      "931:\tlearn: 0.0113523\ttotal: 1m 29s\tremaining: 6.53s\n",
      "932:\tlearn: 0.0113516\ttotal: 1m 29s\tremaining: 6.43s\n",
      "933:\tlearn: 0.0113479\ttotal: 1m 29s\tremaining: 6.34s\n",
      "934:\tlearn: 0.0113474\ttotal: 1m 29s\tremaining: 6.24s\n",
      "935:\tlearn: 0.0113401\ttotal: 1m 29s\tremaining: 6.15s\n",
      "936:\tlearn: 0.0113367\ttotal: 1m 29s\tremaining: 6.05s\n",
      "937:\tlearn: 0.0113354\ttotal: 1m 30s\tremaining: 5.95s\n",
      "938:\tlearn: 0.0113348\ttotal: 1m 30s\tremaining: 5.86s\n",
      "939:\tlearn: 0.0113312\ttotal: 1m 30s\tremaining: 5.76s\n",
      "940:\tlearn: 0.0113248\ttotal: 1m 30s\tremaining: 5.67s\n",
      "941:\tlearn: 0.0113208\ttotal: 1m 30s\tremaining: 5.57s\n",
      "942:\tlearn: 0.0113180\ttotal: 1m 30s\tremaining: 5.47s\n",
      "943:\tlearn: 0.0113158\ttotal: 1m 30s\tremaining: 5.38s\n",
      "944:\tlearn: 0.0113134\ttotal: 1m 30s\tremaining: 5.28s\n",
      "945:\tlearn: 0.0113107\ttotal: 1m 30s\tremaining: 5.18s\n",
      "946:\tlearn: 0.0113102\ttotal: 1m 30s\tremaining: 5.09s\n",
      "947:\tlearn: 0.0113092\ttotal: 1m 31s\tremaining: 4.99s\n",
      "948:\tlearn: 0.0113075\ttotal: 1m 31s\tremaining: 4.9s\n",
      "949:\tlearn: 0.0113060\ttotal: 1m 31s\tremaining: 4.8s\n",
      "950:\tlearn: 0.0113053\ttotal: 1m 31s\tremaining: 4.7s\n",
      "951:\tlearn: 0.0112933\ttotal: 1m 31s\tremaining: 4.61s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952:\tlearn: 0.0112867\ttotal: 1m 31s\tremaining: 4.51s\n",
      "953:\tlearn: 0.0112849\ttotal: 1m 31s\tremaining: 4.42s\n",
      "954:\tlearn: 0.0112832\ttotal: 1m 31s\tremaining: 4.32s\n",
      "955:\tlearn: 0.0112754\ttotal: 1m 31s\tremaining: 4.22s\n",
      "956:\tlearn: 0.0112639\ttotal: 1m 31s\tremaining: 4.13s\n",
      "957:\tlearn: 0.0112588\ttotal: 1m 31s\tremaining: 4.03s\n",
      "958:\tlearn: 0.0112523\ttotal: 1m 32s\tremaining: 3.94s\n",
      "959:\tlearn: 0.0112423\ttotal: 1m 32s\tremaining: 3.84s\n",
      "960:\tlearn: 0.0112406\ttotal: 1m 32s\tremaining: 3.74s\n",
      "961:\tlearn: 0.0112377\ttotal: 1m 32s\tremaining: 3.65s\n",
      "962:\tlearn: 0.0112345\ttotal: 1m 32s\tremaining: 3.55s\n",
      "963:\tlearn: 0.0112327\ttotal: 1m 32s\tremaining: 3.46s\n",
      "964:\tlearn: 0.0112293\ttotal: 1m 32s\tremaining: 3.36s\n",
      "965:\tlearn: 0.0112191\ttotal: 1m 32s\tremaining: 3.26s\n",
      "966:\tlearn: 0.0112185\ttotal: 1m 32s\tremaining: 3.17s\n",
      "967:\tlearn: 0.0112118\ttotal: 1m 32s\tremaining: 3.07s\n",
      "968:\tlearn: 0.0112107\ttotal: 1m 33s\tremaining: 2.98s\n",
      "969:\tlearn: 0.0112091\ttotal: 1m 33s\tremaining: 2.88s\n",
      "970:\tlearn: 0.0112084\ttotal: 1m 33s\tremaining: 2.78s\n",
      "971:\tlearn: 0.0112081\ttotal: 1m 33s\tremaining: 2.69s\n",
      "972:\tlearn: 0.0112051\ttotal: 1m 33s\tremaining: 2.59s\n",
      "973:\tlearn: 0.0112030\ttotal: 1m 33s\tremaining: 2.49s\n",
      "974:\tlearn: 0.0111955\ttotal: 1m 33s\tremaining: 2.4s\n",
      "975:\tlearn: 0.0111920\ttotal: 1m 33s\tremaining: 2.3s\n",
      "976:\tlearn: 0.0111903\ttotal: 1m 33s\tremaining: 2.21s\n",
      "977:\tlearn: 0.0111898\ttotal: 1m 33s\tremaining: 2.11s\n",
      "978:\tlearn: 0.0111864\ttotal: 1m 33s\tremaining: 2.01s\n",
      "979:\tlearn: 0.0111855\ttotal: 1m 34s\tremaining: 1.92s\n",
      "980:\tlearn: 0.0111814\ttotal: 1m 34s\tremaining: 1.82s\n",
      "981:\tlearn: 0.0111790\ttotal: 1m 34s\tremaining: 1.73s\n",
      "982:\tlearn: 0.0111752\ttotal: 1m 34s\tremaining: 1.63s\n",
      "983:\tlearn: 0.0111750\ttotal: 1m 34s\tremaining: 1.53s\n",
      "984:\tlearn: 0.0111732\ttotal: 1m 34s\tremaining: 1.44s\n",
      "985:\tlearn: 0.0111706\ttotal: 1m 34s\tremaining: 1.34s\n",
      "986:\tlearn: 0.0111692\ttotal: 1m 34s\tremaining: 1.25s\n",
      "987:\tlearn: 0.0111686\ttotal: 1m 34s\tremaining: 1.15s\n",
      "988:\tlearn: 0.0111597\ttotal: 1m 34s\tremaining: 1.05s\n",
      "989:\tlearn: 0.0111546\ttotal: 1m 34s\tremaining: 959ms\n",
      "990:\tlearn: 0.0111532\ttotal: 1m 35s\tremaining: 863ms\n",
      "991:\tlearn: 0.0111516\ttotal: 1m 35s\tremaining: 767ms\n",
      "992:\tlearn: 0.0111505\ttotal: 1m 35s\tremaining: 671ms\n",
      "993:\tlearn: 0.0111434\ttotal: 1m 35s\tremaining: 575ms\n",
      "994:\tlearn: 0.0111374\ttotal: 1m 35s\tremaining: 480ms\n",
      "995:\tlearn: 0.0111358\ttotal: 1m 35s\tremaining: 384ms\n",
      "996:\tlearn: 0.0111329\ttotal: 1m 35s\tremaining: 288ms\n",
      "997:\tlearn: 0.0111324\ttotal: 1m 35s\tremaining: 192ms\n",
      "998:\tlearn: 0.0111313\ttotal: 1m 35s\tremaining: 95.9ms\n",
      "999:\tlearn: 0.0111269\ttotal: 1m 35s\tremaining: 0us\n",
      "done\n",
      "XGBOOST... done\n",
      "LIGHTGBM... done\n",
      "ADABOOST... done\n",
      "GBM... done\n",
      "RANDOM FOREST... done\n",
      "BME... done\n",
      "Done.\n",
      "\n",
      "Scoring models.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-350-f8652bdf688a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mscore_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-348-9d604ca743a9>\u001b[0m in \u001b[0;36mscore_models\u001b[1;34m(P, y)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Scoring models.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mP\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%-26s: %.3f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Done.\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 81\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "models = get_models()\n",
    "P = train_predict(models)\n",
    "score_models(P, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ensemble ROC-AUC score: %.3f\" % accuracy_score(y_test, P.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "score_models() got an unexpected keyword argument 'normalize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-150-cf00739f82a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscore_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: score_models() got an unexpected keyword argument 'normalize'"
     ]
    }
   ],
   "source": [
    "base_learners = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner = cb.CatBoostClassifier(\n",
    "    n_estimators=1000,\n",
    "    random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain_base, xpred_base, ytrain_base, ypred_base = train_test_split(\n",
    "    x_train, y_train, test_size=0.3, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_base_learners(base_learners, inp, out, verbose=True):\n",
    "    \"\"\"\n",
    "    Train all base learners in the library.\n",
    "    \"\"\"\n",
    "    if verbose: print(\"Fitting models.\")\n",
    "    for i, (name, m) in enumerate(base_learners.items()):\n",
    "        if verbose: print(\"%s...\" % name, end=\" \", flush=False)\n",
    "        m.fit(inp, out)\n",
    "        if verbose: print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base_learners(base_learners, xtrain_base, ytrain_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_base_learners(pred_base_learners, inp, verbose=True):\n",
    "    \"\"\"\n",
    "    Generate a prediction matrix.\n",
    "    \"\"\"\n",
    "    P = np.zeros((inp.shape[0], len(pred_base_learners)))\n",
    "\n",
    "    if verbose: print(\"Generating base learner predictions.\")\n",
    "    for i, (name, m) in enumerate(pred_base_learners.items()):\n",
    "        if verbose: print(\"%s...\" % name, end=\" \", flush=False)\n",
    "        p = m.predict_proba(inp)\n",
    "        # With two classes, need only predictions for one class\n",
    "        P[:, i] = p[:, 1]\n",
    "        if verbose: print(\"done\")\n",
    "\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_base = predict_base_learners(base_learners, xpred_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner.fit(P_base, ypred_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(base_learners, meta_learner, inp, verbose=True):\n",
    "    \"\"\"\n",
    "    Generate predictions from the ensemble.\n",
    "    \"\"\"\n",
    "    P_pred = predict_base_learners(base_learners, inp, verbose=verbose)\n",
    "    return P_pred, meta_learner.predict_proba(P_pred)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_pred, p = ensemble_predict(base_learners, meta_learner, x_validate)\n",
    "print(\"\\nEnsemble ROC-AUC score: %.3f\" % roc_auc_score(y_validate, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "def stacking(base_learners, meta_learner, X, y, generator):\n",
    "    \"\"\"Simple training routine for stacking.\"\"\"\n",
    "\n",
    "    # Train final base learners for test time\n",
    "    print(\"Fitting final base learners...\", end=\"\")\n",
    "    train_base_learners(base_learners, X, y, verbose=False)\n",
    "    print(\"done\")\n",
    "\n",
    "    # Generate predictions for training meta learners\n",
    "    # Outer loop:\n",
    "    print(\"Generating cross-validated predictions...\")\n",
    "    cv_preds, cv_y = [], []\n",
    "    for i, (train_idx, test_idx) in enumerate(generator.split(X)):\n",
    "\n",
    "        fold_xtrain, fold_ytrain = X[train_idx, :], y[train_idx]\n",
    "        fold_xtest, fold_ytest = X[test_idx, :], y[test_idx]\n",
    "\n",
    "        # Inner loop: step 4 and 5\n",
    "        fold_base_learners = {name: clone(model)\n",
    "                              for name, model in base_learners.items()}\n",
    "        train_base_learners(\n",
    "            fold_base_learners, fold_xtrain, fold_ytrain, verbose=False)\n",
    "\n",
    "        fold_P_base = predict_base_learners(\n",
    "            fold_base_learners, fold_xtest, verbose=False)\n",
    "\n",
    "        cv_preds.append(fold_P_base)\n",
    "        cv_y.append(fold_ytest)\n",
    "        print(\"Fold %i done\" % (i + 1))\n",
    "\n",
    "    print(\"CV-predictions done\")\n",
    "\n",
    "    # Be careful to get rows in the right order\n",
    "    cv_preds = np.vstack(cv_preds)\n",
    "    cv_y = np.hstack(cv_y)\n",
    "\n",
    "    # Train meta learner\n",
    "    print(\"Fitting meta learner...\", end=\"\")\n",
    "    meta_learner.fit(cv_preds, cv_y)\n",
    "    print(\"done\")\n",
    "\n",
    "    return base_learners, meta_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Train with stacking\n",
    "cv_base_learners, cv_meta_learner = stacking(\n",
    "    get_models(), clone(meta_learner), x_train.values, y_train.values, KFold(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_pred, p = ensemble_predict(cv_base_learners, cv_meta_learner, x_validate, verbose=False)\n",
    "print(\"\\nEnsemble ROC-AUC score: %.3f\" % roc_auc_score(y_validate, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125973, 56)"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=10\n",
    "def get_models():\n",
    "    \"\"\"Generate a library of base learners.\"\"\"\n",
    "    #cat = cb.CatBoostClassifier()\n",
    "    xg=xgb.XGBClassifier()\n",
    "    lgbm = lgb.LGBMClassifier(silent=False)\n",
    "    ada = AdaBoostClassifier()\n",
    "    gb = GradientBoostingClassifier( random_state=SEED)\n",
    "\n",
    "    models = {#'CATBOOST': cat,\n",
    "              'XGBOOST': xg,\n",
    "              'LIGHTGBM': lgbm,\n",
    "              'ADABOOST': ada,\n",
    "              'GBM': gb\n",
    "              }\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learners = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_learner =cb.CatBoostClassifier(random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlens.ensemble import SuperLearner\n",
    "# Instantiate the ensemble with 10 folds\n",
    "sl = SuperLearner(\n",
    "    folds=10,\n",
    "    random_state=SEED,\n",
    "    verbose=2,\n",
    "    backend=\"multiprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperLearner(array_check=None, backend=None, folds=10,\n",
       "       layers=[Layer(backend='threading', dtype=<class 'numpy.float32'>, n_jobs=-1,\n",
       "   name='layer-1', propagate_features=None, raise_on_exception=True,\n",
       "   random_state=1289, shuffle=False,\n",
       "   stack=[Group(backend='threading', dtype=<class 'numpy.float32'>,\n",
       "   indexer=FoldIndex(X=None, folds=10, raise_on_e...rer=None)],\n",
       "   n_jobs=-1, name='group-5', raise_on_exception=True, transformers=[])],\n",
       "   verbose=1)],\n",
       "       model_selection=False, n_jobs=None, raise_on_exception=True,\n",
       "       random_state=10, sample_size=20, scorer=None, shuffle=False,\n",
       "       verbose=2)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl.add(list(base_learners.values()), proba=True)\n",
    "sl.add_meta(meta_learner, proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting 2 layers\n",
      "Processing layer-1             "
     ]
    }
   ],
   "source": [
    "# Train the ensemble\n",
    "sl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:10\n",
      "Processing layer-2             done | 00:00:02\n",
      "Predict complete                    | 00:00:14\n"
     ]
    }
   ],
   "source": [
    "# Predict the test set\n",
    "p_sl = sl.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Super Learner ROC-AUC score: 0.957\n",
      "\n",
      "Super Learner Accuracy score: 0.786\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSuper Learner ROC-AUC score: %.3f\" % roc_auc_score(y_test, p_sl[:, 1]))\n",
    "print(\"\\nSuper Learner Accuracy score: %.3f\" % accuracy_score(y_test, p_sl[:, 1].round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting 2 layers\n",
      "Processing layer-1             done | 00:00:12\n",
      "Processing layer-2             done | 00:00:01\n",
      "Predict complete                    | 00:00:14\n",
      "\n",
      "Super Learner ROC-AUC score: 0.714\n",
      "\n",
      "Super Learner Accuracy score: 0.621\n"
     ]
    }
   ],
   "source": [
    "p_sl1 = sl.predict_proba(X_test21)\n",
    "print(\"\\nSuper Learner ROC-AUC score: %.3f\" % roc_auc_score(y_test21, p_sl1[:, 1]))\n",
    "print(\"\\nSuper Learner Accuracy score: %.3f\" % accuracy_score(y_test21, p_sl1[:, 1].round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
